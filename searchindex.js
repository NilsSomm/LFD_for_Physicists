Search.setIndex({"alltitles": {"": [[0, "exercise:ppd_definition_b"], [16, "exercise:ppd_definition"], [16, "exercise:pdf_normalization"], [16, "exercise:rain"], [16, "exercise:monty_hall"], [16, "exercise:coin_ppd"], [35, "exercise:ols_example_1_b"], [35, "exercise:ols_example_2_b"], [35, "exercise:ols_example_3_b"], [35, "exercise:ols_example_4_b"], [35, "exercise:ols_example_5_b"], [49, "id1"], [102, "exercise:ols_example_1"], [102, "exercise:ols_example_2"], [102, "exercise:ols_example_3"], [103, "exercise:ols_example_4"], [103, "exercise:ols_example_5"], [162, "exercise:StochasticProcess:first-example"], [162, "exercise:conditional-probabilities-stochastic-process"], [162, "exercise:construct-stochastic-process"]], " (A reversible Markov chain)": [[157, "exercise:MarkovChains:reversible-chain"]], " (A reversible Markov process)": [[157, "example:reversible-markov-process"]], " (A simple Markov process)": [[157, "example:simple-markov-process"]], " (An exponential growth model)": [[162, "example:exponential-growth-models"]], " (Bayes\u2019 rule/theorem)": [[26, "property:bayes_rule"]], " (Binary classification)": [[66, "example:MLexamples:binary-classification"]], " (Bivariate pdf)": [[131, "exercise:Statistics:bivariate-pdf"]], " (Checklist for statistically sound Bayesian inference)": [[0, "remark:BayesianWorkflow:buqeye-checklist_b"], [44, "remark:BayesianWorkflow:buqeye-checklist"]], " (Conditional discrete probability mass function)": [[131, "exercise:Statistics:conditional-discrete-pmf"]], " (Conditional distributions)": [[157, "exercise:MarkovChains:conditional-distributions"]], " (Conditional expectation)": [[131, "exercise:Statistics:conditional-expectation"]], " (Conditional probabilities of a stochastic process)": [[162, "example:conditional-stochastic-process"]], " (Conditional probability for continuous variables)": [[131, "exercise:Statistics:conditional-probability-continuous"]], " (Conditional probability)": [[131, "definition:conditional-probability"]], " (Conditional probability-distribution)": [[131, "definition:conditional-probability-distribution"]], " (Correlated errors)": [[17, "exercise:BayesianAdvantage:correlated-errors"]], " (Covariance and correlation)": [[131, "definition:covariance-correlation"]], " (Detailed balance)": [[157, "exercise:detailed-balance"]], " (Eigenvector continuation in ab initio nuclear theory)": [[46, "example-0"]], " (Expectation value)": [[131, "definition:expectation-value"]], " (Expected signal)": [[68, "exercise:NeuralNet:expected-signal"]], " (Flip-flop)": [[157, "exercise:flip-flop"]], " (Gaussian process)": [[162, "definition:gaussian-process"]], " (Gaussian product of errors)": [[17, "exercise:BayesianAdvantages:gaussian-product-of-errors"]], " (Gaussian sum of errors)": [[17, "exercise:BayesianAdvantages:gaussian-sum-of-errors"]], " (Generalized normal equation)": [[35, "exercise:BayesianLinearRegression:GeneralizedNormalEquation"]], " (Global minimization)": [[105, "definition:MathematicalOptimization:global-minimization"]], " (Gothenburg winter weather)": [[157, "exercise:MarkovChains:gothenburg-winter-weather"]], " (Gradient descent optimization)": [[106, "algorithm:MathematicalOptimization:gradient-descent"]], " (Illustration of S/IR)": [[45, "example-3"]], " (Implement k-fold cross validation)": [[67, "exercise:ModelValidation:kfold-cross-validation"]], " (Independence)": [[131, "property:independence"]], " (Independent and dependent)": [[115, "exercise:OverviewModeling:independent-dependent"]], " (Independent events)": [[131, "definition:independent-events"]], " (Inferring galactic distances)": [[17, "example:BayesianAdvantage:inferring-galactic-distances"], [17, "exercise:BayesianAdvantages:inferring-galactic-distances-ex"]], " (Inferring galactic distances\u2014revisited)": [[17, "example:BayesianAdvantage:inferring-galactic-distances-revisited"]], " (Is it reversible?)": [[157, "exercise:is-it-reversible"]], " (Joint probability distribution)": [[131, "definition:joint-probability-distribution"]], " (Large training error)": [[67, "exercise:ModelValidation:large-training-error"]], " (Limiting distribution)": [[157, "definition:limiting-distribution"], [157, "exercise:limiting-distribution"]], " (Linear models)": [[113, "example:OverviewModeling:linear-models"]], " (Linear or non-linear)": [[115, "exercise:OverviewModeling:linear-nonlinear"]], " (Linear or non-linear; more examples)": [[115, "exercise:OverviewModeling:linear-nonlinear-examples"]], " (Linear signals)": [[68, "exercise:NeuralNet:linear-signal"]], " (Liquid-drop model for nuclear binding energies)": [[35, "example:LinearModels:liquid-drop-model_b"], [100, "example:LinearModels:liquid-drop-model"]], " (Local minimization)": [[105, "definition:MathematicalOptimization:local-minimization"]], " (Marginal density functions)": [[131, "property:marginal-density-functions"]], " (Markov chains)": [[157, "definition:markov-chains"]], " (Metropolis sampling of a uniform distribution)": [[154, "exercise:metropolis-sampling-uniform"]], " (Misclassification cost function)": [[66, "exercise:MLexamples:misclassification-cost-function"]], " (Model discrepancy)": [[115, "exercise:OverviewModeling:model-discrepancy"]], " (Monte Carlo estimation of \\pi)": [[154, "example-0"]], " (Non-linear models)": [[113, "example:OverviewModeling:nonlinear-models"]], " (Optical pumping)": [[157, "exercise:optical-pumping"]], " (Ordinary least squares (the normal equation))": [[35, "theorem:BayesianLinearRegression:normal-equation_b"], [101, "theorem:LinearModels:normal-equation"]], " (Polynomial basis functions)": [[35, "example:polynomial-linear-model_b"], [100, "example:polynomial-linear-model"]], " (Power-law distributions)": [[154, "exercise:power-law-distribution-sampling"]], " (Practicing the sum and product rule with population characteristics)": [[23, "exercise:Inferenceandpdfs:sumandproductrule"]], " (Prior and posterior predictive checking)": [[44, "remark:BayesianWorkflow:predictive-checking"]], " (Probability density function)": [[131, "definition:probability-density-function"]], " (Probability mass function)": [[131, "definition:probability-mass-function"]], " (Probability measure)": [[131, "definition:probability-measure"]], " (Product rule)": [[26, "property:product_rule"]], " (Prove the Gaussian likelihood)": [[35, "exercise:BayesianLinearRegression:likelihood_pars_b"]], " (R2 score)": [[66, "exercise:MLexamples:R2-score"]], " (Random and colorblind)": [[131, "exercise:Statistics:colorblind"]], " (Random variable and distribution function)": [[131, "definition:random-variable"]], " (Regression analysis)": [[111, "definition:OverviewModeling:regression-analysis"]], " (Remnant memory)": [[157, "exercise:MarkovChains:memory"]], " (Reversibility)": [[157, "exercise:MarkovChains:reversibility"]], " (Scipy.stats)": [[131, "exercise:Statistics:scipy-stats"]], " (Sigmoid decision boundary)": [[66, "exercise:MLexamples:sigmoid-decision-boundary"]], " (Simple random walk)": [[157, "exercise:MarkovChains:simple-random-walk"], [162, "example:simple-random-walk"]], " (Stationary Gothenburg winter weather)": [[157, "exercise:stationary-gothenburg-winter-weather"]], " (Stationary distribution of \u201cA simple Markov process\u201d)": [[157, "example:stationary-simple-markov-process"]], " (Stationary distribution)": [[157, "definition:stationary-distribution"], [157, "exercise:MarkovChains:stationary-distribution"]], " (Stationary processes)": [[157, "definition:stationary-processes"]], " (Stationary two-state distribution)": [[157, "exercise:stationary-2x2"]], " (Statistical inference)": [[111, "definition:OverviewModeling:statistical-inference"]], " (Stochastic matrix)": [[157, "exercise:MarkovChains:stochastic-matrix"]], " (Study of model bias and variance)": [[67, "exercise:ModelValidation:study-model-bias-variance"]], " (Sum of two Gaussian  PDFs)": [[17, "exercise:BayesianAdvantage:complete-the square"]], " (Sum rule)": [[26, "property:sum_rule"]], " (Taking the square root of a number)": [[17, "example:BayesianAdvantage:taking-square-root"]], " (The Gelman-Rubin diagnostic)": [[45, "algorithm:AdvancedMCMC:gelman-rubin"]], " (The Hamiltonian Monte Carlo method)": [[45, "algorithm:AdvancedMCMC:HMC"]], " (The Metropolis algorithm for a discrete distribution)": [[154, "exercise:MCMC:discrete-metropolis"]], " (The Metropolis design for obtaining a discrete limiting distribution)": [[157, "remark:MCMC:Metropolis-discrete"]], " (The Metropolis-Hastings algorithm)": [[154, "algorithm-1"]], " (The Sampling/Importance Resampling method)": [[45, "algorithm:AdvancedMCMC:SIR"]], " (The WAMBS checklist)": [[44, "remark:BayesianWorkflow:wambs-checklist"]], " (The bias-variance tradeoff)": [[67, "theorem:ModelValidation:bias-variance"]], " (The design matrix for polynomial models)": [[35, "example:design-matrix-polynomial-models_b"], [101, "example:design-matrix-polynomial-models"]], " (The history-matching algorithm)": [[47, "algorithm:BayesLinear:History-Matching"]], " (The square root of a number)": [[17, "exercise:BayesianAdvantages:square-root-of-a-number"]], " (The standard random variable)": [[17, "exercise:BayesianAdvantages:standard-random-variable"]], " (Using Bayesian rules of probability on a standard medical problem)": [[23, "exercise:Inferenceandpdfs:medicalexample"]], " (Validation errors)": [[66, "exercise:MLexamples:validation-errors"]], " (Variance)": [[131, "definition:variance"]], " (Warm-up Bayesian linear regression (data errors))": [[35, "exercise:BayesianLinearRegression:warmup_errors"]], " (Warm-up Bayesian linear regression (prior sensitivity))": [[35, "exercise:BayesianLinearRegression:warmup_priors"]], " (Warm-up Bayesian linear regression)": [[35, "exercise:BayesianLinearRegression:warmup"]], " (Weights and signal propagation of a simple neural network)": [[68, "exercise:NeuralNet:simple-network"]], " (Weights and signal propagation of a wide neural network)": [[68, "exercise:NeuralNet:wide-network"]], " (Z = X + Y)": [[17, "example:BayesianAdvantage:Z=X+Y"]], " (k-fold cross-validation)": [[67, "algorithm:ModelValidation:cross-validation"]], " (k=1 NN training error)": [[67, "exercise:ModelValidation:kNN-training-error"]], " (kNN for regression)": [[66, "exercise:MLexamples:kNN-regression"]], " (kNN model complexity)": [[67, "exercise:ModelValidation:kNN-model-complexity"]], " (\u201cIn practice\u201d Bayesian linear regression)": [[35, "exercise:BayesianLinearRegression:in_practice"]], "(Pseudo) random number generator": [[131, "pseudo-random-number-generator"]], "*Aside: Bayesian epistemology": [[8, null]], "*Convolutional Neural Networks": [[76, null]], "*Marking a section in a different color": [[0, "marking-a-section-in-a-different-color"]], "*Neural networks: Backpropagation": [[69, null]], "1 Getting started: The Covariance Function": [[78, "getting-started-the-covariance-function"]], "1. A univariate example with GPyOpt": [[93, "a-univariate-example-with-gpyopt"]], "1. Import ipywidgets and Ipython.display": [[133, "import-ipywidgets-and-ipython-display"], [133, "id1"], [133, "id7"]], "1. n_samples = 1000, noise = 0.2, test_size = 0.5, iterations n = 30000": [[94, "n-samples-1000-noise-0-2-test-size-0-5-iterations-n-30000"]], "1D vs 2D Array": [[137, "d-vs-2d-array"]], "2 Sampling from a Gaussian Process": [[78, "sampling-from-a-gaussian-process"]], "2. Build your own BayesOpt algorithm (optional or for your project)": [[93, "build-your-own-bayesopt-algorithm-optional-or-for-your-project"]], "2. Create a function with all inputs that makes the output figure(s).": [[133, "create-a-function-with-all-inputs-that-makes-the-output-figure-s"], [133, "id8"]], "2. Create a function with all inputs to generate the output figure(s).": [[133, "create-a-function-with-all-inputs-to-generate-the-output-figure-s"]], "2. n_samples = 1000, noise = 0.2, test_size = 0.5, iterations n = 60000": [[94, "n-samples-1000-noise-0-2-test-size-0-5-iterations-n-60000"]], "3 A Gaussian Process Regression Model": [[78, "a-gaussian-process-regression-model"]], "3. Make a widget for each value you want to control.": [[133, "make-a-widget-for-each-value-you-want-to-control"], [133, "id2"], [133, "id9"]], "3. Test on bivariate example (Do this for a plus)": [[93, "test-on-bivariate-example-do-this-for-a-plus"]], "3. n_samples = 1000, noise = 0.05, test_size = 0.5, iterations n = 60000": [[94, "n-samples-1000-noise-0-05-test-size-0-5-iterations-n-60000"]], "3D volumes of neurons": [[76, "d-volumes-of-neurons"]], "4 A Running Example": [[78, "a-running-example"]], "4.  Make any explicit callback functions and add .observe methods.": [[133, "make-any-explicit-callback-functions-and-add-observe-methods"], [133, "id3"], [133, "id10"]], "4. Multivariate test examples (optional)": [[93, "multivariate-test-examples-optional"]], "4. n_samples = 1000, noise = 0.5, test_size = 0.5, iterations n = 60000": [[94, "n-samples-1000-noise-0-5-test-size-0-5-iterations-n-60000"]], "5. Set up the interactive_output function.": [[133, "set-up-the-interactive-output-function"], [133, "id4"], [133, "id11"]], "5. n_samples = 100, noise = 0.2, test_size = 0.5, iterations n = 60000": [[94, "n-samples-100-noise-0-2-test-size-0-5-iterations-n-60000"]], "6. Make the layout of the widgets.": [[133, "make-the-layout-of-the-widgets"], [133, "id5"], [133, "id12"]], "7. Release the Kraken!": [[133, "release-the-kraken"], [133, "id6"], [133, "id13"]], "<a name=\"Python\">Python/Jupyter set up</a>": [[6, "python-jupyter-set-up"]], "A Gaussian Process Regression Model": [[84, "a-gaussian-process-regression-model"]], "A binary classifier with two parameters": [[89, "a-binary-classifier-with-two-parameters"]], "A first summary": [[134, "a-first-summary"]], "A learning algorithm": [[89, "a-learning-algorithm"]], "A more compact expression": [[89, "a-more-compact-expression"]], "A new target prediction using a GP": [[86, null]], "A simple classification problem": [[71, "a-simple-classification-problem"], [75, "a-simple-classification-problem"]], "A spectral line problem": [[97, "a-spectral-line-problem"]], "A tale of two models: contrasting BMA with BMM}": [[49, "a-tale-of-two-models-contrasting-bma-with-bmm"]], "ANNs in the large-width limit": [[118, null]], "About this Jupyter Book": [[57, null]], "Acceptance Rate for the MH Algorithm": [[144, "acceptance-rate-for-the-mh-algorithm"]], "Acceptance rate": [[152, "acceptance-rate"]], "Acknowledgements": [[74, "acknowledgements"]], "Acknowledgments": [[57, "acknowledgments"]], "Activation outputs": [[69, null]], "Activation rule": [[68, null]], "Activation rules": [[68, "activation-rules"]], "Adagrad": [[108, "adagrad"]], "Adam": [[108, "adam"]], "Adaptive gradient descent algorithms": [[108, null]], "Add Dense layers on top": [[77, "add-dense-layers-on-top"]], "Addendum: Ordinary linear regression in practice": [[35, "addendum-ordinary-linear-regression-in-practice"]], "Adding n variables drawn from a distribution": [[34, "adding-n-variables-drawn-from-a-distribution"]], "Adding/removing elements": [[137, "adding-removing-elements"]], "Admonitions": [[0, "admonitions"]], "Advanced Markov Chain Monte Carlo": [[142, null]], "Advanced Markov chain Monte Carlo sampling": [[45, null]], "Advanced feature: Widgets for graphical exploration": [[135, "advanced-feature-widgets-for-graphical-exploration"]], "Advantages of the Bayesian approach": [[7, null]], "Aleatoric uncertainties": [[73, null]], "Algorithm pseudo-code:": [[155, null]], "Anaconda and github": [[138, "anaconda-and-github"]], "Anaconda environments": [[138, "anaconda-environments"]], "Analysis": [[143, "analysis"]], "Analyze sampling results": [[152, "analyze-sampling-results"]], "Another standard class of pdf:  Student t": [[18, "another-standard-class-of-pdf-student-t"]], "Answer": [[0, null], [3, null], [11, null], [12, null], [12, null], [12, null], [15, null], [16, null], [19, null], [19, null], [19, null], [19, null], [19, null], [20, null], [20, null], [24, null], [24, null], [24, null], [25, null], [25, null], [32, null], [32, null], [32, null], [32, null], [32, null], [32, null], [32, null], [32, null], [32, null], [32, null], [32, null], [33, null], [33, null], [33, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [37, null], [37, null], [48, null], [48, null]], "Answer (a)": [[33, null], [33, null]], "Answer (b)": [[33, null], [33, null]], "Answer (c)": [[33, null]], "Answer all the questions": [[32, "answer-all-the-questions"], [33, "answer-all-the-questions"]], "Answer these questions": [[96, "answer-these-questions"]], "Answers": [[37, null], [101, null]], "Application 1: GP emulator from Higdon et al. paper": [[80, "application-1-gp-emulator-from-higdon-et-al-paper"]], "Application of Information Criteria and Bayes factors": [[52, "application-of-information-criteria-and-bayes-factors"]], "Applications of SVD": [[126, "applications-of-svd"]], "Applying the Bayesian approach": [[148, "applying-the-bayesian-approach"], [153, "applying-the-bayesian-approach"]], "Architecture": [[68, null]], "Array Manipulation Routines": [[137, "array-manipulation-routines"]], "Array shape manipulations": [[137, "array-shape-manipulations"]], "Array to/from List conversion": [[137, "array-to-from-list-conversion"]], "Arrays vs Lists": [[137, "arrays-vs-lists"]], "Artifical neural networks": [[68, null]], "Artificial neurons": [[68, "artificial-neurons"]], "Aside: List comprehensions": [[136, "aside-list-comprehensions"]], "Aside: dissection of the Python statement to find the index for accumulation": [[128, "aside-dissection-of-the-python-statement-to-find-the-index-for-accumulation"]], "Aside: how do we make draws from a multivariate     Gaussian (normal) distribution if we know how to make draws from     \\mathcal{N}(0,1)?": [[87, null]], "Aspirational virtues for Bayesian inference and beyond": [[62, null]], "Assigning probabilities": [[2, null]], "Assigning probabilities (I): Indifferences and translation groups": [[3, null]], "Assigning probabilities (II): The principle of maximum entropy": [[4, null]], "Assignment: 2D radioactive lighthouse location using MCMC": [[143, null]], "Autocorrelation": [[45, "autocorrelation"], [160, "autocorrelation"]], "Autocorrelation Plots": [[144, "autocorrelation-plots"]], "Autocorrelation plots": [[152, "autocorrelation-plots"]], "Automation bias": [[64, null]], "Available samplers": [[152, "available-samplers"]], "Average, Variance, and Standard Deviation": [[137, "average-variance-and-standard-deviation"]], "Axioms of probability theory": [[26, "axioms-of-probability-theory"]], "BDA3: Gelman et al, Fig. 11.1": [[144, "bda3-gelman-et-al-fig-11-1"]], "Background info on GPs": [[87, "background-info-on-gps"]], "Background on linear models": [[35, "background-on-linear-models"]], "Basic Mathematical Operations": [[72, "basic-mathematical-operations"]], "Basic idea": [[54, "basic-idea"]], "Basic neural network": [[73, "basic-neural-network"]], "Basic setup of a model": [[152, "basic-setup-of-a-model"]], "Basic structure of MCMC algorithm": [[155, "basic-structure-of-mcmc-algorithm"]], "Basics and notation": [[89, "basics-and-notation"]], "Batch, stochastic and mini-batch gradient descent": [[107, null]], "Bayes by Backprop": [[73, "bayes-by-backprop"]], "Bayes goes fast: Emulators": [[46, null]], "Bayes goes linear: History matching": [[47, null]], "Bayes in practice": [[29, null]], "Bayes linear methods": [[47, "bayes-linear-methods"]], "Bayes linear statistics": [[47, null]], "Bayesian Approach to Outliers #1: A conservative formulation": [[39, "bayesian-approach-to-outliers-1-a-conservative-formulation"]], "Bayesian Approach to Outliers #2: Good-and-bad data": [[39, "bayesian-approach-to-outliers-2-good-and-bad-data"]], "Bayesian Approach to Outliers #3: The Cauchy formulation": [[39, "bayesian-approach-to-outliers-3-the-cauchy-formulation"]], "Bayesian Approach to Outliers #4: Many nuisance parameters": [[39, "bayesian-approach-to-outliers-4-many-nuisance-parameters"]], "Bayesian Linear Regression (BLR)": [[35, null]], "Bayesian Neural Networks in PyMC3": [[74, "bayesian-neural-networks-in-pymc3"]], "Bayesian approach to Gaussian parameter estimation": [[40, "bayesian-approach-to-gaussian-parameter-estimation"], [148, "bayesian-approach-to-gaussian-parameter-estimation"], [153, "bayesian-approach-to-gaussian-parameter-estimation"]], "Bayesian approach to model discrepancy": [[119, null]], "Bayesian approaches to erratic data": [[39, "bayesian-approaches-to-erratic-data"]], "Bayesian credible intervals and frequentist confidence intervals": [[20, "bayesian-credible-intervals-and-frequentist-confidence-intervals"]], "Bayesian evidence": [[96, "id1"]], "Bayesian evidence:": [[96, "bayesian-evidence"]], "Bayesian handling of nuisance parameters": [[42, "bayesian-handling-of-nuisance-parameters"]], "Bayesian inference for multiple models": [[49, "bayesian-inference-for-multiple-models"]], "Bayesian inference in the multi-model setting": [[49, "bayesian-inference-in-the-multi-model-setting"]], "Bayesian linear regression: warmup": [[35, "bayesian-linear-regression-warmup"]], "Bayesian methods for scientific modeling": [[28, null]], "Bayesian model averaging and the \\mathcal{M}-closed assumption": [[49, "bayesian-model-averaging-and-the-mathcal-m-closed-assumption"]], "Bayesian model selection": [[54, "bayesian-model-selection"]], "Bayesian neural networks": [[73, null]], "Bayesian neural networks in PyMC3": [[73, "bayesian-neural-networks-in-pymc3"]], "Bayesian neural networks in practice": [[73, "bayesian-neural-networks-in-practice"]], "Bayesian parameter estimation": [[16, "bayesian-parameter-estimation"]], "Bayesian posteriors": [[27, null]], "Bayesian probability": [[8, "bayesian-probability"]], "Bayesian research workflow": [[44, null]], "Bayesian updating": [[9, "bayesian-updating"], [31, "bayesian-updating"]], "Bayesian workflow": [[60, null]], "Bayes\u2019 theorem": [[23, "bayes-theorem"], [26, "bayes-theorem"]], "Bayes\u2019 theorem applied to PDFs": [[24, "bayes-theorem-applied-to-pdfs"]], "Behavior of the mean of a fixed-size sample": [[34, "behavior-of-the-mean-of-a-fixed-size-sample"]], "Benchmark case: questions": [[5, "benchmark-case-questions"]], "Bibliography": [[1, null]], "Bibliography references": [[0, "bibliography-references"]], "Binary classification": [[89, "binary-classification"]], "Bonus:  Do this section for a plus": [[96, "bonus-do-this-section-for-a-plus"]], "Bonus: additional subtasks": [[95, "bonus-additional-subtasks"]], "Breakout questions": [[42, "breakout-questions"]], "Bridging Deep Learning and Probabilistic Programming": [[74, "bridging-deep-learning-and-probabilistic-programming"]], "Brief guide to online Jupyter Book features": [[57, "brief-guide-to-online-jupyter-book-features"]], "Brief introduction to GPs from Melendez et al.": [[87, "brief-introduction-to-gps-from-melendez-et-al"]], "Brief review of the method": [[45, "brief-review-of-the-method"]], "Brief summary of expectation values and moments": [[25, null]], "Bringing it together, first back propagation equation": [[69, "bringing-it-together-first-back-propagation-equation"]], "Build the network": [[70, "build-the-network"]], "But what about the prior?": [[40, "but-what-about-the-prior"], [148, "but-what-about-the-prior"], [153, "but-what-about-the-prior"]], "CNNs in brief": [[76, "cnns-in-brief"]], "Calculating the evidence": [[52, "calculating-the-evidence"]], "Case 1: Fixed H_0": [[42, "case-1-fixed-h-0"]], "Case 2: Using the inferred pdf for H_0": [[42, "case-2-using-the-inferred-pdf-for-h-0"]], "Case I: uniform (flat) prior": [[13, "case-i-uniform-flat-prior"]], "Case II: conjugate prior": [[13, "case-ii-conjugate-prior"]], "Central moments: Variance and Covariance": [[131, "central-moments-variance-and-covariance"]], "Challenges for gradient descent": [[106, null]], "Challenges in MCMC sampling": [[154, "challenges-in-mcmc-sampling"]], "Changing to the 2025-book-env env kernel when running a Jupyter notebook": [[138, "changing-to-the-2025-book-env-env-kernel-when-running-a-jupyter-notebook"]], "Characteristics of PDFs": [[19, null]], "ChatGPT prompts for original code": [[130, "chatgpt-prompts-for-original-code"]], "Check for between chain variations": [[51, "check-for-between-chain-variations"]], "Check that with the delta functions we get the rule for \\langle f\\rangle.": [[155, null]], "Check the N\\rightarrow \\infty limit": [[53, null]], "Checklists": [[44, "checklists"]], "Checkpoint Question": [[20, null]], "Checkpoint question": [[0, null], [0, null], [3, null], [15, null], [16, null], [20, null], [23, null], [24, null], [24, null], [24, null], [25, null], [25, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [48, null], [48, null], [101, null]], "Checkpoint questions": [[0, "checkpoint-questions"]], "Choosing the GP model hyperparameters": [[86, "choosing-the-gp-model-hyperparameters"]], "Class exercises": [[11, null]], "Class probabilities: The Softmax function": [[89, "class-probabilities-the-softmax-function"]], "Class: state the rule used to justify each step": [[20, null]], "Classification algorithms": [[65, null]], "Clustering algorithms": [[65, null]], "Code": [[130, "code"]], "Code and Markdown cells": [[135, "code-and-markdown-cells"]], "Code example": [[131, "code-example"]], "Code examples: binary classifiers": [[66, "code-examples-binary-classifiers"]], "Coin tossing: Frequentists and Bayesaians": [[11, null]], "Combining Covariance Functions": [[78, "combining-covariance-functions"], [84, "combining-covariance-functions"]], "Combining Covariance Functions in GPy": [[78, "combining-covariance-functions-in-gpy"], [84, "combining-covariance-functions-in-gpy"]], "Comments and suggestions": [[95, "comments-and-suggestions"]], "Common Initialization Methods": [[72, "common-initialization-methods"]], "Common set up and generating data for all samplers": [[153, "common-set-up-and-generating-data-for-all-samplers"]], "Compare Gaussian noise sampling to lighthouse calculation": [[37, "compare-gaussian-noise-sampling-to-lighthouse-calculation"]], "Compare a sum of D Poisson draws with mean 1 to a single Poisson distribution with mean D": [[34, "compare-a-sum-of-d-poisson-draws-with-mean-1-to-a-single-poisson-distribution-with-mean-d"]], "Comparing samplers for a simple problem": [[153, null]], "Comparison with parameter estimation": [[54, "comparison-with-parameter-estimation"]], "Compile and train the model": [[77, "compile-and-train-the-model"]], "Complex Expressions": [[72, "complex-expressions"]], "Computational possibilities for evidence": [[52, "computational-possibilities-for-evidence"]], "Computing the Bayesian evidence": [[52, null]], "Computing the Covariance Function given the Input Data, \\mathbf{X}": [[78, "computing-the-covariance-function-given-the-input-data-mathbf-x"], [84, "computing-the-covariance-function-given-the-input-data-mathbf-x"]], "Computing the posterior analytically": [[13, null]], "Concatenate arrays": [[137, "concatenate-arrays"]], "Confidence intervals": [[19, null]], "Consequences:": [[20, "consequences"]], "Continuing \u2026": [[35, "continuing"]], "Continuous case": [[4, "continuous-case"]], "Contrast Bayesian and significance analyses for coin flipping": [[20, "contrast-bayesian-and-significance-analyses-for-coin-flipping"]], "Convergence tests for MCMC sampling": [[45, "convergence-tests-for-mcmc-sampling"]], "Converting linear models to matrix form": [[35, "converting-linear-models-to-matrix-form"]], "Convolutional Neural Network": [[68, "convolutional-neural-network"]], "Convolutional Neural Network (CNN)": [[77, "convolutional-neural-network-cnn"]], "Correlated posteriors": [[37, "correlated-posteriors"]], "Correlations": [[54, "correlations"]], "Covariance Function Parameter Estimation": [[78, "covariance-function-parameter-estimation"], [84, "covariance-function-parameter-estimation"]], "Covariance Functions in GPy": [[78, "covariance-functions-in-gpy"], [84, "covariance-functions-in-gpy"]], "Covariance functions, aka kernels": [[79, "covariance-functions-aka-kernels"], [83, "covariance-functions-aka-kernels"]], "Covariance, PCA and SVD": [[128, "covariance-pca-and-svd"]], "Create Arrays": [[137, "create-arrays"]], "Create special ndarray": [[137, "create-special-ndarray"]], "Create the convolutional base": [[77, "create-the-convolutional-base"]], "Creating a Sparse Matrix": [[137, "creating-a-sparse-matrix"]], "Creating a conda environment": [[138, "creating-a-conda-environment"]], "Creating a list, range, numpy array": [[136, "creating-a-list-range-numpy-array"]], "Credible regions": [[131, "credible-regions"]], "Cross validation": [[96, "cross-validation"]], "Cross-validation": [[67, "cross-validation"]], "Current trends in Machine Learning": [[74, "current-trends-in-machine-learning"]], "Customizing Initialization in PyTorch": [[72, "customizing-initialization-in-pytorch"]], "Data bias and fairness in machine learning": [[64, null]], "Data bias types in machine learning, including examples": [[64, "data-bias-types-in-machine-learning-including-examples"]], "Data handling, machine learning  and ethical aspects": [[65, "data-handling-machine-learning-and-ethical-aspects"]], "Data normalization": [[66, null], [66, "data-normalization"]], "Data reduction": [[128, "data-reduction"]], "Data sets from scikit-learn": [[75, "data-sets-from-scikit-learn"]], "Data, models, and predictions": [[16, null]], "Dataset and Gaussian process generation": [[82, "dataset-and-gaussian-process-generation"]], "Dataset generation": [[81, "dataset-generation"]], "Debugging aside \u2026": [[135, "debugging-aside"], [135, "id1"]], "Deep Learning": [[74, "deep-learning"]], "Define and plot the posterior for x_0": [[43, "define-and-plot-the-posterior-for-x-0"]], "Define model discrepancy class": [[124, "define-model-discrepancy-class"]], "Define physics model": [[124, "define-physics-model"]], "Define priors": [[124, "define-priors"]], "Define the functions we will need": [[5, "define-the-functions-we-will-need"]], "Definition and examples": [[35, "definition-and-examples"]], "Definition of a stochastic process": [[162, "definition-of-a-stochastic-process"]], "Definition of linear models": [[100, null]], "Definitions": [[69, "definitions"]], "Degree of belief intervals": [[9, "degree-of-belief-intervals"], [31, "degree-of-belief-intervals"]], "Degree of belief/credibility intervals vs frequentist 1-sigma intervals": [[14, null]], "Demo: Multimodal distributions with two samplers": [[51, null]], "Demolition derbies, cows, and crocodiles": [[63, "demolition-derbies-cows-and-crocodiles"]], "Demonstration: Gaussian processes": [[83, null]], "Demonstration: Image recognition with Convolutional Neural Networks": [[77, null]], "Demonstration: Metropolis-Hasting MCMC sampling of a Poisson distribution": [[163, null]], "Demonstration: Neural network classifier": [[70, null]], "Demonstration: Variational Inference and Bayesian Neural Networks": [[74, null]], "Derivation of common pdfs using MaxEnt": [[4, "derivation-of-common-pdfs-using-maxent"]], "Derivative of the cost function": [[69, "derivative-of-the-cost-function"]], "Derivatives and the chain rule": [[69, "derivatives-and-the-chain-rule"]], "Derivatives in terms of z_j^L": [[69, "derivatives-in-terms-of-z-j-l"]], "Deriving the back propagation code for a multilayer perceptron model": [[69, "deriving-the-back-propagation-code-for-a-multilayer-perceptron-model"]], "Detailed Explanation of Each Step:": [[72, "detailed-explanation-of-each-step"]], "Determinant": [[137, "determinant"]], "Determination of weights": [[89, "determination-of-weights"]], "Determining the bias of a coin": [[31, "determining-the-bias-of-a-coin"]], "Determining the likelihood function": [[44, "determining-the-likelihood-function"]], "Developing a code for doing neural networks with back propagation": [[70, "developing-a-code-for-doing-neural-networks-with-back-propagation"]], "Diagnostics": [[152, "diagnostics"]], "Diagonalization of symmetric matrix": [[126, "diagonalization-of-symmetric-matrix"]], "Dimensionality reduction algorithms": [[65, null]], "Dirac delta functions": [[17, null]], "Discrete or continuous optimization": [[105, null]], "Discrete permutation invariance": [[3, "discrete-permutation-invariance"]], "Discuss": [[8, null], [35, null], [54, null], [131, null], [131, null], [131, null], [162, null]], "Discussion": [[39, "discussion"], [148, "discussion"], [153, "discussion"]], "Doing Fourier transforms by numerical integration (rather than FFT)": [[34, "doing-fourier-transforms-by-numerical-integration-rather-than-fft"]], "Dot product versus elementwise multiplication": [[137, "dot-product-versus-elementwise-multiplication"]], "Dot-product kernel": [[82, "dot-product-kernel"]], "Download and prepare the CIFAR10 dataset": [[77, "download-and-prepare-the-cifar10-dataset"]], "Edwin Jaynes and plausible reasoning": [[63, null]], "Eigendecomposition of the covariance matrix": [[128, "eigendecomposition-of-the-covariance-matrix"]], "Eigenvalues and eigenvectors": [[137, "eigenvalues-and-eigenvectors"]], "Eigenvector continuation": [[46, "eigenvector-continuation"]], "Elegant linear algebra tricks to obtain \\boldsymbol{C}_{N+1}^{-1}": [[86, "elegant-linear-algebra-tricks-to-obtain-boldsymbol-c-n-1-1"]], "Emulators": [[48, null], [123, null]], "Epistemic uncertainties": [[73, null]], "Equation references": [[0, "equation-references"]], "Error propagation": [[17, null]], "Error propagation (I): Nuisance parameters and marginalization": [[17, "error-propagation-i-nuisance-parameters-and-marginalization"]], "Error propagation (II): Changing variables": [[17, "error-propagation-ii-changing-variables"]], "Error propagation (III): A useful approximation": [[17, "error-propagation-iii-a-useful-approximation"]], "Ethical principles": [[64, null]], "Ethics guidelines": [[64, "ethics-guidelines"]], "Evaluate the model": [[77, "evaluate-the-model"]], "Evidence Lower Bound": [[73, "evidence-lower-bound"]], "Evidence calculation": [[50, "evidence-calculation"]], "Evidence calculation for EFT expansions": [[50, null]], "Evidence calculations": [[54, "evidence-calculations"]], "Evidence for an expansion": [[53, null]], "Evidence using conjugate prior": [[50, "evidence-using-conjugate-prior"]], "Evidence using linear algebra and Gaussian integrals": [[50, "evidence-using-linear-algebra-and-gaussian-integrals"]], "Evidence with linear algebra": [[53, "evidence-with-linear-algebra"]], "Example of a Complex Expression": [[72, "example-of-a-complex-expression"]], "Example of parallel tempering": [[52, "example-of-parallel-tempering"]], "Example with noise-free target": [[81, "example-with-noise-free-target"]], "Example with noisy targets": [[81, "example-with-noisy-targets"]], "Example: CNN architecture": [[76, "example-cnn-architecture"]], "Example: GP models for regression": [[79, "example-gp-models-for-regression"], [83, "example-gp-models-for-regression"]], "Example: Is this a fair coin?": [[26, "example-is-this-a-fair-coin"]], "Example: Random walk": [[162, "example-random-walk"]], "Example: Straight-line model": [[3, "example-straight-line-model"]], "Example: The Compas algorithm": [[64, "example-the-compas-algorithm"]], "Example: The MNIST dataset": [[76, "example-the-mnist-dataset"]], "Example: good data / bad data": [[39, "example-good-data-bad-data"]], "Examples": [[155, null]], "Examples from Rob Hicks": [[152, "examples-from-rob-hicks"]], "Examples of classifier functions used in logistic regression and neural networks": [[71, "examples-of-classifier-functions-used-in-logistic-regression-and-neural-networks"]], "Examples of information criteria": [[52, "examples-of-information-criteria"]], "Exercise": [[20, null], [20, null], [71, "exercise"]], "Exercise 1": [[78, "exercise-1"], [84, "exercise-1"]], "Exercise 2": [[78, "exercise-2"], [84, "exercise-2"]], "Exercise 3": [[78, "exercise-3"], [84, "exercise-3"]], "Exercise 4": [[78, "exercise-4"], [84, "exercise-4"]], "Exercise 5": [[78, "exercise-5"]], "Exercise: Bayesian neural networks": [[75, null]], "Exercise: Checking the sum and product rules": [[33, null]], "Exercise: Create a neural net binary classifier": [[71, "exercise-create-a-neural-net-binary-classifier"]], "Exercise: Develop your own logistic regression binary classifier": [[71, "exercise-develop-your-own-logistic-regression-binary-classifier"]], "Exercise: Gaussian Process models with GPy": [[78, null]], "Exercise: Gaussian processes using GPy": [[84, null]], "Exercise: Logistic Regression and neural networks": [[71, null]], "Exercise: Random walk": [[145, null]], "Exercise: Standard medical example using Bayes": [[32, null]], "Exercises": [[16, "exercises"], [41, "exercises"], [66, "exercises"], [67, "exercises"], [68, "exercises"], [115, null], [131, "exercises"], [154, "exercises"], [157, "exercises"]], "Exercises and solutions": [[0, "exercises-and-solutions"]], "Exercises for Part I": [[36, null]], "Exercises: covariance matrix manipulations in Python (taken from the Duke course)": [[128, "exercises-covariance-matrix-manipulations-in-python-taken-from-the-duke-course"]], "Exp-Sine-Squared kernel": [[82, "exp-sine-squared-kernel"]], "Expectation values and moments": [[131, "expectation-values-and-moments"]], "Experimentation (of the statistical model)": [[44, "experimentation-of-the-statistical-model"]], "Explorations:  Things to do and Questions to answer": [[96, "explorations-things-to-do-and-questions-to-answer"]], "Explore the data": [[70, "explore-the-data"]], "Explore!": [[37, null]], "Expressions": [[143, "expressions"]], "Extending to more classes": [[89, "extending-to-more-classes"]], "Extending to more features": [[89, "extending-to-more-features"]], "External URL references": [[0, "external-url-references"]], "Fairness and error functions": [[64, "fairness-and-error-functions"]], "Feed-forward neural network for a function in PyTorch": [[72, null]], "Feed-forward neural networks": [[68, "feed-forward-neural-networks"]], "Feedback networks": [[68, "feedback-networks"]], "Figures to analyze!": [[38, "figures-to-analyze"]], "Figures to make every time you run MCMC (following Hogg and Foreman-Mackey sect. 9)": [[147, "figures-to-make-every-time-you-run-mcmc-following-hogg-and-foreman-mackey-sect-9"]], "Fill in the chart based on the Metropolis algorithm we are using and verify that the ratio of p(X_B|X_A) to p(X_A|X_B) agrees with the answer derived above.": [[160, null]], "Final back-propagating equation": [[69, "final-back-propagating-equation"]], "Final outputs": [[69, null]], "Find the Maximum and Minimum Values": [[137, "find-the-maximum-and-minimum-values"]], "First example: each sample is only one point": [[34, "first-example-each-sample-is-only-one-point"]], "First pass: only minimal controls": [[133, "first-pass-only-minimal-controls"]], "First sample with emcee": [[153, "first-sample-with-emcee"]], "First the likelihood": [[13, "first-the-likelihood"]], "Fitting a straight line - revisited": [[144, "fitting-a-straight-line-revisited"]], "Follow-up question on 2.": [[32, null]], "Follow-up question on 5.": [[32, null]], "Follow-up questions and answers to the Exploring PDFs section.": [[19, null]], "Follow-up questions to the medical example": [[32, "follow-up-questions-to-the-medical-example"]], "Follow-up task": [[78, "follow-up-task"]], "Follow-ups": [[38, "follow-ups"]], "Formalizing prior distributions": [[44, "formalizing-prior-distributions"]], "Four-step Bayesian workflow in brief": [[44, null], [60, null]], "Fourth example: each sample is 50 points": [[34, "fourth-example-each-sample-is-50-points"]], "Framework": [[121, null]], "Frequentist Correction for Outliers: Huber Loss": [[39, "frequentist-correction-for-outliers-huber-loss"]], "Frequentist approach to Gaussian parameter estimation": [[148, "frequentist-approach-to-gaussian-parameter-estimation"], [153, "frequentist-approach-to-gaussian-parameter-estimation"]], "Frequentist hypothesis testing": [[54, "frequentist-hypothesis-testing"]], "Frequentist probability": [[8, "frequentist-probability"]], "Frontmatter for markdown files": [[0, "frontmatter-for-markdown-files"]], "Functions": [[135, "functions"]], "Further examples with numpy": [[137, null]], "GP models for regression": [[86, "gp-models-for-regression"]], "GPy demo notebooks": [[85, null]], "Games with Gaussian process websites": [[87, "games-with-gaussian-process-websites"]], "Gaussian Processes regression: basic introductory example": [[81, null]], "Gaussian distribution": [[131, "gaussian-distribution"]], "Gaussian processes": [[86, null]], "Gaussian processes as high-dimensional Gaussian distributions": [[83, "gaussian-processes-as-high-dimensional-gaussian-distributions"]], "Gaussian processes as infinite-dimensional Gaussian distributions": [[79, "gaussian-processes-as-infinite-dimensional-gaussian-distributions"]], "Gaussian processes demonstration": [[79, null]], "Gaussians: A couple of frequentist connections": [[20, null]], "Gelman Rubin Diagnostic": [[144, "gelman-rubin-diagnostic"]], "Gelman Rubin Diagnostic (quoted verbatim from the Hicks notebook)": [[152, "gelman-rubin-diagnostic-quoted-verbatim-from-the-hicks-notebook"]], "General problems in Bayesian inference": [[154, "general-problems-in-bayesian-inference"]], "Generate data": [[97, "generate-data"]], "Generate figures": [[143, "generate-figures"]], "Generate \u201cexperimental\u201d observations for height": [[124, "generate-experimental-observations-for-height"]], "Generating data": [[74, "generating-data"], [94, "generating-data"]], "Generating the data": [[143, "generating-the-data"]], "Generative models": [[65, null]], "Getting help": [[135, "getting-help"]], "Getting started: The Covariance Function": [[84, "getting-started-the-covariance-function"]], "Good online cheat-sheets:": [[139, "good-online-cheat-sheets"]], "Gradient Computations": [[72, "gradient-computations"]], "Gradient-descent optimization": [[98, null], [106, null]], "Group Attribution Biases": [[64, null]], "Guide to Jupyter Book markdown": [[0, null]], "Guides in this Jupyter Book": [[139, "guides-in-this-jupyter-book"]], "HMC algorithm": [[149, "hmc-algorithm"]], "HMC and other samplers": [[158, null]], "HMC physics": [[149, "hmc-physics"]], "Hamiltonian Monte Carlo": [[45, "hamiltonian-monte-carlo"]], "Hamiltonian Monte Carlo (HMC) overview and visualization": [[149, null]], "Helper function": [[82, "helper-function"]], "Hidden code cell": [[0, "hidden-code-cell"]], "Hint": [[20, null], [33, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null], [35, null]], "Hint (a)": [[33, null]], "Hint (b)": [[33, null]], "Hint-1": [[35, null]], "Hint-2": [[35, null]], "Hints": [[35, null], [68, null]], "Histograms matching a t distribution": [[127, "histograms-matching-a-t-distribution"]], "How are N_A and N_B related to the total N and the posteriors p(X_A|D,I) and p(X_B|D,I)?": [[160, null]], "How do we know this chain has converged to the posterior?": [[144, "how-do-we-know-this-chain-has-converged-to-the-posterior"]], "How the Bayesian approach helps in science": [[7, null]], "Hybrid Uncertainty:": [[7, null]], "Hypothesis testing with the chi-squared statistic": [[54, "hypothesis-testing-with-the-chi-squared-statistic"]], "Icons and menus": [[57, null]], "Illustration of prior and posterior Gaussian process for different kernels": [[82, null]], "Implementation": [[41, "implementation"]], "Implicit Biases": [[64, null]], "Import Python modules": [[39, "import-python-modules"]], "Import TensorFlow": [[77, "import-tensorflow"]], "Import functions": [[5, "import-functions"]], "Import modules": [[78, "import-modules"], [84, "import-modules"], [93, "import-modules"], [134, "import-modules"]], "Import of modules": [[96, "import-of-modules"], [145, "import-of-modules"]], "Import statements": [[97, "import-statements"]], "Import theano and pymc3": [[74, "import-theano-and-pymc3"]], "Important definitions": [[131, "important-definitions"]], "Important distributions": [[131, "important-distributions"]], "Imports": [[152, "imports"]], "In terms of p(X_A|X_B), p(X_B|X_A), N_A, and N_B, what is the condition that the exchanges between A and B cancel out? (For now assume a symmetric proposal distribution q.)": [[160, null]], "In-class exercise": [[152, "in-class-exercise"]], "Inference and PDFs": [[21, null]], "Inference using Gaussian processes": [[86, "inference-using-gaussian-processes"]], "Inference with parametric models": [[7, "inference-with-parametric-models"]], "InferenceData object": [[152, "inferencedata-object"]], "Information from ChatGPT about backpropagation": [[72, "information-from-chatgpt-about-backpropagation"]], "Information from ChatGPT about how to switch to normal distributions to intialize": [[72, "information-from-chatgpt-about-how-to-switch-to-normal-distributions-to-intialize"]], "Information from ChatGPT about tensor operations": [[72, "information-from-chatgpt-about-tensor-operations"], [72, "id1"]], "Information from ChatGPT about the default initialization": [[72, "information-from-chatgpt-about-the-default-initialization"]], "Ingredients of Bayes\u2019 theorem": [[26, null]], "Inserting figures and references to them": [[0, "inserting-figures-and-references-to-them"]], "Installation of LearningFromData Jupyter notebooks from GitHub by command line": [[141, "installation-of-learningfromdata-jupyter-notebooks-from-github-by-command-line"]], "Installation of PyTorch": [[72, "installation-of-pytorch"]], "Installing Anaconda": [[138, "installing-anaconda"]], "Integration": [[147, "integration"]], "Integration and marginalization by sampling: intuition": [[147, "integration-and-marginalization-by-sampling-intuition"]], "Interpreting 2D posteriors": [[37, null]], "Introduction": [[58, null], [162, "introduction"]], "Introduction to tensorflow": [[70, "introduction-to-tensorflow"]], "Intuition by sampling and plotting multivariate Gaussians": [[79, "intuition-by-sampling-and-plotting-multivariate-gaussians"]], "Intuition for detailed balance and the MH algorithm": [[160, "intuition-for-detailed-balance-and-the-mh-algorithm"]], "Inverse": [[137, "inverse"]], "Invitation to inductive inference": [[63, null]], "Iterating through a list of parameters to draw multiple lines on a plot": [[136, "iterating-through-a-list-of-parameters-to-draw-multiple-lines-on-a-plot"]], "Iteration versus array operation": [[136, "iteration-versus-array-operation"]], "Iterative history matching": [[47, "iterative-history-matching"]], "Joint PDFs, marginal PDFs, and an example of marginalization": [[24, "joint-pdfs-marginal-pdfs-and-an-example-of-marginalization"]], "KOH and BOH discrepancy models": [[120, null]], "Kernel cookbook": [[82, "kernel-cookbook"]], "Labeling and referencing a section": [[0, "labeling-and-referencing-a-section"]], "Laplace\u2019s method": [[54, "laplaces-method"]], "Large-width limit": [[118, "large-width-limit"]], "Layers used to build CNNs": [[76, "layers-used-to-build-cnns"]], "Learning algorithm": [[68, null], [68, "learning-algorithm"]], "Learning challenges": [[69, "learning-challenges"]], "Learning curves": [[67, "learning-curves"], [98, "learning-curves"]], "Learning goals:": [[95, "learning-goals"], [97, "learning-goals"], [143, "learning-goals"]], "Lecture 12": [[147, null]], "Lecture 20": [[80, null]], "Lets look at what the classifier has learned": [[74, "lets-look-at-what-the-classifier-has-learned"]], "Let\u2019s look at what the classifier has learned": [[94, "lets-look-at-what-the-classifier-has-learned"]], "Likelihood": [[51, "likelihood"]], "Likelihoods (or posteriors) with two variables with quadratic approximation": [[37, "likelihoods-or-posteriors-with-two-variables-with-quadratic-approximation"]], "Limit of Poisson distribution is Gaussian": [[34, "limit-of-poisson-distribution-is-gaussian"]], "Limitations of supervised learning with deep networks": [[68, "limitations-of-supervised-learning-with-deep-networks"]], "Limitations of training data": [[64, "limitations-of-training-data"]], "Linear algebra and numerical operations": [[137, "linear-algebra-and-numerical-operations"]], "Linear classification": [[66, "linear-classification"]], "Linear classifier(s)": [[66, "linear-classifier-s"]], "Linear models": [[99, null]], "Linear regression": [[66, "linear-regression"]], "Linear versus non-linear models": [[113, null]], "Liouville Theorem Visualization": [[150, null]], "Location invariance": [[3, "location-invariance"]], "Log normal distribution": [[4, "log-normal-distribution"]], "Logistic Regression": [[89, null]], "Logistic regression using scikit-learn": [[71, "logistic-regression-using-scikit-learn"]], "Looking ahead": [[25, null]], "Looking at PyMC getting started notebook": [[159, "looking-at-pymc-getting-started-notebook"]], "MCMC Intro from BUQEYE": [[155, null]], "MCMC Sampling Interlude: Assessing Convergence": [[147, "mcmc-sampling-interlude-assessing-convergence"]], "MCMC diagnostics: assessing convergence": [[144, "mcmc-diagnostics-assessing-convergence"]], "MCMC random walk and sampling example": [[160, "mcmc-random-walk-and-sampling-example"]], "MH Sampling and convergence": [[51, "mh-sampling-and-convergence"]], "Machine Learning": [[90, null]], "Machine Learning: First Examples": [[66, null]], "Machine learning": [[61, null]], "Machine learning in science and society": [[65, "machine-learning-in-science-and-society"]], "Machine learning: Overview and notation": [[65, null]], "Macros": [[0, "macros"]], "Main code for coin-flipping UI": [[9, "main-code-for-coin-flipping-ui"]], "Make Liouville theorem visualization": [[150, "make-liouville-theorem-visualization"]], "Make predictions": [[77, "make-predictions"]], "Make predictions and evaluate accuracy": [[70, "make-predictions-and-evaluate-accuracy"]], "Make some plots": [[127, "make-some-plots"]], "Making a movie of the evolution of the distribution": [[127, "making-a-movie-of-the-evolution-of-the-distribution"]], "Making predictions": [[77, "making-predictions"]], "Manipulating probabilities: Bayesian rules of probability as principles of logic": [[23, null]], "Many new target predictions using a GP": [[86, null]], "Marginal posterior distributions": [[35, "marginal-posterior-distributions"]], "Marginalization": [[42, "marginalization"], [147, "marginalization"]], "Marginalization using samples": [[17, null]], "Markov Chain Monte Carlo (MCMC)": [[155, "markov-chain-monte-carlo-mcmc"]], "Markov chain Monte Carlo sampling": [[154, null]], "Markov chains": [[157, null]], "Materials to help you get started": [[57, "materials-to-help-you-get-started"]], "Mathematical functions with numpy": [[135, "mathematical-functions-with-numpy"]], "Mathematical model": [[68, "mathematical-model"]], "Mathematical optimization": [[105, null]], "Matplotlib plotting helper functions": [[18, "matplotlib-plotting-helper-functions"]], "Matrix  Operations": [[137, "matrix-operations"]], "Matrix-vector notation": [[68, "matrix-vector-notation"]], "Mat\u00e9rn kernel": [[82, "matern-kernel"]], "Maximum likelihood": [[89, "maximum-likelihood"]], "Maximum likelihood fits": [[96, "maximum-likelihood-fits"]], "Mean and covariance function": [[83, "mean-and-covariance-function"]], "Mean and the Exponential pdf": [[4, "mean-and-the-exponential-pdf"]], "Mean, median, mode": [[131, "mean-median-mode"]], "Meet the Pandas": [[134, "meet-the-pandas"]], "Metropolis Poisson example (Gregory, section 12.2)": [[155, "metropolis-poisson-example-gregory-section-12-2"]], "Metropolis condition": [[155, null]], "Metropolis design": [[157, "metropolis-design"]], "Metropolis-Hasting MCMC sampling of a Poisson distribution": [[146, null]], "Mini-batch ADVI": [[74, "mini-batch-advi"]], "Mini-project I: Parameter estimation for a toy model of an EFT": [[95, null]], "Mini-project IIIa: Bayesian Optimization": [[93, null]], "Mini-project IIIb: Bayesian Neural Networks": [[94, null]], "Mini-project IIa: Model selection basics": [[96, null]], "Mini-project IIb: How many lines are there?": [[97, null]], "Minimize the effective potential and plot results for benchmark case": [[5, "minimize-the-effective-potential-and-plot-results-for-benchmark-case"]], "Minimizing the cross entropy": [[89, "minimizing-the-cross-entropy"]], "Model Selection": [[54, null]], "Model checking:": [[7, null]], "Model comparison:": [[7, null]], "Model mixing": [[49, null]], "Model specification": [[74, "model-specification"], [94, "model-specification"]], "Model validation": [[67, null], [67, "id7"]], "Model-order reduction": [[46, null]], "Models in science": [[111, null]], "Monte Carlo integration": [[154, "monte-carlo-integration"]], "Monte Carlo integration in statistics": [[154, "monte-carlo-integration-in-statistics"]], "Moral qualities of the scientist": [[62, null]], "More details on naive MC": [[155, null]], "More on Python and using Jupyter notebooks": [[139, null]], "More on Ridge Regression": [[67, "more-on-ridge-regression"]], "Multi-model inference with Bayes": [[55, null]], "Multivariate Gaussian distribution": [[131, "multivariate-gaussian-distribution"]], "Multivariate normal distributions": [[83, "multivariate-normal-distributions"]], "N dimensional arrays": [[137, "n-dimensional-arrays"]], "N=2 moments": [[5, "n-2-moments"]], "N=3 moments": [[5, "n-3-moments"]], "N=4 moments": [[5, "n-4-moments"]], "N=5 moments": [[5, "n-5-moments"]], "Network training": [[73, "network-training"]], "Neural network architecture": [[68, "neural-network-architecture"]], "Neural network types": [[68, "neural-network-types"]], "Next steps": [[74, "next-steps"]], "No-core shell model \\hbar\\omega dependence": [[79, "no-core-shell-model-hbar-omega-dependence"], [83, "no-core-shell-model-hbar-omega-dependence"]], "Noisy networks": [[68, null]], "Non-parametric approach: Mean and covariance functions": [[86, "non-parametric-approach-mean-and-covariance-functions"]], "Normalization and marginalization": [[26, null]], "Normalization and marginalization in the continuum limit": [[26, null]], "Normalization of a multivariate Gaussian": [[54, "normalization-of-a-multivariate-gaussian"]], "Notation": [[65, "notation"], [86, null], [89, null], [110, null], [131, "notation"], [162, "notation"]], "Note on \\chi^2/\\text{dof} for model assessment and comparison  \\newcommand{\\pars}{\\boldsymbol{\\theta}}": [[30, "note-on-chi-2-text-dof-for-model-assessment-and-comparison-newcommand-pars-boldsymbol-theta"]], "Note on donuts in high dimensions": [[155, null]], "Notebook:": [[20, "notebook"]], "Notes": [[0, "notes"], [50, "notes"]], "Now ask ChatGPT to use this code to learn a specified function in a specified region": [[72, "now-ask-chatgpt-to-use-this-code-to-learn-a-specified-function-in-a-specified-region"]], "Now do the sampling and plot the posteriors": [[124, "now-do-the-sampling-and-plot-the-posteriors"]], "Now sample with PyMC": [[153, "now-sample-with-pymc"]], "Now sample with zeus": [[153, "now-sample-with-zeus"]], "Now try it with zeus!": [[51, "now-try-it-with-zeus"]], "Numerical integration": [[154, "numerical-integration"]], "Occam\u2019s razor": [[7, null]], "Odds-ratios": [[96, "odds-ratios"]], "One adjustable parameter each": [[54, "one-adjustable-parameter-each"]], "One adjustable parameter each; different prior ranges": [[54, "one-adjustable-parameter-each-different-prior-ranges"]], "One solution (how could these functions be improved?)": [[41, "one-solution-how-could-these-functions-be-improved"]], "One solution (how could this solution be improved?)": [[41, "one-solution-how-could-this-solution-be-improved"]], "One view": [[8, null]], "Open an issue": [[57, null]], "Operating on matrices with special properties": [[137, null]], "Optimization and Deep learning": [[89, "optimization-and-deep-learning"]], "Optional task: log probabilities": [[145, "optional-task-log-probabilities"]], "Ordinary linear regression in practice": [[103, null]], "Ordinary linear regression: warmup": [[102, null]], "Organizing our data": [[134, "organizing-our-data"]], "Original background": [[153, "original-background"]], "Output Distribution of Randomly-Initialized feed-forward ANN (1 Input \u2192 1 Output)": [[130, "output-distribution-of-randomly-initialized-feed-forward-ann-1-input-1-output"]], "Output Distribution of Randomly-Initialized feed-forward ANN (2 Inputs \u2192 1 Output)": [[130, "output-distribution-of-randomly-initialized-feed-forward-ann-2-inputs-1-output"]], "Over- and underfitting": [[67, "over-and-underfitting"]], "Overfitting and underfitting the data": [[64, null]], "Overgeneralization Bias": [[64, null]], "Overview of Gaussian process": [[87, null]], "Overview of Intro to PyMC notebook": [[159, null]], "Overview of Markov Chain Monte Carlo": [[156, null]], "Overview of Mini-project IIb: How many lines?": [[91, null]], "Overview of Part II: Advanced Bayesian methods": [[56, null]], "Overview of Part III: Sampling": [[161, null]], "Overview of TALENT mini-projects": [[92, null]], "Overview of getting started materials": [[132, null]], "Overview of modeling": [[109, null]], "Overview of other topics": [[125, null]], "Overview of scientific modeling material": [[117, null]], "Overview: MCMC Diagnostics": [[144, null]], "PCA (from Duke course)": [[128, "pca-from-duke-course"]], "PCA, SVD, and all that": [[126, null]], "PDFs for applying Bayes\u2019 rule": [[143, "pdfs-for-applying-bayes-rule"]], "PT Sampler": [[51, "pt-sampler"]], "Parallel tempering": [[52, "parallel-tempering"]], "Parameter Estimation:": [[0, null], [7, null]], "Parameter choices": [[94, "parameter-choices"]], "Parameter estimation example: Gaussian noise and averages II": [[148, null]], "Parameter estimation example: fitting a straight line": [[41, null]], "Parameter estimation with your favorite MCMC sampler (emcee here!)": [[97, "parameter-estimation-with-your-favorite-mcmc-sampler-emcee-here"]], "Parameters known before the analysis (explore different values for these as requested)": [[97, "parameters-known-before-the-analysis-explore-different-values-for-these-as-requested"]], "Parameters that should be learned from the data": [[97, "parameters-that-should-be-learned-from-the-data"]], "Parametric approach": [[86, "parametric-approach"]], "Parametric versus non-parametric models": [[112, null]], "Part 1": [[84, "part-1"]], "Part 1: Random walk in [-5,5] region": [[145, "part-1-random-walk-in-5-5-region"]], "Part 2": [[84, "part-2"]], "Part 2: MCMC sampling of a Lorentzian pdf using the random walk Metropolis algorithm": [[145, "part-2-mcmc-sampling-of-a-lorentzian-pdf-using-the-random-walk-metropolis-algorithm"]], "Part 3": [[84, "part-3"]], "Part 3: Detailed balance and the Metropolis-Hastings algorithm": [[145, "part-3-detailed-balance-and-the-metropolis-hastings-algorithm"]], "Pendulum class and utility functions": [[150, "pendulum-class-and-utility-functions"]], "Perform thermodynamic integration from PT sampler": [[97, "perform-thermodynamic-integration-from-pt-sampler"]], "Philosophical remarks on probabilities": [[8, "philosophical-remarks-on-probabilities"]], "Physicist\u2019s perspective": [[59, null]], "Pick a potential": [[151, "pick-a-potential"]], "Plot orbit and check energy conservation": [[151, "plot-orbit-and-check-energy-conservation"]], "Plotting with Matplotlib": [[135, "plotting-with-matplotlib"]], "Point estimates": [[19, null]], "Point estimates and credible regions": [[131, "point-estimates-and-credible-regions"]], "Poisson distribution": [[4, "poisson-distribution"], [38, "poisson-distribution"]], "Polya and Jaynes": [[63, "polya-and-jaynes"]], "Polya and plausible inference": [[63, null]], "Possible answers": [[0, null], [11, null], [23, null]], "Posterior": [[51, "posterior"]], "Posterior with a Gaussian prior": [[35, "posterior-with-a-gaussian-prior"]], "Posterior with a uniform prior": [[35, "posterior-with-a-uniform-prior"]], "Predict based on your own experience: How does this behavior change if we have more data (higher energy) or more certain data?": [[53, null]], "Preliminaries": [[127, "preliminaries"]], "Preliminary exercise: manipulations using the index form of matrices": [[128, "preliminary-exercise-manipulations-using-the-index-form-of-matrices"]], "Preliminary exercises": [[126, "preliminary-exercises"]], "Prelude: ordinary linear regression": [[35, "prelude-ordinary-linear-regression"]], "Preparing data and the pdfs we\u2019ll need": [[38, "preparing-data-and-the-pdfs-well-need"]], "Principal components": [[128, "principal-components"]], "Prior": [[51, "prior"]], "Prior PDFs for straight line model": [[6, "prior-pdfs-for-straight-line-model"]], "Prior elicitation.": [[44, "prior-elicitation"]], "Probabilistic Programming at scale": [[74, "probabilistic-programming-at-scale"]], "Probabilistic model": [[73, "probabilistic-model"]], "Probability density functions": [[24, null]], "Probability surface": [[74, "probability-surface"], [94, "probability-surface"]], "Product rule": [[23, "product-rule"]], "Projected posterior plots": [[18, "projected-posterior-plots"]], "Proof of penultimate equality": [[13, null]], "Proof of the CLT in a special case:": [[20, "proof-of-the-clt-in-a-special-case"]], "Pukelsheim\u2019s three-sigma rule": [[47, "pukelsheims-three-sigma-rule"], [47, null]], "PyMC Introduction": [[152, null]], "PyMC implementation": [[152, "pymc-implementation"]], "PyMC3:": [[154, null]], "PyMultiNest:": [[154, null]], "PyStan:": [[154, null]], "PyTorch Default Initialization": [[72, "pytorch-default-initialization"]], "Python expressions and strings": [[135, "python-expressions-and-strings"]], "Python for machine learning": [[65, null]], "Python imports": [[51, "python-imports"], [128, "python-imports"], [143, "python-imports"]], "Python/Jupyter set up": [[9, "python-jupyter-set-up"]], "QBism references": [[129, "qbism-references"]], "Quadrature methods": [[154, "quadrature-methods"]], "Quantum Bayesianism (QBism)": [[129, null]], "Question": [[4, null], [12, null], [37, null], [84, "question"], [86, null], [89, null], [89, null], [96, "question"], [155, null]], "Question 1": [[32, null], [33, null]], "Question 2": [[32, null], [33, null]], "Question 3": [[32, null], [33, null]], "Question 4": [[32, null], [33, null]], "Question 5": [[32, null], [33, null]], "Question 6": [[32, null]], "Question 7": [[32, null]], "Question 8": [[32, null]], "Question 9": [[32, null]], "Questions": [[145, "questions"]], "Questions / tasks": [[145, "questions-tasks"], [145, "id2"]], "Questions and things to do": [[146, "questions-and-things-to-do"]], "Questions for the class": [[37, null]], "Questions:": [[145, "id1"]], "Quick introduction to  scipy.stats": [[18, "quick-introduction-to-scipy-stats"], [131, "quick-introduction-to-scipy-stats"]], "Quick review: To a Bayesian, everything is a PDF (probability density function)": [[18, "quick-review-to-a-bayesian-everything-is-a-pdf-probability-density-function"]], "RMSprop": [[108, "rmsprop"]], "Radial Basis Function kernel": [[82, "radial-basis-function-kernel"]], "Random Walk Metropolis-Hasting (MH)": [[155, "random-walk-metropolis-hasting-mh"]], "Random variables: probability distribution and density": [[131, "random-variables-probability-distribution-and-density"]], "Rank": [[137, "rank"]], "Rational Quadradtic kernel": [[82, "rational-quadradtic-kernel"]], "Recall Beta function": [[13, null]], "Recall Metropolis algorithm for p(\\thetavec | D, I) (or any other posterior).": [[160, null]], "Recall the basic structure of Metropolis-Hastings": [[155, null]], "Recap of GPs": [[80, "recap-of-gps"]], "Recap of Poisson MCMC example": [[160, "recap-of-poisson-mcmc-example"]], "Recaps": [[160, null]], "Recurrent neural networks": [[68, "recurrent-neural-networks"]], "Reduced-order methods": [[46, "reduced-order-methods"]], "Reference: Bayesian rules of probability": [[32, "reference-bayesian-rules-of-probability"], [33, "reference-bayesian-rules-of-probability"]], "References:": [[86, "references"]], "Regression algorithms": [[65, null]], "Regression analysis with linear models": [[101, null]], "Regression analysis: optimization versus inference": [[114, null]], "Regular NNs don\u2019t scale well to full images": [[76, "regular-nns-dont-scale-well-to-full-images"]], "Regularization": [[89, "regularization"]], "Regularization: Ridge and Lasso": [[67, "regularization-ridge-and-lasso"]], "Remarks": [[0, "remarks"]], "Remarks on bias and variance": [[67, "remarks-on-bias-and-variance"]], "Reporting Biases": [[64, null]], "Reproducibility": [[44, "reproducibility"]], "Requirements for AI systems": [[64, null]], "Reshape": [[137, "reshape"]], "Results": [[44, "results"]], "Reversibility": [[157, "reversibility"]], "Review of Bayes\u2019 theorem": [[26, null]], "Review of bivariate normal case": [[79, "review-of-bivariate-normal-case"]], "Rewriting the likelihood": [[35, "rewriting-the-likelihood"]], "Row-major order": [[137, null]], "Run MCMC": [[143, "run-mcmc"]], "S/IR limitations": [[45, "s-ir-limitations"]], "SVD applied to images for compression": [[128, "svd-applied-to-images-for-compression"]], "SVD basics": [[128, "svd-basics"]], "Sampling": [[19, null], [39, "sampling"], [152, "sampling"]], "Sampling / Importance Resampling": [[45, "sampling-importance-resampling"]], "Sampling a distribution": [[157, null]], "Sampling and plotting multivariate Gaussians": [[83, "sampling-and-plotting-multivariate-gaussians"]], "Sampling from a Gaussian Process": [[84, "sampling-from-a-gaussian-process"]], "Sampling from a PDF": [[154, "sampling-from-a-pdf"]], "Sampling of 1d pdfs in Python": [[18, "sampling-of-1d-pdfs-in-python"]], "Saving a figure": [[135, "saving-a-figure"]], "Scalar operations": [[137, "scalar-operations"]], "Scale invariance": [[3, "scale-invariance"]], "Scikit-learn demo notebooks": [[88, null]], "Second example: each sample is two points": [[34, "second-example-each-sample-is-two-points"]], "Second pass: More elaborate controls and options": [[133, "second-pass-more-elaborate-controls-and-options"]], "Select element(s)": [[137, "select-element-s"]], "Selected exercises from notebook": [[80, "selected-exercises-from-notebook"]], "Selection bias": [[64, null]], "Set plot style": [[124, "set-plot-style"]], "Setting Covariance Function Parameters": [[78, "setting-covariance-function-parameters"], [84, "setting-covariance-function-parameters"]], "Setting it up": [[76, "setting-it-up"]], "Setting up the back-propagation algorithm": [[69, "setting-up-the-back-propagation-algorithm"]], "Setting up to use this Jupyter book": [[140, null]], "Setup sampling with emcee and pocomc samplers": [[124, "setup-sampling-with-emcee-and-pocomc-samplers"]], "Shape, size, length and data type": [[137, "shape-size-length-and-data-type"]], "Singular value decomposition (SVD)": [[126, "singular-value-decomposition-svd"]], "Sivia example on \u201csignal on top of background\u201d": [[37, "sivia-example-on-signal-on-top-of-background"]], "Solution strategy:": [[97, "solution-strategy"]], "Solution to": [[35, "solution:BayesianLinearRegression:likelihood_pars"], [35, "solution:ols_example_1_b"], [35, "solution:ols_example_3_b"]], "Solution to Exercise 17.1": [[162, "solution:StochasticProcess:first-example"]], "Solution to Exercise 17.2": [[162, "solution:conditional-probabilities-stochastic-process"]], "Solution to Exercise 17.3": [[162, "solution:construct-stochastic-process"]], "Solution to Exercise 18.1 (Stochastic matrix)": [[157, "solution:MarkovChains:stochastic-matrix"]], "Solution to Exercise 18.10 (Flip-flop)": [[157, "solution:flip-flop"]], "Solution to Exercise 18.11 (Gothenburg winter weather)": [[157, "solution:MarkovChains:gothenburg-winter-weather"]], "Solution to Exercise 18.12 (Stationary Gothenburg winter weather)": [[157, "solution:stationary-gothenburg-winter-weather"]], "Solution to Exercise 18.13 (Is it reversible?)": [[157, "solution:is-it-reversible"]], "Solution to Exercise 18.14 (Optical pumping)": [[157, "solution:optical-pumping"]], "Solution to Exercise 18.15 (Detailed balance)": [[157, "solution:detailed-balance"]], "Solution to Exercise 18.16 (Metropolis sampling of a uniform distribution)": [[154, "solution:metropolis-sampling-uniform"]], "Solution to Exercise 18.17 (Power-law distributions)": [[154, "solution:power-law-distribution-sampling"]], "Solution to Exercise 18.18 (The Metropolis algorithm for a discrete distribution)": [[154, "solution:MCMC:discrete-metropolis"]], "Solution to Exercise 18.2 (Simple random walk)": [[157, "solution:MarkovChains:simple-random-walk"]], "Solution to Exercise 18.3 (Remnant memory)": [[157, "solution:MarkovChains:memory"]], "Solution to Exercise 18.4 (Conditional distributions)": [[157, "solution:MarkovChains:conditional-distributions"]], "Solution to Exercise 18.5 (Stationary distribution)": [[157, "solution:MarkovChains:stationary-distribution"]], "Solution to Exercise 18.6 (Reversibility)": [[157, "solution:MarkovChains:reversibility"]], "Solution to Exercise 18.7 (A reversible Markov chain)": [[157, "solution:MarkovChains:reversible-chain"]], "Solution to Exercise 18.8 (Stationary two-state distribution)": [[157, "solution:stationary-2x2"]], "Solution to Exercise 18.9 (Limiting distribution)": [[157, "solution:limiting-distribution"]], "Solution to Exercise 23.1 (Sigmoid decision boundary)": [[66, "solution:MLexamples:sigmoid-decision-boundary"]], "Solution to Exercise 23.4 (kNN for regression)": [[66, "solution:MLexamples:kNN-regression"]], "Solution to Exercise 23.5 (R2 score)": [[66, "solution:MLexamples:R2-score"]], "Solution to Exercise 24.1 (Weights and signal propagation of a simple neural network)": [[68, "solution:NeuralNet:simple-network"]], "Solution to Exercise 24.2 (Weights and signal propagation of a wide neural network)": [[68, "solution:NeuralNet:wide-network"]], "Solution to Exercise 24.3 (Linear signals)": [[68, "solution:NeuralNet:linear-signal"]], "Solution to Exercise 24.4 (Expected signal)": [[68, "solution:NeuralNet:expected-signal"]], "Solution to Exercise 24.5 (k=1 NN training error)": [[67, "solution:ModelValidation:kNN-training-error"]], "Solution to Exercise 24.6 (kNN model complexity)": [[67, "solution:ModelValidation:kNN-model-complexity"]], "Solution to Exercise 24.7 (Study of model bias and variance)": [[67, "solution:ModelValidation:study-model-bias-variance"]], "Solution to Exercise 24.8 (Implement k-fold cross validation)": [[67, "solution:ModelValidation:kfold-cross-validation"]], "Solution to Exercise 24.9 (Large training error)": [[67, "solution:ModelValidation:large-training-error"]], "Solution to Exercise 34.1": [[0, "solution:ppd_definition_b"]], "Solution to Exercise 35.1 (Random and colorblind)": [[131, "solution:Statistics:colorblind"]], "Solution to Exercise 35.2 (Conditional discrete probability mass function)": [[131, "solution:Statistics:conditional-discrete-pmf"]], "Solution to Exercise 35.3 (Conditional probability for continuous variables)": [[131, "solution:Statistics:conditional-probability-continuous"]], "Solution to Exercise 35.4 (Conditional expectation)": [[131, "solution:Statistics:conditional-expectation"]], "Solution to Exercise 35.5 (Scipy.stats)": [[131, "colution:Statistics:scipy-stats"]], "Solution to Exercise 35.6 (Bivariate pdf)": [[131, "solution:Statistics:bivariate-pdf"]], "Solution to Exercise 38.1 (Independent and dependent)": [[116, "solution:OverviewModeling:independent-dependent"]], "Solution to Exercise 38.2 (Linear or non-linear)": [[116, "solution:OverviewModeling:linear-nonlinear"]], "Solution to Exercise 38.3 (Linear or non-linear; more examples)": [[116, "solution:OverviewModeling:linear-nonlinear-examples"]], "Solution to Exercise 38.4 (Model discrepancy)": [[116, "solution:OverviewModeling:model-discrepancy"]], "Solution to Exercise 39.1": [[104, "solution:ols_example_1"]], "Solution to Exercise 39.3": [[104, "solution:ols_example_3"]], "Solution to Exercise 4.3": [[16, "solution:ppd_definition"]], "Solution to Exercise 4.4": [[16, "solution:pdf_normalization"]], "Solution to Exercise 4.5": [[16, "solution:rain"]], "Solution to Exercise 4.6": [[16, "solution:monty_hall"]], "Solution to Exercise 4.7": [[16, "solution:coin_ppd"]], "Solution to Exercise 8.1 (Correlated errors)": [[17, "solution:BayesianAdvantage:correlated-errors"]], "Solution to Exercise 8.3 (Inferring galactic distances)": [[17, "solution:BayesianAdvantages:inferring-galactic-distances-ex"]], "Solution to Exercise 8.4 (The standard random variable)": [[17, "solution:BayesianAdvantages:standard-random-variable"]], "Solution to Exercise 8.5 (The square root of a number)": [[17, "solution:BayesianAdvantages:square-root-of-a-number"]], "Solution to Exercise 8.6 (Gaussian sum of errors)": [[17, "solution:BayesianAdvantages:gaussian-sum-of-errors"]], "Solution to Exercise 8.7 (Gaussian product of errors)": [[17, "solution:BayesianAdvantages:gaussian-product-of-errors"]], "Solutions": [[16, "solutions"], [17, "solutions"], [66, "solutions"], [67, "solutions"], [68, "solutions"], [104, null], [116, null], [131, "solutions"], [154, "solutions"], [157, "solutions"], [162, "solutions"]], "Solutions to selected exercises": [[35, "solutions-to-selected-exercises"]], "Solving matrix equations with SVD": [[128, "solving-matrix-equations-with-svd"]], "Solving orbital equations with different algorithms": [[151, null]], "Some standard pdfs: the normal (aka Gaussian) and beta distributions": [[18, "some-standard-pdfs-the-normal-aka-gaussian-and-beta-distributions"]], "Sorting": [[137, "sorting"]], "Sparsity": [[118, "sparsity"]], "Special case: Gaussian process": [[162, "special-case-gaussian-process"]], "Speed comparisons": [[136, "speed-comparisons"]], "Splitting arrays": [[137, "splitting-arrays"]], "Spot the error!": [[35, null]], "Standard Error of the Mean": [[144, "standard-error-of-the-mean"]], "Standard Likelihood Approach": [[39, "standard-likelihood-approach"]], "Standard activation functions": [[89, "standard-activation-functions"]], "State-of-the-art MCMC implementations": [[154, "state-of-the-art-mcmc-implementations"]], "Statements": [[22, null]], "Stationary and limiting distributions": [[157, "stationary-and-limiting-distributions"]], "Stationary kernels": [[86, "stationary-kernels"]], "Stationary processes": [[157, "stationary-processes"]], "Statistical Operations": [[137, "statistical-operations"]], "Statistical formulation": [[124, "statistical-formulation"]], "Statistics concepts and notation": [[131, null]], "Step 1: Maximum likelihood estimate": [[42, "step-1-maximum-likelihood-estimate"]], "Step 2: Single-parameter model": [[42, "step-2-single-parameter-model"]], "Step 3: Full Bayesian approach": [[42, "step-3-full-bayesian-approach"]], "Step 4: Error propagation": [[42, "step-4-error-propagation"]], "Stochastic processes": [[162, null]], "Student t distribution as a mixture of Gaussians": [[127, null]], "Sub-task": [[71, "sub-task"]], "Sub-tasks and follow-up questions": [[71, "sub-tasks-and-follow-up-questions"]], "Subtasks (put your answers here):": [[97, "subtasks-put-your-answers-here"]], "Suggestions for how to proceed:": [[95, "suggestions-for-how-to-proceed"]], "Sum of normally distributed random variables.": [[86, null]], "Sum rule": [[23, "sum-rule"]], "Summary": [[8, "summary"], [17, null], [42, "summary"], [86, null]], "Summary points from arXiv:1710.06068": [[160, null]], "Symmetry invariance": [[3, "symmetry-invariance"]], "Systematic error example": [[42, "systematic-error-example"]], "Systematic reduction": [[76, "systematic-reduction"]], "Systemic biases": [[64, null]], "Table of results": [[37, null]], "Take aways: Coin tossing": [[26, "take-aways-coin-tossing"]], "Take-aways and follow-up questions from coin flipping:": [[15, null]], "Task 1: Logistic regression using scikit-learn": [[75, "task-1-logistic-regression-using-scikit-learn"]], "Task 2: Bayesian logistic regression using MCMC sampling": [[75, "task-2-bayesian-logistic-regression-using-mcmc-sampling"]], "Task 3: Bayesian logistic regression using Variational Inference": [[75, "task-3-bayesian-logistic-regression-using-variational-inference"]], "Telling ChatGPT 4 to make a network for a function of one variable": [[72, "telling-chatgpt-4-to-make-a-network-for-a-function-of-one-variable"]], "Terminology": [[68, "terminology"]], "Test the sum of normal variables squared": [[30, "test-the-sum-of-normal-variables-squared"]], "The Central Limit Theorem": [[20, "the-central-limit-theorem"]], "The Data": [[41, "the-data"], [144, "the-data"]], "The Data and the question": [[42, "the-data-and-the-question"]], "The Data and the true result": [[50, "the-data-and-the-true-result"]], "The Gaussian is to statistics what the harmonic oscillator is to mechanics": [[20, "the-gaussian-is-to-statistics-what-the-harmonic-oscillator-is-to-mechanics"]], "The Gelman-Rubin test": [[45, "the-gelman-rubin-test"]], "The Jupyter Notebook menu and shortcuts": [[135, "the-jupyter-notebook-menu-and-shortcuts"]], "The Kullback-Leibler divergence": [[73, "the-kullback-leibler-divergence"]], "The Metropolis-Hastings algorithm": [[154, "the-metropolis-hastings-algorithm"]], "The Model": [[39, "the-model"], [41, "the-model"], [42, "the-model"], [96, "the-model"], [144, "the-model"]], "The Prior": [[41, "the-prior"]], "The RBF kernel (a.k.a Gaussian)": [[79, "the-rbf-kernel-a-k-a-gaussian"], [83, "the-rbf-kernel-a-k-a-gaussian"]], "The Story of Dr. A and Prof. B": [[54, "the-story-of-dr-a-and-prof-b"]], "The Zeus Ensemble Slice Sampler": [[164, null]], "The ball-drop model": [[122, null]], "The bias-variance tradeoff": [[67, "the-bias-variance-tradeoff"]], "The continuum limit": [[26, "the-continuum-limit"]], "The cost function rewritten as cross entropy": [[89, "the-cost-function-rewritten-as-cross-entropy"]], "The covariance matrix as the central object": [[86, "the-covariance-matrix-as-the-central-object"]], "The entropy of Scandinavians": [[4, "the-entropy-of-scandinavians"]], "The friends of Bayes\u2019 theorem": [[26, "the-friends-of-bayes-theorem"]], "The likelihood": [[35, "the-likelihood"]], "The logistic function": [[89, "the-logistic-function"]], "The monkey argument": [[4, "the-monkey-argument"]], "The near ubiquity of Gaussians": [[20, "the-near-ubiquity-of-gaussians"]], "The normal distribution": [[4, null]], "The normal equation": [[35, "the-normal-equation"], [101, "the-normal-equation"]], "The perceptron": [[89, "the-perceptron"]], "The perceptron classifier": [[66, "the-perceptron-classifier"]], "The posterior": [[35, "the-posterior"]], "The posterior predictive": [[35, "the-posterior-predictive"]], "The posterior predictive distribution": [[16, "the-posterior-predictive-distribution"]], "The prior": [[35, "the-prior"]], "The probability measure": [[131, "the-probability-measure"]], "The pseudo-inverse (or Moore-Penrose inverse)": [[35, null]], "The soft classifier": [[66, "the-soft-classifier"]], "The statistical model (recap)": [[50, "the-statistical-model-recap"]], "The tip class": [[0, "the-tip-class"]], "The toy model": [[50, "the-toy-model"]], "The uniform distribution": [[131, "the-uniform-distribution"]], "Theory": [[124, "theory"]], "Things for you to do:": [[50, "things-for-you-to-do"]], "Things to do and Questions to answer": [[96, "things-to-do-and-questions-to-answer"]], "Things to do:": [[41, "things-to-do"], [128, "things-to-do"]], "Things to try:": [[130, "things-to-try"]], "Third example: each sample is 10 points": [[34, "third-example-each-sample-is-10-points"]], "Third pass:  a more elaborate user interface with tabs": [[133, "third-pass-a-more-elaborate-user-interface-with-tabs"]], "This makes sense:": [[87, null]], "Three main ingredients of machine learning": [[65, null]], "To do": [[94, "to-do"]], "To our real data: nuclear binding energies. Brief reminder on masses and binding energies": [[134, "to-our-real-data-nuclear-binding-energies-brief-reminder-on-masses-and-binding-energies"]], "To think about \u2026": [[20, null]], "Trace": [[137, "trace"]], "Train and evaluate the model:": [[70, "train-and-evaluate-the-model"]], "Training and validation scores": [[67, null]], "Training scores": [[66, "training-scores"]], "Transformation property of multivariate normal distributions": [[35, null]], "Transforming images": [[76, "transforming-images"]], "Try it yourself with the Jupyter notebook": [[134, null]], "Trying a different function": [[5, "trying-a-different-function"]], "Two dependent parameters": [[54, "two-dependent-parameters"]], "Two independent parameters": [[54, "two-independent-parameters"]], "Two views on the likelihood": [[35, null]], "Types of Machine Learning": [[65, "types-of-machine-learning"]], "Types of probability": [[131, "types-of-probability"]], "Uncertainty in predicted value": [[74, "uncertainty-in-predicted-value"], [94, "uncertainty-in-predicted-value"]], "Uncorrelated assignments": [[4, null]], "Univariate Approaches": [[144, "univariate-approaches"]], "Updating via Bayes\u2019 rule": [[10, null]], "Updating your conda environment for Learning from Data": [[138, "updating-your-conda-environment-for-learning-from-data"]], "User-interface for coin-flipping": [[9, "user-interface-for-coin-flipping"]], "Using Anaconda": [[138, null]], "Using Bayesian model mixing to open the model space": [[49, "using-bayesian-model-mixing-to-open-the-model-space"]], "Using GitHub": [[141, null]], "Using SVD for PCA": [[128, "using-svd-for-pca"]], "Using parallel tempering: ptemcee": [[97, "using-parallel-tempering-ptemcee"]], "Utilizing GPU Acceleration": [[72, "utilizing-gpu-acceleration"]], "Variance and the Gaussian pdf": [[4, "variance-and-the-gaussian-pdf"]], "Variance of the mean": [[45, "variance-of-the-mean"]], "Variational Inference: Bayesian Neural Networks": [[94, "variational-inference-bayesian-neural-networks"]], "Variational Inference: Scaling model complexity": [[74, "variational-inference-scaling-model-complexity"], [94, "variational-inference-scaling-model-complexity"]], "Variational inference for Bayesian neural networks": [[73, "variational-inference-for-bayesian-neural-networks"]], "Verification of PyTorch installation (suggested in PyTorch website)": [[72, "verification-of-pytorch-installation-suggested-in-pytorch-website"]], "Verify the data": [[77, "verify-the-data"]], "Verifying sampling": [[19, null]], "Virtues": [[62, null]], "Visualization of MCMC sampling": [[155, "visualization-of-mcmc-sampling"]], "Visualization of PDFs": [[18, "visualization-of-pdfs"]], "Visualizations of MCMC": [[154, "visualizations-of-mcmc"]], "Visualizing PDFs": [[24, "visualizing-pdfs"]], "Warnings": [[0, "warnings"]], "What are arrays?": [[137, "what-are-arrays"]], "What does it mean that the ellipses are slanted?": [[37, null]], "What failure looks like": [[5, "what-failure-looks-like"]], "What if the only moves accepted were those that went uphill (i.e., to higher probability density)? What would happen to N_A and N_B over time? Is this stationary?": [[160, null]], "What is p(\\thetavec_i|D,I)?": [[160, null]], "What is special about machine learning in physics?": [[61, null]], "What is the ratio of p(X_B|X_A) to p(X_A|X_B) in terms of p(X_A|D,I) and p(X_B|D,I)?": [[160, null]], "What is well determined?": [[80, null]], "What next?": [[47, "what-next"]], "What order polynomial?": [[96, "what-order-polynomial"]], "What pairs are highly correlated?": [[80, null]], "What returns the prior?": [[80, null]], "What to do about sampling from correlated distributions?": [[147, "what-to-do-about-sampling-from-correlated-distributions"]], "What you should know about Python and using Jupyter notebooks": [[139, "what-you-should-know-about-python-and-using-jupyter-notebooks"]], "When do priors matter? When don\u2019t they matter?": [[12, null]], "Why MCMC?": [[155, "why-mcmc"]], "Why deep neural networks?": [[68, "why-deep-neural-networks"]], "Why do you think that this property is called detailed balance? Can you make an analogy with thermodynamic equilibrium for e.g. a collection of hydrogen atoms?": [[160, null]], "Why maximize the entropy?": [[4, "why-maximize-the-entropy"]], "With model discrepancy": [[124, "with-model-discrepancy"]], "Without model discrepancy": [[124, "without-model-discrepancy"]], "Workflow for Bayesian linear regression": [[35, "workflow-for-bayesian-linear-regression"]], "Yet another function": [[5, "yet-another-function"]], "Zero-based indexing": [[137, null]], "emcee": [[97, "emcee"]], "emcee:": [[154, null]], "k nearest neighbors classification": [[66, "k-nearest-neighbors-classification"]], "kNN classifier": [[66, "knn-classifier"]], "l1-norm": [[4, "l1-norm"]], "numpy arrays": [[135, "numpy-arrays"]], "p or \\log p?": [[20, null]], "p-values: when all you can do is falsify": [[20, "p-values-when-all-you-can-do-is-falsify"]], "\ud83d\udce5 Amplitude of a signal in the presence of background": [[38, null]], "\ud83d\udce5 Dealing with outliers": [[39, null]], "\ud83d\udce5 Demonstration:  Bayesian Coin Tossing": [[31, null]], "\ud83d\udce5 Demonstration: Coin tossing (with widget)": [[9, null]], "\ud83d\udce5 Demonstration: Prior PDFs for straight lines": [[6, null]], "\ud83d\udce5 Demonstration: Reading Data and fitting": [[134, null]], "\ud83d\udce5 Demonstration: Sum of normal variables squared": [[30, null]], "\ud83d\udce5 Distributions of Randomly-Initialized ANNs": [[130, null]], "\ud83d\udce5 Exercise: Jupyter Notebooks and Python": [[135, null]], "\ud83d\udce5 Exercise: Linear algebra operations with NumPy": [[137, null]], "\ud83d\udce5 Exercise: Python lists and iterations": [[136, null]], "\ud83d\udce5 Exploring PDFs": [[18, null]], "\ud83d\udce5 Linear algebra games including SVD for PCA": [[128, null]], "\ud83d\udce5 Making a simple widget-based UI": [[133, null]], "\ud83d\udce5 Maximum Entropy for reconstructing a function from its moments": [[5, null]], "\ud83d\udce5 Model discrepancy example: The ball-drop experiment": [[124, null]], "\ud83d\udce5 Parameter estimation example: Gaussian noise and averages I": [[40, null]], "\ud83d\udce5 Parameter estimation example: fitting a straight line II": [[42, null]], "\ud83d\udce5 Radioactive lighthouse problem": [[43, null]], "\ud83d\udce5 Visualization of the Central Limit Theorem": [[34, null]]}, "docnames": ["LearningFromData-content/Backmatter/JB_tests", "LearningFromData-content/Backmatter/bibliography", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/Assigning", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/IgnorancePDF", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt2", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt_Function_Reconstruction", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/demo-straight_lines", "LearningFromData-content/BayesianStatistics/BayesianBasics/BayesianAdvantages", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_epistemology", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_updating_coinflip_interactive", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-01-coin-tossing-frequentists-and-bayesaians", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-02-when-do-priors-matter-when-don-t-they-matter", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-03-computing-the-posterior-analytically", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-04-degree-of-belief-credibility-intervals-vs-frequentist-1-sigm", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-05-take-aways-and-follow-up-questions-from-coin-flipping", "LearningFromData-content/BayesianStatistics/BayesianBasics/DataModelsPredictions", "LearningFromData-content/BayesianStatistics/BayesianBasics/ErrorPropagation", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs_followups", "LearningFromData-content/BayesianStatistics/BayesianBasics/Gaussians", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-01-statements", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-02-manipulating-probabilities-bayesian-rules-of-probability-as", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-03-probability-density-functions", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-04-summary", "LearningFromData-content/BayesianStatistics/BayesianBasics/MoreBayesTheorem", "LearningFromData-content/BayesianStatistics/BayesianBasics/Posteriors", "LearningFromData-content/BayesianStatistics/BayesianBasics/RootBayesianBasics", "LearningFromData-content/BayesianStatistics/BayesianBasics/UsingBayes", "LearningFromData-content/BayesianStatistics/BayesianBasics/chi_squared_tests", "LearningFromData-content/BayesianStatistics/BayesianBasics/demo-BayesianBasics", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_medical_example_by_Bayes", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_sum_product_rule", "LearningFromData-content/BayesianStatistics/BayesianBasics/visualization_of_CLT", "LearningFromData-content/BayesianStatistics/BayesianLinearRegression/BayesianLinearRegression_rjf", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/Exercises_parameter_estimation", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/Interpreting2Dposteriors", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/amplitude_in_presence_of_background", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/dealing_with_outliers", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_Gaussian_noise", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_I", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_II", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/radioactive_lighthouse_exercise", "LearningFromData-content/BayesianStatistics/BayesianWorkflow/BayesianWorkflow", "LearningFromData-content/BayesianStatistics/ComputationalBayes/AdvancedMCMC", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesFast", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesLinear", "LearningFromData-content/BayesianStatistics/ComputationalBayes/extra_RBM_emulators", "LearningFromData-content/BayesianStatistics/ModelMixing/model_mixing", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/Evidence_for_model_EFT_coefficients", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/MCMC-parallel-tempering_ptemcee_vs_zeus", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/computing_evidence", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/two_model_evidence", "LearningFromData-content/BayesianStatistics/ModelSelection/ModelSelection", "LearningFromData-content/BayesianStatistics/Multimodel_inference", "LearningFromData-content/BayesianStatistics/RootAdvancedMethods", "LearningFromData-content/Intro/About", "LearningFromData-content/Intro/Introduction", "LearningFromData-content/Intro/Introduction/sec-01-physicist-s-perspective", "LearningFromData-content/Intro/Introduction/sec-02-bayesian-workflow", "LearningFromData-content/Intro/Introduction/sec-03-machine-learning", "LearningFromData-content/Intro/Introduction/sec-04-virtues", "LearningFromData-content/Intro/Invitation", "LearningFromData-content/MachineLearning/ANN/DataBiasFairness", "LearningFromData-content/MachineLearning/ANN/MachineLearning", "LearningFromData-content/MachineLearning/ANN/MachineLearningExamples", "LearningFromData-content/MachineLearning/ANN/ModelValidation", "LearningFromData-content/MachineLearning/ANN/NeuralNet", "LearningFromData-content/MachineLearning/ANN/NeuralNet/NeuralNetBackProp", "LearningFromData-content/MachineLearning/ANN/NeuralNet/demo-NeuralNet", "LearningFromData-content/MachineLearning/ANN/NeuralNet/exercises_LogReg_NeuralNet", "LearningFromData-content/MachineLearning/ANN/Neural_Network_for_simple_function_in_PyTorch", "LearningFromData-content/MachineLearning/BNN/bnn", "LearningFromData-content/MachineLearning/BNN/demo-bnn", "LearningFromData-content/MachineLearning/BNN/exercises_BNN", "LearningFromData-content/MachineLearning/CNN/cnn", "LearningFromData-content/MachineLearning/CNN/demo-cnn", "LearningFromData-content/MachineLearning/GP/BUQ/Gaussian_processes_exercises", "LearningFromData-content/MachineLearning/GP/BUQ/demo-GaussianProcesses", "LearningFromData-content/MachineLearning/GP/BUQ/lecture_20", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_noisy_targets", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_prior_posterior", "LearningFromData-content/MachineLearning/GP/CF/demo-GaussianProcesses", "LearningFromData-content/MachineLearning/GP/CF/exercise_GP_GPy", "LearningFromData-content/MachineLearning/GP/GPy_demos", "LearningFromData-content/MachineLearning/GP/GaussianProcesses", "LearningFromData-content/MachineLearning/GP/RootGP", "LearningFromData-content/MachineLearning/GP/Sklearn_demos", "LearningFromData-content/MachineLearning/LogReg/LogReg", "LearningFromData-content/MachineLearning/RootML", "LearningFromData-content/Mini-projects/Mini-project_IIb_overview", "LearningFromData-content/Mini-projects/RootMiniProjects", "LearningFromData-content/Mini-projects/mini-project_IIIa_bayesian_optimization", "LearningFromData-content/Mini-projects/mini-project_IIIb_Bayesian_neural_networks_from_demo", "LearningFromData-content/Mini-projects/mini-project_I_toy_model_of_EFT", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIa", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIb_How_many_lines_ptemcee", "LearningFromData-content/ModelingOptimization/GradientDescent", "LearningFromData-content/ModelingOptimization/LinearModels", "LearningFromData-content/ModelingOptimization/LinearModels/sec-01-definition-of-linear-models", "LearningFromData-content/ModelingOptimization/LinearModels/sec-02-regression-analysis-with-linear-models", "LearningFromData-content/ModelingOptimization/LinearModels/sec-03-ordinary-linear-regression-warmup", "LearningFromData-content/ModelingOptimization/LinearModels/sec-04-ordinary-linear-regression-in-practice", "LearningFromData-content/ModelingOptimization/LinearModels/sec-05-solutions", "LearningFromData-content/ModelingOptimization/MathematicalOptimization", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-01-gradient-descent-optimization", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-02-batch-stochastic-and-mini-batch-gradient-descent", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-03-adaptive-gradient-descent-algorithms", "LearningFromData-content/ModelingOptimization/OverviewModeling", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-01-notation", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-02-models-in-science", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-03-parametric-versus-non-parametric-models", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-04-linear-versus-non-linear-models", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-05-regression-analysis-optimization-versus-inference", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-06-exercises", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-07-solutions", "LearningFromData-content/ModelingOptimization/RootScientificModeling", "LearningFromData-content/OtherTopics/ANNFT", "LearningFromData-content/OtherTopics/DiscrepancyModels", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-01-koh-and-boh-discrepancy-models", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-02-framework", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-03-the-ball-drop-model", "LearningFromData-content/OtherTopics/Emulators", "LearningFromData-content/OtherTopics/MD_balldrop_v1", "LearningFromData-content/OtherTopics/RootOtherTopics", "LearningFromData-content/OtherTopics/SVD", "LearningFromData-content/OtherTopics/Student_t_distribution_from_Gaussians", "LearningFromData-content/OtherTopics/linear_algebra_games_including_SVD", "LearningFromData-content/OtherTopics/qbism", "LearningFromData-content/OtherTopics/random_initialized_ANN_vs_width", "LearningFromData-content/Reference/Statistics", "LearningFromData-content/Setup/RootGettingStarted", "LearningFromData-content/Setup/Simple_widgets_v1", "LearningFromData-content/Setup/demo-Intro", "LearningFromData-content/Setup/exercise_Intro_01_Jupyter_Python", "LearningFromData-content/Setup/exercise_Intro_02_Jupyter_Python", "LearningFromData-content/Setup/exercise_Intro_03_Numpy", "LearningFromData-content/Setup/installing_anaconda", "LearningFromData-content/Setup/more_python_and_jupyter", "LearningFromData-content/Setup/setting_up", "LearningFromData-content/Setup/using_github", "LearningFromData-content/StochasticProcesses/Advanced_MCMC", "LearningFromData-content/StochasticProcesses/BUQ/Assignment_extending_radioactive_lighthouse", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-diagnostics", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-random-walk-and-sampling", "LearningFromData-content/StochasticProcesses/BUQ/Metropolis_Poisson_example", "LearningFromData-content/StochasticProcesses/BUQ/intuition_sampling", "LearningFromData-content/StochasticProcesses/BUQ/parameter_estimation_Gaussian_noise-2", "LearningFromData-content/StochasticProcesses/BUQ2/HMC_intro_BUQ", "LearningFromData-content/StochasticProcesses/BUQ2/Liouville_theorem_visualization", "LearningFromData-content/StochasticProcesses/BUQ2/Orbital_eqs_with_different_algorithms", "LearningFromData-content/StochasticProcesses/BUQ2/PyMC_intro_updated", "LearningFromData-content/StochasticProcesses/BUQ2/parameter_estimation_Gaussian_noise_compare_samplers", "LearningFromData-content/StochasticProcesses/MCMC", "LearningFromData-content/StochasticProcesses/MCMC_intro_BUQ", "LearningFromData-content/StochasticProcesses/MCMC_overview", "LearningFromData-content/StochasticProcesses/MarkovChains", "LearningFromData-content/StochasticProcesses/Other_samplers", "LearningFromData-content/StochasticProcesses/OverviewIntroPyMC", "LearningFromData-content/StochasticProcesses/Recap_BUQ", "LearningFromData-content/StochasticProcesses/RootMCMC", "LearningFromData-content/StochasticProcesses/StochasticProcesses", "LearningFromData-content/StochasticProcesses/demo-MCMC", "LearningFromData-content/StochasticProcesses/zeus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["LearningFromData-content/Backmatter/JB_tests.md", "LearningFromData-content/Backmatter/bibliography.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/Assigning.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/IgnorancePDF.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt2.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt_Function_Reconstruction.ipynb", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/demo-straight_lines.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/BayesianAdvantages.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_epistemology.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_updating_coinflip_interactive.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-01-coin-tossing-frequentists-and-bayesaians.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-02-when-do-priors-matter-when-don-t-they-matter.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-03-computing-the-posterior-analytically.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-04-degree-of-belief-credibility-intervals-vs-frequentist-1-sigm.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-05-take-aways-and-follow-up-questions-from-coin-flipping.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/DataModelsPredictions.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/ErrorPropagation.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs_followups.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Gaussians.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-01-statements.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-02-manipulating-probabilities-bayesian-rules-of-probability-as.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-03-probability-density-functions.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-04-summary.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/MoreBayesTheorem.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Posteriors.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/RootBayesianBasics.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/UsingBayes.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/chi_squared_tests.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/demo-BayesianBasics.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_medical_example_by_Bayes.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_sum_product_rule.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/visualization_of_CLT.ipynb", "LearningFromData-content/BayesianStatistics/BayesianLinearRegression/BayesianLinearRegression_rjf.md", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/Exercises_parameter_estimation.md", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/Interpreting2Dposteriors.md", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/amplitude_in_presence_of_background.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/dealing_with_outliers.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_Gaussian_noise.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_I.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_II.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/radioactive_lighthouse_exercise.ipynb", "LearningFromData-content/BayesianStatistics/BayesianWorkflow/BayesianWorkflow.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/AdvancedMCMC.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesFast.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesLinear.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/extra_RBM_emulators.md", "LearningFromData-content/BayesianStatistics/ModelMixing/model_mixing.md", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/Evidence_for_model_EFT_coefficients.ipynb", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/MCMC-parallel-tempering_ptemcee_vs_zeus.ipynb", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/computing_evidence.md", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/two_model_evidence.md", "LearningFromData-content/BayesianStatistics/ModelSelection/ModelSelection.md", "LearningFromData-content/BayesianStatistics/Multimodel_inference.md", "LearningFromData-content/BayesianStatistics/RootAdvancedMethods.md", "LearningFromData-content/Intro/About.md", "LearningFromData-content/Intro/Introduction.md", "LearningFromData-content/Intro/Introduction/sec-01-physicist-s-perspective.md", "LearningFromData-content/Intro/Introduction/sec-02-bayesian-workflow.md", "LearningFromData-content/Intro/Introduction/sec-03-machine-learning.md", "LearningFromData-content/Intro/Introduction/sec-04-virtues.md", "LearningFromData-content/Intro/Invitation.md", "LearningFromData-content/MachineLearning/ANN/DataBiasFairness.md", "LearningFromData-content/MachineLearning/ANN/MachineLearning.md", "LearningFromData-content/MachineLearning/ANN/MachineLearningExamples.md", "LearningFromData-content/MachineLearning/ANN/ModelValidation.md", "LearningFromData-content/MachineLearning/ANN/NeuralNet.md", "LearningFromData-content/MachineLearning/ANN/NeuralNet/NeuralNetBackProp.md", "LearningFromData-content/MachineLearning/ANN/NeuralNet/demo-NeuralNet.ipynb", "LearningFromData-content/MachineLearning/ANN/NeuralNet/exercises_LogReg_NeuralNet.ipynb", "LearningFromData-content/MachineLearning/ANN/Neural_Network_for_simple_function_in_PyTorch.ipynb", "LearningFromData-content/MachineLearning/BNN/bnn.md", "LearningFromData-content/MachineLearning/BNN/demo-bnn.ipynb", "LearningFromData-content/MachineLearning/BNN/exercises_BNN.ipynb", "LearningFromData-content/MachineLearning/CNN/cnn.md", "LearningFromData-content/MachineLearning/CNN/demo-cnn.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/Gaussian_processes_exercises.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/demo-GaussianProcesses.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/lecture_20.md", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_noisy_targets.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_prior_posterior.ipynb", "LearningFromData-content/MachineLearning/GP/CF/demo-GaussianProcesses.ipynb", "LearningFromData-content/MachineLearning/GP/CF/exercise_GP_GPy.ipynb", "LearningFromData-content/MachineLearning/GP/GPy_demos.md", "LearningFromData-content/MachineLearning/GP/GaussianProcesses.md", "LearningFromData-content/MachineLearning/GP/RootGP.md", "LearningFromData-content/MachineLearning/GP/Sklearn_demos.md", "LearningFromData-content/MachineLearning/LogReg/LogReg.md", "LearningFromData-content/MachineLearning/RootML.md", "LearningFromData-content/Mini-projects/Mini-project_IIb_overview.md", "LearningFromData-content/Mini-projects/RootMiniProjects.md", "LearningFromData-content/Mini-projects/mini-project_IIIa_bayesian_optimization.ipynb", "LearningFromData-content/Mini-projects/mini-project_IIIb_Bayesian_neural_networks_from_demo.ipynb", "LearningFromData-content/Mini-projects/mini-project_I_toy_model_of_EFT.ipynb", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIa.ipynb", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIb_How_many_lines_ptemcee.ipynb", "LearningFromData-content/ModelingOptimization/GradientDescent.md", "LearningFromData-content/ModelingOptimization/LinearModels.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-01-definition-of-linear-models.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-02-regression-analysis-with-linear-models.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-03-ordinary-linear-regression-warmup.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-04-ordinary-linear-regression-in-practice.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-05-solutions.md", "LearningFromData-content/ModelingOptimization/MathematicalOptimization.md", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-01-gradient-descent-optimization.md", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-02-batch-stochastic-and-mini-batch-gradient-descent.md", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-03-adaptive-gradient-descent-algorithms.md", "LearningFromData-content/ModelingOptimization/OverviewModeling.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-01-notation.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-02-models-in-science.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-03-parametric-versus-non-parametric-models.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-04-linear-versus-non-linear-models.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-05-regression-analysis-optimization-versus-inference.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-06-exercises.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-07-solutions.md", "LearningFromData-content/ModelingOptimization/RootScientificModeling.md", "LearningFromData-content/OtherTopics/ANNFT.md", "LearningFromData-content/OtherTopics/DiscrepancyModels.md", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-01-koh-and-boh-discrepancy-models.md", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-02-framework.md", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-03-the-ball-drop-model.md", "LearningFromData-content/OtherTopics/Emulators.md", "LearningFromData-content/OtherTopics/MD_balldrop_v1.ipynb", "LearningFromData-content/OtherTopics/RootOtherTopics.md", "LearningFromData-content/OtherTopics/SVD.md", "LearningFromData-content/OtherTopics/Student_t_distribution_from_Gaussians.ipynb", "LearningFromData-content/OtherTopics/linear_algebra_games_including_SVD.ipynb", "LearningFromData-content/OtherTopics/qbism.md", "LearningFromData-content/OtherTopics/random_initialized_ANN_vs_width.ipynb", "LearningFromData-content/Reference/Statistics.md", "LearningFromData-content/Setup/RootGettingStarted.md", "LearningFromData-content/Setup/Simple_widgets_v1.ipynb", "LearningFromData-content/Setup/demo-Intro.ipynb", "LearningFromData-content/Setup/exercise_Intro_01_Jupyter_Python.ipynb", "LearningFromData-content/Setup/exercise_Intro_02_Jupyter_Python.ipynb", "LearningFromData-content/Setup/exercise_Intro_03_Numpy.ipynb", "LearningFromData-content/Setup/installing_anaconda.md", "LearningFromData-content/Setup/more_python_and_jupyter.md", "LearningFromData-content/Setup/setting_up.md", "LearningFromData-content/Setup/using_github.md", "LearningFromData-content/StochasticProcesses/Advanced_MCMC.md", "LearningFromData-content/StochasticProcesses/BUQ/Assignment_extending_radioactive_lighthouse.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-diagnostics.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-random-walk-and-sampling.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/Metropolis_Poisson_example.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/intuition_sampling.md", "LearningFromData-content/StochasticProcesses/BUQ/parameter_estimation_Gaussian_noise-2.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/HMC_intro_BUQ.md", "LearningFromData-content/StochasticProcesses/BUQ2/Liouville_theorem_visualization.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/Orbital_eqs_with_different_algorithms.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/PyMC_intro_updated.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/parameter_estimation_Gaussian_noise_compare_samplers.ipynb", "LearningFromData-content/StochasticProcesses/MCMC.md", "LearningFromData-content/StochasticProcesses/MCMC_intro_BUQ.md", "LearningFromData-content/StochasticProcesses/MCMC_overview.md", "LearningFromData-content/StochasticProcesses/MarkovChains.md", "LearningFromData-content/StochasticProcesses/Other_samplers.md", "LearningFromData-content/StochasticProcesses/OverviewIntroPyMC.md", "LearningFromData-content/StochasticProcesses/Recap_BUQ.md", "LearningFromData-content/StochasticProcesses/RootMCMC.md", "LearningFromData-content/StochasticProcesses/StochasticProcesses.md", "LearningFromData-content/StochasticProcesses/demo-MCMC.ipynb", "LearningFromData-content/StochasticProcesses/zeus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 3, 4, 8, 9, 11, 12, 15, 16, 17, 18, 20, 22, 23, 24, 26, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 57, 58, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 93, 95, 96, 97, 98, 99, 101, 102, 103, 111, 115, 116, 118, 120, 121, 122, 124, 126, 127, 128, 129, 130, 131, 134, 135, 136, 138, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 160, 162, 163], "0": [0, 1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 15, 16, 17, 18, 20, 22, 23, 25, 26, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 89, 93, 95, 96, 97, 98, 100, 101, 103, 105, 108, 115, 121, 122, 124, 126, 127, 128, 130, 131, 133, 134, 135, 136, 137, 138, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 160, 162, 163, 164], "00": [1, 40, 51, 67, 70, 78, 79, 84, 94, 124, 128, 131, 146, 148, 151, 152, 153, 162, 163], "000": [32, 33, 44, 45, 76, 77, 134, 146, 152, 157, 160, 162, 163], "0000": 72, "000000": 134, "00000000e": [79, 128], "00001": 1, "000054": 134, "00008": 1, "00009": 134, "0001": [32, 71], "00011": 134, "00012": 134, "00040356e": 79, "00046": 134, "00049": 134, "0005": 79, "0005735": 40, "00088142": 40, "000e": [124, 128], "001": [1, 78, 83, 84, 108, 131, 151, 152], "00107510802066753": 1, "00128795": 128, "0015": 50, "001mb": 78, "002": [134, 153], "00227556": 152, "00297317": 40, "0029802": 40, "003": [128, 152], "003100": 134, "003620": 134, "0038": 77, "00398911": 40, "004": [5, 128, 131, 152, 162], "0040": 130, "00400084": 40, "00429143": [148, 153], "0043": 32, "004752": 79, "00484214": 152, "005": [45, 79, 83, 144, 147, 152, 163], "00510316": 128, "00560623": [148, 153], "00568668": 40, "005903716602368191": 78, "006": 152, "00634733e": 152, "007": 128, "00727646693": 134, "007315": 134, "007825": 134, "00788": 73, "00796648": 40, "00806543": 40, "0084806e": 77, "00854895": 40, "008664": 134, "0086649156": 134, "009": 1, "0091265": 103, "0094": 77, "00941": 93, "00978733": 40, "009e": 124, "00arviz_vers": 152, "01": [3, 17, 18, 34, 35, 38, 43, 50, 66, 67, 68, 70, 71, 72, 74, 77, 78, 79, 82, 84, 93, 94, 96, 124, 131, 152, 153, 162, 163], "01012718": 40, "010902": 134, "011": 144, "01120706": 40, "01125": 1, "012": 163, "013": [33, 162], "01335268": 40, "01382247": 40, "013e": 124, "014": 32, "014004": 1, "014101": 134, "01431045": 128, "01480651": 103, "015": 162, "0159663": 152, "01652757": 40, "017": [1, 128, 162], "01710817": 128, "01715": 1, "01716473": 40, "01740941": 40, "01795589": 40, "01818182": 128, "018232": 134, "01855247": 40, "01900195": 128, "01963464": 152, "01e": 82, "01it": 153, "02": [1, 38, 43, 45, 77, 78, 79, 81, 83, 96, 124, 127, 152, 153, 162, 163], "020": [1, 163], "02010975": 40, "0202": 130, "021": 162, "02124813": 40, "02186284": 40, "022": 1, "022227": 40, "02227172": [148, 153], "023": [32, 128, 152], "024": 163, "02400493e": 152, "025": 134, "02507": 1, "02599999": 40, "026218253x": 1, "02673241": 40, "027": [39, 144], "028": 39, "02827408": [148, 153], "02920769e": 128, "02941762": 40, "02955388": 152, "029733": 134, "03": [1, 4, 51, 72, 77, 79, 84, 96, 124, 152, 153, 163], "030002": 134, "030003": [1, 134], "0303": 83, "03062645": 128, "03084561": 127, "03085711": 40, "031": 128, "03224": 134, "03241329": 128, "032501": 1, "03261455": 40, "03298378": 40, "033": 128, "0334508": 40, "03368687": 40, "034": [128, 152], "034047": 134, "03431": 1, "0343265": 71, "034328": [79, 83], "03493433": [148, 153], "03494359": 40, "035": 128, "035002": 1, "0353601": 40, "035909": 134, "036111": 103, "037": [128, 131], "0370": 1, "03703898": 40, "0387364": 40, "0388246": 40, "03998411": 131, "03arrai": 152, "03e": 96, "04": [34, 40, 72, 77, 78, 96, 124, 131, 144, 152, 153, 163], "04008915": 40, "04011": 1, "04037143": 40, "041": 128, "04183091": 40, "042": 39, "04221375": 40, "04278640498515118": 5, "04279159257882259": 5, "04286718": 128, "0429e": 72, "043": [39, 162], "04359686": 40, "04366899": 40, "044001": 87, "0441": 127, "044334": 134, "04444209": 40, "04457474": 40, "04499441": 40, "045": 30, "04527": 1, "0453": 72, "04548788": [148, 153], "04584462": 128, "046": [128, 152], "04618286": [148, 153], "0462994": 40, "04631165e": 152, "0465673": 40, "047": 162, "0476": 72, "04789471": 40, "0479379": 40, "048": 128, "0484": 1, "048920": 134, "049": 39, "04906169": 40, "0490804": 40, "04909075": 40, "04912": 1, "04921829": 40, "04938272": 154, "04944746": 128, "049462": 134, "04it": 153, "04t14": 152, "05": [9, 18, 20, 43, 47, 50, 51, 66, 72, 77, 78, 82, 83, 84, 95, 96, 97, 124, 127, 131, 152, 153, 163], "050": 39, "05031709": 40, "05080775": 40, "051": 128, "05117344": 40, "05132077": 40, "05156034": 40, "052e": 124, "053": 4, "05340954": 40, "054": 134, "05418781": 134, "05424": 1, "0546241": 40, "05495304": 40, "055": 128, "05528": 1, "055676": 134, "056": [9, 152], "0562e": 72, "05635552": 40, "05667659": 40, "057121": 40, "05713879": 128, "05741082": 40, "058": 20, "05862823": 128, "0587121": 50, "05931904": 40, "05it": 153, "06": [39, 70, 74, 82, 83, 94, 96, 152, 153, 163], "06032751": 40, "060349": 134, "06056664": [148, 153], "0607502": 40, "061679": 134, "0617284": 154, "06185497": 128, "063443": 134, "06370611": 128, "063724": 134, "0637e": 72, "06423057": 40, "06477355": 128, "065": [128, 152], "065026": 134, "06511669": 152, "06578332": 40, "06581816": 40, "065e": 124, "066": [4, 152], "06608534": 40, "067": 82, "06798079e": 66, "068": [128, 134], "06802716": 134, "0684": 50, "06881686": 128, "06897162": 40, "06898597": 40, "069584": 134, "06996554": 40, "06arrai": 152, "06it": 153, "07": [4, 70, 78, 79, 83, 96, 131, 153, 163], "070": 4, "070043": 134, "07011185": 128, "07084": 152, "07090": 1, "07125243": 40, "0713": 134, "0719842": 128, "072": 128, "0722519": 40, "07272727": 128, "07291282": 35, "073": 153, "07312806": 40, "074001": 50, "07432055": 40, "0752e": 72, "0761167e": 77, "07638048": 40, "077": 128, "07734007": 40, "07782113": 40, "078": [9, 153], "07941624": 153, "07960373": 127, "08": [70, 79, 84, 94, 96, 148, 152, 153, 163], "0803": 1, "08075099": 40, "0809271": 40, "08155996": 40, "08176782": 40, "08183677": 152, "082875": 134, "083527": 134, "08352721390288316": 134, "08392411e": 152, "08397362": 128, "08420815": 40, "08442820e": 79, "08457563": 40, "08541926": 128, "08601": 1, "08646441": 40, "0868086": 152, "087887": 134, "087e": 124, "088": 128, "0883": 77, "08958761": [148, 153], "08968641": 40, "08972912": 40, "08arrai": 152, "08it": 153, "09": [30, 32, 70, 83, 96, 152, 153], "091": 152, "09169": 1, "09499611": 40, "09542509": 40, "0955536": 128, "09574677": 40, "096": 128, "097": 128, "09736301": 152, "09811225": 40, "09836551": 40, "09899633": 40, "099": 128, "09914922": [148, 153], "09it": 153, "0_": 152, "0_1": 1, "0arrai": 152, "0e": [51, 67, 150, 151], "0f": [6, 42, 70, 77, 135], "0inference_librari": 152, "0l": 68, "0m": [78, 84], "0px": 133, "0th": 77, "1": [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 20, 22, 23, 24, 25, 26, 28, 30, 31, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 60, 62, 64, 65, 69, 70, 71, 72, 73, 74, 76, 77, 79, 81, 82, 83, 89, 91, 95, 96, 97, 98, 100, 101, 102, 103, 106, 107, 108, 111, 113, 114, 115, 118, 121, 122, 124, 126, 127, 128, 134, 135, 136, 137, 138, 143, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 159, 160, 163, 164], "10": [0, 1, 3, 4, 6, 9, 17, 18, 26, 30, 31, 32, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 50, 51, 52, 54, 66, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 94, 96, 97, 103, 108, 124, 126, 128, 130, 131, 133, 134, 135, 137, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 160, 162, 163], "100": [0, 3, 4, 6, 9, 16, 17, 18, 30, 34, 35, 37, 38, 39, 41, 42, 43, 46, 51, 52, 66, 67, 68, 70, 71, 72, 74, 77, 79, 80, 82, 83, 87, 97, 124, 126, 127, 128, 131, 134, 137, 138, 144, 145, 146, 148, 150, 151, 152, 153, 154, 155, 159, 160, 162, 163], "1000": [6, 9, 18, 26, 30, 31, 34, 35, 39, 40, 41, 42, 43, 51, 66, 72, 74, 79, 83, 96, 97, 103, 128, 131, 134, 135, 138, 144, 145, 146, 147, 148, 152, 153, 160, 163], "10000": [6, 9, 18, 32, 34, 39, 42, 43, 71, 83, 131, 145, 152, 162], "100000": [6, 18, 34, 42, 83, 131, 152, 163], "1000000": 18, "1000010": 152, "10000coordin": 152, "1000xarrai": 152, "10025514": 40, "100480": 70, "1007": 1, "100_000": 152, "100coordin": 152, "100j": [74, 94], "101": [130, 136, 162], "1010002": 40, "10118794": 40, "10131681": 40, "1016": 1, "10165": 1, "1017": 1, "101770": 70, "10177778": 128, "102001": 1, "10215718": 152, "1022": 127, "10223673": 40, "1023": 127, "1024": [51, 77, 97, 127], "1026": 127, "1027": 127, "1028": 127, "1029": 127, "1030": 127, "1031": 127, "1032": 127, "1033": 127, "1034": 127, "1035": 127, "1036": 127, "10363908": 40, "1037": 127, "1038": 1, "104": [1, 144], "10405339": 40, "10417433": 40, "104411": 134, "10473305": 40, "105": [1, 9], "1056643": 128, "10581": 87, "1058809": [1, 45], "10622272": 40, "10630779": 152, "106431": 134, "1066": 128, "107": [128, 152], "10717545": 40, "10734329": 40, "10735333": 40, "10770823": [148, 153], "108": [96, 134], "1080": 1, "10803082": 40, "10836462": 152, "10854853": [148, 153], "1086": 1, "10861676": 40, "1088": 1, "1092931": 1, "1093": 127, "1094027": 40, "10944442": 40, "1095": 127, "1096": 127, "1097": 127, "10972845": 40, "1098": 127, "1099": 127, "10_000": 152, "10e": 96, "10it": 153, "11": [26, 31, 35, 38, 39, 40, 41, 43, 47, 51, 68, 74, 78, 79, 80, 82, 84, 87, 94, 96, 97, 101, 103, 106, 121, 122, 124, 127, 134, 135, 137, 145, 147, 148, 149, 152, 153, 154, 155, 162, 163], "110": 134, "1100": [72, 127], "1101": 127, "11017061": 152, "1102": 127, "1102748": 128, "1103": 1, "11060505": 40, "111": [71, 153], "1110567": 40, "1111": 1, "1112": 134, "11133727": 40, "112": 162, "11236849": 40, "11237104": 40, "11243841": 131, "11248774": 40, "1132": 72, "11327453": 128, "1137": 1, "1139": 64, "11438298": 40, "115": [20, 153, 157], "1157018": 40, "11584111": 40, "116": [9, 144], "1163464": 152, "117430": 134, "1176": [51, 153], "11762398": 128, "118": [42, 144], "1181334": 40, "118318": 134, "11858913": 40, "1186": 1, "11900865": 40, "1194224": 40, "1196": 1, "11981094": 40, "11it": 153, "12": [0, 1, 5, 6, 9, 16, 17, 18, 26, 31, 34, 35, 38, 39, 40, 42, 44, 45, 50, 51, 53, 66, 67, 68, 73, 74, 76, 77, 78, 79, 80, 83, 84, 87, 94, 95, 96, 97, 124, 127, 128, 131, 133, 134, 137, 144, 145, 146, 148, 151, 152, 153, 154, 163], "120": [76, 127, 130, 153], "1200": [1, 42, 72], "1201": 89, "12015895": 40, "121": [1, 153], "1212": 1, "1214": 1, "12141771": 40, "12182127": 40, "122": [77, 144, 153], "12214158": 40, "122282": 134, "1223": 131, "12232832": 40, "12270807": 128, "12271848": 40, "123": 145, "1234": 18, "12341216": 40, "12369125": [148, 153], "124": [1, 131, 134], "12475615": 128, "1249115293": 152, "125": [1, 43], "1253235": 40, "126": [128, 131, 144], "12617770e": 152, "12683902": 40, "126e": 152, "127": [35, 128], "1278": 42, "127812": 134, "128": [43, 70, 76], "12837699": 40, "1287": 42, "12878515": [148, 153], "1290": 70, "12910158": 40, "12911235": 40, "12948391": 40, "12999178": 40, "12it": 153, "13": [0, 1, 5, 17, 33, 35, 38, 40, 52, 54, 57, 67, 68, 77, 78, 79, 82, 84, 96, 128, 130, 134, 147, 152, 153, 154, 162, 163], "1300": 72, "1304781454370705": 124, "130k": 131, "13135": 134, "13162939": 40, "13178285e": 152, "13219435": 5, "13221278": 40, "13223132": 40, "13224778": 40, "1327083": [148, 153], "132e": 152, "133": [51, 153], "13376944": 40, "1340482": 40, "13437312": 40, "13442538": 152, "13444589": 124, "134e": 124, "135": 127, "13513688": [148, 153], "136": [42, 127], "1361": 1, "13622942": 5, "1365": 1, "1369": 64, "13692407": 128, "137": [42, 127], "1375": 72, "13767682": 128, "13770121": 40, "13782807": 40, "138": 127, "13850032": 128, "13868364": 40, "139": [64, 96, 127, 153], "13917682": 152, "13it": 153, "14": [1, 5, 9, 20, 26, 31, 38, 39, 43, 45, 47, 54, 70, 71, 73, 79, 83, 96, 127, 128, 134, 147, 151, 152, 153], "140": [0, 17, 153], "1400": 72, "14010988": 40, "14039544": 40, "14048406": 40, "140px": 133, "1411": 41, "1412": 1, "14164054": 40, "14189485": 71, "142": 152, "14201814": 40, "14225137": 40, "14250318": 40, "1426": 72, "14295123": 128, "14381452": [148, 153], "144": [9, 31, 128], "14472371": 40, "1449": 72, "144993": 134, "145": [128, 153, 157], "1454651347": 152, "14548": 1, "1462": 153, "14676526": 40, "14690038": 40, "147": 128, "14854434": 40, "1487": 153, "14961103": 128, "14it": 153, "15": [1, 5, 17, 18, 20, 26, 34, 35, 37, 38, 39, 41, 42, 43, 51, 53, 54, 66, 77, 79, 83, 94, 96, 127, 128, 131, 134, 147, 150, 152, 153, 162], "150": [34, 39, 124, 153], "1500": 72, "15000": [39, 145], "15001628": 40, "15016552": 128, "15032639268769732": 78, "1505": 1, "15058409": 131, "1506": 1, "15078772": 128, "1509": 1, "150px": 9, "1514e": 72, "15259914": 40, "15262604": 128, "153036": 134, "15380938891512716": 84, "153e": 124, "15431": 1, "15452884": 131, "15479436": 40, "15528789": 40, "156": 134, "15626385": 40, "1563": 77, "1567906": 128, "15697499": 152, "157": [134, 153], "1570": 77, "158": 134, "159": [134, 153], "15908203": 152, "1591e": 72, "1593": 1, "15it": 153, "16": [5, 18, 26, 34, 38, 39, 41, 42, 43, 51, 76, 83, 95, 96, 97, 124, 128, 130, 131, 133, 134, 136, 144, 147, 148, 150, 152, 153, 157, 162, 163], "160": [134, 153], "1600": [72, 124, 128], "16000": [146, 163], "16001109": 40, "16003707": 40, "1601": 1, "1603": 73, "16033857": 40, "16056499": 40, "160kb": 152, "16128569": 40, "1614": 1, "16143998": 40, "1623": 1, "162999": 134, "16363636": 128, "16384": 76, "164": 128, "1646": 153, "16466507": 40, "165": 153, "1662312": 152, "1663e": 72, "16651": 152, "167": 31, "16707517": 40, "1674": 1, "16754706": 152, "16760465": 40, "168": 153, "169": 153, "16938243": 40, "1698281": 40, "16983114": 40, "16986926": 40, "16998901": 40, "16b": 152, "16e": 96, "16it": [51, 153], "17": [1, 33, 35, 51, 70, 83, 96, 98, 106, 128, 134, 137, 152, 153, 157, 163], "1700": 72, "1711": 1, "17111395": 127, "17137202": 40, "17195713": 40, "172": [96, 153], "173": [128, 153], "17352735": 128, "17390257": 40, "174": 153, "175": 153, "17516773": 40, "175300": 134, "1755e": 72, "176": [103, 153], "17608015": 40, "1769e": 72, "177": 153, "17718772": 40, "17753281": 40, "1778e": 72, "178": 153, "17801963736677": 124, "179": 153, "1796e": 72, "17e": 96, "17it": 153, "18": [1, 5, 9, 17, 33, 34, 38, 39, 46, 47, 66, 72, 79, 82, 94, 128, 131, 133, 137, 138, 152, 153, 163], "180": [94, 153], "1800": 72, "1800880e": 77, "1805": 111, "1809": 111, "18103874": 40, "1810401e": 77, "18228344": 152, "184": 153, "1841262e": 70, "184519": 134, "18496": 77, "185": [82, 153], "1850492": 71, "18515642": 40, "1853": 47, "1855": 72, "18553562": 40, "18557541": 40, "186": 153, "18656139": 40, "1867": 47, "18676366": 128, "18697965": 40, "187": 153, "1870": 78, "188": 153, "18843153": 153, "189": 153, "1892932": 40, "189367": 134, "189496": 134, "1896": 78, "189622": 134, "18986165": 40, "18it": 153, "18th": 8, "19": [0, 1, 5, 16, 39, 45, 66, 67, 72, 83, 97, 118, 134, 147, 152, 153, 162, 163], "190": 153, "1900": 72, "1902": 93, "1904": 87, "19069973": 40, "19091548": 40, "191": 153, "1911528": 40, "191963": 134, "192": 153, "19268607": 40, "193": 153, "1931924": 131, "19381518": 40, "19382179": 40, "1939": 54, "1943": 68, "1948": 4, "195": 1, "1950": [154, 155], "19501328": [148, 153], "1953": [127, 145], "1954": [1, 63, 127], "19540886": [148, 153], "1954606": 152, "1955": 127, "1956": 127, "1957": 127, "1960": 4, "1961": 1, "1963": 4, "19686978": 40, "197": 153, "1970": 145, "19783084": 40, "1979": [86, 109], "1980": [47, 154, 155], "19829972": 40, "1983": 47, "1984": [4, 5], "1986": 1, "1987": 1, "1988": [1, 4, 54, 64], "1989": 1, "19891788": 40, "199": 128, "1992": 1, "1994": [1, 47], "1997": 145, "19975956": 40, "19981329": 128, "19e": 96, "19it": 153, "19th": [8, 111], "1_": 68, "1_000": [81, 82, 136, 152, 153], "1_1": 68, "1_2": 68, "1_3": 68, "1_j": 68, "1_l": 68, "1a": 80, "1arrai": 152, "1b": 80, "1cm": 134, "1d": [27, 77, 124], "1darrai": 124, "1e": [42, 51, 79, 81, 82, 83, 124, 144], "1e15": 82, "1e2": 81, "1e30": 124, "1e5": 124, "1f": [18, 34, 38, 39, 41, 42, 43, 83, 97, 127, 131, 133, 136, 144, 146, 150, 151, 163], "1mgaussian_nois": [78, 84], "1mgp_regress": [78, 84], "1mlengthscal": [78, 84], "1mmat52": [78, 84], "1mmul": [78, 84], "1mrbf": [78, 84], "1msum": [78, 84], "1mvarianc": [78, 84], "1n": [53, 134], "1sampling_tim": 152, "1st": [15, 74, 94, 135], "1x": 134, "1xarrai": 152, "2": [0, 1, 3, 4, 6, 9, 13, 15, 16, 17, 18, 19, 20, 24, 25, 26, 27, 28, 31, 34, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 60, 64, 66, 67, 69, 70, 71, 72, 73, 74, 77, 79, 80, 81, 82, 83, 86, 87, 89, 91, 95, 96, 97, 98, 100, 101, 102, 103, 104, 108, 113, 114, 115, 118, 121, 122, 124, 126, 127, 128, 134, 135, 136, 137, 138, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 159, 160, 163, 164], "20": [0, 16, 17, 18, 20, 30, 33, 34, 37, 39, 41, 42, 45, 51, 52, 54, 66, 71, 72, 75, 78, 79, 84, 96, 97, 124, 127, 133, 134, 144, 146, 151, 152, 153, 154, 157, 162, 163, 164], "200": [9, 12, 34, 35, 39, 41, 42, 71, 72, 76, 79, 83, 103, 124, 130, 133, 144, 145, 151, 160], "2000": [42, 45, 51, 66, 72, 124, 144, 147, 160], "20000": [124, 130, 144, 162], "2003": [1, 57], "2004": 52, "20045251": 40, "2005": [1, 57], "2006": [1, 54, 57], "2007": 1, "2007187": 128, "2008": 1, "2009": 1, "200_000": 152, "2010": 1, "2011": 1, "2012": [1, 78, 129], "2013": [0, 1, 57, 129], "2014": 1, "2015": 1, "2016": [1, 73, 74, 79, 83, 94, 134], "2017": [1, 134, 149, 155], "2018": [1, 74, 79, 83, 94], "20183018": 40, "2019": [1, 5, 39, 40, 51, 54, 57, 74, 75, 77, 78, 79, 87, 92, 96, 144, 145, 148, 150, 153], "20199118": [148, 153], "2020": [6, 74], "20205486": 40, "2021": [1, 5, 64, 152], "2022": [1, 45, 66], "2023": 152, "2024": 79, "20243123e": 152, "2025": [51, 68, 82, 97, 124, 127, 152, 153], "20273021": 40, "2030": 78, "20303737": [148, 153], "2035808": [148, 153], "204": 134, "20433313": 134, "20437739": 40, "2048": 124, "2048px": 0, "205": 153, "205231": 134, "20563366": 128, "20596743": 152, "206": [128, 144], "2066079": 40, "206915": 40, "20779238": 131, "207888": 134, "208": 1, "20845633": 40, "2086": 153, "2088896239": 39, "20900359": 40, "20909668": 40, "20920005": 40, "209789": 134, "20_000": 152, "20px": 43, "20th": 8, "21": [1, 35, 39, 42, 44, 51, 68, 80, 83, 87, 96, 97, 138, 145, 152, 157], "2104": [1, 127], "2106": 1, "2110": 1, "21112476": 40, "2112": 1, "21150911": 131, "21208711": 40, "2121": 1, "213": 9, "2130": 42, "2135339": 40, "21364989": 128, "21397852": 128, "214": 45, "2140": 1, "21424701": 128, "21440984": 66, "214466": 40, "21502456": 128, "2153": 1, "2159": 1, "216": [1, 127, 153], "217": 127, "21726515": [148, 153], "21746553": 40, "2179409": 40, "218": 127, "21808832": 40, "21987438": 40, "22": [1, 35, 39, 42, 46, 47, 68, 72, 80, 83, 84, 86, 87, 96, 119, 127, 131, 152, 153], "220": 127, "22018852": 128, "2203": 1, "221": 127, "2210": 1, "221180": 134, "2212": 1, "222": [1, 9, 127], "22214117": 40, "222400": 134, "22243362": 40, "2228": 42, "223": 127, "22372221": 40, "224": [42, 127, 128, 153], "22440082e": 79, "2245077": 40, "2246093": 1, "22483838": 40, "22492971": 40, "225": 128, "22509772": 50, "22515585": 40, "22557254": 128, "227": 33, "22863013": [148, 153], "22895559": 40, "229": 128, "22it": 153, "23": [64, 68, 83, 96, 97, 128, 137, 152, 154, 157], "230": 32, "23009474": 40, "2305582": 40, "23066907": 5, "231": 128, "2320": 128, "23219625": 40, "23225307": 40, "232435": 134, "23249456": 40, "23269017": 40, "23289919": 40, "23333913": 40, "234": [51, 97, 144], "2344157": 40, "235": [51, 97, 128], "236": 153, "23616403": 40, "23630349": 131, "23669220e": 152, "237": [51, 97], "2373327": 40, "238": 128, "2387931": 40, "23931144": 40, "2396822455476193": 78, "23it": 153, "24": [1, 5, 35, 39, 41, 66, 79, 83, 128, 133, 134, 152, 153, 163], "240": 33, "2404": 5, "24050555": 40, "2405e": 72, "24073709": 40, "240kb": 152, "24193267": 40, "242": 153, "24266944": 40, "24294853": 152, "24313367e": 128, "24407436": 40, "24417853": 152, "24433723": 40, "24454398": [148, 153], "2446001": 152, "245": 31, "2453781259": 152, "24542285": 40, "24560206": 40, "24610704": [148, 153], "247": 144, "24787741": 152, "248": 152, "24879916": 40, "24957254": 128, "24e": 96, "25": [8, 16, 34, 37, 39, 41, 42, 47, 50, 70, 74, 77, 79, 93, 94, 95, 128, 134, 137, 145, 152, 153, 162, 163], "250": [9, 35, 74, 94, 103], "2500": [0, 17, 144], "25003038": 40, "250154": 134, "250636": 134, "251879": 134, "252": 39, "252436": 134, "25261831": 128, "25284171": 40, "25286816": 40, "253": 31, "253775": 134, "255": [70, 77], "255001": 134, "25558087": 38, "256": [43, 153], "2562": 42, "25647226": [148, 153], "2566277": [148, 153], "257": 152, "258": [51, 97, 128, 134], "25839": 5, "259": [51, 97], "2593": 72, "2593743975": 38, "25945479": 131, "25976847": 128, "26": [42, 47, 73, 79, 134, 138, 152, 153], "2607": 77, "261": [51, 97, 153], "262": [51, 97], "26246745": 40, "26271037": 40, "26299534e": 152, "2632": 1, "264": [51, 97, 134], "264421": 134, "26494970e": 152, "265": 134, "2650": 72, "26551159": [148, 153], "2656424": 40, "266": 134, "26607016": [148, 153], "26666667": 154, "2667284": 40, "267": 33, "2680305": [148, 153], "2684253": 1, "26846902": 40, "269": [128, 134], "2693": 1, "26972154": 128, "26992411": 128, "26it": 153, "27": [4, 35, 39, 66, 73, 83, 96, 136, 152, 162], "270": 134, "271": 153, "27146251": 40, "27196636": 50, "27196637": 50, "27196645": 50, "27196707": 50, "27197113": 50, "27199435": 50, "27212631": 50, "27244608": 128, "2731394": 50, "27375593": 40, "27440288": 40, "27478507": 40, "275": 51, "275082": 50, "27568905": 152, "276": [31, 153], "2764993": 40, "2768953": 152, "276e": 124, "27752452": 152, "27760809": 40, "27852808": 40, "279": 82, "27991444": [148, 153], "28": [35, 51, 70, 76, 78, 84, 144, 145, 149, 152, 153, 154, 155], "280": 153, "280179": 134, "28060553": 40, "28066508": 40, "281930": 134, "282259": 134, "28267571": 40, "28299553": 40, "283": 134, "283619": 152, "284": 147, "28441311e": 152, "28474811": 40, "28558733": 40, "28669904": 128, "2872e": 72, "28807817": 40, "28883234": 40, "289": [34, 152], "2890": 134, "2890942": [148, 153], "28959684": 128, "289972": 152, "28it": 153, "28x28": 70, "29": [1, 35, 38, 39, 46, 48, 50, 67, 78, 86, 95, 96, 128, 152, 163], "29090909": 128, "2911889": 40, "2919282": 50, "29209002": 128, "292185": 152, "2931": 134, "29322588": 40, "2935": 72, "29354962": 40, "29371761": 40, "29415949": 40, "2949430162": 152, "295": 134, "29564967": 40, "296": 153, "296247": 134, "296414": 134, "2966": 1, "2968": 134, "2970796": 40, "29735": 152, "2979": 72, "2980": 134, "298273": 134, "298375": 134, "29865557": 40, "299": 153, "2990": 134, "29946356": 152, "2996015": 40, "299748": 134, "29it": 153, "2_": [37, 53, 67, 68, 97, 108], "2_000": [152, 153], "2_1": 68, "2_2": 68, "2_3": 68, "2_n": 108, "2b": 96, "2d": [27, 34, 38, 41, 76, 78, 79, 80, 83], "2draw": 152, "2e": [67, 96, 144], "2e_i": 39, "2f": [39, 40, 42, 43, 50, 78, 84, 96, 97, 124, 131, 135, 145, 146, 148, 151, 153, 162, 163], "2k": 52, "2kb": 152, "2l": [20, 35, 37], "2m": [47, 91, 97], "2n": 45, "2nd": [1, 15, 24, 35, 38, 74, 80, 94, 103, 137, 149, 160], "2p": 20, "2px": 43, "2r": 151, "2sigma": 42, "2w": 37, "2x": [5, 35, 102], "2x2": 4, "2x3": 137, "2z": 17, "3": [0, 1, 3, 4, 6, 9, 15, 18, 20, 23, 24, 26, 31, 34, 35, 37, 38, 40, 41, 43, 44, 46, 47, 48, 50, 51, 52, 54, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 83, 86, 95, 96, 97, 100, 101, 102, 103, 114, 121, 124, 127, 128, 130, 134, 135, 136, 137, 138, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 163], "30": [0, 9, 17, 31, 38, 39, 41, 51, 77, 83, 96, 97, 127, 128, 131, 135, 144, 152, 153, 163], "300": [41, 72, 150], "30000": 74, "30017032": 40, "30032012": 152, "3006664": 40, "301": [5, 9, 31], "30163826": 40, "30196005": 40, "30218997": [148, 153], "30247927": 152, "3025": 5, "30253554": 40, "303": 1, "30424368": 128, "30471708": 131, "3049": 1, "3050791": 40, "30526704": 40, "3053064": 40, "306": 1, "30620607": 40, "3072": 76, "30740678": 152, "307e": 124, "30833925": 40, "30847308": [148, 153], "3088": 128, "309": [1, 127], "30970591": 40, "30979757": 124, "3098": 72, "30981676": 40, "30992950726916": 43, "30it": 153, "31": [37, 38, 39, 68, 96, 127, 131, 152, 157], "310": [127, 152], "31027229": 40, "310e": 124, "311": 127, "31123344": 152, "312": [1, 127], "31216994": [148, 153], "31223869": 40, "31251261": 40, "3128273": 40, "313": 77, "31344978": 128, "31354772": 40, "314": 1, "31475378": [148, 153], "31515939": 40, "31563495": 40, "31594001": 40, "316": [82, 153], "31627214": 40, "31663724": 40, "3166589": 40, "31694": 50, "317": [152, 153], "31713": 134, "3180143": 40, "3181542": 40, "319": [1, 51, 97, 127], "3190391": 40, "31914843": 40, "31932186": 40, "31935642": [148, 153], "31965694": 40, "31it": 153, "32": [35, 42, 51, 53, 68, 70, 76, 77, 78, 80, 83, 97, 127, 152, 153, 154, 157], "320": [51, 77, 97, 127], "3200": 127, "32061622": 40, "321": [51, 97, 127], "32107876": 40, "32126591": 40, "32145303": 152, "3217": 72, "32187747": 152, "322": 127, "32245679": 128, "323": [1, 51, 97, 127], "32352735": 40, "323533a0": 1, "324": [9, 39, 51, 97, 127], "32404129": 128, "32427424": 40, "32580419": 40, "3258e": 72, "326": [1, 51, 97], "326238": 134, "327": [51, 97], "3272": 134, "3273e": 72, "32755196": 40, "3278": 134, "328": 128, "3285": 134, "32875387": 40, "329": [9, 83], "32933771": 40, "329492": 134, "32it": 153, "32m": 77, "33": [35, 39, 42, 68, 83, 94, 96, 152, 162], "3306": 134, "3311": 72, "3312": 134, "33145711": 40, "3315865": [148, 153], "331939": 134, "332": [96, 152], "33311912": 50, "33312055": 152, "33333333": 154, "33424548": 40, "33459264": 79, "33463254": 152, "335": [9, 153], "33513223": 40, "33525": 152, "33587406": 40, "337": 152, "33722094": 40, "33776818e": 66, "3380": 72, "3380117": 40, "33844": 50, "33865576": 40, "3389": 1, "33930166": 35, "33it": 153, "34": [39, 96, 152, 153], "340583": 134, "3417e": 72, "342680": 134, "34281921": 79, "342e": 124, "3436": 134, "3437": 134, "34539683": 40, "3465969": 128, "347": 134, "34710546": 40, "34850784": 128, "349": [64, 134], "3490481": 134, "34927873": 40, "34962": 152, "34it": 153, "35": [26, 35, 39, 41, 83, 94, 152, 153, 157, 162], "35010682": 40, "35016716": 40, "35054598": 40, "3511169": 40, "35249436": 40, "352e": 124, "353": 153, "35308331": 40, "35323281": 124, "35356722": 40, "35379069": 124, "35387043": 40, "353e": 124, "354": 153, "354e": 124, "355": 124, "35528451": 40, "35550875": 152, "35571726": 40, "356": 9, "356399": 134, "357508": 134, "35884475": 152, "35it": 153, "36": [42, 79, 96, 137, 152, 154, 157, 162], "36126959": 40, "361556": 134, "36180164": 40, "36184732": 40, "36255041": 40, "36300435": 40, "36347669": 5, "36633201": 40, "36723181": 40, "36758306": 152, "3680856227874756": 152, "3680856227874756tuning_step": 152, "369": 64, "36919047": 40, "36928": 77, "36949272": 40, "36it": 153, "37": [33, 35, 39, 84, 96, 152, 153], "370": 31, "37024831": 50, "3705584": 40, "371": 153, "37167029": 40, "371e": 124, "3720": 72, "37245685": 40, "37256166": 40, "3728": 152, "373": 153, "3733791492": 134, "37406499": 128, "37426332": 50, "374658": 40, "37491135": 50, "37501876": 50, "37503449": 50, "37503656": 50, "37503681": 50, "375694": 134, "37646927": 40, "376547": 134, "37756379": 40, "37887176": 128, "37975819": 40, "37999916": 40, "37it": 153, "38": [33, 39, 79, 83, 96, 111, 137, 152], "38017837": 128, "38049834": 5, "38161433": 79, "38196315": 40, "38218508e": 152, "382187": 134, "38263794": 40, "38271517": 40, "382e": 152, "3832e": 72, "384": 83, "38417184": 152, "38422765": 40, "3845": 72, "38496733": [148, 153], "38499134": 40, "38560229": 40, "3862": 152, "38631426": 40, "38653915": 40, "387": 1, "38755787": 40, "38759303": 40, "388": [9, 128], "38824359": 40, "3887794": 40, "389": 153, "38it": 153, "38m": 77, "39": [64, 67, 98, 101, 106, 113, 134, 146, 152, 153, 154], "39014596": 40, "39206493": 66, "39233491": 40, "39279587": 79, "39286306": 5, "393": [42, 153], "3930016": 40, "39310924": 40, "39334122": [148, 153], "39378773": 40, "394": 82, "39401868": 40, "39442803": 40, "3947": 72, "39470366": [148, 153], "39475787": 152, "39485658": 152, "395": 1, "39539703": 40, "39607937": 40, "397": 70, "39788042": 40, "39799638": [148, 153], "398": [1, 128], "39859839": 40, "3988432": 40, "39977467": 40, "399836": 134, "39984394": 40, "3998612": 40, "39988306": 35, "3d": [24, 38, 66, 77, 131], "3e": [67, 144], "3f": [6, 9, 31, 34, 35, 39, 51, 70, 82, 83, 96, 97, 103, 124, 130, 134, 144, 148, 153, 162, 163], "3gb": 138, "3m": 47, "3rd": [15, 35, 38, 79, 87, 94, 103, 160], "3x": 24, "3x3": 137, "3x4": 137, "4": [0, 1, 2, 3, 4, 6, 8, 9, 12, 18, 20, 23, 24, 26, 31, 34, 35, 37, 38, 40, 43, 44, 47, 48, 50, 51, 54, 59, 60, 62, 64, 67, 70, 71, 74, 77, 82, 83, 89, 91, 95, 96, 97, 103, 119, 122, 124, 127, 128, 130, 134, 135, 136, 137, 138, 144, 145, 146, 148, 151, 152, 153, 154, 162, 163], "40": [5, 34, 35, 39, 41, 96, 108, 114, 124, 127, 152, 153, 154], "400": [31, 72, 79, 83, 124], "4000": [124, 146, 163], "40000": [74, 130, 157], "40019547": 40, "40020999": [148, 153], "401": 34, "4012205600738525": 152, "4012205600738525tuning_step": 152, "402": 1, "4027718": 128, "40349164": 40, "40391367": 40, "404": 31, "40433212": 40, "40517452": 152, "40615693": 40, "40665625": 40, "4073e": 72, "40753871": 40, "40754": 40, "408": 153, "4089": 1, "40890054": 40, "40925339": 40, "4096": [26, 31], "40_000": 152, "40it": 153, "41": [1, 35, 39, 137, 146, 152, 153], "41000": 127, "41005165": 40, "41026575": 40, "412": 153, "41211903": 35, "41220075": 128, "41347606": 40, "415201": 134, "41536733": 128, "417": 31, "417302": 40, "41767401": 40, "417e": 124, "41881241e": 152, "41m": 77, "42": [18, 35, 39, 41, 74, 83, 94, 96, 97, 124, 131, 134, 152], "4202822": 40, "4205927": 152, "42084371": 40, "42142": 50, "4230685e": 77, "42349435": 40, "42361443": 40, "4244e": 72, "42592018": 40, "426": [31, 153], "42626028": 152, "42887697": 40, "42952614": 40, "42it": 153, "42m": 77, "43": [32, 35, 39, 50, 72, 78, 79, 81, 84, 96, 152, 153], "43085135": 40, "431": 153, "43103028": 128, "43181": 131, "43302619": [148, 153], "43426185": 40, "43479389": 152, "43499832": 40, "43514849": 128, "435163": 134, "4352351e": 70, "43542254": 128, "43549215": 40, "4359862": 40, "43621127": 40, "4367634": 40, "43741585": 152, "43769457": 40, "438136": 134, "43816635": 40, "43996003": 131, "43rd": 134, "44": [35, 39, 64, 78, 152, 153], "44031858": 40, "441": 6, "441264": 134, "44136444": 40, "44250528": 40, "44287693": 40, "44305844": 40, "4430e": 72, "443217": 134, "44386247": 128, "4438e": 72, "444": 152, "4442863": 152, "44442621": 152, "445": 153, "44509671": 40, "44513761": [148, 153], "446": 9, "44610076": 128, "446353734003711": 84, "446453": 134, "44703778": 128, "44730122": 40, "44838065": 40, "4489894": 40, "449": 39, "44936865": 40, "44it": 153, "45": [16, 35, 79, 83, 96, 152, 153, 163], "450": 39, "45015551": 40, "45021774": 40, "45024082": 128, "4504": 77, "45069099": [148, 153], "4508": 152, "451": 153, "45112294": 40, "45128402": 40, "45142926": 40, "45161595": 40, "45194604": 40, "452553": 134, "4529": 72, "45391758": 40, "45422583": 40, "45453166": 128, "45454545": 128, "45459971": [148, 153], "45576187": 5, "4558919": 128, "455947": 134, "45652739": 40, "457": 1, "45794708": 40, "458027": 134, "45810824": 40, "4581e": 72, "45934751": 152, "45it": 153, "46": [1, 79, 152, 153, 163], "46012093": [148, 153], "46031844": 40, "4607812": 128, "46089238": 40, "4609029": [148, 153], "461": [9, 64], "4611641": 40, "46120675": 40, "462": 42, "46210794": 40, "46218949e": 79, "46277698": 40, "463": 153, "46353432": 40, "46361772": 152, "463861": 134, "46476976": 51, "46664327": 40, "46697967": 40, "4674011": 50, "4675": 72, "46765106": [148, 153], "46776598": 40, "468": 96, "46850185": 152, "4696879e": 70, "469849": 134, "4698802": 40, "46m": 77, "47": [35, 78, 152, 153], "47016034": 40, "47054044": 51, "47057627": 128, "4706e": 72, "47070392": [148, 153], "470714": 134, "47073986": 40, "470e": 124, "471": 153, "47182825": 40, "472": 1, "47253169e": 79, "474": 41, "47431968": 40, "47761018": 40, "47764353": 40, "478": 128, "47985237": 40, "47x": [50, 95], "48": [1, 39, 78, 83, 84, 152, 153], "480": 134, "481": [9, 153], "48185445": 40, "48290554": 40, "48365209": 40, "48369614": 40, "484": 82, "4840": 127, "484537": [148, 153], "48550": 1, "486": 31, "487": 51, "48834586": 152, "48851815": 40, "48946635": 5, "48954362": 40, "48it": 153, "49": [1, 20, 39, 79, 96, 131, 152, 153, 162], "490": 153, "49042732": 40, "49056104": 40, "49086467": 128, "491": 51, "49102772": 40, "49152": 76, "49154287": 40, "49167851": [148, 153], "49233656": 40, "493": 33, "49355935": 40, "493754387128709": 79, "494": 33, "4940954": 134, "49434165": 40, "49487103e": 128, "49515861": 40, "49521132": 40, "49553414": 40, "49564980962978": 43, "49588477": 40, "49602605": 40, "49681303": 66, "497": 131, "4972691": 40, "49737484": 128, "497630": 134, "4977e": 72, "49810818": 40, "4982711": [148, 153], "499": 153, "49930281": 128, "4_000": 152, "4d": [76, 144], "4e": [72, 97], "4f": [72, 83, 97, 130], "4th": 15, "4x": 5, "4x6": 137, "5": [0, 1, 2, 3, 4, 6, 9, 11, 12, 13, 18, 20, 26, 30, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 50, 51, 52, 54, 68, 70, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 91, 93, 95, 96, 97, 100, 103, 121, 122, 124, 127, 128, 130, 134, 135, 136, 137, 138, 144, 146, 147, 148, 150, 151, 152, 153, 154, 160, 162, 163], "50": [18, 37, 39, 41, 42, 48, 51, 72, 74, 75, 77, 78, 80, 83, 84, 95, 96, 97, 107, 127, 130, 131, 133, 134, 137, 144, 145, 148, 152, 153, 154, 157], "500": [0, 17, 18, 34, 35, 38, 43, 72, 74, 78, 84, 94, 103, 124, 127, 133, 143, 144, 145, 146, 152], "5000": [0, 9, 17, 42, 72, 74, 97, 124, 145, 152, 162], "50000": [18, 148, 153], "500000": 127, "500px": [9, 133], "50142959": 40, "50172511": 40, "50178644": 40, "5018": 41, "50249434": 40, "50274088": 40, "503": [9, 131], "50315846": 128, "50318481": 40, "50361825": 128, "505": 64, "5053819": 40, "50580623": 40, "50598029": 40, "506": 33, "50887486": 40, "509": 153, "50955513565884": 84, "50it": 153, "51": [20, 64, 79, 152, 153, 163], "510": 51, "5103076": 40, "51066278": [148, 153], "51093777": 40, "5118e": 72, "512": [42, 43], "51238578": [74, 94], "51292982": 40, "5135": 77, "51350548": 40, "514219": 134, "51484355": 40, "51507361": 40, "5154138": 40, "517": 153, "51714207": 128, "51790686": [148, 153], "518": 42, "51802526": 152, "5186162635839": 43, "518895": 134, "51981682": 40, "51e": 96, "52": [33, 42, 64, 79, 96, 152, 153], "520319": 134, "52057634": 40, "52081508": 40, "5208429": 40, "52132764": 40, "52138593": 40, "52182601": 152, "52241915": 40, "522836": 134, "52287579": 40, "52343734": 40, "52385799": [148, 153], "52462712": 40, "52475049": 40, "528": 153, "52800342": 40, "52832571": 40, "52877987": 128, "52884307": 40, "52887975": 40, "52946532": 40, "52976291": 40, "53": [39, 152, 153], "53035547": 40, "53116379": 40, "531280": 134, "53132618": 40, "532": 64, "533": 1, "5336585": 131, "53384514": 40, "534362": 134, "53478108e": 152, "53499597": 5, "535": 153, "53522913": 124, "53594643": 40, "536": 1, "53653633": 40, "537": 128, "5385964": 40, "53920701": 40, "5394e": 72, "54": [39, 70, 79, 83, 137, 152, 153], "54005717": 40, "5400699": 40, "54026428": 128, "54028232": 40, "54156998e": 152, "541605": 134, "54167554": 40, "54208317": 128, "54264529": 40, "54301214": 40, "54335911": 40, "54388244": 40, "544439": 134, "5447030e": 77, "545": 31, "54747503": 40, "54755159": 5, "5476": 77, "548": [152, 153], "54812958": 40, "54823027": 152, "548arrai": 152, "54996206": 128, "54e": 96, "54it": 153, "55": [16, 39, 83, 152, 153, 163], "550": 5, "5505375": 40, "55126197": 40, "55155435": 128, "551e": 128, "55210482": 40, "55287144": 40, "553": 153, "5533008": 40, "555": 31, "55501599": 40, "55588619": 40, "55607351": 40, "556378888999681": 124, "55682807": 40, "55743945": 40, "55777072": 40, "558": 31, "55812346e": 152, "55880554": 40, "559": 9, "55912398": 40, "5593865e": 70, "55it": 153, "56": [39, 77, 79, 152], "560kb": 152, "56100234": 40, "56179973": 40, "56218": 50, "56249102": 40, "5627611": 40, "563167": 134, "56372833": 128, "56438286": 40, "56504332": 40, "56515267": [148, 153], "56516224": 40, "56536": 134, "5667e": 72, "567": 153, "5673": 72, "56877654": 66, "56it": 153, "57": [33, 83, 97, 134, 152, 153], "570": 77, "5701": 1, "5707963": 50, "57085772": 40, "571": [128, 153], "57180488": 40, "572069": 134, "57296273": 40, "57344458": 40, "57357138": 40, "575": 128, "57546791": 40, "57550721": 40, "57582227": 5, "57586212": 128, "576": 77, "5765217": 40, "57709": 50, "57714304": 40, "57846442": 40, "57x": [50, 95], "58": [16, 42, 128, 138, 152], "580147499327772": 79, "58033011": 40, "58085122": 40, "58102806": 152, "5810621": 40, "58144397": [148, 153], "58281521": 40, "58295012": 152, "583": 124, "583595": 134, "58418115": 152, "58464661": 40, "585": 43, "5851531": 40, "585662": 40, "58591043": 40, "586497": 40, "58662319": 40, "58697069": 40, "587": 153, "58836084": 40, "58869929": 128, "589": 153, "5892963": 5, "5893": 152, "5898": 77, "58e": 96, "58it": 153, "59": [52, 64, 83, 96, 97, 152, 153], "59003946": 40, "59241338": 152, "5924728": 40, "59274796": 40, "59275998": 40, "5929783": 152, "59357852": 40, "594": 82, "59767085": 40, "598": [42, 152], "59883628": 128, "59912181": 40, "59921324": 40, "59it": 153, "5a": 93, "5d": 93, "5r": 80, "5th": [15, 137], "5x5": 137, "6": [0, 3, 4, 5, 8, 13, 15, 20, 24, 26, 31, 34, 35, 38, 39, 40, 41, 42, 45, 48, 50, 51, 52, 54, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 83, 84, 89, 94, 95, 96, 97, 101, 103, 119, 122, 124, 127, 128, 130, 134, 135, 137, 144, 145, 146, 149, 151, 152, 153, 155, 162, 163], "60": [16, 39, 42, 77, 96, 97, 122, 124, 152, 153], "600": 72, "6000": [54, 127], "60000": 70, "600px": 0, "60118718": 40, "602": [31, 68], "60231928": 40, "60236865": 79, "6024509": 40, "60324647": 40, "60337958": 40, "60350366": 40, "603636": 134, "60471697": 40, "60531032": 40, "6058e": 72, "606": 153, "60640394": 40, "6065484": 40, "60679775": 152, "607": 153, "60818376": 40, "60830612": 40, "6085147": 40, "60878366": 40, "6088": 1, "609": 82, "60it": 153, "61": [1, 39, 152, 153], "61223252": 40, "612939": 134, "61320418": [148, 153], "61336137": 40, "613579": 134, "61368808": 152, "61369766": 131, "6145": 77, "6147": 5, "61472628": 40, "61516775": 40, "61594565": 40, "61615285": 128, "6169496": 40, "61720311": 40, "61786327": 152, "61798553": 40, "61838026": 40, "61853913": 40, "618982": 134, "619": 1, "62": 152, "62048248": 40, "62060066": [148, 153], "6209": 72, "62091229": 40, "6210827": 40, "621102": 134, "6212": 152, "62133597": [148, 153], "6218035": 40, "6222546e": 77, "62284909": 40, "62336218": 40, "62434536": 40, "6244": 152, "62471505": 40, "62512273": 152, "62519531": 40, "62556168": 40, "626": 153, "62688268": 40, "626e": 124, "62743708": 40, "62765075": 40, "62896866": 153, "63": [4, 38, 39, 42, 47, 64, 152, 153], "63019567": 40, "63043757": 40, "6307441": 40, "63169151": 40, "63180047": 152, "632": 128, "633949": 134, "634": 39, "63546195": 40, "63658341": 40, "63738791": 40, "63750082": [148, 153], "63781955": [148, 153], "64": [42, 43, 77, 79, 96, 97, 134, 138, 152, 153, 162], "640": 127, "6407759": 40, "64098587": 40, "6418": 77, "64435367": 40, "645": 153, "64659002": 40, "6471": 1, "64775015": 40, "648": 33, "64857497": 79, "64864364": 40, "64896781": 131, "64912811": [148, 153], "64925537183554": 43, "6497": 77, "64it": 153, "65": [1, 79, 83, 131, 137, 152, 162], "650": 77, "65032321": 40, "6504": 72, "65065728": 40, "65101581": 40, "65130355": 40, "65188274": 128, "6519e": 72, "65223506": 40, "65345523": 128, "65458015": 40, "65498998": 40, "65501279": 40, "65600": 77, "65605512": 128, "65609929": 40, "65614632": 40, "65686671": 152, "656e": 124, "657041": 134, "65712464": 40, "65732421": 40, "6590498": 40, "65980218": 40, "65it": 153, "66": [39, 77, 83, 152, 153], "66023155": [148, 153], "66085975": [148, 153], "66102029": 40, "66168108": 40, "66236766": [148, 153], "663": 82, "66356073": 131, "664": 153, "66479728": 40, "6648e": 72, "6652e": 72, "666597": 134, "667239": 134, "6678e": 72, "66804833": 40, "668172": 134, "66871683": 40, "669": 1, "66921416": 152, "66962282": 152, "67": [39, 79, 152], "670067": 1, "6705": 152, "67094845": 40, "67244070e": 66, "67261975": 40, "67262221": [148, 153], "67271033": 152, "672721": 134, "6735005": 40, "67393869": 40, "674": 82, "6743961": 40, "67457071": 40, "67471153": 40, "67486677": 50, "67545381": 40, "6755": 72, "67579578": 40, "6775828": 40, "67780757": 40, "678": 128, "6780": 77, "67851499": 79, "67887983": 124, "678e": 124, "67973374e": 152, "68": [9, 14, 15, 18, 20, 31, 37, 38, 39, 41, 42, 45, 127, 131, 148, 152, 153], "68006984": 40, "680144": 134, "6801984": 40, "681": 152, "682": [41, 153], "68255141": 40, "68295077": 127, "683": 42, "6830988": 40, "684": [144, 153], "68400133": 40, "68543614": 40, "6858752e": 77, "686": 144, "68620289": 152, "68661021": 152, "6870999932289124": 77, "6871": 77, "6875": 77, "68771659": 40, "68851": 50, "68901502": 40, "689345": 134, "68969107": 128, "68976067": 152, "68988323": 40, "69": [39, 83, 144, 152], "690617": 134, "69087868": 40, "692": 31, "6924546": 40, "6925445": 128, "69257369": 50, "69257435": 40, "69257536": 50, "69258849": 50, "69268364": 50, "69329912": 50, "69336623": 40, "69346593": 40, "69379599": 40, "69380911": 40, "69427308": 40, "69509206": 40, "69665959": 152, "69680935": 50, "696e": 124, "6980": 1, "69803203": 40, "6984613": 40, "699": 31, "69902385": 40, "69942478": 5, "69it": 153, "6f": 79, "6omndqaaqbaj": 1, "7": [0, 1, 4, 5, 13, 18, 26, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 48, 50, 51, 52, 54, 70, 71, 72, 77, 78, 79, 82, 83, 84, 93, 95, 96, 97, 108, 114, 122, 124, 127, 128, 130, 131, 134, 135, 136, 137, 144, 145, 148, 151, 152, 153, 162], "70": [0, 4, 17, 35, 77, 103, 128, 131, 152, 153], "700": 72, "70018815": 40, "70098212": 40, "701": 153, "70100741": 152, "70179412": 40, "70190716": 40, "70263812": 40, "70335885": 40, "704": 153, "7040": 77, "70422569": 152, "70459417": 40, "70474211": 40, "70548352": 40, "70562061": 131, "705875531258476": 78, "707": 52, "7071082637875796": 84, "70816002": [148, 153], "7084054": 40, "709698": 134, "70px": [9, 133], "71": [1, 16, 39, 97, 137, 152], "71066184": 40, "71100266": 40, "71146298": 128, "71195902": [148, 153], "7120435": 128, "71269214": 40, "713": 135, "71304905": 40, "713163": 134, "7134e": 72, "71361508": 40, "714": 124, "7141": 72, "7147896": 40, "7151525e": 70, "71527897": [148, 153], "71713645": 40, "71826373": 40, "71829074": 40, "719": [148, 153], "72": [39, 64, 83, 96, 97, 152, 153, 157], "720": 153, "72090228": 40, "72101303": 152, "72171129": 40, "72176": 134, "722702": 40, "724": [76, 153], "72415394": 40, "725": 128, "725474": 40, "72552256": 40, "72555052": 40, "72591685": 40, "72744124": 40, "7278135": 40, "72809089e": 152, "72875201": [148, 153], "7288": 134, "72953922": 40, "72it": 153, "73": [39, 73, 77, 79, 83, 146, 152, 163], "731": 51, "731000": 134, "73140252": 40, "7316287": 40, "73211192": 40, "73268281": [148, 153], "73302323": 40, "733096": 134, "73335362e": 152, "7334831242552866": 79, "73367312": 40, "73378149": 40, "73625": 50, "739": 153, "73953394": 40, "74": [79, 152, 153, 157], "74055645": 40, "74101715": 40, "74204416": 40, "74335654": 40, "744": 153, "74481176": 40, "74481415": [148, 153], "74488454": 40, "74545455": 128, "74582013": 40, "746410510387339": 78, "74643509": 40, "74832579": 40, "7492896": 152, "749765": 134, "74it": 153, "75": [16, 33, 37, 42, 66, 79, 81, 83, 84, 131, 134, 152], "750": 42, "75041164": 40, "750445": 134, "7504512": 131, "75062962": 40, "75133724": 40, "75136522": 40, "75316589": 152, "75525508": 128, "75539203": 40, "75545933": 152, "756352": 134, "758": 153, "75880566": 40, "7595e": 72, "76": [79, 124, 152, 153, 157, 163], "760": 33, "76024923": 40, "76041518": 40, "76201118": 40, "76205806": 40, "76212473": 40, "76291349": 40, "76314662": 40, "76356305": 40, "764": 153, "76430245": 152, "7653351": 40, "76687926": 40, "76743401": 128, "76781774": [148, 153], "76795995": 40, "76916026": 40, "76994186": 40, "76it": 153, "77": 152, "77042575": 40, "77123417": 40, "77124583": 40, "77185931": 40, "77288737": 40, "77323981": 40, "77368576": 40, "77576423": 40, "776": 6, "776e": 128, "777": 153, "7772263": [148, 153], "77741921": 40, "77758597": 40, "77767186": 40, "777777": [70, 77], "777e": 124, "77811": 134, "77817418": 40, "7789711": 40, "7795e": 72, "77it": 153, "78": [38, 42, 79, 96, 152, 153, 163], "78002714": 40, "7802556": 40, "78046993": 40, "78126654": 40, "782": 134, "78282844": 152, "784": [70, 153], "78421011": [148, 153], "78477065": 40, "785061": 134, "78522692": 40, "78534616": 40, "7859": 72, "78666187": 40, "78693299": 134, "787": 134, "78730236": [148, 153], "7876": 130, "7884716764647624e": 84, "78975468": 40, "7898": 5, "789e": 124, "78it": 153, "79": [43, 96, 152, 163], "790": 152, "79024706": 40, "7903551e": 70, "79057545": 152, "7908587e": 70, "791": 82, "79110577": 40, "79203455": 128, "79215821": 40, "79280687": 40, "793167": 134, "7935": 72, "794": 128, "79452824": 40, "79502609": 40, "7957695978": 82, "796": 153, "79660555": 40, "7980638": 40, "799": 82, "79924193": 40, "79940931": 128, "8": [1, 2, 15, 26, 31, 34, 35, 38, 39, 40, 41, 42, 43, 47, 48, 50, 51, 64, 66, 70, 71, 72, 74, 77, 78, 79, 80, 82, 83, 84, 94, 96, 97, 103, 108, 122, 124, 127, 128, 130, 134, 135, 136, 137, 138, 144, 145, 148, 151, 152, 153, 162], "80": [1, 41, 42, 43, 78, 127, 152, 153, 163], "800": [42, 72, 124], "80043928": 40, "80073197": 40, "800b": 152, "80100182": 40, "80106255": 40, "80116214": 40, "80186103": 40, "80358898": 40, "804": 153, "80413849": 40, "80494266": 40, "805": 64, "80539342": 40, "80574084": 152, "80667836": 40, "8071": 134, "80745592": 40, "8079963": 40, "80816445": 40, "808393": 152, "80856518": 152, "80884436": 40, "8094517": 40, "80977897": 40, "80it": 153, "80kb": 152, "80px": 9, "81": [1, 47, 78, 79, 152, 162, 163], "810": 1, "81053491": 40, "81095167": 40, "81176563": 152, "81252782": 40, "81299039e": 128, "81304498": 40, "81342101": 40, "81343023": 40, "81434313": 40, "815": 153, "81582367": 40, "81595119": 152, "81604368": 40, "81642497": 131, "816454": 134, "8165998": 40, "816847": 134, "81693801": 40, "81757959": 40, "81768187": 40, "818": 41, "81889683": 40, "8190797": 40, "81it": 153, "82": [152, 153], "82033": 131, "82038771": 40, "82074983": 152, "822": 128, "8223678": 40, "823": 96, "824": 153, "82400562": 40, "82401733": 40, "8242e": 72, "82454103": 40, "82458307": 152, "82458463": 40, "82491575": 128, "82502982": 40, "82529684": 40, "82539979": [148, 153], "82581966": 40, "82699862": [148, 153], "827": 6, "82757179": 40, "82797464": 40, "82818662": 40, "82it": 153, "83": [42, 78, 83, 96, 124, 152, 153, 163], "83180116": 40, "83189927": 128, "83278962": 131, "83351405": 40, "8337": 72, "834": 153, "8340": 130, "83471763": 40, "83599203": 40, "83600472": 40, "8367e": 72, "83762945": 152, "8383258e": 70, "83863475": 40, "83880168": 40, "83898341": 40, "8390e": 72, "839818": 134, "8398299": 40, "8399": 77, "83it": 153, "84": [1, 5, 18, 39, 42, 51, 95, 96, 97, 124, 131, 144, 148, 152, 153], "84086156": 40, "8415": 72, "84222474": [148, 153], "842436": 134, "8424e": 72, "84300633": 40, "844": 153, "84501737": 40, "84550881": 40, "84589891": 5, "84616065": 40, "847": [128, 153], "84733205": 128, "848": 128, "84858": 1, "84949567": 40, "84958685": 40, "84it": 153, "85": [9, 43, 74, 94, 152, 153], "85129577": 40, "85143789": 40, "8515102": 40, "852": 153, "85257974": [148, 153], "85270406": 40, "852e": 124, "85300949": 40, "85328122": 40, "85328219": 40, "85372673": 40, "853835": 134, "85555595": 40, "85565861": 40, "85680425": 40, "8574818": 40, "85753327": 40, "858185": 134, "85865238": 128, "85947687": 131, "85987097": 40, "85it": 153, "86": [78, 79, 96, 152, 153, 163], "86028827": 40, "86064819": 40, "86089124": 40, "8616231": 40, "861676": 134, "86334532": 40, "86339779": [148, 153], "86355526": 40, "864": 153, "86402267": 40, "86520687": 40, "86540763": 40, "86543415": 152, "86620796": 40, "86647138": 40, "86828789": [148, 153], "86832437": 40, "86888616": 40, "86922651e": 128, "8694594e": 77, "86it": 153, "87": [1, 52, 82, 84, 94, 152, 153, 163], "870": 153, "87044111": 152, "8709698": 40, "87202521": 128, "8726145e": 70, "87270": 50, "874": 128, "87488328": 152, "87583893": 40, "87616892": 40, "87710977": 40, "87784598": 40, "87798127": 40, "87809431": [148, 153], "878123": 134, "87953543": 40, "87985002": 40, "87it": 153, "88": [1, 39, 42, 73, 79, 152, 153], "8805": 51, "8808846": 40, "88094581": 40, "88122883": 40, "88176277": 128, "8820": [51, 149], "88268965": 40, "88288931": 40, "88327861": 152, "88352998": 40, "88355585": 40, "884": 153, "88401481": 40, "88490881": 40, "88512895": 40, "88514116": 40, "8858258": 40, "88583608": 40, "8865639": 40, "887": 51, "88772753": [148, 153], "888": 153, "88888889": 154, "889": 51, "88955297": 40, "88959159": 152, "8895a785550b": 136, "88it": 153, "89": [83, 137, 152, 153, 163], "89000851": 40, "89160793": 40, "8922875": 40, "89320601": 40, "89334929e": 152, "89342693": 40, "89353988": 40, "89465529": 40, "895": 153, "896": 77, "89711278": 40, "89712203": 152, "89806796": 40, "89825413": 40, "89938082": 40, "89984477": 40, "89it": 153, "8x8": [79, 83], "9": [0, 12, 15, 17, 35, 38, 39, 40, 42, 43, 46, 47, 48, 50, 51, 54, 70, 72, 74, 77, 79, 80, 81, 83, 93, 94, 95, 103, 108, 122, 124, 127, 128, 131, 134, 136, 137, 138, 148, 152, 153, 154, 162], "90": [1, 45, 80, 96, 128, 131, 152, 153, 163], "900": 72, "90010873": 40, "90085595": 40, "90148689": 40, "90159072": 40, "902340": 1, "90279699": 152, "90284564": 40, "90399917": 40, "904": [128, 153], "90446213e": 152, "90465871": 40, "9050": 72, "90508815": 40, "90575218": 40, "906": 128, "9063": 77, "9066333": 103, "90685561": 152, "9069": 72, "907": 153, "90756768": 40, "90849929": 128, "90909091": 128, "90966167": 40, "9099": 77, "90it": 153, "91": [1, 30, 128, 137, 152, 153, 163], "9104236": 40, "911": 152, "9116924877687354e": 79, "91197": 1, "91360943": 40, "91373914": 79, "9150833487510681": 70, "9154": 77, "91549197": 40, "91549927": 40, "91582": 134, "917": 128, "91745894": [148, 153], "9180": 72, "91826915": [148, 153], "91887782": [148, 153], "918992": 134, "91928931": 40, "91979229": 40, "91it": 153, "92": [34, 79, 152, 153, 163], "92001793": 40, "92002987": 152, "92019511": [148, 153], "92061512": 40, "92145007": 40, "923": 153, "92319798": 40, "92332064": 40, "923602": 134, "92381543": 40, "9239": 72, "92442829": 40, "925": [1, 153], "9252e": 72, "92550121": 40, "9268873": 40, "92703138": 40, "92703572": 40, "9277111": 131, "927732": 134, "92842155": 152, "92847731": 152, "92861601": 128, "929": 152, "92923923e": 152, "92it": 153, "93": [84, 96, 152, 163], "93037546": 40, "9306713": 40, "931": 134, "93110208": 40, "93112242": 131, "93122954": 40, "93125568": 40, "93145484": 50, "93145567": 50, "93146285": 50, "93152154": 50, "93196044": 50, "93212342": 40, "93258998": 40, "93272141": 40, "93415215": [148, 153], "93495946": 50, "93514778": 40, "937082": 134, "93727344": 152, "93752881": 40, "93808797": [148, 153], "93820324": 40, "939": 134, "93916874": 40, "93934751": 40, "93985929": 40, "93it": 153, "94": [1, 152, 153, 163], "94056472": 131, "9406321": 40, "94173412": 152, "942": 153, "943": 153, "94317552": 40, "945": 5, "94623562": 40, "94645393": 40, "94651631": 40, "947": 82, "94750117": 40, "94881155": 40, "94940459": 124, "94980882": 40, "949e": 124, "94it": 153, "95": [9, 17, 18, 20, 30, 31, 37, 38, 41, 54, 78, 79, 81, 83, 84, 94, 97, 124, 127, 131, 133, 152, 153, 163], "95029742": 40, "95093225": 40, "95103519": 131, "95116949": [148, 153], "9518": 72, "952": 41, "95362323": 152, "95413331": 40, "95446575": 40, "95449567": 40, "95486746": [148, 153], "95487808": 40, "955": 42, "95537129": 127, "95541062": 40, "9560789": 40, "9561217": 40, "95628186e": 128, "95755425": 131, "95756889": 50, "9578333497047424": 70, "9586027": 40, "96": [78, 81, 83, 96, 124, 152, 153, 163], "9603313": 40, "96081768": 40, "96082174": 40, "961": 153, "96130449": 40, "96279877": 40, "962990": 134, "96318234": 40, "96371871": 40, "96400982": 40, "96463208": 40, "965548": 134, "96602": 5, "96622086": 40, "96653925": 40, "966899": 134, "9670395": 153, "96710175": 40, "96818283": 40, "9685333371162415": 70, "96908858": 40, "96it": 153, "97": [78, 79, 83, 84, 148, 152, 153, 163], "97061": 134, "971": 42, "97247061": 40, "9734333157539368": 70, "974": 33, "97409466": [148, 153], "97538304": 40, "97682437": 124, "977": 128, "9771833419799805": 70, "97779878": 40, "97794526": 124, "977e": 124, "978": 1, "9780470015629": 1, "9780470028735": 1, "9780521642989": 1, "9781009023405": 1, "9781108843607": 1, "97811406": 40, "9781420079425": 1, "9781491912133": 1, "9781491962299": 1, "9783319154305": 1, "978e": 124, "979": 153, "98": [16, 40, 43, 54, 83, 94, 96, 152, 153, 163], "980": [70, 153], "9800500273704529": 70, "98010712": 128, "98047744": 40, "98048015": 40, "98068359": 127, "98076837": 40, "98099948": 40, "9811": 5, "981321": 134, "9817500114440918": 70, "98181818": 128, "98218245": 40, "98228168": 40, "98254505": 40, "983310": 134, "9834499955177307": 70, "984": 153, "98401224": 40, "98495167": 40, "9850666522979736": 70, "98508459": [148, 153], "98519631": 40, "9857833385467529": 70, "986": 32, "98633519": 40, "98635218": 40, "9873354": 40, "9888561e": 77, "98907246": [148, 153], "98it": 153, "99": [16, 37, 38, 80, 96, 128, 131, 152, 153, 162, 163], "990": [64, 134, 163], "990e": 124, "99129514": 152, "99149955": 152, "99161615": [148, 153], "992": 35, "99296196e": 152, "9930": [72, 83], "994": 35, "995": 128, "9968": 72, "997": [38, 41, 42, 153, 163], "9972": 41, "99755610e": 152, "99810852": 40, "998527": 79, "999": [26, 31, 108, 131], "9990": 152, "9991": 152, "9992": 152, "99920392": 152, "9993": 152, "9994": 152, "9995": 152, "9996": 152, "99962499": 40, "9997": 152, "9998": 152, "99983081": 40, "9999": 152, "9999052e": 70, "9999arrai": 152, "9999xarrai": 152, "99arrai": 152, "99it": 153, "A": [0, 1, 4, 8, 16, 19, 22, 23, 24, 25, 26, 27, 28, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 57, 62, 63, 64, 65, 66, 67, 68, 72, 73, 74, 76, 77, 79, 80, 81, 82, 83, 87, 90, 94, 95, 96, 98, 100, 101, 103, 105, 106, 107, 111, 118, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 131, 133, 135, 137, 146, 147, 148, 150, 151, 152, 153, 154, 155, 162, 163, 164], "AND": [26, 80], "AS": 77, "And": [20, 37, 38, 42, 45, 49, 60, 63, 65, 67, 70, 76, 78, 84, 87, 147, 148, 153, 154, 155, 162], "As": [4, 8, 10, 18, 24, 34, 35, 39, 42, 46, 48, 49, 52, 53, 54, 60, 64, 65, 66, 68, 69, 73, 74, 76, 77, 78, 79, 83, 84, 89, 93, 99, 103, 108, 111, 113, 127, 128, 131, 134, 135, 136, 143, 148, 152, 153, 154, 155, 157], "At": [0, 5, 8, 16, 26, 35, 38, 41, 47, 52, 54, 57, 67, 89, 95, 106, 108, 128, 144, 145, 149, 154], "BE": [35, 100, 134], "BY": [44, 57], "Be": [33, 68, 82, 91, 93, 107, 126, 134, 137, 138, 143, 157], "Being": 48, "But": [4, 8, 13, 17, 20, 22, 23, 24, 30, 32, 35, 39, 41, 42, 49, 52, 53, 59, 60, 61, 63, 64, 67, 74, 79, 83, 87, 96, 102, 116, 118, 122, 127, 137, 138, 144, 146, 147, 152, 154, 155, 160, 163], "By": [16, 26, 32, 34, 35, 39, 43, 49, 54, 65, 67, 72, 76, 78, 79, 83, 84, 103, 120, 124, 131, 135, 143, 146, 152, 157, 162, 163], "For": [0, 4, 7, 8, 9, 16, 17, 18, 19, 20, 22, 26, 30, 31, 32, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 57, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86, 87, 89, 93, 94, 96, 97, 101, 104, 106, 111, 112, 118, 120, 126, 127, 128, 131, 132, 133, 134, 135, 137, 138, 140, 144, 145, 148, 150, 152, 153, 154, 157, 162], "If": [0, 4, 9, 11, 13, 16, 17, 18, 19, 20, 23, 24, 26, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 57, 63, 64, 67, 68, 69, 70, 72, 73, 74, 76, 77, 78, 79, 82, 84, 86, 87, 89, 91, 96, 97, 101, 118, 121, 124, 126, 128, 131, 132, 134, 135, 137, 138, 144, 147, 148, 149, 152, 153, 154, 155, 157, 160, 162], "In": [0, 2, 3, 4, 5, 7, 8, 9, 13, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 89, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 133, 134, 135, 136, 137, 138, 145, 146, 147, 148, 149, 153, 154, 155, 156, 157, 158, 159, 162, 163, 164], "Ising": [68, 118, 146, 163], "It": [0, 3, 4, 7, 8, 16, 17, 20, 22, 23, 24, 26, 32, 35, 37, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 54, 57, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 76, 78, 79, 80, 81, 84, 86, 89, 93, 94, 95, 96, 98, 101, 105, 106, 108, 111, 112, 114, 116, 118, 124, 128, 130, 131, 134, 135, 136, 137, 138, 143, 144, 145, 147, 148, 149, 151, 152, 153, 154, 155, 157, 160, 162], "Its": [47, 68, 79, 83, 86, 157], "No": [4, 16, 37, 45, 48, 49, 52, 60, 63, 66, 70, 71, 74, 80, 87, 94, 124, 127, 129, 152, 154, 155], "Not": [4, 37, 39, 40, 42, 43, 44, 45, 52, 65, 77, 127, 145, 148, 153, 160], "OF": 77, "OR": [26, 77, 80], "Of": [32, 35, 101], "On": [4, 22, 63, 64, 65, 67, 71, 74, 76, 124, 130, 135, 162], "One": [9, 11, 19, 20, 30, 34, 35, 39, 47, 48, 49, 53, 56, 60, 62, 63, 66, 67, 68, 70, 74, 89, 122, 134, 137, 138, 147, 149, 154, 155, 157, 162], "Or": [18, 26, 54, 59, 78, 84, 96, 131, 134, 147], "Such": [17, 35, 44, 47, 63, 65, 67, 112, 131, 154, 157], "TO": 134, "That": [15, 18, 23, 32, 34, 35, 39, 41, 42, 48, 49, 50, 54, 63, 67, 68, 69, 73, 74, 89, 96, 101, 116, 124, 131, 135, 144, 145, 146, 147, 148, 152, 153, 154, 157, 163], "The": [1, 3, 5, 7, 8, 9, 10, 11, 12, 13, 15, 18, 19, 21, 23, 24, 25, 27, 30, 31, 32, 33, 34, 37, 38, 40, 43, 46, 48, 49, 51, 52, 53, 56, 57, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 72, 74, 77, 80, 81, 82, 85, 87, 88, 90, 91, 92, 93, 94, 95, 97, 98, 100, 103, 105, 106, 107, 108, 111, 112, 114, 116, 117, 118, 121, 123, 125, 126, 127, 128, 130, 133, 134, 136, 137, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 159, 160, 162, 163], "Their": [48, 68, 73], "Then": [3, 4, 9, 17, 20, 23, 24, 31, 35, 38, 42, 44, 45, 52, 53, 54, 66, 71, 72, 78, 80, 86, 87, 93, 126, 128, 131, 135, 136, 138, 143, 144, 145, 147, 148, 151, 153, 154, 155, 157, 159, 160, 164], "There": [4, 8, 9, 11, 16, 20, 26, 31, 33, 38, 39, 41, 44, 45, 46, 47, 48, 52, 57, 61, 64, 67, 68, 74, 76, 83, 87, 91, 96, 98, 105, 116, 130, 131, 133, 134, 135, 138, 144, 145, 147, 149, 152, 154, 155, 157, 164], "These": [4, 8, 23, 35, 38, 40, 44, 45, 46, 48, 49, 52, 53, 60, 62, 65, 66, 67, 68, 69, 70, 72, 73, 76, 83, 86, 89, 95, 96, 97, 102, 108, 111, 127, 128, 130, 131, 135, 148, 149, 152, 153, 155, 157, 162, 163], "To": [0, 8, 15, 16, 19, 26, 31, 35, 37, 39, 40, 44, 45, 47, 48, 49, 51, 52, 53, 54, 60, 62, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 82, 87, 95, 97, 102, 103, 107, 118, 131, 135, 138, 144, 145, 147, 148, 151, 153, 154, 155, 157], "Will": [18, 24, 35, 83, 103], "With": [4, 9, 16, 17, 30, 31, 35, 37, 41, 42, 45, 47, 48, 52, 54, 63, 66, 67, 68, 69, 70, 73, 77, 80, 87, 96, 98, 105, 134, 136, 148, 152, 153, 157, 162], "_": [4, 6, 9, 10, 11, 12, 17, 20, 24, 25, 31, 34, 35, 37, 40, 45, 46, 47, 49, 53, 54, 65, 66, 67, 68, 73, 74, 78, 79, 81, 82, 83, 84, 87, 93, 94, 96, 98, 101, 106, 107, 108, 114, 118, 124, 126, 128, 130, 131, 136, 138, 148, 151, 153, 154, 157, 162], "_0": [4, 40, 43, 54, 98, 148, 153, 154], "_1": [0, 7, 35, 49, 66, 68, 69], "_2": [35, 49, 67, 68, 101], "__": [74, 94], "_________________________________________________________________": [70, 77], "__enter__": 127, "__former_attrs__": [51, 97], "__future__": 77, "__getattr__": [51, 97], "__init__": [9, 51, 72, 97, 124, 127, 150, 151], "__version__": [39, 42, 51, 70, 97, 144, 152, 153], "_a": 54, "_adjust_frame_s": 127, "_alpha": 97, "_amp1": 51, "_amp2": 51, "_amplitud": 97, "_background": 97, "_base": 51, "_beta": [51, 97], "_check_optimize_result": 82, "_config": 0, "_d": [122, 124, 149], "_data": 9, "_execute_child": 127, "_fig": 127, "_g": [45, 122], "_generatorcontextmanag": 127, "_gpr": 82, "_h": [124, 127], "_i": [7, 17, 35, 45, 47, 66, 67, 68, 98, 151, 154, 157], "_imag": 128, "_is_sav": 127, "_j": 47, "_k": [49, 67, 93], "_log": 127, "_m": [67, 68, 86], "_n": [86, 93, 108, 147], "_p": [25, 131], "_pformat_subprocess": 127, "_posit": 97, "_proc": 127, "_run": 127, "_sample_proba": [74, 94], "_setattr_cm": 127, "_sig": 51, "_sort": 42, "_supports_transpar": 127, "_t": 124, "_true": [40, 148, 153], "_v": 124, "_w": [89, 127, 133], "a0": [17, 97], "a0boogfu": 134, "a1": [18, 127, 131, 134], "a2": [18, 131, 134], "a3": 134, "a4": 134, "a_": [17, 37, 97, 126, 128], "a_0": [17, 35, 37, 50, 53, 91, 97, 100, 113], "a_1": [35, 50, 53, 83, 91, 97, 100, 113, 131], "a_1a": [35, 100, 134], "a_2": [35, 53, 83, 100, 131], "a_2a": [35, 100, 134], "a_3": [35, 100, 134], "a_4": [35, 100, 134], "a_arr": 17, "a_bar": 50, "a_grid": 38, "a_hat": 50, "a_i": [50, 54, 69, 83, 95, 131, 134], "a_j": [69, 83, 97, 131], "a_k": [50, 53, 69, 83], "a_margin": 38, "a_mat": 50, "a_max": 38, "a_n": [35, 113, 131, 157], "a_posterior": 17, "a_pt": 38, "a_tru": 38, "a_w": 133, "a_x": 54, "aa": 137, "ab": [1, 3, 6, 39, 41, 79, 83, 93, 124, 126, 137, 144, 145, 151, 154, 162], "abandon": 149, "abar": 50, "abar_": 50, "abbrevi": [120, 135], "abeca3": 1, "abil": [39, 47, 48, 65, 72, 74, 112, 135, 137, 154], "abl": [16, 26, 35, 39, 44, 45, 46, 48, 54, 57, 68, 72, 74, 79, 83, 89, 96, 132, 135, 143, 145, 162], "abnormal_termination_in_lnsrch": 82, "abolut": 39, "about": [0, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 23, 24, 26, 31, 32, 34, 35, 37, 38, 39, 41, 42, 43, 44, 47, 48, 49, 50, 51, 54, 59, 60, 63, 64, 65, 67, 68, 70, 73, 74, 77, 78, 79, 80, 82, 83, 84, 86, 87, 89, 91, 94, 95, 96, 97, 98, 102, 111, 118, 120, 121, 122, 131, 132, 133, 134, 135, 137, 138, 144, 145, 146, 152, 154, 155, 159, 160, 163], "abov": [0, 4, 5, 9, 17, 18, 20, 23, 24, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 45, 49, 50, 52, 54, 64, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 83, 84, 89, 93, 94, 102, 103, 108, 121, 122, 124, 128, 131, 134, 135, 137, 144, 145, 146, 147, 148, 152, 153, 154, 157, 162, 163, 164], "absenc": [8, 64, 118], "abserr": [150, 151], "absolut": [3, 4, 8, 16, 48, 66, 67, 68, 86, 111, 126, 134, 137, 154], "absolute_import": 77, "absorb": 26, "abspath": [131, 157, 162], "abstract": [8, 16, 54, 67, 74, 157, 162], "abstractmoviewrit": 127, "abund": 106, "abundantli": 39, "ac": [33, 78], "ac83dd": 1, "academ": [44, 57], "accelar": 124, "acceler": [63, 65, 122, 124], "accentu": 34, "accept": [6, 20, 30, 40, 45, 46, 47, 51, 52, 54, 62, 65, 72, 76, 124, 138, 145, 146, 147, 148, 149, 153, 154, 155, 157, 162, 163, 164], "acceptance_fract": [6, 51, 124, 144, 148, 153], "acceptance_r": 152, "access": [8, 16, 35, 44, 46, 49, 52, 54, 57, 65, 66, 72, 78, 84, 89, 101, 114, 131, 134, 135, 137, 138, 140, 154, 155], "accid": [37, 65], "accommod": [8, 89], "accompani": 65, "accomplish": [49, 51, 72, 137, 147, 155], "accor": 66, "accord": [9, 16, 17, 30, 34, 35, 42, 43, 44, 45, 47, 51, 54, 61, 68, 69, 72, 97, 118, 127, 131, 134, 145, 154, 157, 159], "accordingli": [24, 44], "account": [0, 4, 16, 24, 30, 35, 38, 39, 44, 49, 56, 60, 61, 62, 64, 73, 120, 124, 128, 134, 144, 146, 162, 163], "accumul": [17, 45, 68, 72, 108, 124, 160], "accur": [41, 46, 48, 49, 54, 64, 66, 67, 70, 81, 90, 118, 120, 123, 125, 127, 151], "accuraci": [39, 41, 42, 44, 48, 49, 50, 51, 52, 64, 66, 68, 71, 74, 77, 94, 126, 131, 144, 146, 151, 155, 163], "accus": 8, "aceept": 149, "acf": 145, "achiev": [8, 42, 45, 47, 48, 54, 65, 66, 67, 68, 77, 89, 112, 118, 122, 134, 144, 154, 157], "acknowledg": [49, 62, 64], "acor": [144, 145], "acquaint": [35, 102, 111], "acquir": [9, 10, 11, 28, 63, 68, 118], "acquisit": [59, 93], "across": [35, 41, 44, 47, 48, 49, 72, 76, 78, 84, 103, 120, 144, 149, 160], "act": [8, 17, 41, 42, 52, 54, 59, 63, 111, 118, 130, 135], "act_1": [74, 94], "act_2": [74, 94], "act_out": [74, 94], "action": [64, 65, 118, 129, 164], "activ": [8, 47, 48, 65, 66, 70, 71, 72, 73, 74, 75, 76, 77, 94, 118, 124, 130, 135, 138], "activaiton": 118, "activit": 68, "actual": [7, 8, 9, 13, 16, 20, 22, 23, 26, 31, 32, 35, 37, 39, 41, 42, 44, 47, 52, 54, 59, 64, 66, 67, 72, 73, 78, 84, 87, 89, 94, 96, 105, 112, 118, 120, 134, 143, 146, 154, 157, 160, 163], "ad": [20, 26, 38, 39, 41, 45, 51, 54, 57, 67, 70, 74, 75, 78, 80, 81, 84, 87, 93, 94, 95, 96, 97, 98, 108, 118, 122, 124, 128, 131, 135, 143, 144, 145, 148, 153, 157, 160, 162], "adadelta": [1, 108], "adagrad": [68, 72], "adam": [1, 57, 68, 70, 72, 77], "adapt": [1, 9, 35, 38, 39, 40, 41, 48, 51, 57, 62, 68, 72, 78, 79, 83, 84, 88, 91, 96, 117, 118, 122, 123, 128, 143, 144, 145, 146, 148, 149, 151, 152, 153, 155, 163], "adapt_diag": [152, 153], "adaptation_lag": [51, 97], "adaptation_tim": [51, 97], "add": [0, 9, 18, 20, 32, 34, 35, 41, 48, 53, 65, 67, 69, 71, 74, 75, 76, 80, 81, 83, 87, 91, 94, 95, 96, 116, 123, 124, 131, 134, 135, 136, 137, 138, 139, 143, 144, 145, 148, 149, 151, 153, 154, 160], "add_ax": 127, "add_subplot": [5, 9, 18, 38, 39, 41, 42, 43, 50, 66, 71, 96, 127, 128, 133, 135, 136, 146, 150, 151, 163], "addbackward0": 72, "addit": [0, 2, 16, 17, 25, 26, 28, 32, 35, 43, 45, 47, 49, 52, 53, 54, 59, 62, 63, 65, 67, 68, 69, 72, 73, 74, 76, 78, 79, 81, 83, 86, 89, 94, 108, 111, 122, 125, 135, 138, 152, 155, 157], "addition": 68, "address": [39, 54, 56, 57, 58, 64, 73, 91, 96, 111, 117, 123, 148, 149, 153, 154], "adequ": [7, 64], "adher": [44, 54, 64], "adjac": [52, 68], "adjust": [9, 18, 38, 39, 43, 45, 64, 68, 70, 72, 73, 74, 87, 89, 112, 118, 127, 131, 133, 143, 149, 150, 152, 155], "admin": 138, "admir": 134, "adopt": [35, 39, 52, 64, 76, 121], "ador": 64, "adress": 45, "advanc": [8, 9, 48, 51, 57, 64, 68, 72, 92, 96, 97, 132, 138, 154, 157, 161], "advantag": [16, 28, 29, 35, 39, 44, 48, 57, 72, 76, 108], "advertis": 87, "advi": [73, 94, 152], "advic": 160, "advoc": [41, 89, 96, 149], "af_fig": 17, "affect": [20, 26, 39, 41, 42, 44, 63, 64, 65, 72, 81, 101, 131, 150, 154], "affin": [1, 48, 124, 147, 148, 149, 153, 154], "afford": [45, 77], "after": [4, 8, 9, 10, 11, 12, 16, 17, 18, 22, 23, 24, 26, 31, 38, 39, 44, 45, 47, 48, 49, 53, 54, 60, 63, 65, 67, 68, 69, 70, 72, 78, 81, 82, 84, 86, 96, 124, 127, 134, 135, 137, 144, 145, 147, 149, 151, 152, 157, 160, 162], "afterward": 134, "ag": [64, 65], "again": [4, 9, 17, 23, 24, 31, 32, 34, 38, 45, 50, 54, 64, 66, 69, 78, 91, 96, 98, 113, 115, 116, 118, 126, 128, 131, 134, 135, 138, 145, 147, 148, 150, 152, 153, 154, 155, 157, 162], "against": [8, 13, 14, 17, 47, 52, 54, 64, 72, 128, 146, 162, 163], "agenc": 64, "agenda": 4, "agent": [8, 129], "aggress": 108, "agre": [13, 20, 54, 62, 77, 128, 148, 153], "agreement": [35, 40, 54, 103, 138, 148, 153], "ahead": [21, 24, 74, 94, 135], "ai": [1, 65, 90, 118], "aic": 52, "aid": [44, 47], "aim": [4, 35, 45, 47, 48, 57, 62, 63, 64, 65, 66, 67, 68, 78, 84, 101, 106, 124, 134, 162], "aip": 52, "air": [122, 124], "airplan": 77, "aka": [9, 31, 48, 86, 123], "akaiko": 52, "al": [0, 44, 45, 57, 67, 124, 127, 145], "alea": 73, "alexandr": 1, "alfio": 1, "algebra": [1, 17, 35, 51, 65, 68, 96, 100, 101, 113, 126, 135, 139], "algorithm": [1, 20, 39, 45, 48, 54, 57, 63, 66, 67, 71, 72, 73, 74, 90, 94, 98, 105, 106, 107, 112, 117, 118, 128, 131, 134, 137, 147, 152, 161], "alia": [51, 97], "alias": [51, 97], "align": [0, 4, 13, 15, 17, 20, 23, 25, 34, 35, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 52, 67, 68, 73, 78, 80, 83, 84, 86, 87, 89, 96, 101, 108, 126, 127, 128, 131, 146, 147, 149, 150, 151, 152, 157, 159, 160, 163], "align_test": 0, "all": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 22, 23, 24, 26, 28, 31, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 54, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 76, 78, 79, 80, 83, 84, 86, 87, 89, 90, 93, 95, 96, 97, 101, 103, 105, 106, 107, 108, 109, 118, 120, 121, 124, 125, 127, 128, 130, 131, 134, 135, 137, 138, 143, 144, 145, 146, 147, 148, 149, 152, 154, 157, 159, 160, 162, 163], "all_orbit": 150, "allow": [3, 4, 8, 9, 11, 12, 16, 17, 26, 31, 35, 39, 40, 44, 45, 47, 50, 54, 65, 66, 72, 74, 76, 81, 82, 83, 86, 90, 94, 96, 103, 105, 111, 112, 118, 124, 131, 134, 135, 137, 138, 145, 148, 152, 153, 154, 162], "allud": [0, 23], "almost": [17, 20, 64, 65, 66, 68, 74, 79, 83, 127, 149, 152, 154, 155, 162], "alo": 37, "alon": [4, 8, 52], "along": [44, 48, 63, 73, 76, 83, 91, 137, 149, 152, 157], "alongsid": [78, 84], "alp": 1, "alpha": [3, 6, 9, 13, 18, 20, 30, 31, 34, 35, 38, 40, 41, 42, 43, 48, 50, 51, 52, 66, 68, 71, 73, 74, 75, 78, 79, 81, 82, 83, 86, 89, 93, 94, 95, 96, 97, 103, 118, 124, 127, 128, 130, 131, 134, 144, 145, 151, 153, 154, 157, 159], "alpha_1": [9, 31], "alpha_1_w": 9, "alpha_2": 9, "alpha_2_w": 9, "alpha_3": 9, "alpha_3_w": 9, "alpha_bound": 82, "alpha_v": 124, "alphabet": 57, "alphavec": [24, 91], "alreadi": [16, 17, 18, 20, 32, 35, 38, 40, 50, 53, 57, 61, 64, 66, 74, 78, 84, 87, 111, 118, 128, 134, 135, 138, 145, 146, 148, 153, 155, 157, 161, 163], "also": [0, 3, 4, 5, 7, 8, 9, 16, 17, 18, 20, 22, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 53, 54, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 78, 79, 82, 83, 84, 86, 87, 89, 90, 93, 95, 96, 97, 98, 101, 102, 103, 105, 108, 111, 112, 114, 117, 118, 122, 125, 127, 128, 130, 131, 133, 134, 135, 136, 137, 138, 143, 144, 145, 148, 149, 152, 153, 154, 155, 157, 160, 162], "alter": [8, 9, 31], "altern": [3, 4, 6, 18, 35, 39, 40, 42, 45, 47, 48, 49, 54, 62, 65, 67, 89, 93, 95, 98, 116, 123, 127, 131, 139, 143, 153, 154, 157, 161], "although": [0, 8, 11, 17, 20, 23, 26, 34, 35, 44, 46, 48, 49, 54, 57, 61, 64, 83, 98, 99, 100, 105, 106, 113, 131, 134, 137, 154, 157, 160, 162], "altogeth": [45, 86], "alwai": [6, 7, 8, 16, 17, 18, 20, 23, 24, 30, 35, 41, 44, 49, 50, 54, 59, 64, 65, 66, 67, 68, 73, 86, 93, 99, 102, 104, 113, 130, 131, 134, 135, 136, 145, 146, 147, 152, 154, 155, 157, 159, 160, 162, 163], "am": 1, "amat": 128, "amatt": 128, "amax": [43, 97], "amaz": [65, 74], "amazon": 57, "ambigu": 68, "ambit": [46, 68], "ambiti": [59, 63], "ame2003": 134, "ame2012": 134, "ame2016": 134, "amelior": 67, "american": [1, 62, 129], "amin": [43, 97], "among": [8, 30, 39, 41, 44, 48, 49, 56, 57, 67, 76, 89, 157], "amount": [8, 9, 26, 40, 41, 52, 54, 63, 64, 67, 74, 76, 91, 98, 112, 147, 148, 153, 157], "amplifi": 64, "amplitud": [17, 35, 51, 52, 54, 81, 83, 91, 97, 133], "an": [0, 1, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 98, 100, 101, 105, 106, 107, 108, 111, 113, 114, 115, 116, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 161, 163, 164], "anaconda": [51, 57, 72, 132, 135, 140, 141], "anaconda3": [51, 138], "anal": 1, "analog": [52, 67, 95, 126, 145, 155], "analogi": [0, 1, 8, 23, 34, 52, 62, 68, 73, 145], "analys": [26, 31, 35, 44, 47, 48, 123, 127], "analysi": [0, 1, 7, 8, 16, 17, 20, 26, 28, 30, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 57, 62, 64, 65, 66, 67, 74, 87, 89, 94, 95, 96, 100, 103, 113, 117, 118, 122, 124, 125, 126, 128, 134, 135, 146, 148, 153, 154, 160, 163], "analyt": [7, 16, 17, 31, 35, 37, 40, 41, 45, 48, 50, 54, 64, 66, 67, 68, 83, 89, 98, 100, 145, 148, 153, 157, 160], "analyz": [8, 16, 20, 26, 30, 35, 39, 50, 60, 64, 65, 76, 91, 95, 97, 99, 103, 118, 143], "anayt": 154, "ancestor": 111, "andrea": [1, 46, 57, 79, 83], "andrei": 26, "andrew": [0, 1, 57], "ang_mom": 151, "angl": [37, 41, 43, 143], "angular": 43, "angwin": 64, "anharmon": 48, "ani": [0, 4, 5, 7, 8, 9, 11, 16, 17, 18, 20, 23, 26, 31, 32, 33, 34, 35, 39, 41, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 57, 59, 60, 62, 64, 65, 66, 68, 72, 74, 77, 79, 81, 83, 86, 87, 89, 93, 96, 97, 102, 103, 118, 121, 124, 131, 135, 136, 137, 143, 144, 153, 154, 155, 157, 162, 164], "anim": [68, 127], "anindita": 1, "ankl": 77, "ann": 90, "ann_input": [74, 94], "ann_output": [74, 94], "anneal": 52, "annft": 118, "annot": [9, 18, 38, 43, 96, 127, 145], "anoth": [0, 4, 9, 13, 16, 17, 20, 24, 26, 34, 35, 38, 44, 45, 52, 54, 56, 64, 65, 66, 67, 68, 69, 76, 77, 80, 89, 91, 95, 96, 98, 111, 128, 131, 134, 135, 136, 137, 145, 146, 149, 151, 153, 155, 157, 160, 163], "ansatz": 134, "answer": [7, 8, 27, 28, 34, 40, 43, 53, 54, 60, 64, 65, 67, 78, 80, 84, 86, 93, 94, 95, 99, 104, 124, 128, 131, 135, 145, 148, 152, 153, 155, 162], "anteced": 48, "anti": [9, 11, 12, 54, 79, 131], "antialias": [38, 131], "anticip": 64, "anymor": 86, "anyon": [60, 136], "anyth": [11, 16, 22, 43, 62, 68, 131, 135, 143, 152, 154, 155], "anywai": 145, "anywher": [0, 18, 24, 33, 44, 53, 157], "ap": 128, "apach": 77, "apart": [45, 54, 74, 80, 87], "aperiod": [145, 154, 157], "api": [74, 77, 94], "apologi": 63, "app": [1, 87], "appar": [26, 147, 160], "apparatu": 24, "appeal": [47, 131], "appear": [4, 7, 8, 17, 23, 33, 35, 39, 43, 44, 46, 48, 54, 57, 64, 65, 67, 68, 73, 78, 84, 86, 94, 116, 126, 134, 138, 150, 154, 155, 157, 159, 162], "append": [34, 37, 39, 51, 66, 71, 97, 124, 130, 133, 134, 136, 137, 138, 144, 145, 150, 154, 160, 162], "appendix": [24, 25, 28, 57, 93, 127, 132], "appl": 138, "appli": [0, 7, 8, 15, 17, 18, 20, 23, 26, 32, 33, 35, 36, 40, 44, 45, 48, 49, 52, 53, 54, 59, 64, 66, 68, 69, 71, 72, 73, 74, 76, 89, 95, 105, 111, 118, 124, 130, 134, 137, 146, 149, 150, 154, 155, 157, 163], "applic": [1, 7, 8, 16, 19, 24, 25, 26, 38, 40, 42, 44, 45, 46, 47, 48, 49, 53, 57, 60, 63, 64, 65, 66, 67, 68, 72, 74, 77, 87, 89, 90, 105, 113, 122, 148, 153, 157, 162], "approach": [1, 4, 8, 9, 11, 16, 17, 18, 19, 20, 22, 26, 29, 31, 34, 35, 37, 41, 44, 45, 46, 47, 48, 49, 52, 54, 56, 60, 61, 62, 65, 66, 67, 72, 73, 74, 75, 79, 80, 84, 89, 96, 98, 102, 103, 111, 112, 114, 118, 120, 121, 122, 126, 128, 129, 130, 131, 136, 149, 152, 154, 155], "appropri": [0, 4, 16, 18, 26, 35, 44, 49, 54, 64, 78, 84, 86, 121, 127, 128, 131, 135, 147, 155], "approx": [3, 4, 12, 16, 17, 20, 30, 32, 33, 39, 42, 46, 47, 53, 54, 68, 73, 74, 80, 94, 96, 111, 116, 126, 128, 147, 154, 155, 157, 160, 162], "approxim": [1, 4, 19, 20, 30, 35, 40, 42, 45, 46, 48, 52, 53, 54, 56, 67, 68, 72, 73, 74, 91, 94, 96, 97, 101, 111, 112, 116, 120, 123, 128, 131, 145, 147, 148, 149, 153, 154, 155, 159], "ar": [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 162, 163, 164], "aragorn": 134, "arang": [34, 38, 40, 43, 50, 51, 66, 71, 78, 79, 81, 83, 84, 96, 97, 131, 134, 135, 136, 137, 139, 144, 150, 151, 153], "arbitrari": [24, 44, 47, 48, 68, 81, 131, 154], "arbitrarili": [35, 83, 145], "archetyp": 68, "architectur": [70, 72, 74, 77, 118], "archiv": 8, "arcsin": 3, "area": [19, 20, 44, 49, 54, 57, 65, 73, 76, 105, 134, 149, 150, 164], "aren": 64, "arg": [0, 5, 6, 17, 35, 39, 41, 42, 71, 83, 93, 97, 101, 114, 124, 127, 131, 133, 144, 147, 148, 153], "argmax": [4, 9, 18, 31, 42, 43, 70, 77, 127], "argmin": [38, 67, 86, 105, 150, 151, 162], "argsort": [42, 97], "argu": [4, 8, 17, 20, 35, 44, 47, 59, 60, 61, 63, 64, 74, 118, 134, 144, 152], "argument": [0, 13, 17, 34, 35, 39, 44, 47, 51, 53, 68, 73, 77, 80, 93, 97, 103, 105, 118, 128, 134, 135, 137, 139, 145, 157, 160], "aris": [7, 35, 48, 49, 52, 54, 67, 78, 84, 125, 134, 162], "aristotelian": 63, "arithmet": [23, 137], "arlier": 136, "around": [13, 17, 20, 24, 26, 30, 35, 37, 42, 44, 45, 54, 72, 74, 77, 78, 84, 90, 106, 111, 127, 128, 131, 144, 145, 149, 152, 160, 164], "arr": 137, "arr1": 137, "arr1_2d": 137, "arr2": 137, "arr_from_list": 137, "arr_int": 137, "arr_to_list": 137, "arrai": [3, 5, 9, 17, 18, 26, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 45, 50, 51, 66, 68, 70, 71, 74, 77, 78, 79, 80, 83, 84, 94, 95, 96, 97, 104, 124, 127, 128, 131, 134, 139, 144, 145, 147, 148, 150, 151, 152, 153, 154, 157, 162, 163], "arrang": [76, 128], "array_equ": 137, "array_lik": 124, "array_split": 137, "arrest": 64, "arriv": [8, 67, 68, 101, 134, 135], "arrow": [18, 68, 118, 127, 135, 149, 155], "arrowprop": [18, 38, 127, 145], "arrowstyl": 145, "arsen": 23, "art": [45, 74], "articl": [28, 49, 67, 77, 90, 122, 124, 129, 137], "articul": [49, 54, 58, 62], "artifact": 7, "artifici": [35, 41, 46, 48, 64, 65, 71, 75, 89, 90, 102, 103, 105, 118], "artificialneuron": 68, "arviz": [74, 94, 152, 153], "arviz_vers": 152, "arxiv": [1, 41, 73, 87, 93, 95, 127, 164], "as_cmap": [74, 94], "as_grai": 128, "asarrai": [6, 78, 84, 93, 97], "ascend": [38, 137], "ascertain": [44, 54, 154], "asid": [21, 22, 26, 40, 44, 148, 152, 153], "ask": [11, 16, 17, 23, 32, 34, 42, 43, 44, 50, 52, 54, 60, 61, 69, 101, 135, 138, 146, 147, 163], "aspect": [26, 27, 38, 48, 50, 54, 57, 59, 61, 64, 78, 79, 83, 84, 89, 90, 131, 164], "aspir": 44, "ass": 74, "assembl": [76, 93], "assembli": 134, "assert": [34, 38, 51, 71, 83, 97, 145, 148, 153, 162], "assess": [7, 35, 44, 49, 52, 64], "assign": [8, 17, 22, 23, 26, 31, 35, 39, 44, 45, 47, 54, 56, 59, 66, 73, 80, 86, 89, 102, 120, 121, 131, 137, 152, 155, 162], "assist": 135, "associ": [35, 40, 44, 46, 54, 68, 74, 78, 79, 84, 86, 98, 105, 111, 118, 134, 148, 151, 152, 153], "assum": [3, 4, 8, 16, 17, 20, 22, 23, 24, 26, 30, 32, 35, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 64, 66, 67, 68, 72, 73, 74, 79, 81, 83, 86, 87, 89, 91, 93, 96, 97, 100, 102, 103, 114, 116, 120, 121, 122, 124, 127, 131, 134, 137, 138, 143, 144, 145, 148, 152, 153, 154, 155, 157, 162], "assumpt": [7, 8, 12, 17, 35, 42, 43, 44, 47, 54, 62, 63, 64, 66, 76, 79, 83, 96, 98, 101, 120, 134, 157], "asterisk": [0, 35, 135], "astro": 81, "astronom": [1, 16, 17, 42, 59, 111, 160], "astrophysicist": 160, "astropi": 143, "astyp": [74, 94, 137], "asymmet": 20, "asymmetr": [19, 20, 145, 155, 160], "asymmetri": [64, 134], "asymptot": [24, 67], "atari": 74, "atleast_1d": 124, "atol": [150, 151], "atom": [1, 63, 134, 145], "atomic_mass": 134, "attack": 48, "attain": [8, 49], "attempt": [9, 16, 37, 45, 49, 54, 67, 73], "attend": 64, "attent": [16, 23, 64], "attitud": [62, 64, 65], "attr": [51, 97, 157], "attract": 134, "attractor": 52, "attribut": [7, 44, 51, 54, 97, 131, 137, 152], "attributeerror": [51, 97], "au": 35, "audi": [1, 134], "augment": [45, 93], "aurelien": 67, "author": [47, 57, 74, 77, 78, 81, 82, 92, 118, 120], "authorize_download": 78, "authour": 65, "auto": [79, 83, 144, 152], "autocorrel": [44, 145, 147, 164], "autoencod": 74, "automag": 65, "automat": [1, 7, 39, 65, 72, 73, 74, 90, 98, 106, 134, 137, 159], "automobil": 77, "autonomi": 64, "autoscal": [9, 43, 130], "autoscale_on": [79, 83], "autotun": 147, "auxiliari": [157, 164], "avail": [4, 9, 18, 24, 26, 40, 41, 44, 45, 47, 49, 57, 65, 74, 78, 82, 83, 84, 86, 95, 105, 120, 122, 124, 131, 134, 135, 138, 139, 140, 145, 148, 151, 153, 154, 155], "availa": 124, "available_cor": 124, "avec": [50, 53], "avec_1": 53, "avec_2": 53, "avenu": 74, "averag": [4, 16, 19, 20, 22, 34, 37, 44, 45, 52, 53, 54, 60, 66, 67, 68, 72, 73, 76, 94, 97, 108, 111, 131, 134, 144, 145, 146, 147, 153, 154, 155, 160, 162, 163], "avg": 152, "avg_lnl": 97, "avoid": [16, 23, 32, 44, 45, 47, 51, 67, 68, 72, 73, 74, 87, 93, 97, 108, 134, 135, 138, 149], "awai": [12, 17, 35, 39, 40, 47, 54, 128, 135, 147, 148, 149, 153, 155, 160], "awar": [48, 62, 64, 82, 89, 107, 157], "award": 68, "awesom": 35, "awkward": 136, "ax": [0, 3, 5, 6, 9, 17, 18, 26, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 50, 51, 54, 66, 71, 74, 78, 79, 82, 83, 84, 89, 94, 96, 97, 103, 126, 127, 128, 130, 131, 133, 134, 135, 136, 137, 144, 145, 147, 148, 150, 153, 154, 157, 162, 163], "ax1": [18, 38, 40, 79, 83, 127, 128, 135, 145, 153], "ax2": [5, 18, 38, 40, 79, 83, 127, 128, 135, 145, 153], "ax2_1": 38, "ax2_2": 38, "ax2_3": 38, "ax2_4": 38, "ax3": [18, 38, 127, 128, 145], "ax3d": 131, "ax4": 38, "ax_1": [18, 43], "ax_2": [18, 43, 151], "ax_3": [18, 43], "ax_4a": 151, "ax_4b": 151, "ax_4c": 151, "ax_4d": 151, "ax_5a": 151, "ax_c": 150, "ax_pass": 136, "ax_plot": [146, 163], "ax_run": [157, 162], "ax_trac": [146, 163], "ax_tru": 38, "axes3d": [51, 66], "axhlin": [38, 127, 148, 151, 152, 153], "axi": [9, 18, 34, 37, 38, 39, 40, 41, 43, 51, 66, 67, 74, 78, 79, 82, 83, 89, 94, 95, 97, 124, 127, 128, 131, 135, 136, 137, 139, 143, 147, 150, 153, 157, 162], "axiom": [8, 16, 25], "axiomat": [26, 63], "axis_label": 150, "axs_vec": [26, 31], "axvlin": [9, 38, 43, 127, 128, 131, 145, 148, 153], "az": [152, 153], "azim": 66, "b": [0, 1, 4, 9, 13, 18, 22, 23, 24, 26, 32, 35, 37, 38, 39, 41, 42, 43, 45, 47, 48, 50, 63, 65, 66, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 83, 84, 91, 93, 94, 96, 97, 115, 116, 118, 124, 126, 127, 128, 131, 134, 135, 136, 144, 145, 147, 152, 155], "b1": [18, 127], "b2": 18, "b_": [37, 96], "b_0": 37, "b_1": [113, 131], "b_2": 131, "b_grid": 38, "b_i": [68, 131], "b_j": [68, 69, 131], "b_k": 128, "b_m": 68, "b_margin": [37, 38], "b_max": 38, "b_n": [35, 113, 131], "b_pt": 38, "b_std": 130, "b_true": 38, "b_true_fix": [37, 38], "b_true_index": 38, "b_x": 54, "b_y": 54, "ba": 1, "ba524": 1, "baath": 127, "bacciagaluppi": 129, "back": [1, 8, 9, 10, 11, 16, 18, 26, 31, 37, 41, 52, 54, 64, 66, 67, 68, 71, 72, 76, 79, 80, 83, 89, 94, 128, 135, 136, 144, 147, 152, 154, 155, 160], "backend": [74, 135], "background": [4, 8, 16, 25, 26, 39, 44, 54, 57, 63, 64, 91, 96, 97, 123, 155, 159, 161], "backpropag": 73, "backtick": 0, "backward": [15, 68, 69, 72, 73, 128, 147, 149], "bacteri": 162, "bacteria": 162, "bad": [20, 42, 67, 74, 77], "badli": [49, 152], "bag": 16, "baggin": 134, "bailei": 127, "baishan": 1, "balanc": [52, 54, 64, 67, 149, 154], "ball": [4, 16, 121, 148, 153], "balldrop": 122, "balzac": 46, "banana": [4, 154, 155], "band": [18, 48, 49, 80, 83, 87, 95, 157], "bandwidth_factor": 83, "bar": [4, 16, 17, 18, 23, 30, 32, 34, 38, 39, 41, 42, 45, 50, 53, 54, 66, 67, 70, 77, 78, 84, 108, 121, 124, 127, 128, 131, 134, 135, 144, 145, 147, 148, 152, 153], "bare": [37, 52, 64], "barnett": 86, "bartlett": 67, "base": [1, 4, 8, 9, 22, 23, 26, 32, 33, 34, 35, 38, 39, 40, 44, 46, 47, 48, 49, 51, 52, 54, 59, 63, 64, 65, 67, 68, 70, 72, 73, 78, 79, 83, 84, 89, 90, 93, 94, 96, 97, 101, 102, 108, 114, 118, 120, 124, 125, 131, 134, 135, 136, 138, 139, 141, 144, 145, 148, 149, 152, 153, 154, 155], "baselin": [34, 38, 151], "basi": [1, 4, 17, 23, 46, 48, 54, 63, 64, 66, 77, 80, 81, 86, 87, 89, 101, 102, 103, 111, 122, 123, 126, 128], "basic": [8, 17, 21, 23, 28, 37, 45, 48, 50, 51, 57, 63, 65, 67, 69, 70, 74, 80, 86, 88, 91, 92, 94, 106, 131, 134, 135, 139, 143, 147, 149, 150, 154, 157, 159, 160, 163, 164], "basic_model": [152, 159], "basic_model_alt": 152, "batch": [67, 68, 69, 77, 89, 98], "batch_siz": [70, 74, 107], "bay": [1, 7, 8, 9, 13, 15, 16, 17, 20, 21, 25, 28, 31, 33, 35, 36, 37, 38, 40, 42, 43, 44, 45, 50, 53, 54, 56, 57, 59, 60, 63, 86, 89, 96, 145, 148, 152, 153, 159], "bayes_text": 9, "bayesian": [1, 2, 11, 12, 13, 14, 17, 19, 21, 22, 24, 25, 26, 29, 30, 36, 37, 38, 41, 43, 45, 46, 47, 48, 50, 51, 53, 57, 58, 59, 61, 63, 65, 80, 86, 87, 89, 90, 91, 92, 95, 97, 98, 101, 102, 104, 111, 114, 117, 118, 120, 121, 122, 123, 124, 125, 127, 131, 143, 144, 145, 146, 152, 155, 162, 163, 164], "bayesian_7": 152, "bayesian_cr_slope_max": 42, "bayesian_cr_slope_min": 42, "bayesian_neural_network_advi": [74, 94], "bayesian_neural_networks_tif285": 94, "bayesian_research_cycl": 0, "bayesian_slope_maxprob": 42, "bayesian_slope_mean": 42, "bayesianastronomi": [38, 41], "bayesianoptim": 93, "bayesianworkflow": 0, "baysian": 73, "bbox": [96, 127], "bbox_inch": [150, 151], "bbox_to_anchor": 82, "bckw15": [1, 73], "bda": [52, 147], "bda3": [0, 1, 35, 52, 54], "beach": [148, 153], "beam": 52, "bearer": 8, "beat": 74, "beaten": 63, "becaus": [5, 13, 17, 20, 24, 26, 32, 34, 35, 37, 39, 40, 41, 43, 44, 48, 49, 50, 52, 53, 54, 59, 63, 64, 67, 72, 73, 76, 77, 78, 79, 81, 83, 84, 96, 98, 126, 128, 136, 137, 144, 145, 147, 148, 149, 153, 155, 160], "bechmark": 74, "becom": [0, 4, 7, 17, 18, 20, 26, 34, 35, 37, 40, 45, 46, 47, 49, 53, 54, 63, 65, 66, 67, 68, 73, 74, 78, 79, 83, 84, 86, 87, 90, 96, 98, 100, 101, 106, 108, 114, 121, 122, 123, 134, 135, 137, 148, 153, 154, 155, 157, 162], "been": [4, 8, 17, 20, 26, 28, 32, 44, 45, 47, 48, 49, 50, 54, 57, 60, 62, 64, 65, 67, 68, 73, 74, 81, 101, 108, 120, 124, 127, 138, 147, 152, 155, 159], "befor": [0, 8, 9, 10, 16, 17, 24, 25, 26, 32, 35, 40, 41, 43, 44, 45, 49, 53, 54, 60, 64, 66, 67, 68, 69, 70, 72, 76, 77, 78, 79, 81, 82, 83, 84, 89, 98, 106, 128, 131, 134, 137, 143, 144, 148, 149, 151, 153, 160], "beforehand": [54, 145, 154], "begin": [0, 3, 4, 7, 8, 9, 13, 15, 16, 17, 20, 23, 25, 26, 35, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 50, 52, 54, 64, 66, 67, 68, 69, 72, 73, 76, 78, 79, 80, 83, 84, 86, 87, 89, 96, 98, 100, 101, 103, 104, 105, 107, 108, 114, 121, 124, 126, 128, 131, 133, 134, 135, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 160, 162, 163], "beginn": 70, "behav": [17, 124, 155], "behavior": [11, 38, 45, 51, 54, 65, 72, 80, 91, 97, 122, 130, 134, 145], "behaviour": [54, 68, 69, 86], "behind": [16, 54, 64, 96, 134, 149], "being": [4, 16, 17, 20, 22, 23, 24, 26, 32, 33, 34, 35, 40, 41, 44, 45, 47, 48, 49, 54, 57, 59, 64, 65, 67, 68, 69, 72, 74, 78, 84, 86, 89, 90, 94, 118, 123, 127, 131, 138, 144, 145, 147, 148, 153, 155, 157, 159, 160], "belatedli": 24, "belief": [8, 10, 11, 15, 16, 18, 20, 23, 26, 35, 42, 44, 47, 62, 64, 131, 145], "believ": [10, 11, 26, 35, 43, 49, 58, 62, 64, 74, 111, 128], "bell": [127, 135], "belong": [63, 64, 66, 70, 73, 83, 87, 89, 126, 162], "below": [0, 4, 7, 17, 18, 20, 22, 23, 34, 35, 39, 40, 44, 45, 47, 48, 51, 52, 54, 61, 64, 66, 67, 68, 70, 71, 73, 74, 77, 78, 79, 83, 84, 86, 93, 94, 96, 97, 101, 103, 121, 122, 127, 128, 131, 134, 135, 137, 143, 145, 146, 147, 151, 152, 154, 157, 160, 162, 163], "benchmark": 74, "benefici": 154, "benefit": [48, 57, 64, 67, 72], "benign": 67, "berg": 134, "bernardo": 1, "bernardo94": 49, "bernoulli": [8, 9, 74, 94], "besid": [16, 43, 87, 152], "best": [0, 4, 5, 8, 9, 11, 17, 18, 19, 20, 26, 30, 31, 35, 37, 39, 48, 51, 52, 54, 56, 60, 63, 66, 67, 68, 71, 72, 75, 80, 87, 89, 92, 93, 96, 98, 105, 107, 122, 124, 131, 135, 138, 143, 154, 155, 162, 163], "bet": [8, 26, 135], "beta": [9, 19, 20, 31, 35, 39, 42, 46, 48, 51, 52, 97, 124, 127, 128, 131, 134, 145, 157], "beta0": 35, "beta1": 35, "beta1_label": 18, "beta2_dist": 18, "beta2_label": 18, "beta_": 52, "beta_0": 35, "beta_1": [9, 31, 35, 159], "beta_1_w": 9, "beta_2": [9, 52, 159], "beta_2_w": 9, "beta_3": 9, "beta_3_w": 9, "beta_dist": 18, "beta_grid": 35, "beta_i": [35, 46, 48, 52, 159], "beta_n": 52, "beta_sampl": 18, "beta_v": 124, "betai": 35, "betas0": 97, "betavec": 48, "better": [0, 4, 5, 7, 8, 24, 26, 30, 32, 34, 35, 37, 40, 41, 43, 47, 48, 54, 64, 66, 67, 68, 70, 71, 72, 74, 76, 78, 80, 84, 86, 93, 94, 97, 98, 111, 118, 124, 126, 131, 134, 136, 148, 149, 151, 152, 153, 154, 155], "betti": [22, 63], "between": [0, 4, 9, 11, 15, 16, 17, 20, 22, 23, 24, 26, 27, 31, 35, 37, 38, 39, 41, 43, 44, 45, 47, 49, 52, 53, 54, 57, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 79, 84, 86, 87, 89, 93, 94, 96, 97, 98, 105, 106, 111, 115, 117, 118, 120, 121, 124, 127, 131, 134, 135, 137, 139, 144, 147, 149, 152, 154], "beutler": 164, "bewar": 23, "beyond": [8, 20, 27, 48, 49, 54, 63, 79, 120, 146, 163], "bf": [50, 122, 124], "bf02551274": 1, "bfg": 93, "bgd": 107, "bgjm11": [1, 45], "bi": [35, 52, 83], "bia": [1, 20, 26, 35, 65, 66, 68, 69, 72, 73, 75, 78, 84, 89, 94, 96, 98, 100, 108, 118, 130], "bianca": 1, "bias": [9, 16, 24, 26, 31, 40, 60, 62, 65, 68, 69, 72, 73, 76, 94, 118, 120, 148, 153, 162], "bias_std": 130, "bib": 0, "bibtex": 0, "bic": 52, "bicyclist": 65, "bienaym\u00e9": 47, "big": [35, 61, 65, 101, 118, 155, 157], "bigg": [35, 46, 101], "bigger": [43, 57, 69], "biggest": 64, "biggl": [80, 87], "biggr": [80, 87], "bigl": [4, 20, 25, 30, 35, 37, 48, 52, 80, 87, 118, 149, 160], "bigr": [4, 20, 25, 30, 35, 37, 48, 52, 80, 87, 118, 149, 160], "bilbo": 134, "billiard": 39, "billion": 68, "bimod": [18, 68, 131], "bin": [4, 18, 20, 30, 34, 37, 38, 42, 43, 51, 83, 97, 127, 130, 131, 144, 145, 146, 147, 152, 157, 163], "bin_arrai": 34, "bin_bound": 43, "bin_edg": 127, "bin_num": [146, 163], "bin_width": [34, 43], "binari": [9, 31, 64, 65, 67, 70, 72, 73, 74, 75, 77, 94, 134], "binary_classification_data_fig": 66, "binarygibbsmetropoli": 152, "binarymetropoli": 152, "bind": 155, "binder": 138, "binomi": [13, 20, 26, 34], "biolog": [49, 68, 89, 111], "biologi": [1, 47], "bipoc": 64, "bird": 77, "birth": 134, "bit": [9, 11, 20, 39, 52, 138, 148, 153], "bitrat": 127, "bivari": [17, 45, 54, 73, 83, 87, 121, 154, 157, 162], "bivariate_fig": 131, "bla": 137, "black": [7, 18, 24, 35, 38, 39, 41, 43, 48, 61, 64, 66, 82, 89, 103, 118, 124, 127, 136, 146, 151, 163, 164], "blank": 33, "blei": [1, 73], "blind": [17, 131], "blindli": 152, "block": [17, 65, 67, 70, 86, 131, 134], "blockedstep": 152, "blog": [39, 73, 74, 94, 108, 127, 128, 135, 145, 149, 154, 155], "blond": 4, "bloodi": 63, "blow": 118, "blown": 92, "blr": [16, 29, 101, 104, 114], "blue": [5, 9, 18, 24, 31, 32, 33, 34, 35, 38, 39, 41, 43, 45, 48, 50, 66, 67, 70, 73, 76, 77, 80, 81, 89, 94, 96, 103, 122, 127, 128, 133, 135, 144, 145, 146, 148, 151, 153, 155, 163, 164], "blundel": 1, "bmatrix": [35, 89, 101], "bmax": 97, "bmc": 1, "bn": 96, "bnn": 90, "bnn_binary_classifier_mean": 73, "bnn_binary_classifier_stddev": 73, "bo": 154, "bob": 137, "bodi": [16, 46, 63, 65, 111, 115, 127], "boh": 122, "bohr": 26, "boil": 8, "bold": [35, 100, 111, 135], "boldfac": [94, 118, 128], "boldsymbol": [0, 7, 9, 17, 31, 35, 45, 66, 67, 68, 69, 73, 75, 79, 83, 89, 97, 98, 101, 105, 106, 107, 121, 124, 128, 131, 134, 154, 157, 162], "boltzman": 52, "boltzmann": [4, 5, 45, 52, 68], "bon": 35, "bonu": [39, 91, 97], "book": [1, 9, 24, 40, 41, 43, 51, 59, 60, 63, 64, 73, 76, 82, 96, 97, 127, 132, 141, 153], "boolean": [26, 31, 124, 128, 137, 154], "boost": [68, 74], "boot": 77, "bootstrap": [15, 45, 74], "border": [43, 133, 135, 160], "bore": 52, "bori": [1, 57], "born": 24, "borrow": 134, "boson": [20, 131], "both": [4, 7, 11, 17, 20, 23, 26, 32, 34, 35, 38, 39, 41, 44, 45, 48, 49, 51, 54, 57, 60, 64, 66, 67, 68, 72, 73, 75, 78, 81, 82, 86, 94, 98, 107, 108, 111, 114, 120, 121, 122, 126, 127, 131, 133, 134, 135, 137, 143, 144, 145, 146, 149, 151, 152, 160, 161, 162, 163], "bother": [8, 49], "bottleneck": 106, "bottom": [10, 11, 18, 34, 38, 54, 95, 127, 155, 160], "bought": 8, "bound": [20, 35, 39, 43, 47, 48, 54, 68, 83, 93, 101, 124, 145], "boundari": [35, 48, 71, 73, 74, 75, 145, 154, 160], "bovin": 63, "bower": 1, "bowl": 149, "box": [0, 4, 9, 16, 18, 20, 33, 44, 48, 51, 57, 61, 66, 109, 118, 133, 135, 138, 160, 164], "br": 9, "bra": 48, "bracket": [78, 84], "bragg": 17, "brain": [1, 63, 68, 89], "braket": 48, "branch": [8, 44], "brand": 74, "break": [0, 3, 23, 49, 72, 134, 135], "breakdown": 72, "bremen": [81, 82], "breviti": 131, "brewer": [0, 24], "bridg": 1, "brief": [49, 54, 123, 126, 135, 159], "briefli": [16, 24, 49, 65, 98, 134], "bring": [63, 64], "british": 64, "broad": [35, 40, 42, 48, 54, 65, 148, 153], "broaden": [60, 112], "broader": [105, 113], "broadli": [46, 49, 57, 62, 90, 126], "broken": 60, "brook": 1, "brown": [23, 33], "brownian": [78, 84, 162], "browser": 135, "bruno": 47, "brynjarsd\u00f3ttir": 120, "bs06": [1, 45], "bsd": [81, 82], "bubnov": 48, "bufsiz": 127, "bug": [63, 93, 134, 135], "build": [1, 4, 7, 24, 35, 43, 46, 48, 49, 62, 63, 64, 65, 66, 67, 71, 74, 75, 78, 84, 86, 90, 94, 96, 130, 135, 138, 149, 155], "build_model": 130, "built": [18, 20, 24, 34, 48, 49, 52, 67, 72, 131, 134, 135, 136, 154], "builtin": [51, 97], "bukov": 1, "bulk": 47, "bullet": [16, 124, 135], "buqey": [0, 1, 123, 128], "burden": 47, "burn": [6, 39, 51, 90, 97, 124, 146, 147, 148, 152, 153, 155, 160, 163], "burnin": [51, 153], "busi": 64, "bution": 44, "button": [5, 9, 133, 135, 138, 139], "button_styl": 9, "bv": 115, "bvec": 53, "bx": 128, "byte": [70, 134], "b\u00e5\u00e5th": 127, "c": [0, 1, 3, 11, 16, 22, 35, 37, 39, 45, 50, 51, 52, 54, 57, 65, 66, 67, 68, 69, 71, 72, 73, 74, 78, 79, 80, 83, 84, 87, 89, 93, 94, 98, 101, 105, 106, 107, 108, 114, 121, 124, 127, 128, 131, 132, 134, 135, 138, 143, 147, 151, 152, 157, 162], "c0": 124, "c2pread": 127, "c2pwrite": 127, "c41": 134, "c_": [67, 71, 83, 86, 101, 107], "c_0": 80, "c_1": 16, "c_2": 16, "c_i": 47, "c_k": 16, "c_n": [106, 107], "c_w": 73, "cal": [49, 69], "calcul": [0, 7, 9, 13, 16, 17, 20, 23, 32, 34, 35, 38, 40, 43, 44, 45, 47, 48, 51, 53, 66, 68, 69, 72, 73, 87, 92, 96, 97, 102, 123, 124, 126, 127, 131, 133, 134, 135, 137, 144, 146, 147, 148, 149, 151, 152, 153, 155, 157, 159, 160, 163], "calculu": [0, 8, 16, 20, 59, 60, 155, 162], "calibr": [44, 45, 46, 48, 67, 78, 80, 87, 111, 120, 122, 123, 145, 152], "call": [0, 3, 8, 9, 11, 12, 15, 16, 17, 18, 19, 20, 24, 26, 30, 32, 35, 38, 39, 41, 45, 47, 48, 51, 53, 54, 56, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 79, 80, 87, 89, 94, 95, 96, 97, 98, 101, 103, 105, 111, 126, 127, 128, 131, 133, 134, 135, 136, 137, 138, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 157, 162, 163, 164], "callabl": [124, 145], "callback": [9, 127], "cambridg": [1, 57], "camco": 1, "camp": 54, "can": [0, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86, 87, 89, 90, 91, 93, 94, 95, 96, 97, 98, 101, 102, 103, 105, 106, 107, 108, 111, 112, 113, 114, 116, 118, 120, 123, 124, 125, 126, 127, 128, 129, 131, 132, 134, 135, 136, 137, 138, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 162], "canada": 1, "cancel": [4, 45, 52, 53, 54, 67, 145], "candid": [4, 26, 56, 64, 105, 154, 155, 160], "cannot": [17, 20, 22, 26, 35, 44, 47, 48, 54, 64, 66, 74, 94, 101, 104, 131, 135], "canon": [45, 49, 149], "canva": 127, "cap": [23, 67, 131], "capabl": [18, 65, 105], "caprici": 23, "capsiz": 124, "caption": [0, 157], "captur": [44, 45, 47, 48, 64, 67, 68, 72, 120, 122, 144], "car": [16, 65, 74], "card": 33, "care": [5, 8, 16, 18, 24, 32, 33, 37, 38, 44, 48, 52, 59, 73, 74, 91, 128, 131, 134, 136, 137], "carefulli": [44, 47, 57], "carl": [1, 86], "carlin": 1, "carlo": [1, 16, 17, 44, 65, 73, 97, 124, 146, 148, 152, 153, 158, 160, 161, 162, 163, 164], "carlsson": 57, "carmak": 65, "carmen": [143, 149], "carri": [13, 35, 38, 44, 45, 50, 54, 60, 61, 62, 63, 67, 87, 89, 118, 122, 145, 146, 155, 163], "carrol": 59, "cartesian": 151, "cartoon": 52, "case": [0, 8, 9, 10, 16, 17, 19, 22, 23, 24, 26, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 45, 48, 49, 50, 53, 54, 64, 65, 66, 67, 68, 69, 72, 73, 74, 76, 80, 81, 87, 89, 93, 94, 96, 97, 98, 101, 102, 103, 104, 106, 111, 116, 118, 121, 124, 128, 131, 134, 135, 137, 138, 143, 145, 147, 148, 149, 152, 153, 154, 155, 157, 160, 164], "casino": 162, "cast": [48, 61, 68], "cat": [77, 118], "categor": [22, 44, 46, 65, 73, 111], "categori": [8, 48, 64, 65, 66, 68, 76, 89, 105, 125], "categoricalgibbsmetropoli": 152, "cauchi": [43, 127, 145], "cauchy_dist": 43, "cauchypropos": 152, "caus": [15, 32, 39, 49, 54, 63, 67, 72, 106, 107, 127, 152, 155], "causal": 63, "caution": [7, 42, 136], "caveat": 138, "cbar": [51, 74, 94, 124], "cbarbieri": 46, "cbo9780511790423": 1, "cbo9780511791277": 1, "cbook": 127, "cc": [35, 44, 68, 79, 104, 134, 157], "ccc": [68, 157], "cccc": 128, "cd": [138, 141], "cdf": 93, "cdot": [13, 16, 20, 24, 32, 33, 34, 35, 43, 45, 46, 48, 49, 50, 53, 66, 68, 72, 89, 95, 121, 124, 128, 137, 143, 144, 147, 157, 160], "ceil": 137, "celebr": 47, "cell": [17, 38, 43, 51, 66, 70, 71, 74, 94, 97, 127, 134, 136, 139, 143, 145, 152, 154], "cent": 8, "center": [8, 11, 20, 34, 35, 37, 38, 43, 51, 54, 73, 74, 75, 89, 126, 127, 128, 131, 144, 145, 151], "central": [25, 27, 43, 44, 65, 95, 121, 129, 130, 151, 155], "centrifug": 151, "centuri": [8, 54, 63, 111], "certain": [7, 11, 15, 35, 44, 46, 47, 49, 59, 64, 73, 74, 76, 89, 96, 105, 120, 134, 137, 145, 154, 157], "certainli": [45, 65, 68, 106, 135, 136, 148, 153, 162], "certainti": [8, 16, 44, 73], "cf": [20, 32, 33, 37, 52, 53, 74, 80, 86, 87, 94, 123, 149, 155, 160], "cft": 34, "cft_n": 34, "cft_n_pt": 34, "ch": [39, 40, 54, 153], "chain": [1, 6, 16, 17, 39, 42, 44, 52, 60, 68, 70, 72, 97, 124, 145, 146, 147, 148, 149, 152, 153, 160, 161, 162, 163, 164], "chain1": [51, 144], "chain1d": [144, 145], "chain2": [51, 144], "chain_data": 124, "chain_length": 152, "chainpandasindexpandasindex": 152, "challeng": [8, 16, 35, 45, 49, 52, 54, 74, 89, 93, 108, 111, 114, 120, 123, 155], "chalmer": [1, 57, 79], "champion": 74, "chanc": [16, 20, 26, 73, 145, 160], "chang": [3, 4, 9, 11, 13, 16, 18, 23, 25, 26, 31, 34, 35, 37, 38, 40, 41, 44, 46, 48, 50, 52, 54, 57, 59, 62, 65, 68, 69, 72, 74, 78, 80, 84, 87, 93, 94, 95, 96, 97, 123, 124, 127, 128, 132, 133, 134, 135, 136, 143, 144, 145, 147, 149, 150, 151, 152, 153, 154, 157, 159, 160], "channel": [66, 74, 76, 77, 89, 138], "chapman": [0, 1, 57], "chapter": [2, 7, 16, 21, 27, 28, 29, 31, 35, 36, 37, 38, 44, 45, 47, 54, 56, 58, 62, 64, 65, 67, 73, 76, 87, 89, 90, 99, 100, 106, 111, 119, 120, 125, 154, 155, 157, 161], "charact": [9, 134], "character": [8, 16, 18, 20, 37, 44, 48, 67, 68, 80, 95, 107, 112, 123, 126, 127, 144, 148, 153, 155], "characteris": 64, "characterist": [64, 72, 87], "charg": [22, 134], "charl": 1, "chart": 96, "chase": 7, "chatterji": 67, "cheat": 137, "cheatsheet": 135, "chebyshev": 47, "check": [0, 3, 4, 13, 17, 19, 23, 35, 36, 37, 38, 39, 43, 45, 50, 52, 60, 67, 70, 74, 78, 84, 86, 87, 93, 94, 95, 97, 124, 127, 128, 135, 137, 138, 144, 146, 147, 149, 152, 154, 157, 160, 163], "checkabl": 50, "checkbox": [5, 9, 133], "checklist": 29, "checklist_b": 0, "checkmark": 25, "checkpoint": 135, "chess": 80, "chi": [17, 19, 20, 27, 39, 46, 50, 52, 53, 96, 97, 98, 126, 128, 149, 154, 155], "chi2": 30, "chi_": 124, "chi_sqs_dof": 96, "chi_squar": 96, "chief": 60, "child": [46, 127], "child_exception_typ": 127, "children": [9, 64, 133], "chines": [1, 134], "ching": 1, "chiral": [1, 48, 127], "chisq_min": 50, "choic": [4, 8, 9, 15, 16, 18, 20, 24, 26, 31, 39, 40, 41, 42, 44, 45, 47, 54, 64, 65, 66, 67, 68, 72, 75, 78, 81, 84, 93, 95, 96, 101, 107, 108, 114, 118, 121, 131, 135, 139, 145, 148, 153, 154, 157, 160, 162, 164], "choleski": [79, 87], "choos": [5, 7, 13, 20, 37, 39, 41, 42, 43, 44, 45, 47, 48, 49, 54, 59, 63, 64, 67, 68, 70, 72, 73, 78, 84, 105, 106, 135, 144, 145, 146, 147, 154, 163], "chose": [48, 97, 157], "chosen": [0, 7, 26, 37, 47, 48, 51, 52, 54, 78, 84, 86, 106, 145, 146, 152, 154, 155, 163], "chri": [86, 129], "christian": [1, 39, 40, 45, 51, 57, 74, 78, 79, 94, 96, 144, 145, 148, 153], "christoph": [1, 129], "chromosom": 131, "ci": [9, 31, 124], "cifar": 77, "circ": [69, 79], "circl": [4, 35, 37, 39, 68, 73, 79, 154], "circular": 154, "circumst": [8, 20, 44, 64], "circumstanti": 63, "circumv": 54, "citat": [0, 64], "cite": [0, 44, 49, 73], "citizen": 65, "clabel": 131, "claim": [22, 43, 45, 52, 64, 65, 80, 87, 112, 116, 118, 128, 152, 155], "clang": [74, 94], "clariti": [79, 118], "class": [9, 29, 35, 47, 48, 54, 64, 65, 66, 68, 70, 71, 72, 73, 74, 75, 76, 77, 82, 94, 97, 98, 106, 126, 131, 134, 138, 146, 151, 157, 160, 162, 163], "class_i": 66, "class_mean": 66, "class_mean_list": 66, "class_nam": 77, "class_weight": 71, "classic": [8, 26, 40, 43, 52, 134, 148, 149, 153, 154], "classif": [44, 48, 63, 67, 68, 70, 72, 73, 74, 76, 77, 92, 94], "classifi": [64, 65, 67, 68, 73, 75, 77], "classifier_elbo": [73, 74], "classmat": 35, "claus": [81, 82], "clean": [72, 127], "cleaner": 74, "cleans": 93, "cleanup": 127, "clear": [10, 17, 20, 24, 35, 39, 41, 45, 52, 54, 60, 62, 72, 73, 74, 79, 91, 96, 97, 98, 104, 131, 135, 157], "clearer": [32, 44], "clearli": [7, 12, 35, 39, 44, 62, 64, 67, 74, 76, 80, 102, 157, 160], "clever": [35, 157], "clf": [71, 127, 134], "click": [18, 57, 135, 138, 162], "clickabl": 57, "climat": 47, "climb": 145, "clint": 1, "clip": 39, "clockwis": 128, "clone": [138, 140, 141], "close": [0, 12, 16, 30, 32, 34, 35, 38, 39, 41, 44, 45, 50, 54, 57, 65, 68, 69, 73, 74, 78, 81, 84, 87, 90, 96, 97, 98, 105, 108, 120, 126, 128, 134, 144, 145, 152, 154, 155], "close_fd": 127, "closer": [18, 39, 87, 152], "closest": [9, 17, 31, 38, 54, 66, 128], "cloth": 77, "cloud": [0, 23, 57, 132, 138], "clt": [34, 130], "clt_pdf": 34, "cluster": [48, 63, 67, 149], "cluster_std": 75, "clutter": [20, 87], "cm": [35, 38, 50, 51, 66, 70, 71, 77, 127, 131], "cmap": [35, 38, 41, 51, 66, 70, 71, 74, 77, 94, 128, 131], "cnn": [68, 90], "cntl": 155, "co": [34, 35, 47, 52, 72, 78, 83, 84, 93, 113, 135, 150, 151], "code": [13, 17, 18, 31, 34, 35, 37, 39, 41, 43, 44, 48, 51, 52, 57, 65, 71, 74, 77, 78, 84, 88, 93, 94, 95, 96, 97, 103, 107, 124, 134, 139, 143, 145, 146, 147, 152, 154, 159, 162, 163], "codebas": 44, "codec": 127, "codeloc": [124, 157, 162], "coef": 134, "coef_": [71, 134], "coeffici": [4, 17, 25, 48, 50, 66, 67, 68, 74, 87, 89, 95, 124, 131, 134, 137], "coerc": 134, "coher": [8, 129], "coin": [8, 13, 16, 24, 111, 162], "coin_data": 9, "coin_ppd": 0, "coinflipping_fig_1": 26, "col": [26, 31, 134, 135, 136], "colab": 77, "collabor": [16, 57], "collaps": 53, "collat": 78, "colleagu": [57, 64], "collect": [8, 12, 16, 26, 35, 36, 38, 40, 44, 45, 47, 48, 49, 63, 64, 65, 66, 67, 69, 70, 79, 80, 83, 86, 87, 101, 102, 103, 111, 118, 124, 125, 129, 131, 145, 148, 153, 154, 157, 162], "collid": 22, "collis": 162, "colon": [0, 135], "color": [3, 4, 5, 9, 18, 24, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 50, 64, 66, 67, 70, 72, 74, 76, 77, 78, 79, 81, 82, 83, 84, 89, 94, 96, 103, 121, 124, 127, 128, 131, 133, 135, 136, 144, 145, 146, 148, 150, 151, 153, 157, 162, 163], "color_channel": 77, "colorbar": [35, 51, 70, 74, 79, 83, 94, 153], "colour": 4, "columbia": 1, "column": [17, 32, 33, 35, 39, 46, 66, 96, 101, 103, 126, 129, 134, 135, 137, 144, 145, 147, 154, 157, 160], "com": [1, 74, 81, 82, 94, 128, 131, 136, 138, 141, 162], "combin": [0, 8, 16, 20, 32, 34, 35, 38, 40, 44, 45, 47, 48, 49, 51, 54, 56, 60, 63, 67, 68, 72, 74, 79, 80, 83, 86, 87, 89, 94, 107, 118, 121, 124, 126, 128, 143, 147, 148, 153, 154, 157, 159], "come": [0, 4, 8, 9, 10, 11, 16, 18, 20, 22, 30, 31, 35, 37, 39, 41, 44, 50, 52, 54, 63, 64, 67, 68, 73, 74, 80, 87, 93, 94, 102, 104, 127, 134, 138, 144, 145, 147, 148, 153, 155, 159, 160, 164], "comet": 111, "comfort": [20, 47], "comm": 1, "command": [0, 65, 70, 72, 78, 84, 95, 127, 134, 135, 136, 138, 143, 152], "comment": [18, 20, 37, 38, 41, 44, 50, 51, 52, 54, 66, 74, 97, 128, 135, 151, 155, 159], "commiss": 64, "commit": 64, "common": [0, 7, 11, 17, 20, 27, 35, 39, 41, 42, 44, 45, 47, 48, 49, 54, 57, 59, 61, 63, 66, 67, 68, 69, 71, 74, 77, 79, 83, 86, 87, 89, 96, 98, 100, 106, 111, 114, 118, 127, 131, 133, 134, 136, 137, 149, 150, 151, 152, 154, 155, 162], "common_num": 136, "commonli": [4, 41, 67, 89, 108, 118, 152, 154], "commun": [20, 57, 62, 65, 68, 98, 157], "comp": 1, "compact": [24, 66, 68, 69, 124], "compani": 64, "compar": [1, 6, 7, 9, 11, 14, 17, 18, 20, 30, 31, 35, 38, 39, 43, 44, 45, 48, 51, 52, 54, 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 79, 83, 84, 87, 93, 94, 95, 96, 121, 122, 126, 128, 130, 131, 134, 145, 151, 152, 157, 159, 160, 162, 164], "comparison": [16, 17, 18, 34, 35, 39, 44, 48, 52, 53, 63, 74, 94, 96, 103, 108, 117, 120, 127, 145, 147, 151, 157], "compat": [44, 89, 93, 128, 147], "compel": 62, "compet": [7, 49, 54, 62, 63, 65], "competit": 48, "compil": [35, 65, 70, 74, 94, 134], "compl": 67, "complaint": 152, "complementari": 54, "complet": [0, 3, 16, 17, 23, 26, 29, 32, 33, 35, 38, 39, 44, 47, 49, 50, 52, 53, 66, 68, 72, 77, 83, 86, 87, 117, 124, 131, 134, 135, 152, 154, 157, 162], "completemodel": 49, "completenn": 68, "complex": [1, 17, 45, 47, 48, 49, 63, 65, 68, 71, 75, 96, 118, 120, 137, 152, 155], "complianc": 77, "complic": [16, 35, 39, 52, 54, 65, 68, 71, 96, 98, 100, 106, 107, 108, 113, 145, 148, 152, 153, 154, 155], "compon": [42, 48, 54, 65, 72, 86, 125, 126, 147, 150, 151, 155], "compos": [48, 68, 97, 157], "compoundstep": 152, "comprehens": [38, 44], "compress": [48, 126, 134, 135, 137], "compromis": [64, 72], "comput": [1, 5, 9, 11, 16, 20, 26, 31, 35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 54, 57, 59, 60, 61, 63, 65, 66, 67, 68, 69, 71, 73, 74, 76, 77, 79, 80, 81, 83, 86, 87, 89, 90, 93, 96, 97, 98, 103, 105, 106, 108, 120, 123, 124, 125, 128, 131, 132, 134, 135, 137, 138, 141, 144, 145, 146, 147, 148, 152, 153, 154, 157, 160, 163], "computation": [7, 39, 45, 52, 72, 77, 80, 86, 106, 113, 123], "compute_sigma_level": 42, "compute_test_valu": [74, 94], "concat": 134, "concaten": [51, 97, 124, 135, 139, 163], "concentr": [9, 44, 73, 154], "concept": [1, 24, 25, 39, 44, 49, 62, 67, 74, 78, 84, 118], "conceptu": [20, 49, 67, 68], "concern": [7, 8, 17, 35, 46, 47, 54, 65, 66, 74, 89, 105, 129, 131, 134, 157], "concic": 134, "concis": 67, "conclud": [20, 32, 35, 40, 41, 51, 52, 64, 67, 103, 128, 153], "conclus": [12, 18, 35, 37, 38, 41, 52, 59, 62, 63, 68, 96, 97, 111, 131, 151], "concret": [16, 25, 118, 144, 154, 155], "conda": [71, 72, 74, 94, 135, 143], "condemn": 47, "condens": 44, "condit": [4, 8, 16, 20, 22, 23, 24, 25, 26, 30, 31, 32, 33, 35, 36, 38, 44, 45, 48, 54, 59, 62, 77, 78, 84, 86, 87, 121, 124, 126, 128, 130, 149, 150, 151, 154], "condition": 16, "conduct": [8, 22, 44, 49], "conf": 52, "confid": [9, 11, 16, 18, 26, 27, 30, 31, 42, 44, 47, 54, 56, 77, 78, 81, 84, 89, 122, 148, 153], "config": [74, 94, 130, 138], "configur": [44, 52, 77, 130, 138, 157], "confin": 160, "confirm": [47, 64, 68], "confiur": 147, "conflict": [44, 135], "conform": 63, "confront": [26, 31, 47, 63, 65], "confus": [33, 42, 64, 66, 97], "conisd": 116, "conjectur": 62, "conjug": [9, 35, 41, 45, 53, 96, 127, 137], "conjugaci": 53, "conjunct": 48, "connect": [4, 8, 24, 27, 34, 45, 47, 49, 52, 61, 62, 64, 67, 68, 69, 70, 74, 76, 91, 97, 108, 118, 128, 136], "consecut": 137, "consensu": [44, 62], "consequ": [8, 25, 34, 35, 36, 46, 47, 48, 59, 62, 64, 66, 67, 68, 69, 130, 145, 147, 150, 154], "conserv": [17, 45, 80, 122, 149, 152], "consid": [3, 4, 5, 6, 7, 8, 9, 10, 16, 17, 20, 23, 26, 27, 30, 34, 35, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 53, 54, 58, 63, 64, 65, 66, 67, 68, 69, 73, 74, 75, 76, 78, 83, 86, 87, 89, 94, 97, 100, 101, 105, 106, 111, 112, 115, 116, 118, 124, 125, 126, 131, 145, 148, 149, 150, 151, 153, 155, 157, 159, 160, 161, 162], "consider": [10, 49, 52, 62, 63, 72, 101], "considerd": 124, "consist": [4, 8, 18, 23, 33, 35, 44, 48, 49, 50, 52, 54, 59, 60, 63, 66, 67, 68, 70, 72, 73, 75, 76, 80, 94, 122, 124, 127, 135, 137, 143, 146, 157, 163], "consolid": 130, "consruct": 74, "constant": [3, 4, 5, 13, 17, 26, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 50, 52, 54, 68, 74, 79, 81, 86, 89, 91, 94, 95, 96, 97, 100, 103, 116, 121, 122, 123, 124, 131, 134, 135, 144, 145, 149, 154, 155, 160, 162], "constant_": 72, "constant_valu": 83, "constantkernel": [82, 83], "constantli": 155, "constitu": 134, "constitut": [12, 67, 73, 86], "constrain": [40, 41, 47, 48, 53, 54, 61, 67, 74, 76, 78, 84, 86, 112, 120, 122, 148, 153, 157], "constrain_posit": [78, 84], "constrained_layout": [124, 127], "constraint": [4, 8, 30, 39, 44, 47, 48, 67, 78, 84, 105, 127, 157, 162], "construct": [0, 8, 17, 19, 22, 23, 26, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 54, 65, 66, 68, 71, 73, 74, 78, 83, 84, 86, 97, 111, 120, 130, 131, 135, 136, 147, 148, 150, 152, 153, 154, 157], "construct_nn": [74, 94], "constructor": 72, "consum": [61, 64], "contact": 134, "contain": [8, 9, 15, 17, 18, 20, 26, 31, 42, 45, 47, 49, 63, 68, 70, 73, 74, 76, 77, 89, 94, 112, 124, 128, 131, 134, 137, 143, 148, 152, 153, 154, 157], "contemp": 1, "contemporari": 149, "content": [9, 44, 57, 92, 120, 123, 126, 133, 134, 137, 138], "context": [2, 4, 16, 17, 23, 24, 30, 35, 44, 45, 48, 49, 51, 54, 58, 59, 60, 61, 62, 64, 66, 67, 72, 73, 78, 84, 86, 97, 105, 111, 112, 125, 126, 131, 147, 151, 152, 159], "contextlib": 127, "contextmanag": 127, "contigu": 137, "contin": 87, "conting": [4, 10, 22, 23, 24, 59, 125], "continu": [1, 9, 11, 16, 18, 21, 23, 24, 25, 26, 27, 45, 47, 48, 49, 50, 54, 64, 65, 66, 67, 68, 72, 73, 83, 87, 89, 98, 102, 106, 123, 152, 154, 155, 157, 160, 162], "continuo": 66, "continuosli": 65, "continuous_upd": [9, 133], "continuum": [4, 24, 31, 44], "contour": [37, 38, 41, 42, 45, 51, 54, 66, 71, 74, 79, 83, 94, 131, 152, 153], "contour_func": [51, 153], "contour_level": [38, 41, 42], "contourf": [35, 38, 41, 51, 66, 71, 74, 94], "contract": 128, "contradict": [23, 62], "contrari": [40, 60, 148, 153], "contrast": [8, 27, 30, 37, 50, 63, 68, 73, 122, 162], "contribut": [39, 52, 53, 54, 57, 62, 65, 86, 134, 154], "contributor": 65, "control": [1, 9, 11, 48, 65, 71, 72, 75, 77, 81, 95, 121, 134, 143], "controversi": [40, 148, 153], "conv": 76, "conv2d": [72, 77], "conv2d_1": 77, "conv2d_2": 77, "convei": 48, "conveni": [35, 37, 38, 39, 40, 41, 42, 48, 50, 68, 69, 74, 118, 133, 135, 144, 148, 153], "convent": [0, 35, 48, 54, 68, 102, 117, 128, 133, 135, 155], "convention": [24, 135], "converg": [5, 12, 26, 42, 44, 47, 50, 69, 72, 74, 82, 93, 94, 106, 107, 108, 152, 153, 154, 160, 161, 164], "convergencewarn": [51, 82], "convers": [20, 129, 131, 157], "convert": [20, 43, 49, 70, 134, 135, 137, 152], "convex": [89, 98, 105], "convexhul": 150, "convinc": [4, 16], "convolut": [17, 72, 74, 90], "cookbook": 87, "coolwarm": [66, 131], "coordin": [8, 41, 48, 54, 66, 97, 128, 144, 149, 151, 152], "copi": [9, 45, 77, 79, 94, 97, 134, 136, 143, 144, 145, 152, 155, 160], "copyright": 77, "core": [8, 124, 134, 152], "cornebis": 1, "corner": [7, 8, 18, 26, 37, 39, 42, 51, 52, 73, 75, 83, 95, 97, 124, 131, 138, 143, 144, 147, 148, 153, 157, 162], "cornerplot": [51, 153], "corollari": 15, "corrcoef": 137, "correct": [12, 16, 17, 23, 24, 44, 49, 52, 53, 54, 66, 67, 70, 77, 86, 87, 108, 116, 118, 134, 135, 143, 149, 154, 155, 160], "correctli": [16, 19, 35, 70, 102, 136, 137, 148, 151, 153, 160], "correl": [0, 4, 25, 44, 45, 47, 48, 51, 65, 68, 74, 79, 83, 86, 87, 94, 95, 111, 118, 121, 128, 137, 145, 154, 155, 160, 162, 164], "corrent": 106, "correspond": [4, 17, 25, 26, 35, 38, 39, 42, 44, 45, 47, 48, 49, 51, 54, 61, 62, 66, 67, 68, 69, 71, 73, 75, 76, 77, 78, 79, 82, 83, 84, 87, 89, 97, 98, 100, 101, 102, 103, 106, 107, 108, 113, 114, 116, 118, 121, 122, 128, 131, 134, 135, 137, 145, 147, 150, 154, 157, 162], "correspondingli": 68, "cortex": 68, "cosh": 72, "cosin": [34, 35, 135], "cosineft": 34, "cosineft2": 34, "cosmo": 52, "cosmolog": 52, "cosmologi": [1, 22, 41, 96], "cosmologist": 160, "cost": [35, 45, 46, 47, 52, 54, 64, 65, 67, 68, 70, 71, 73, 86, 98, 101, 105, 106, 107, 108, 114, 124, 155], "cost_funct": 107, "costli": [45, 74, 106], "couch": [59, 63], "could": [3, 5, 8, 9, 11, 20, 22, 23, 26, 35, 44, 45, 47, 48, 49, 52, 53, 54, 59, 62, 66, 67, 68, 71, 73, 74, 76, 78, 84, 89, 97, 98, 102, 105, 106, 111, 112, 116, 120, 125, 127, 131, 133, 134, 136, 145, 147, 152, 154, 155, 157, 159], "coulomb": [35, 100, 134], "count": [4, 8, 9, 18, 34, 37, 38, 40, 43, 61, 68, 118, 124, 127, 134, 144, 153], "countabl": [87, 105, 131, 157], "counter": [16, 40, 43, 64, 128, 148, 153], "counterexampl": 157, "counterpart": [32, 89], "coupl": [24, 27, 41, 48, 53, 54, 118, 123, 135], "courag": 62, "cours": [1, 4, 20, 26, 31, 32, 35, 39, 40, 41, 51, 57, 64, 73, 78, 80, 89, 92, 95, 96, 98, 101, 135, 139, 144, 145, 148, 153], "cov": [25, 35, 47, 51, 66, 79, 83, 96, 128, 131, 144, 147, 162], "cov_exp": 124, "cov_mat": 50, "cov_matrix": 124, "cov_new": 83, "cov_opt": 83, "cov_rbf": [79, 83], "cov_tot": 124, "covari": [4, 17, 25, 35, 42, 47, 48, 50, 54, 73, 80, 81, 87, 93, 96, 120, 121, 122, 124, 126, 147, 149, 154, 162], "covariancematrix": 83, "cover": [20, 45, 64, 73, 117, 122, 124, 135, 155], "coverag": [90, 154], "covparslr": 35, "covr": 35, "cow": 22, "cox": [1, 23, 32, 33], "cox61": [1, 23], "cprob": [16, 22, 23, 47, 131, 157], "cpu": [39, 42, 51, 74, 94, 124, 137, 144, 164], "cpu_affin": 124, "cpu_count": 124, "cr": [39, 42], "crank": 152, "crash": [65, 139], "crc": [0, 1, 57], "creat": [6, 17, 35, 37, 38, 39, 41, 42, 48, 65, 66, 67, 68, 72, 74, 75, 76, 78, 81, 82, 83, 84, 89, 93, 94, 95, 96, 103, 112, 124, 127, 128, 130, 131, 135, 141, 144, 145, 149, 150, 152, 154, 155, 157, 162], "create_multiple_process": [157, 162], "created_at": 152, "creation": [74, 136, 137], "creationflag": 127, "creativ": 57, "cred68": [9, 18, 31, 127], "cred95": [9, 18, 31, 127], "credibl": [9, 18, 19, 27, 31, 42, 44, 45, 63, 83, 87, 95, 127], "credible_range_dist": 83, "credibleregions_fig": 131, "credit": 144, "creep": 64, "cri": 63, "cricl": 71, "crime": 64, "crimin": 64, "crit": 20, "criterion": [54, 72, 149, 154, 155], "critic": [8, 39, 44, 54, 62, 64, 65, 67, 68, 72, 74, 118, 129, 131, 137, 149], "cross": [4, 48, 52, 65, 66, 68, 71, 73, 129], "crossval_err": 96, "croupier": 162, "crowd": 67, "crucial": [16, 23, 44, 49, 54, 64, 72], "crudest": 151, "cs231": 76, "cset": [51, 153], "csr": 137, "csr_matrix": 137, "cstride": [38, 66], "csv": 78, "cubehelix_palett": [74, 94], "cubehelix_r": 51, "cubic": 54, "cubism": 129, "cuda": 72, "cultur": [64, 162], "cumsum": [38, 41, 42, 128, 134, 137], "cumul": [45, 128, 137], "cup": [23, 131], "cup_": 131, "current": [9, 22, 26, 35, 45, 47, 50, 51, 52, 54, 68, 70, 72, 77, 78, 84, 96, 108, 135, 138, 144, 145, 149, 152, 154, 155, 157], "current_posit": [145, 160], "curs": 154, "cursor": 135, "curv": [18, 20, 39, 48, 72, 79, 83, 121, 127, 128, 130, 131, 145, 162], "curvatur": [35, 42], "cusp": 74, "custom": [74, 124, 154], "cut": [17, 18, 50, 53, 54, 96, 134, 136], "cutoff": [38, 39, 41, 42, 47], "cv": [65, 67, 71, 96], "cwd": 127, "cxxflag": [74, 94], "cyb89": [1, 68], "cybenko": 1, "cycl": [44, 68], "cycle_b": 0, "cycler": 50, "d": [0, 1, 3, 8, 9, 10, 11, 15, 16, 17, 18, 20, 24, 26, 31, 32, 35, 37, 38, 39, 40, 41, 42, 43, 45, 49, 50, 52, 53, 54, 57, 67, 68, 72, 73, 78, 79, 80, 83, 84, 86, 87, 89, 93, 94, 96, 97, 101, 103, 115, 116, 118, 122, 124, 126, 127, 131, 134, 144, 145, 146, 147, 148, 149, 151, 153, 154, 155, 159, 163], "d0": [0, 17, 42], "d1": 38, "d1_": 50, "d1_c_5": 95, "d2": 38, "d_": [26, 31, 37, 73], "d_1": [15, 35], "d_2": [15, 35], "d_3": 15, "d_i": [39, 40, 52, 148, 153], "d_k": [4, 15, 37, 38, 97], "d_list": 34, "d_max": 38, "da": [17, 37, 53], "daan": 1, "dagger": [46, 49], "dai": [1, 16, 54, 157], "daili": 64, "damian": [79, 83], "damp": 150, "dan": [118, 148, 153], "danc": 144, "danger": [44, 46, 64], "daniel": [1, 5, 57, 134, 152, 160], "dare": 47, "dark": [18, 39, 57, 131], "darkgreen": [9, 24, 31], "darkgrid": [79, 93], "dash": [9, 17, 38, 39, 45, 95, 131, 148, 151, 153], "dat": [95, 134], "dat_id": 134, "data": [0, 1, 3, 4, 7, 8, 9, 10, 11, 12, 15, 17, 18, 20, 21, 22, 24, 25, 26, 30, 31, 37, 40, 43, 44, 45, 47, 48, 49, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 67, 68, 69, 71, 72, 73, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 93, 95, 96, 98, 99, 101, 102, 103, 104, 106, 107, 110, 111, 112, 114, 116, 118, 119, 120, 122, 124, 126, 127, 130, 131, 132, 135, 139, 145, 146, 147, 148, 152, 154, 155, 159, 160, 163], "data1": 18, "data2": 18, "data_": [7, 35, 65, 67], "data_batch": 107, "data_fram": [35, 103], "data_generating_process": 67, "data_generating_process_measur": [35, 103], "data_generating_process_r": [35, 103], "data_i": [35, 67, 107], "data_id": 134, "data_in": 152, "data_inst": 107, "data_panda": 134, "data_path": 134, "dataarrai": 152, "databin": 38, "datacamp": 139, "datafil": 134, "datafram": [35, 103, 134, 144], "dataframegroupbi": 134, "datapoint": [35, 81, 89, 102, 103], "dataset": [38, 39, 40, 41, 53, 64, 67, 68, 70, 71, 72, 73, 74, 75, 78, 89, 94, 110, 118, 124, 143, 148, 152, 153], "dataset_mirror": 78, "datasetdimens": 152, "datat": 66, "date": [8, 46, 52, 64, 65, 127, 134, 138, 154, 155], "date_format": 127, "datetim": 127, "datum": [35, 39, 67, 73, 101], "daughter": 46, "dave": 122, "david": [1, 47, 57, 64, 73, 127, 129, 160], "db": 37, "dbeta": 97, "dc": 78, "ddot": [35, 53, 101, 151], "de": [1, 35, 44, 46, 47, 81, 82], "deactiv": 138, "deal": [8, 17, 18, 26, 35, 42, 49, 52, 53, 54, 56, 60, 63, 65, 66, 68, 76, 111, 113, 118, 126, 131, 134, 157], "dealt": 4, "dean": 1, "death": [148, 153], "debat": [148, 153], "debug": [72, 127, 139], "dec": 152, "decad": 65, "decai": [38, 48, 72, 73, 75, 89, 108, 134, 154, 157], "decemb": 1, "decid": [4, 15, 20, 24, 26, 35, 39, 49, 50, 65, 66, 72, 76, 93, 103, 133, 145, 147, 149, 154, 155, 160], "decim": [33, 124, 128, 134, 135, 155], "decis": [8, 16, 52, 62, 64, 71, 73, 74, 75, 89, 112, 154, 155, 157], "deck": 33, "declar": [9, 54, 63, 133, 135, 137], "decompos": [48, 49, 54, 128], "decomposit": [48, 68, 79, 87, 125, 128], "decreas": [26, 34, 47, 50, 53, 65, 67, 72, 96, 106, 107, 108, 122, 145, 152, 154, 155, 160], "decreasing_learning_r": 107, "decri": 154, "deduc": [16, 38, 63, 65], "deduct": 63, "deem": 47, "deep": [1, 69, 70, 72, 76, 94, 118, 162], "deeper": [44, 46, 63, 64, 65, 74, 77], "deeplearn": [74, 94], "deepli": 63, "deer": 77, "def": [0, 5, 6, 9, 17, 18, 26, 30, 31, 34, 35, 38, 39, 41, 42, 43, 50, 51, 66, 70, 71, 72, 74, 77, 78, 79, 82, 83, 89, 93, 94, 96, 97, 103, 124, 127, 128, 130, 131, 133, 134, 135, 136, 139, 144, 145, 146, 148, 150, 151, 152, 153, 157, 162, 163], "defalt": 9, "default": [9, 24, 31, 34, 35, 50, 51, 67, 70, 78, 80, 83, 84, 93, 96, 97, 103, 108, 124, 127, 130, 134, 135, 137, 138, 139, 147, 150, 151, 152], "default_rng": [31, 35, 103, 131], "defect": [24, 54, 60], "defend": 64, "defer": 17, "defici": 42, "defin": [0, 6, 7, 8, 11, 13, 16, 17, 18, 19, 20, 24, 35, 37, 38, 39, 41, 42, 44, 45, 47, 48, 50, 51, 52, 54, 57, 60, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 84, 86, 87, 89, 90, 93, 94, 95, 96, 97, 101, 103, 108, 111, 114, 118, 121, 122, 126, 127, 131, 134, 135, 138, 139, 144, 145, 146, 148, 151, 152, 153, 157, 160, 162, 163], "definit": [0, 8, 9, 11, 16, 18, 20, 22, 24, 25, 26, 31, 41, 42, 43, 45, 47, 50, 62, 63, 66, 67, 71, 72, 78, 79, 83, 84, 86, 87, 89, 96, 97, 111, 121, 128, 135, 139, 145, 157, 160], "deform": 80, "deg": [22, 96], "degener": 51, "degeneraci": 48, "degre": [4, 8, 15, 18, 20, 23, 26, 30, 35, 39, 40, 44, 45, 47, 54, 56, 67, 87, 96, 97, 100, 101, 103, 118, 127, 128, 131, 148, 153], "degree_max": 96, "degreef": 131, "del": 127, "del_x": 38, "delet": [35, 96, 103, 135, 137], "deliber": 145, "delimit": [0, 135], "deliv": 98, "delta": [4, 15, 16, 18, 20, 24, 30, 35, 37, 38, 39, 41, 42, 46, 47, 50, 52, 53, 54, 69, 86, 89, 105, 119, 121, 124, 131, 134, 144, 147, 149, 151, 154, 157, 159, 162], "delta_": [30, 66, 67, 86, 126, 128], "delta_bin": 127, "delta_h": 134, "delta_i": 39, "delta_j": 69, "delta_k": 69, "delta_n": 134, "delta_t": [150, 151], "delta_x": 38, "deltah": [0, 17], "delv": 162, "demand": [57, 86, 113], "demetropoli": 152, "demetropolisz": 152, "demo": [17, 71, 87, 94, 149, 154, 155], "democraci": 64, "demograph": 64, "demonst": 128, "demonstr": [11, 17, 20, 27, 35, 40, 45, 48, 60, 63, 67, 72, 73, 87, 88, 90, 98, 103, 137, 148, 153, 154, 161], "den": 145, "denisti": 157, "denomin": [10, 13, 16, 17, 26, 35, 43, 47, 50, 53, 54, 108, 143, 144, 154], "denot": [4, 16, 20, 24, 26, 30, 35, 43, 45, 46, 47, 64, 67, 68, 69, 73, 79, 83, 86, 87, 89, 96, 97, 98, 100, 107, 111, 121, 124, 131, 144, 147, 152, 154, 155, 157], "dens": [35, 70, 87, 103], "dense_1": [70, 77], "denser": [35, 103], "densest": 83, "densiti": [8, 9, 11, 20, 21, 23, 26, 28, 30, 31, 34, 35, 37, 38, 43, 44, 45, 47, 49, 52, 54, 80, 83, 86, 124, 127, 130, 145, 149, 152, 154, 155, 157, 162], "depaoli": 1, "departur": 52, "depend": [4, 12, 13, 16, 19, 20, 26, 35, 37, 38, 39, 41, 44, 46, 47, 48, 49, 52, 53, 62, 64, 65, 66, 67, 68, 69, 72, 73, 77, 80, 86, 87, 89, 95, 97, 98, 100, 101, 105, 106, 107, 110, 111, 113, 118, 121, 130, 135, 136, 138, 141, 147, 148, 151, 152, 153, 154, 155, 157, 162], "depict": 157, "deploi": 64, "deploy": 64, "deprec": [38, 51, 71, 97, 134], "deprecationwarn": 38, "depth": [47, 54, 68, 72, 76, 118, 130, 135, 161], "deriv": [0, 8, 16, 17, 20, 26, 32, 34, 35, 38, 39, 40, 43, 44, 45, 46, 47, 48, 53, 54, 67, 72, 73, 89, 91, 97, 98, 101, 106, 108, 115, 118, 120, 124, 148, 149, 152, 153, 159], "derivati": 149, "desai": 52, "descend": [111, 128, 137], "descent": [66, 67, 68, 69, 71, 72, 74, 76, 89, 114, 117, 155], "describ": [4, 16, 17, 20, 35, 38, 39, 40, 42, 44, 45, 47, 48, 49, 50, 56, 57, 64, 65, 66, 67, 68, 72, 73, 74, 86, 89, 94, 96, 98, 101, 106, 108, 111, 112, 116, 117, 118, 119, 121, 131, 134, 138, 143, 144, 145, 148, 149, 151, 153, 154, 157, 161, 162], "descript": [9, 24, 35, 43, 44, 66, 100, 101, 111, 133, 135, 137, 152, 157], "deserv": [67, 98], "desiderata": 63, "design": [0, 8, 16, 24, 37, 38, 44, 45, 47, 48, 52, 54, 57, 61, 66, 68, 72, 73, 78, 84, 86, 89, 102, 103, 104, 123, 131, 134, 151, 154, 162], "desir": [17, 20, 26, 39, 42, 44, 48, 52, 54, 65, 67, 72, 87, 101, 118, 131, 144, 149, 157], "despin": [74, 94], "despis": 64, "despit": [17, 40, 44, 48, 64, 66, 67, 68, 111, 148, 153, 154], "desrib": 20, "destroi": [148, 153], "det": [50, 51, 53, 54, 79, 87, 96, 97, 124, 137, 157], "deta": 67, "detail": [9, 11, 16, 20, 21, 23, 24, 25, 28, 29, 35, 37, 39, 41, 44, 45, 46, 48, 51, 52, 53, 60, 61, 70, 73, 78, 87, 96, 97, 112, 117, 126, 127, 135, 138, 140, 143, 147, 148, 149, 153, 154, 159, 161], "detect": [7, 39, 43, 44, 63, 67, 68, 143], "detector": 52, "determin": [3, 4, 9, 11, 17, 20, 24, 35, 37, 38, 42, 50, 53, 54, 63, 64, 66, 67, 68, 69, 79, 83, 86, 87, 91, 97, 104, 111, 118, 122, 131, 134, 145, 148, 151, 153, 154, 155, 157, 162], "determinist": [49, 67, 73, 89, 111, 118, 124, 131, 146, 149, 162, 163], "determmin": 66, "detour": 45, "dev": [18, 82, 127], "devalu": 64, "devdoc": [51, 97], "develop": [8, 16, 34, 47, 48, 57, 62, 64, 65, 66, 68, 74, 122, 135], "devianc": 52, "deviat": [3, 4, 12, 17, 18, 20, 25, 30, 34, 35, 37, 38, 39, 40, 41, 42, 44, 47, 51, 54, 66, 72, 73, 74, 75, 79, 81, 82, 94, 95, 96, 121, 122, 124, 127, 130, 131, 134, 136, 144, 145, 146, 147, 148, 152, 153, 159, 160, 163], "devic": [26, 52, 74], "devinderjit": 7, "devis": [45, 68], "df": [17, 127, 131, 134], "df1": 134, "df_chain": 144, "dfm": 160, "dft": 80, "dgrid": [0, 17], "dh": [17, 122, 124], "dh_0": 42, "dhdt": 124, "dhs11": [1, 108], "di": [0, 17], "diag": [35, 48, 50, 51, 83, 124, 128], "diagnos": [44, 64], "diagnost": [44, 74, 94, 95, 142, 147, 153, 154, 160, 161], "diagon": [35, 42, 46, 48, 51, 54, 67, 73, 79, 83, 86, 87, 95, 108, 128, 131, 137, 147, 148, 149, 153, 157, 162], "dialect": 65, "dic": 52, "dice": [3, 73], "dick": [0, 5, 39, 51, 57, 78, 79, 133, 138, 144, 150, 152], "dick_in_tailcoat": 128, "dict": [9, 18, 38, 96, 127, 133, 145], "dict_kei": 70, "dictat": [8, 35, 38, 68, 79, 154], "dictionari": 134, "did": [7, 26, 35, 41, 51, 64, 74, 97, 131, 145, 146, 148, 151, 153, 163], "didn": [32, 50, 51, 127, 154, 155], "die": [4, 8, 24], "diederik": 1, "diff": [97, 127], "diffeq": 151, "differ": [3, 4, 6, 7, 8, 9, 11, 12, 15, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 57, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96, 98, 100, 101, 105, 106, 108, 112, 118, 124, 127, 130, 131, 134, 135, 136, 137, 138, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 157, 160, 162, 163], "different": [73, 74], "different_num": 136, "differenti": [1, 17, 37, 52, 65, 68, 72, 73, 74, 76, 79, 83, 86, 94, 98, 106, 131, 149, 150, 151, 159, 162, 164], "differentialmov": 51, "difficult": [26, 44, 45, 48, 53, 64, 68, 96, 98, 105, 106, 120, 147, 149, 155, 157, 160], "difficulti": [54, 106, 108], "diffus": [44, 149, 155], "digit": [64, 126, 134, 163], "dillon": 1, "dim": [42, 51, 68, 93, 97], "dimenion": 19, "dimens": [8, 24, 35, 45, 46, 48, 51, 61, 68, 76, 77, 78, 79, 80, 83, 84, 86, 87, 97, 98, 101, 106, 114, 124, 127, 128, 134, 137, 144, 145, 147, 148, 149, 152, 153, 154], "dimensin": 137, "dimension": [16, 18, 20, 24, 27, 34, 35, 41, 44, 45, 46, 47, 48, 50, 52, 54, 68, 70, 73, 74, 78, 81, 84, 86, 87, 93, 94, 114, 125, 126, 128, 130, 131, 134, 145, 147, 148, 149, 153, 154, 155, 157, 162, 164], "dimensionalisti": 52, "dimensionless": [24, 45, 114, 131], "diminish": 120, "dip": 44, "dir": 152, "dirac": [24, 124], "direc": 124, "direct": [4, 8, 13, 20, 35, 49, 54, 67, 68, 70, 89, 98, 106, 124, 128, 135, 145, 147, 148, 149, 151, 153, 154, 155, 160], "directli": [20, 24, 33, 34, 43, 45, 47, 48, 73, 74, 86, 94, 95, 122, 125, 128, 131, 162], "directori": [0, 124, 127, 131, 138, 141], "disabl": [9, 64, 127, 133], "disadvantag": [39, 64], "disappear": [54, 154, 157], "discard": [6, 45, 49, 51, 144, 148, 152, 153], "disciplin": [65, 68], "disclaim": 65, "discov": [16, 20, 129], "discoveri": [62, 63, 68], "discrep": [16, 30, 35, 49, 56, 60, 111, 112, 121, 122, 159], "discret": [4, 9, 11, 16, 18, 23, 24, 25, 26, 38, 45, 65, 66, 68, 73, 89, 111, 122, 124, 146, 147, 162, 163], "discrimin": [54, 64, 89], "discuss": [7, 16, 17, 20, 22, 24, 26, 30, 38, 40, 41, 42, 45, 47, 49, 57, 59, 60, 61, 64, 65, 67, 69, 73, 74, 89, 95, 96, 97, 99, 106, 111, 114, 115, 118, 121, 122, 128, 144, 152, 155, 157, 160], "diseas": [23, 32, 64, 89], "dishonest": 62, "disjoint": 131, "disk": [52, 135], "dismiss": 157, "disord": 89, "disp": 39, "dispers": 45, "displai": [3, 5, 9, 17, 49, 66, 67, 68, 70, 77, 79, 89, 127, 131, 134, 135, 145, 152, 153, 154, 157, 162], "display_nam": 0, "displaystyl": [35, 101, 160], "dispos": 147, "disproportion": 39, "disregard": 64, "disrupt": 65, "dist": [9, 18, 31, 43, 83, 127], "dist_hist_plot": 43, "dist_label": [18, 127], "dist_mod": [9, 18, 31, 127], "dist_plot": [18, 127], "dist_pt": 43, "dist_pts_alt": 43, "dist_stuff": [9, 18, 31, 127], "distanc": [35, 42, 48, 52, 66, 71, 79, 83, 115, 116, 124, 149, 162], "distant": 54, "distinct": [4, 7, 44, 47, 49, 59, 76, 90, 105, 122, 136], "distinguish": [23, 49, 52, 58, 59, 98, 154], "distract": 44, "distrbut": 162, "distri": 44, "distribut": [1, 5, 6, 7, 8, 9, 11, 13, 17, 19, 20, 21, 24, 25, 26, 27, 28, 30, 31, 37, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 52, 54, 61, 64, 68, 73, 74, 75, 77, 78, 82, 84, 89, 90, 93, 94, 95, 96, 97, 103, 111, 118, 121, 122, 124, 125, 138, 143, 144, 145, 148, 149, 152, 153, 155, 159, 161, 162, 164], "distrubt": 157, "div": 0, "dive": [39, 134], "diverg": [20, 69], "diverging_palett": [74, 94], "divers": [24, 64], "divid": [4, 28, 30, 34, 39, 44, 54, 67, 68, 70, 77, 93, 94, 96, 105, 137, 144, 145, 147, 160], "divis": [67, 72, 77, 108, 137], "divorc": 24, "dj\u00e4rv": 57, "dk": [38, 97], "dk_pt": 38, "dkpr87": [1, 45], "dl": [20, 37], "dlnz": 97, "dmat": [35, 101, 102, 103, 104], "dmf": [1, 46], "dna": 89, "dnn": 68, "do": [0, 1, 3, 4, 5, 7, 8, 9, 11, 13, 15, 16, 17, 18, 19, 24, 25, 26, 30, 31, 32, 33, 35, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 60, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 76, 77, 78, 80, 84, 86, 90, 91, 95, 97, 98, 101, 102, 103, 105, 118, 126, 130, 131, 133, 134, 135, 136, 137, 138, 143, 145, 148, 149, 151, 152, 153, 154, 155, 157, 163, 164], "dob": [9, 18, 20, 26, 31, 42], "dobrow": 162, "doc": [18, 74, 94, 131, 152], "docstr": [80, 135, 137, 152], "doctor": 64, "document": [9, 11, 13, 38, 40, 43, 44, 71, 72, 78, 84, 88, 95, 128, 135, 136, 137, 138, 146, 147, 148, 149, 152, 153, 159, 163, 164], "documentari": 63, "doe": [1, 5, 8, 9, 12, 16, 17, 19, 20, 23, 26, 30, 31, 32, 33, 35, 38, 39, 40, 41, 43, 45, 48, 49, 50, 51, 52, 54, 63, 64, 65, 66, 67, 68, 71, 72, 76, 78, 84, 86, 87, 91, 94, 95, 96, 97, 101, 108, 122, 125, 130, 131, 134, 135, 136, 137, 143, 144, 145, 147, 148, 149, 151, 152, 153, 155, 157, 160, 162], "doesn": [5, 13, 23, 30, 34, 39, 40, 52, 64, 69, 76, 148, 149, 150, 153, 155, 160], "dof": [96, 118], "dog": [77, 135], "doi": [1, 44], "dollar": 8, "domain": [0, 8, 18, 24, 44, 47, 48, 49, 54, 61, 65, 67, 83, 111, 120, 122, 124, 131, 147], "domin": [12, 20, 30, 49, 53, 54, 66, 74, 86, 111, 126], "don": [9, 11, 15, 18, 24, 26, 30, 31, 32, 34, 35, 37, 41, 43, 50, 59, 62, 64, 65, 66, 67, 73, 78, 79, 83, 84, 86, 95, 96, 97, 118, 134, 135, 146, 147, 152, 154, 155, 160, 163], "donald": [1, 154], "done": [0, 35, 37, 39, 42, 44, 49, 50, 51, 54, 59, 63, 67, 72, 73, 74, 98, 126, 127, 128, 136, 138, 144, 149, 155], "donut": [149, 154], "door": 16, "dordrecht": 1, "dot": [4, 35, 45, 49, 66, 67, 68, 69, 71, 74, 76, 79, 81, 83, 89, 94, 101, 103, 124, 128, 143, 144, 145, 150, 151], "dot_product_term": 124, "dotproduct": [82, 124], "doubl": [26, 44, 48, 64, 73, 126, 135, 136, 138, 162], "doubt": [20, 57], "dougla": 57, "down": [0, 8, 17, 18, 23, 53, 60, 68, 69, 72, 74, 79, 83, 94, 111, 118, 131, 135, 137, 157], "downhil": [98, 106], "download": [57, 71, 78, 134, 135, 138, 140, 141], "downsampl": 76, "downward": 124, "dozen": 128, "dp": [3, 20, 150], "dp_h": [11, 13, 26, 31], "dp_i": 149, "dp_phi": 150, "dphi": [150, 151], "dpi": [124, 127, 150, 151], "dq": 150, "dq_i": 149, "dr": [96, 124, 151], "draft": [1, 78, 84], "drag": [115, 116, 122, 124], "drastic": [118, 145], "draw": [16, 18, 19, 20, 24, 30, 33, 37, 39, 43, 45, 48, 52, 59, 67, 68, 73, 74, 75, 78, 80, 82, 84, 90, 97, 111, 121, 127, 131, 145, 147, 148, 152, 153, 154, 155, 157, 160], "draw_ev": 127, "drawback": [44, 67, 74, 96, 135], "drawn": [20, 30, 38, 42, 45, 72, 73, 82, 89, 96, 118, 124, 148, 149, 153, 160, 164], "drawpandasindexpandasindex": 152, "drawstyl": 38, "dream": 65, "dress": [66, 135, 139], "drink": 7, "drischler": 1, "drive": [51, 52, 59, 65, 97, 150, 157], "driven": [46, 48], "driver": 65, "drop": [16, 52, 74, 103, 121, 131, 134, 152, 160, 164], "drop_const": [35, 103], "dropbox": 51, "dropdown": [0, 5, 9, 133], "dropna": 134, "dropout": [68, 70], "drug": 64, "dry": [16, 65], "dsdt": 17, "dstack": [35, 66, 79, 83], "dt": [13, 17, 39, 122, 124, 149, 150, 151, 162], "dtp2023": 46, "dtype": [6, 34, 38, 51, 70, 72, 74, 77, 94, 96, 97, 130, 134, 137, 146, 152, 163], "du": [54, 151], "du_": 151, "du_1": 131, "du_cf": 151, "du_eff": 151, "du_i": 54, "du_n": 131, "dual": 71, "dualiti": 45, "duan": [1, 45], "dubourg": 81, "duchi": 1, "duchi11a": 1, "duco": 1, "due": [4, 17, 35, 39, 41, 47, 52, 54, 68, 72, 73, 74, 97, 98, 101, 105, 122, 124, 134, 144, 154, 157, 162], "dumb": 145, "dummi": [71, 136, 145], "dummy_out": [74, 94], "dumpti": 59, "dunson": 1, "duplic": 128, "durat": 116, "dure": [8, 45, 47, 68, 70, 72, 73, 74, 78, 84, 107, 115, 124, 137, 148, 153, 162], "durham": 57, "durrand": [78, 84], "dustin": [1, 74], "duvenaud": 87, "dvdt": 124, "dwell": 8, "dx": [3, 4, 17, 18, 20, 24, 25, 26, 37, 53, 83, 131, 147, 154], "dx1": 51, "dx2": 51, "dx_1": [20, 34, 131], "dx_2": [0, 18, 24, 34, 131], "dx_j": 20, "dx_k": 43, "dx_n": [20, 34], "dxdy": 17, "dxp": 51, "dy": [17, 37, 39, 41, 42, 68, 96, 131, 144, 147, 154, 162], "dy2": 41, "dy_data": 50, "dy_dt": [150, 151], "dy_pt": 50, "dynam": [45, 48, 68, 72, 74, 94, 124, 149, 162], "dz": [17, 131], "e": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 60, 61, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 83, 84, 86, 87, 89, 91, 93, 94, 95, 96, 97, 98, 101, 102, 103, 106, 115, 118, 120, 121, 123, 124, 125, 126, 128, 131, 132, 134, 135, 137, 138, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 161, 163, 164], "e1": 128, "e2": 128, "e_": [35, 46, 67, 128, 134, 160], "e_1": 128, "e_2": 128, "e_i": [35, 39, 103], "e_tot_0": 151, "e_tot_0_eul": 151, "e_tot_0_lf": 151, "e_tot_pt": 151, "e_tot_pts_eul": 151, "e_tot_pts_lf": 151, "e_tot_rel_pt": 151, "e_tot_rel_pts_eul": 151, "e_tot_rel_pts_lf": 151, "e_w": [73, 89], "each": [4, 6, 7, 8, 9, 11, 15, 18, 25, 26, 30, 31, 32, 33, 35, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 57, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 79, 80, 82, 83, 84, 87, 89, 91, 94, 97, 101, 107, 108, 111, 118, 121, 124, 126, 127, 128, 130, 131, 134, 135, 136, 137, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 155, 157, 160, 162, 163], "eapprox": 134, "earli": [8, 12, 47, 49, 74, 108, 122], "earlier": [35, 50, 54, 69, 72, 89, 122, 128, 138, 157], "earliest": 111, "earn": 154, "earth": 116, "easi": [0, 11, 13, 20, 22, 34, 43, 44, 45, 52, 67, 69, 74, 78, 84, 89, 131, 134, 135, 136, 144, 154, 157, 160], "easier": [6, 17, 41, 43, 52, 54, 65, 67, 68, 95, 120, 134, 152], "easiest": [47, 53], "easili": [0, 4, 35, 38, 44, 48, 54, 65, 69, 74, 78, 84, 89, 96, 102, 134, 135, 136, 137, 149, 154], "eat": [22, 63], "ebegin": 67, "ebind": 134, "ec": [48, 96, 127], "eccentr": [37, 54, 79, 151], "ecolor": 97, "econometr": 134, "economist": 63, "ed": 90, "edg": [48, 96, 105, 127, 160], "edgecolor": [38, 39, 66], "edit": [0, 1, 57, 87, 130, 135, 138], "edu": [0, 1, 52, 79, 81, 133, 138, 150, 152], "educ": [64, 65], "edward": [1, 65, 73, 74, 86], "eff": [45, 151], "effect": [1, 7, 16, 20, 26, 35, 39, 41, 44, 45, 47, 48, 49, 50, 51, 52, 54, 58, 63, 64, 67, 72, 73, 78, 81, 84, 95, 97, 115, 118, 124, 127, 128, 134, 147, 151, 152, 155, 164], "effectivepotenti": 5, "effici": [1, 34, 39, 45, 47, 48, 52, 68, 72, 74, 76, 94, 95, 107, 108, 128, 134, 137, 149, 152, 154, 155, 161, 164], "effort": [49, 57, 61, 64, 148, 153, 164], "eft": [46, 48, 53, 92], "ei": [33, 93], "eig": [78, 84, 128, 137], "eigen": 48, "eigen_galerkin": 48, "eigenenergi": 46, "eigensolut": 139, "eigenst": 46, "eigenvalu": [46, 48, 54, 78, 79, 80, 83, 84, 126, 128, 154, 157], "eigenvector": [1, 37, 48, 54, 123, 126, 128, 154, 157], "eigh": [128, 137], "eigval": [78, 79, 83, 84, 128], "eigvec": 128, "einstein": [8, 16, 128, 135], "einstein_equ": 0, "either": [0, 8, 9, 11, 17, 20, 39, 41, 44, 52, 54, 57, 64, 66, 67, 68, 73, 77, 87, 89, 131, 134, 135, 136, 138, 145, 162], "ek": 97, "ekstr\u00f6m": [1, 46, 57], "el": 134, "elabor": [11, 26, 28, 44], "elad": 1, "elast": 67, "elbo": [73, 74, 94], "eleanor": [1, 57], "elect": 26, "electr": [68, 134], "electromagnet": 91, "electron": [22, 131, 157], "elegantli": 7, "element": [1, 3, 9, 35, 38, 42, 44, 45, 46, 48, 54, 64, 65, 67, 68, 72, 73, 78, 79, 83, 84, 86, 89, 97, 101, 105, 108, 126, 128, 134, 135, 136, 139, 149, 151, 154, 157, 162], "elementwis": 76, "eleph": [105, 128], "elessar": 134, "elev": 66, "elevanth": [149, 155], "elif": [35, 79, 83, 97, 103, 124, 130, 135, 150], "elimin": [7, 12, 18, 64, 127, 128], "ell": [79, 80, 83, 87, 118, 121, 124], "ell_rbf": 79, "ellips": [38, 54, 79, 87, 147], "ellipsoid": 47, "ellipt": 37, "els": [3, 6, 8, 35, 38, 39, 41, 43, 49, 51, 70, 71, 77, 79, 83, 97, 103, 124, 127, 130, 143, 144, 145, 146, 148, 150, 153, 154, 155, 157, 160, 162, 163], "elsewher": [17, 35, 41, 43, 96, 131, 144, 159], "elu": [68, 71, 130], "em": [9, 46], "email": 138, "emce": [1, 6, 37, 39, 42, 51, 52, 91, 95, 143, 144, 147, 148, 149, 155, 160, 164], "emcee_lnprob": 42, "emcee_sampl": 124, "emcee_trac": 42, "emerg": [20, 52, 57], "emilia": 135, "emiss": 54, "emit": [43, 143], "emph": [49, 123], "emphas": [22, 32, 35, 48, 58, 66, 120, 131, 155], "emphasi": [32, 35, 134, 147], "empir": [4, 41, 44, 46, 54, 89, 90, 96, 111, 118, 130, 134, 145], "emploi": [9, 16, 17, 31, 35, 47, 52, 54, 63, 67, 68, 73, 97, 107, 108, 120, 145, 157], "employ": [64, 65], "employe": 65, "empti": [94, 97, 127, 130, 131, 135, 144, 145], "empty_lik": [74, 94], "emptyset": [67, 131], "emul": [1, 47, 63, 68, 125, 126], "en": [42, 105, 153, 164], "enabl": [8, 26, 35, 39, 44, 46, 48, 52, 54, 59, 63, 72, 80, 135, 147, 154, 155], "encapsul": 26, "enclos": 20, "encod": [20, 39, 40, 41, 50, 54, 59, 76, 79, 83, 122, 127, 148, 153, 159], "encompass": [8, 11, 47, 51, 52, 54], "encount": [8, 16, 26, 27, 39, 54, 58, 61, 65, 66, 67, 69, 89, 98, 105, 112, 135, 145, 154, 162], "encourag": [28, 44, 47, 60, 73, 134, 135, 138], "end": [0, 3, 4, 7, 8, 9, 12, 13, 15, 16, 17, 20, 23, 24, 25, 26, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 54, 64, 65, 66, 67, 68, 69, 73, 76, 78, 79, 80, 83, 84, 86, 87, 89, 93, 96, 98, 100, 101, 104, 105, 107, 108, 114, 124, 126, 127, 128, 131, 133, 135, 137, 138, 147, 148, 149, 150, 151, 152, 153, 154, 157, 159, 160, 162], "end_tim": 124, "endeavor": 48, "endeavour": 111, "endow": 49, "endpoint": [9, 18, 131, 136, 149], "energi": [22, 45, 46, 48, 52, 73, 79, 80, 83, 92, 105, 131, 149, 152, 155, 157], "energy_0": 151, "enforc": [7, 34, 48, 68, 74], "engin": [1, 48, 64, 65, 68, 72], "english": [36, 54, 162], "enlighten": 4, "enorm": 46, "enough": [5, 9, 12, 20, 30, 31, 35, 38, 41, 44, 45, 46, 48, 54, 57, 64, 68, 78, 84, 87, 128, 132, 146, 147, 155, 157, 163], "ensambl": [73, 148, 153], "ensembl": [1, 51, 68, 73, 74, 97, 148, 153, 154], "ensemblesampl": [6, 39, 42, 51, 97, 124, 144, 147, 148, 153], "ensur": [4, 5, 44, 47, 48, 64, 72, 73, 78, 79, 83, 84, 124, 157, 159], "entail": [8, 35, 54, 103], "enter": [0, 26, 35, 44, 47, 65, 78, 84, 97, 100, 106, 113, 135, 141, 154, 155], "entir": [20, 35, 44, 49, 51, 52, 53, 64, 67, 76, 89, 133, 135], "entireti": 49, "entiti": 24, "entitl": [62, 65, 118], "entri": [0, 33, 39, 40, 43, 53, 64, 69, 73, 87, 127, 128, 134, 152, 153, 154, 155, 157], "entropi": [8, 17, 39, 41, 43, 44, 56, 63, 66, 68, 71, 73], "enumer": [0, 3, 6, 17, 34, 39, 42, 43, 47, 66, 78, 79, 82, 83, 84, 96, 97, 124, 131, 136], "env": [51, 71, 82, 97, 127, 153], "envelop": 80, "envi": 46, "environ": [37, 57, 70, 71, 94, 132, 135, 140, 143], "environment": 64, "environment_jb": [138, 141], "environment_window": 94, "envis": 45, "eotwash": 52, "epidemiologi": [47, 49], "epistemologi": [21, 22, 26], "eplac": 34, "epoch": [67, 68, 69, 70, 71, 72, 77, 89, 107], "epsilon": [3, 4, 35, 67, 73, 78, 80, 84, 101, 106, 124, 149, 151], "epsilon_i": [3, 35, 67, 96, 101, 121], "epsrel": 5, "eq": [0, 16, 17, 26, 35, 45, 46, 47, 48, 49, 54, 66, 67, 98, 101, 106, 108, 111, 121, 124, 131, 147, 150, 154, 157, 162], "eq_ppd": 0, "eqn": [49, 54], "equal": [3, 4, 8, 11, 20, 23, 24, 26, 32, 33, 34, 35, 37, 38, 39, 41, 45, 47, 51, 54, 64, 66, 67, 69, 72, 73, 78, 79, 83, 84, 101, 124, 126, 128, 131, 136, 137, 145, 146, 147, 151, 154, 157, 160, 163], "equat": [1, 3, 4, 7, 8, 16, 17, 23, 24, 26, 40, 45, 46, 47, 48, 49, 50, 52, 54, 57, 65, 66, 67, 68, 73, 76, 80, 86, 89, 98, 100, 102, 105, 107, 108, 114, 115, 116, 121, 122, 124, 126, 131, 135, 143, 148, 149, 150, 153, 154, 157, 160, 162], "equilibr": [146, 155, 157, 160, 163], "equilibrium": [145, 154, 157, 162], "equip": 16, "equiv": [3, 4, 7, 13, 17, 18, 20, 22, 25, 30, 35, 37, 40, 46, 47, 50, 52, 54, 66, 67, 69, 73, 80, 83, 86, 87, 89, 95, 96, 97, 101, 106, 107, 108, 126, 131, 144, 148, 150, 153, 154, 155, 157], "equival": [3, 4, 7, 20, 26, 35, 39, 40, 48, 49, 50, 54, 73, 79, 95, 97, 135, 147, 148, 153, 157], "ergod": 149, "eriador": 134, "ermal": 1, "ernest": 131, "err": 95, "err_filenam": 127, "err_msg": 127, "err_slop": 42, "err_slope_max": 42, "err_slope_min": 42, "err_theta_ml": 42, "err_v0": 42, "errno": 127, "errno_num": 127, "erron": [56, 64, 105], "error": [0, 1, 3, 4, 7, 16, 18, 29, 30, 34, 39, 41, 44, 45, 47, 48, 49, 50, 51, 54, 56, 57, 60, 61, 65, 68, 69, 72, 73, 74, 78, 80, 86, 89, 94, 95, 96, 97, 98, 101, 102, 103, 111, 116, 121, 122, 124, 126, 127, 128, 134, 135, 136, 137, 147, 148, 152, 153, 154], "errorbar": [35, 39, 41, 42, 50, 81, 96, 97, 103, 124, 144], "errread": 127, "errstat": 93, "errwrit": 127, "esc": 135, "especi": [26, 68, 72, 74, 111], "ess": 45, "ess_bulk": [152, 153], "ess_tail": [152, 153], "essai": 118, "essenc": 72, "essenti": [1, 5, 8, 48, 49, 52, 58, 59, 62, 65, 68, 69, 122, 145, 149], "est": 35, "establish": [8, 48, 49, 63], "estim": [1, 5, 9, 11, 14, 17, 18, 20, 21, 22, 23, 25, 26, 28, 31, 35, 37, 38, 39, 43, 44, 45, 47, 50, 52, 60, 61, 65, 66, 67, 72, 73, 74, 80, 81, 89, 91, 92, 94, 96, 101, 103, 108, 111, 120, 122, 124, 125, 127, 128, 134, 143, 144, 146, 147, 152, 155, 157, 163], "et": [0, 44, 45, 57, 67, 124, 127, 145], "eta": [7, 50, 69, 71, 80, 89, 98, 106, 107, 108, 121, 124], "eta0": 71, "eta_n": [106, 108], "etc": [4, 8, 9, 11, 17, 18, 59, 61, 65, 68, 76, 78, 84, 89, 97, 111, 138, 157], "ethic": 1, "eti": 131, "euclidean": [35, 66, 79, 101, 105], "euclidean_dist": 66, "euler": [149, 151], "euro": 162, "european": 64, "evalu": [0, 1, 7, 13, 16, 17, 26, 30, 35, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 52, 54, 64, 66, 67, 68, 72, 73, 74, 83, 86, 93, 94, 96, 101, 102, 103, 106, 107, 121, 124, 128, 134, 135, 136, 139, 144, 145, 146, 148, 151, 153, 154, 155, 157, 163], "evaluate_gradi": 107, "evd": 126, "even": [0, 5, 7, 8, 12, 16, 18, 22, 26, 35, 40, 44, 45, 46, 48, 49, 50, 54, 57, 59, 64, 65, 66, 67, 68, 73, 74, 76, 77, 79, 80, 83, 86, 87, 102, 104, 122, 134, 135, 143, 148, 149, 152, 153, 154, 157, 160], "evenli": [38, 41, 78, 84, 137], "event": [4, 8, 16, 18, 23, 24, 26, 38, 64, 157], "eventu": [12, 20, 26, 41, 50, 53, 57, 67, 68, 98, 108, 132, 135, 144, 145, 157, 160], "ever": [8, 16, 54, 63, 64], "everi": [6, 9, 11, 12, 20, 24, 26, 45, 50, 51, 52, 64, 68, 72, 76, 77, 79, 80, 83, 86, 97, 106, 107, 108, 124, 127, 153, 160], "everybodi": 54, "everydai": [54, 57], "everyon": 8, "everyth": [16, 24, 69, 74, 126, 135, 155], "everywher": [9, 49, 64, 68, 136], "evid": [3, 7, 8, 9, 10, 16, 24, 26, 30, 31, 35, 40, 51, 60, 63, 64, 91, 92, 97, 124], "evluat": 66, "evolut": [26, 73, 149, 154, 157], "evolv": [26, 31, 57, 65, 118, 150, 157, 162], "exac": 163, "exact": [38, 45, 46, 48, 49, 50, 52, 69, 73, 95, 107, 111, 134, 146, 149, 160, 163], "exact_data": 38, "exact_fev": 93, "exactli": [16, 30, 31, 35, 41, 49, 67, 69, 76, 103, 126], "examin": [39, 44, 45, 52, 70, 77, 122, 144, 152], "exampl": [0, 4, 6, 7, 8, 9, 11, 16, 17, 18, 20, 22, 23, 28, 31, 33, 36, 38, 44, 45, 46, 47, 48, 49, 51, 53, 54, 56, 65, 67, 68, 69, 70, 73, 74, 75, 77, 80, 82, 84, 86, 88, 89, 94, 95, 96, 97, 98, 102, 103, 106, 108, 111, 113, 118, 120, 121, 122, 123, 126, 128, 130, 133, 134, 135, 136, 138, 145, 146, 149, 153, 154, 157, 159, 161, 163, 164], "example_revers": 157, "exce": [54, 68, 124, 162], "exceed": 124, "excel": [57, 65, 73, 145, 148, 149, 153, 154, 155, 164], "except": [32, 35, 38, 44, 66, 67, 72, 77, 97, 124, 127, 148, 153, 154, 160], "excercis": 152, "excerpt": 49, "excess": [98, 134], "exchang": [20, 52, 62], "excit": [11, 48, 65, 157], "exclud": [26, 47, 64, 67, 96, 134, 162], "exclus": [23, 24, 26, 32, 33, 49, 64, 67, 69, 77, 134], "execut": [72, 127, 136, 138], "exemplifi": [35, 131], "exercis": [9, 13, 23, 31, 39, 50, 57, 70, 92, 93, 103, 132, 144], "exercisesp": 162, "exert": 39, "exhaust": [23, 24, 26, 32, 33, 47, 67, 131], "exhibit": 147, "exist": [4, 8, 20, 26, 35, 40, 49, 51, 61, 62, 63, 64, 65, 77, 93, 97, 101, 118, 131, 134, 135, 143, 148, 150, 153, 157], "exit": 135, "exp": [0, 4, 5, 17, 25, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 49, 50, 51, 54, 66, 68, 69, 71, 72, 73, 79, 83, 86, 89, 91, 93, 96, 97, 113, 121, 124, 130, 131, 135, 139, 144, 145, 146, 148, 153, 159, 162, 163], "expand": [8, 20, 23, 24, 32, 33, 35, 37, 39, 44, 48, 49, 54, 89, 90, 118, 164], "expans": [7, 16, 20, 35, 48, 54, 59, 68, 95, 118], "expect": [4, 8, 9, 10, 12, 13, 17, 20, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 66, 67, 69, 73, 74, 80, 87, 93, 94, 103, 111, 115, 127, 134, 137, 143, 144, 146, 147, 152, 153, 154, 155, 157, 159, 160, 162, 163], "expected_improv": 93, "expens": [32, 48, 80, 96, 123, 125], "experi": [4, 8, 9, 11, 16, 20, 22, 26, 31, 37, 38, 41, 43, 44, 52, 60, 61, 62, 63, 64, 65, 72, 81, 87, 90, 93, 97, 111, 115, 121, 122, 128, 129, 131, 134, 154], "experienc": 160, "experiment": [0, 9, 17, 18, 24, 26, 30, 31, 38, 40, 42, 48, 49, 52, 54, 59, 61, 63, 67, 97, 111, 120, 122, 123, 125, 131, 134, 148, 153], "expert": [0, 16, 44, 48, 63, 64, 68, 128], "expertis": 48, "explain": [7, 12, 20, 35, 44, 49, 60, 64, 66, 67, 72, 80, 91, 95, 97, 101, 127, 128, 134, 135, 143, 146, 154, 162, 163], "explan": [7, 20, 54, 63, 67, 108, 157, 159], "explanatori": 111, "explcitli": 86, "explic": 64, "explicit": [7, 9, 18, 35, 40, 44, 45, 48, 54, 60, 68, 76, 86, 118, 128, 135, 148, 153, 157], "explicitli": [4, 16, 23, 24, 26, 34, 43, 49, 54, 65, 72, 74, 81, 86, 87, 90, 124, 133, 134, 137, 162], "explod": [69, 72, 118], "exploit": [9, 11, 39, 45, 48, 68, 93], "explor": [9, 24, 27, 28, 31, 35, 38, 39, 42, 43, 45, 46, 48, 50, 52, 54, 56, 60, 64, 66, 67, 74, 87, 92, 93, 95, 98, 103, 106, 111, 118, 120, 121, 124, 127, 136, 137, 147, 149, 154, 155, 157, 160, 162], "exploratori": [74, 94], "expon": [17, 35, 45, 53], "exponenti": [20, 35, 37, 45, 51, 68, 72, 78, 79, 83, 84, 86, 108, 116, 135, 139, 145, 154], "expos": [60, 67], "exposit": 44, "express": [4, 9, 15, 16, 17, 20, 23, 31, 32, 35, 39, 40, 41, 42, 45, 46, 47, 49, 50, 52, 54, 59, 60, 66, 67, 68, 69, 74, 76, 77, 78, 84, 86, 94, 97, 98, 100, 101, 102, 105, 115, 118, 121, 126, 128, 131, 134, 144, 145, 148, 153, 154, 157], "expsinesquar": 82, "expt": [30, 159], "extend": [4, 24, 28, 40, 48, 56, 57, 60, 63, 64, 66, 74, 79, 95, 135, 153, 162], "extens": [0, 21, 24, 44, 48, 64, 65, 68, 72, 86, 96, 108, 122, 128, 134, 135], "extent": [8, 18, 35, 38, 47, 65], "extern": [9, 133, 162], "extra": [37, 44, 53, 54, 68, 77, 87, 157, 164], "extra_anim": 127, "extra_arg": 127, "extra_group": 127, "extra_rbm_emul": 123, "extract": [17, 18, 24, 35, 39, 42, 45, 51, 70, 74, 75, 78, 83, 84, 89, 95, 96, 97, 103, 112, 120, 122, 124, 131, 138, 145, 148, 152, 153, 163], "extrapol": [46, 48, 49, 72, 80, 123, 134], "extrem": [8, 16, 20, 26, 39, 44, 49, 54, 64, 65, 67, 68, 74, 134, 135, 160], "extremum": [16, 35, 101], "ey": [23, 33, 39, 44, 50, 51, 65, 79, 83, 137, 144, 147], "e\u00f6t": 52, "f": [0, 1, 3, 4, 5, 6, 9, 13, 16, 17, 18, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 45, 50, 51, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 79, 81, 82, 83, 84, 87, 89, 93, 94, 96, 97, 103, 118, 122, 124, 127, 128, 130, 131, 133, 134, 135, 136, 137, 138, 144, 146, 147, 151, 152, 153, 154, 160, 162, 163, 164], "f11": 134, "f12": 134, "f13": 134, "f9": 134, "f_": [35, 48, 49, 68, 101], "f_0": [17, 35, 100, 101], "f_1": [49, 87], "f_2": [49, 68, 87], "f_arr": 17, "f_j": [35, 100, 101], "f_k": [49, 97], "f_likelihood": 17, "f_posterior": 17, "f_r": 136, "fab": [38, 150, 151], "face": [4, 16, 53, 154], "facecolor": [18, 38, 97, 127], "facet": 56, "facilit": [35, 44, 48, 74], "fact": [3, 4, 15, 16, 17, 24, 26, 35, 37, 39, 42, 45, 54, 63, 64, 65, 66, 67, 68, 73, 76, 83, 86, 100, 111, 112, 131, 134, 144, 154, 155, 157, 162], "factor": [5, 10, 16, 17, 20, 26, 34, 35, 37, 39, 43, 44, 45, 48, 49, 50, 51, 53, 54, 62, 64, 91, 96, 97, 101, 124, 128, 131, 143, 144, 145, 151, 152, 154, 155, 160], "factori": [4, 34, 38, 146, 163], "fail": [5, 17, 20, 23, 39, 43, 44, 45, 52, 54, 56, 60, 64, 82, 127, 134, 135, 138, 147], "failur": [30, 45, 49, 89], "fair": [3, 8, 9, 11, 13, 16, 20, 31, 44, 54], "fairli": [40, 63, 148, 153], "faith": 35, "fake": 149, "fall": [20, 35, 44, 47, 54, 64, 81, 103, 115, 116, 124], "fallaci": 32, "fallen": 115, "fals": [3, 9, 17, 22, 30, 32, 34, 35, 38, 39, 41, 42, 51, 64, 65, 66, 71, 74, 77, 79, 81, 83, 89, 93, 96, 103, 124, 127, 128, 131, 133, 134, 144, 145, 150, 154, 157, 162], "falsif": 62, "falsifi": [54, 63], "famili": [48, 57, 64, 67, 68, 87, 89, 113, 134, 157, 162], "familiar": [4, 7, 23, 24, 30, 32, 35, 38, 48, 54, 63, 66, 118, 134, 136, 146, 162, 163], "famou": [16, 47, 68, 69], "fan_out": 72, "fantast": 65, "far": [8, 16, 17, 26, 34, 35, 45, 48, 54, 64, 68, 72, 74, 77, 80, 81, 87, 127, 145, 147, 149, 154], "farther": 52, "fashion": 62, "fast": [18, 20, 47, 48, 69, 107, 125, 127, 131, 135, 136, 152, 160, 164], "faster": [46, 47, 48, 72, 74, 94, 136, 152], "fastest": 12, "fat": 154, "favor": [20, 39, 52, 53, 64, 66, 89, 98, 149, 154], "favour": [4, 38, 54], "fc": [76, 96], "feasibl": [105, 154, 155], "featur": [9, 11, 35, 38, 39, 40, 42, 47, 48, 54, 61, 63, 64, 65, 66, 67, 68, 69, 72, 74, 79, 87, 94, 95, 98, 100, 101, 106, 118, 126, 128, 130, 131, 134, 137, 148, 149, 153, 159], "fed": 70, "federico": 1, "feed": [42, 69, 70, 71, 73, 77, 79, 118, 134], "feedforward": 68, "feel": [16, 26, 31, 38, 64, 145], "femal": 131, "feng": [17, 149, 154, 155], "feroz": 1, "few": [4, 9, 11, 17, 18, 24, 38, 39, 41, 43, 48, 54, 64, 65, 68, 70, 72, 76, 77, 81, 93, 127, 128, 131, 134, 149, 152, 154, 157, 162], "fewer": [30, 48, 54, 66, 67, 126, 134, 149], "ffmpeg": 127, "ffmpegwrit": 127, "ffnn": 68, "fhb09": [1, 154], "fhi": [1, 46], "fiber": 52, "fictiti": 149, "fiddl": 74, "fidel": [46, 47, 48, 123], "field": [1, 8, 16, 44, 48, 50, 63, 64, 65, 68, 74, 90, 92, 94, 95, 105, 118, 127, 155], "fieri": 54, "fifth": [54, 134, 144, 145], "fig": [0, 3, 4, 5, 6, 9, 17, 18, 26, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 54, 66, 67, 68, 71, 73, 74, 76, 78, 79, 80, 82, 83, 84, 89, 94, 96, 97, 98, 103, 121, 122, 124, 127, 128, 130, 131, 133, 134, 135, 136, 145, 146, 148, 150, 153, 154, 157, 162, 163, 164], "fig1": [40, 153], "fig2": [38, 40, 153], "fig3": 34, "fig3d": 131, "fig_2": 151, "fig_4": 151, "fig_5": 151, "fig_af": 17, "fig_corn": [157, 162], "fig_cprob_revers": 157, "fig_cr": 131, "fig_id": 134, "fig_knn_classifi": 66, "fig_linear_classifi": 66, "fig_linear_classifier_plan": 66, "fig_pdfi": 131, "fig_point": 131, "fig_run": [157, 162], "fig_runs_revers": 157, "fig_slopesampl": 3, "fig_train_data": 66, "fig_tru": 38, "fig_x1x2": 131, "fig_x2givenx0": 157, "fig_xmgivenx0": 157, "figsiz": [5, 6, 9, 17, 18, 26, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 50, 51, 66, 70, 71, 74, 77, 78, 79, 82, 83, 84, 89, 94, 96, 103, 124, 127, 128, 130, 131, 134, 135, 136, 144, 145, 146, 150, 151, 152, 153, 154, 162, 163], "figur": [5, 9, 17, 18, 26, 34, 37, 39, 40, 41, 42, 43, 50, 51, 52, 54, 66, 67, 69, 70, 71, 73, 77, 78, 79, 80, 81, 83, 84, 87, 89, 93, 94, 95, 96, 97, 121, 122, 124, 127, 128, 134, 136, 138, 139, 146, 149, 150, 151, 153, 157, 160, 163, 164], "figure1": 18, "figure2": 18, "figure_id": 134, "figure_titl": 43, "figurefil": 134, "file": [9, 44, 51, 71, 77, 94, 97, 124, 127, 133, 134, 135, 138, 140, 141], "filenam": [70, 127], "filenotfounderror": 127, "fill": [9, 31, 33, 35, 43, 47, 48, 53, 78, 80, 95, 97, 126, 127, 134, 143, 155], "fill_between": [9, 18, 42, 81, 82, 83, 95, 97, 127, 131], "filter": [76, 127, 128, 152], "filterwarn": [74, 94, 144], "final": [4, 6, 17, 24, 26, 32, 35, 39, 41, 42, 43, 44, 45, 47, 51, 54, 58, 63, 65, 66, 67, 68, 70, 72, 73, 75, 76, 77, 86, 93, 98, 101, 107, 116, 121, 126, 134, 144, 148, 153, 157, 159, 164], "financi": 65, "find": [0, 3, 4, 5, 9, 16, 17, 18, 20, 23, 24, 26, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 57, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 84, 86, 87, 89, 90, 93, 94, 95, 96, 97, 98, 100, 101, 102, 105, 106, 107, 111, 114, 118, 122, 124, 126, 127, 131, 132, 133, 134, 135, 136, 139, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 157, 159, 160, 162, 163], "find_contour_level": 38, "find_index": 38, "find_map": [152, 153], "findabl": 44, "fine": [48, 67, 72], "finer": [51, 52, 97], "finetti": 47, "finish": [41, 94, 138], "finit": [16, 20, 34, 35, 44, 45, 48, 67, 68, 79, 83, 86, 87, 92, 118, 126, 145, 157, 162], "firmli": 8, "first": [1, 3, 5, 8, 9, 11, 15, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 32, 33, 35, 37, 39, 40, 43, 44, 45, 48, 49, 50, 51, 52, 54, 58, 60, 64, 65, 67, 68, 70, 72, 73, 74, 76, 77, 78, 79, 81, 83, 84, 86, 87, 89, 93, 94, 95, 96, 97, 108, 111, 116, 118, 122, 126, 127, 128, 131, 135, 136, 137, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 157, 159, 160, 161, 162, 163], "first_nam": 135, "fisher": [1, 96], "fission": 48, "fist": 157, "fit": [17, 18, 24, 30, 35, 37, 39, 44, 48, 50, 52, 53, 54, 64, 66, 67, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 93, 94, 95, 97, 98, 102, 103, 104, 105, 112, 120, 122, 125, 128, 139, 147, 154], "fit_degree_n": 96, "fit_intercept": [71, 134], "fit_transform": 124, "fiti": 134, "five": [26, 35, 38, 100, 105, 121, 131, 134], "fix": [3, 9, 17, 20, 23, 24, 35, 38, 44, 50, 51, 52, 54, 67, 72, 73, 76, 78, 83, 84, 86, 97, 106, 107, 118, 121, 122, 124, 129, 130, 131, 133, 134, 135, 144, 145, 146, 149, 151, 154, 155, 157, 159, 162, 163], "fk": 97, "flag": [38, 39], "flash": 37, "flat": [6, 8, 22, 26, 35, 37, 38, 39, 40, 41, 51, 53, 69, 87, 97, 124, 148, 153], "flatchain": [39, 42, 51, 144], "flatlnprob": 42, "flatten": [6, 34, 37, 42, 50, 51, 70, 76, 77, 78, 83, 84, 127, 137, 144, 147, 148, 152, 153], "flavor": 8, "flavour": 106, "flaw": 60, "flexibl": [38, 39, 48, 54, 67, 68, 72, 74, 86, 112, 134], "flexibli": 74, "flick": 149, "flip": [11, 13, 16, 26, 31, 149, 162], "flipper": 9, "float": [43, 51, 70, 71, 83, 97, 124, 130, 134, 135, 137, 150, 151], "float32": [70, 72, 74, 77, 130], "float64": [51, 97, 134, 152], "float640": 152, "float641": 152, "float6410": 152, "float648": 152, "float_widget": 133, "floatslid": [5, 9, 133, 135], "floatx": [74, 94], "floor": 137, "florian": 164, "flow": [45, 68, 118, 124, 154], "flowchart": 139, "fluctuat": [11, 24, 30, 37, 38, 41, 43, 91, 95, 97, 106, 107, 152, 155, 160], "fluid": 162, "flux": 54, "fly": [74, 94], "fm": 48, "fmhlg13": [1, 154], "fmin": 39, "fmt": [35, 39, 41, 42, 50, 96, 97, 103, 124, 144], "fn": [64, 65], "fnois": 93, "focu": [24, 44, 45, 65, 67, 73, 78, 84, 86, 105, 134, 143, 154, 157], "focus": [35, 44, 50, 63, 65, 74, 89, 90, 154], "fold": 96, "folder": 134, "follow": [4, 8, 9, 11, 12, 16, 17, 18, 20, 23, 26, 27, 35, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 54, 58, 62, 63, 65, 66, 67, 68, 70, 72, 73, 74, 76, 84, 86, 89, 93, 94, 95, 96, 97, 103, 104, 105, 106, 107, 111, 118, 120, 121, 124, 126, 127, 128, 131, 134, 135, 136, 137, 138, 139, 140, 143, 145, 146, 148, 149, 152, 153, 154, 155, 157, 160, 161, 162, 163], "font": [5, 9, 35, 38, 43, 111, 127, 128, 133, 134, 150, 151], "font_siz": [5, 9, 133, 150, 151], "font_size_w": 133, "fontsiz": [17, 18, 34, 39, 43, 51, 82, 97, 124, 131, 144, 148, 153], "food": 162, "fool": 32, "foolish": 67, "foral": [48, 66, 105, 157], "forc": [1, 52, 54, 60, 66, 115, 116, 122, 124, 127, 151, 155], "forcefulli": 149, "forecast": [16, 68], "forefront": 7, "foreman": [1, 148, 153, 160], "forest": [68, 74], "forestgreen": 121, "forev": 144, "forg": [74, 138], "forget": [22, 31, 66, 74, 94, 135], "forgotten": 134, "fork": 51, "form": [0, 4, 8, 13, 17, 20, 24, 26, 34, 38, 39, 41, 44, 48, 49, 50, 53, 54, 59, 64, 65, 66, 68, 69, 71, 72, 74, 76, 78, 79, 81, 83, 84, 87, 89, 92, 94, 96, 98, 101, 105, 107, 111, 118, 121, 126, 131, 135, 143, 145, 149, 151, 152, 154, 155, 157], "formal": [8, 26, 35, 48, 49, 54, 83, 101, 102, 111, 128, 157], "format": [0, 1, 26, 31, 39, 40, 41, 42, 43, 50, 51, 57, 70, 72, 74, 77, 93, 96, 97, 133, 134, 135, 136, 137, 144, 146, 148, 153], "format_nam": 0, "former": [8, 35, 44, 54, 67, 86, 101, 105, 111, 126], "formul": [0, 4, 5, 8, 9, 12, 26, 40, 44, 48, 60, 61, 66, 82, 91, 97, 114, 148, 153, 157, 162], "formula": [20, 38, 43, 48, 49, 50, 52, 54, 80, 86, 87, 91, 128, 134, 135, 145, 147], "forssen": [39, 40, 51, 78, 79, 96, 144, 145, 148, 153], "forss\u00e9n": [1, 45, 57, 74, 79, 94], "forth": [52, 68, 135], "fortran": [65, 134], "fortun": [44, 74, 138, 162], "forward": [8, 13, 42, 69, 71, 73, 76, 89, 98, 106, 115, 118, 149, 154], "fou": 52, "found": [4, 5, 8, 15, 18, 20, 22, 28, 30, 37, 39, 41, 45, 47, 48, 52, 54, 57, 64, 66, 68, 72, 73, 93, 105, 131, 137, 138, 145, 146, 151, 152, 154, 155, 160, 163, 164], "foundat": [26, 63], "four": [4, 38, 48, 51, 52, 64, 68, 69, 86, 87, 105, 121, 135, 157, 162], "fourier": [20, 35, 128], "fourth": [15, 69, 134], "fp": [64, 65, 127], "fphy": 1, "fr": [30, 34, 38, 131, 144, 157, 162], "frac": [3, 4, 8, 9, 10, 13, 16, 17, 20, 23, 24, 25, 26, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 47, 49, 50, 52, 53, 54, 66, 67, 68, 69, 73, 79, 80, 83, 86, 87, 89, 95, 96, 97, 98, 101, 108, 114, 115, 121, 122, 124, 126, 127, 128, 131, 134, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 160, 162, 163], "frac12": [50, 79, 95, 150], "fraction": [4, 6, 9, 33, 43, 51, 54, 64, 66, 67, 70, 98, 106, 108, 111, 124, 128, 131, 144, 145, 148, 153, 154, 155], "fraction_100_after_10min": 162, "fraction_kept": 128, "fragoso2018": 49, "frame": [1, 49, 127, 134, 157], "frame_skip": 127, "frame_switch": 127, "frameon": 30, "framework": [8, 16, 26, 28, 29, 31, 44, 47, 49, 61, 62, 72, 74, 79, 86, 118, 120, 122, 124], "franci": [1, 111], "franciscan": 54, "frederi": 57, "free": [31, 39, 42, 50, 52, 68, 73, 96, 115, 116, 118, 124, 126, 164], "freedom": [20, 30, 40, 45, 54, 96, 118, 127, 131, 148, 153, 160], "freeli": [65, 74], "freq": 135, "frequenc": [4, 8, 33, 34, 35, 39, 91, 131, 133, 135, 150], "frequent": [4, 7, 24, 39, 40, 65, 89, 107, 148, 153, 154, 155], "frequentist": [9, 22, 23, 24, 26, 27, 31, 33, 35, 36, 37, 40, 42, 44, 52, 96, 102, 131], "fresh": 148, "frictionless": 149, "friedman": 1, "friedrich": 1, "friend": 135, "friendli": 28, "frivol": 22, "frobeniu": 128, "frodo": 134, "frog": 77, "from": [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 16, 17, 18, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 79, 81, 82, 83, 86, 89, 90, 91, 93, 94, 95, 96, 98, 100, 101, 102, 103, 105, 106, 111, 112, 115, 116, 118, 120, 121, 122, 123, 124, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 143, 144, 145, 146, 148, 149, 150, 151, 153, 157, 159, 162, 163, 164], "front": [1, 40, 45, 135, 136, 153], "fruition": 8, "frustra": 54, "fstring": [40, 135, 139, 153], "ft": 34, "ft_pt": 34, "ft_uniform": 34, "ft_uniform_pt": 34, "ft_valu": 34, "fuch": 129, "fuction": 130, "fulfil": [4, 44, 105, 131, 154, 157, 162], "full": [17, 18, 19, 20, 35, 39, 41, 44, 45, 47, 48, 50, 52, 54, 57, 62, 68, 73, 77, 79, 80, 81, 83, 92, 94, 96, 97, 101, 107, 126, 128, 131, 137, 138, 144, 147, 149, 150, 152, 155, 160, 164], "full_cov": [78, 84], "full_matric": 128, "full_nam": 135, "fulli": [10, 44, 47, 52, 67, 68, 70, 74, 76, 120, 157, 160, 162], "fun": [34, 74, 93, 124], "func": [96, 127], "funcanim": 127, "function": [1, 3, 4, 7, 8, 9, 11, 15, 16, 20, 21, 25, 26, 27, 28, 31, 34, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 65, 67, 68, 70, 73, 74, 75, 76, 80, 81, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 105, 106, 107, 108, 111, 114, 116, 117, 118, 121, 122, 124, 127, 128, 130, 134, 136, 137, 139, 144, 145, 147, 148, 149, 151, 152, 153, 154, 157, 160, 162], "fundament": [8, 16, 26, 35, 40, 57, 61, 67, 102, 148, 153], "fundtion": 101, "fungibl": [9, 11], "furnstah": 51, "furnstahl": [0, 1, 5, 39, 51, 57, 78, 79, 133, 138, 144, 150, 152], "further": [4, 7, 17, 21, 22, 24, 25, 35, 37, 47, 49, 53, 54, 73, 74, 76, 79, 83, 87, 135, 136, 147, 149, 152, 154, 155, 157], "furthermor": [17, 26, 35, 39, 40, 42, 45, 47, 48, 50, 61, 67, 68, 73, 76, 78, 83, 84, 86, 89, 131, 134, 148, 153, 154, 162], "futur": [16, 25, 26, 35, 44, 51, 64, 66, 67, 74, 97, 111, 134, 152, 157, 162], "futuredata": 16, "futurewarn": [51, 97, 134, 152], "fvec": 87, "fvec_1": [80, 87], "fvec_2": [80, 87], "fwhm": 145, "g": [0, 1, 3, 4, 7, 8, 16, 17, 18, 19, 20, 22, 24, 26, 34, 35, 37, 39, 45, 46, 47, 48, 49, 50, 52, 53, 54, 57, 61, 62, 64, 66, 67, 68, 72, 73, 74, 76, 77, 79, 80, 81, 82, 83, 87, 93, 94, 95, 96, 97, 106, 116, 118, 121, 122, 123, 124, 125, 126, 127, 128, 131, 132, 134, 135, 138, 143, 145, 147, 149, 150, 154, 155, 161, 162, 164], "g1": 39, "g2": 39, "g_": [50, 95], "g_1": 39, "g_2": 39, "g_fun": 50, "g_i": 39, "gabri": 52, "gain": [44, 48, 53, 54, 57, 65, 74, 128], "galact": 42, "galaxi": [1, 17, 42, 54, 57, 63], "galerkin": 48, "galerkin_ortho": 48, "galleri": [17, 65, 135, 154], "galton": 111, "gambl": 8, "gambler": 162, "game": [16, 48, 73, 74, 126, 162], "gamge": 134, "gamma": [13, 18, 39, 43, 45, 108, 127, 143], "gamma2_dist": 127, "gamma_1": 108, "gamma_2": 108, "gamma_a": 127, "gamma_dist": 127, "gamma_label": 127, "gamma_scal": 127, "gap": [67, 98], "garcia": 1, "gate": 68, "gather": [20, 54, 68, 87, 157, 162], "gaug": [68, 72], "gauss": 111, "gaussian": [0, 1, 3, 16, 19, 24, 25, 27, 30, 38, 39, 41, 42, 43, 45, 46, 48, 51, 52, 53, 61, 71, 72, 73, 74, 75, 80, 88, 90, 91, 93, 95, 96, 97, 118, 119, 120, 121, 122, 124, 125, 130, 143, 144, 147, 149, 154, 155, 159], "gaussian_model": 153, "gaussian_nois": [78, 79, 84], "gaussian_norm": 50, "gaussian_process": [81, 82, 83, 123, 124], "gaussianmov": [51, 144, 147], "gaussianprocessregressor": [81, 82, 83, 93], "gave": [9, 64], "gc": [0, 1, 35, 52, 54, 57], "gca": [51, 79, 83, 96, 97, 128, 150], "gcc": [74, 94], "gcf": [97, 127], "gd": 69, "ge": [17, 68, 73, 89], "gedankenmodel": 49, "gelfand": 1, "gelman": [0, 1, 52, 57, 62, 73, 87, 145, 147], "gelman2013bayesian": 0, "gelman_rubin_diagnostic_calc": 144, "gelmen": 152, "gen": 127, "gen_gaussian_sampl": 79, "gen_plot_gaussian_sampl": 79, "gene": [1, 131], "gener": [0, 3, 4, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 23, 24, 27, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 57, 58, 60, 62, 63, 66, 67, 68, 69, 71, 72, 73, 75, 78, 79, 80, 83, 84, 86, 87, 90, 91, 93, 95, 96, 98, 101, 102, 103, 105, 106, 107, 108, 110, 111, 112, 113, 116, 117, 118, 121, 122, 123, 125, 126, 127, 128, 134, 135, 138, 140, 144, 145, 146, 147, 148, 150, 151, 152, 155, 157, 159, 161, 162, 163], "generaliz": 90, "generallay": 68, "generate_binaryclass_data": 66, "generate_data": 9, "genesi": 57, "gentli": 145, "geoff": 108, "geoffrei": 1, "geometr": 8, "geometri": 16, "georg": [1, 16, 47, 62, 63, 64, 109], "geq": [4, 30, 37, 38, 39, 47, 83, 93, 105, 131, 146, 154, 155, 157, 160, 162, 163], "geron": 67, "geron17": [1, 67], "get": [0, 4, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 24, 26, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 43, 45, 47, 49, 50, 51, 52, 54, 66, 68, 69, 73, 74, 80, 87, 89, 91, 93, 94, 95, 96, 97, 102, 124, 126, 127, 128, 130, 131, 133, 137, 138, 139, 140, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 160, 162, 163], "get_ax": 18, "get_batch": 107, "get_chain": [51, 124, 153], "get_cmap": 50, "get_fram": 9, "get_param": 83, "get_subplotspec": 3, "gev": 131, "gewek": 152, "gg": [4, 30, 38, 45, 49, 53, 54, 68], "gibb": 152, "gid": [71, 127], "gif": 127, "gif_filenam": 127, "gilk": 145, "git": [45, 65, 138, 141], "github": [41, 44, 57, 65, 71, 74, 77, 85, 94, 123, 131, 132, 137, 140, 149, 154, 155, 162], "githubusercont": 128, "gitlab": 65, "give": [0, 3, 4, 9, 12, 13, 16, 17, 18, 23, 24, 25, 26, 29, 31, 32, 33, 35, 37, 39, 41, 45, 46, 47, 49, 52, 54, 56, 64, 65, 66, 67, 68, 71, 72, 73, 74, 77, 78, 79, 80, 82, 83, 84, 86, 89, 95, 117, 125, 126, 128, 130, 131, 133, 134, 135, 137, 145, 147, 154, 156, 157, 160, 161, 162], "given": [0, 4, 5, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 63, 65, 66, 67, 68, 69, 71, 72, 73, 79, 80, 81, 83, 86, 87, 89, 91, 92, 94, 96, 101, 105, 106, 108, 111, 118, 121, 122, 123, 124, 127, 128, 130, 131, 134, 135, 137, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 160, 162, 163, 164], "glanc": 8, "glass": 59, "glean": 63, "glib": 138, "global": [1, 39, 51, 52, 54, 89, 98, 106, 127, 160, 164], "globalmov": 51, "glorot": 72, "gloss": [40, 148, 153], "glue": [3, 17, 66, 89, 131, 154, 157, 162], "gm": 116, "gmail": [81, 82], "go": [4, 9, 11, 13, 15, 16, 20, 23, 26, 30, 31, 34, 45, 53, 54, 57, 60, 64, 69, 74, 77, 87, 94, 98, 118, 128, 133, 134, 135, 137, 138, 141, 145, 146, 147, 148, 149, 153, 157, 160, 163], "goal": [9, 17, 18, 23, 31, 32, 33, 35, 37, 38, 43, 44, 45, 47, 49, 56, 59, 62, 65, 73, 80, 89, 90, 92, 98, 101, 105, 114, 118, 128, 148, 152, 153, 162], "goat": 16, "god": 20, "goe": [4, 17, 33, 53, 56, 67, 147, 157], "goggan": 52, "gold": [16, 78], "goldstein": [1, 47], "goldstein2009reifi": 49, "gone": 160, "good": [1, 2, 20, 23, 28, 30, 34, 35, 37, 40, 41, 43, 44, 45, 47, 48, 52, 54, 62, 64, 65, 67, 68, 69, 72, 74, 76, 78, 84, 86, 87, 93, 98, 101, 108, 122, 126, 127, 135, 137, 144, 145, 148, 149, 152, 153, 160], "goodman": [1, 154], "googl": [1, 18, 24, 43, 77, 80, 131, 133, 135, 139], "googlenet": 74, "gossett": [0, 24], "got": 30, "gothenburg": 16, "gotten": 20, "govern": [16, 64, 77, 122], "gp": [48, 78, 84, 88, 90, 93, 118, 120, 121, 122, 123, 124], "gp_kernel": 82, "gp_regress": [78, 79, 84], "gp_sklearn": 83, "gpkernel": 93, "gpplot": 83, "gpr": [82, 93], "gpr_model": 82, "gpr_sklearn": 83, "gpregress": [78, 79, 80, 84], "gpu": [74, 94], "gpy": [79, 80, 86, 87, 93], "gr92": [1, 45], "grab_fram": 127, "grad": 72, "grad_fn": 72, "grade": 8, "gradient": [35, 45, 66, 67, 68, 69, 71, 73, 74, 76, 89, 101, 114, 117, 118, 152, 155, 159, 164], "gradienttap": 77, "gradual": 48, "graduat": 57, "grai": [38, 39, 41, 97, 127, 128, 149], "grand": 33, "graph": [1, 9, 18, 37, 43, 65, 72, 74, 77, 78, 94, 105, 133, 136, 146, 155, 163], "graphic": [127, 138], "graphs_rjf": 127, "grass": [22, 63], "grate": 57, "gratefulli": 9, "gravit": [7, 52, 116, 122], "gravitation_orbit_1": 151, "graviti": [52, 122, 124], "grayscal": 76, "gre05": [1, 2, 28, 54, 57, 155, 163], "great": [7, 16, 48, 57, 74, 88, 138, 160], "greater": [20, 34, 38, 39, 45, 52, 54, 78, 84, 121, 122, 124, 144, 152], "greatest": [16, 94], "greatli": 66, "greedi": 48, "greek": 131, "green": [9, 34, 45, 70, 76, 97, 122, 127, 131, 135, 145, 149, 151, 155, 160, 164], "greenfield": 99, "gregori": [1, 2, 28, 38, 54, 57, 146, 163], "gregory_7_2": 54, "grei": [48, 66], "grid": [0, 17, 35, 38, 41, 42, 51, 52, 66, 71, 73, 74, 75, 77, 87, 94, 97, 103, 135, 157], "grid_2d": [74, 94], "griffith": 129, "grist": 59, "ground": [8, 48, 49, 122, 124, 134, 157], "groundwork": 35, "group": [4, 38, 65, 74, 78, 84, 86, 118, 127, 134, 137], "groupbi": 134, "grow": [30, 69, 87, 116, 118, 148, 153, 154, 155, 162], "growth_fig": 162, "growth_quest": 162, "gsl": 35, "gt": [116, 152, 155, 160], "guarante": [8, 16, 35, 48, 79, 83, 101, 145, 151, 157], "guess": [17, 18, 39, 83, 87, 93, 124, 148, 153, 157], "guesswork": 157, "gui": 127, "guid": [1, 11, 28, 42, 54, 63, 65, 70, 72, 82, 95, 118, 120, 132, 133, 138, 140], "guidanc": [51, 97, 127], "guidelin": [44, 95], "guido": 129, "guillaum": [81, 82], "guilti": 64, "guin": 24, "guiness": 0, "gull": [4, 43, 54], "gw07": [1, 47], "gw10": [1, 154], "h": [0, 1, 8, 16, 17, 25, 26, 32, 35, 45, 46, 47, 48, 54, 71, 86, 96, 116, 122, 124, 126, 131, 134, 145, 149, 150, 160, 162], "h0": [0, 17, 42, 124], "h2mc": 155, "h_": [17, 35, 42, 48, 54], "h_0": [17, 122, 124], "h_1": 26, "h_3": 16, "h_i": 26, "h_j": 16, "ha": [0, 4, 8, 9, 10, 16, 17, 18, 20, 23, 24, 26, 29, 30, 31, 32, 35, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 60, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 76, 77, 78, 79, 80, 81, 83, 86, 87, 89, 90, 91, 93, 95, 96, 97, 98, 105, 106, 107, 108, 112, 115, 116, 118, 122, 124, 126, 128, 131, 132, 134, 135, 136, 137, 138, 145, 146, 147, 148, 149, 152, 153, 154, 155, 157, 161, 162, 163], "habit": 44, "hackernoon": 136, "had": [4, 13, 16, 18, 20, 26, 42, 54, 57, 73, 131, 134, 145, 147, 155, 160], "hadamard": [69, 137], "hagan": 120, "hair": 4, "hal21": [1, 118], "half": [8, 18, 37, 38, 39, 41, 42, 45, 54, 71, 144, 149, 157], "halfnorm": 152, "halfwai": [52, 151], "hall": [0, 1, 16, 57], "halt": 108, "halv": [47, 144], "halverson": 1, "hamilton": [45, 149, 150], "hamiltonian": [1, 46, 48, 123, 150, 154, 155, 158, 161], "hamiltonianmc": 152, "hamiltonianpendulum": 150, "hammer": 1, "hand": [0, 1, 4, 9, 16, 17, 22, 23, 26, 27, 35, 39, 54, 63, 65, 67, 68, 70, 73, 74, 76, 78, 84, 98, 128, 138, 150, 151, 154, 157, 162, 164], "handbook": [1, 45, 67], "handed": 4, "handl": [45, 68, 71, 72, 83, 96, 111, 114, 134], "handle_color": 9, "handsid": 69, "hang": 52, "hanin": 1, "hao": 1, "happen": [5, 8, 11, 12, 17, 30, 35, 37, 38, 41, 42, 50, 59, 67, 69, 77, 78, 87, 91, 97, 128, 131, 145, 147, 152], "happend": 35, "happi": 133, "hard": [1, 32, 45, 50, 66, 68, 74, 89, 118, 145, 152, 155], "harder": [35, 68, 152], "hardest": 73, "hardli": 68, "hardwar": [65, 138], "hare": 68, "harm": [64, 67], "harmon": 48, "harsher": 54, "hashtag": 135, "hast": [51, 52, 144, 147, 149, 152, 160, 161], "hasti": [1, 67], "hat": [30, 39, 44, 45, 50, 52, 53, 64, 86, 108, 122, 124, 144, 152], "have": [0, 3, 4, 5, 7, 8, 9, 10, 11, 13, 16, 17, 19, 20, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 54, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 83, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 108, 112, 113, 114, 116, 118, 120, 121, 124, 125, 126, 127, 128, 130, 131, 132, 134, 135, 136, 137, 138, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 157, 159, 160, 161, 162, 163], "haven": 54, "hazan": 1, "hbox": [5, 9, 133], "hbox0": [9, 133], "hbox1a": [9, 133], "hbox1b": [9, 133], "hbox2": [9, 133], "hbox3": [9, 133], "hbox_1": 133, "hbox_2": 133, "hd": 17, "hdi_3": [152, 153], "hdi_97": [152, 153], "hdr": 131, "he": [1, 8, 16, 26, 38, 47, 48, 54, 62, 63, 72, 89, 118, 127], "head": [0, 8, 9, 11, 13, 16, 20, 24, 26, 31, 53, 134, 135, 162], "header": [134, 135], "headlin": 74, "heads_in_data_to_n": 9, "headstart": 128, "health": 74, "healthcar": 64, "hear": 65, "heart": [59, 120], "heavi": [12, 18, 19, 48, 65, 127], "heavili": [52, 65, 66, 107, 155], "heavisid": 45, "hei": 74, "height": [0, 9, 18, 37, 54, 76, 77, 111, 116, 122, 127, 133, 147, 164], "heisenberg": 16, "held": [23, 51, 149], "hello": [135, 136], "hello_funct": 135, "help": [9, 39, 43, 44, 45, 59, 64, 65, 67, 68, 70, 72, 74, 86, 94, 108, 112, 124, 133, 139, 140, 144], "help_bayes_w": 9, "help_max_height": [9, 133], "help_overview_w": [9, 133], "help_parameters_w": 133, "help_priors_w": 9, "help_setup_w": [9, 133], "help_tab": [9, 133], "help_times_w": 133, "help_toss_coin_w": 9, "helper": [35, 70, 71, 77, 103], "henc": [0, 23, 24, 35, 54, 67, 79, 83, 86, 92, 100, 134, 157], "henceforth": 157, "hendrik": [81, 82], "hennig": 62, "hensman": [78, 84], "her": [54, 64], "here": [0, 4, 5, 9, 13, 16, 17, 18, 20, 24, 25, 26, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 57, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 82, 84, 86, 87, 88, 89, 90, 93, 94, 96, 101, 103, 104, 113, 116, 117, 118, 121, 122, 123, 124, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 157, 159, 160, 161, 162, 163], "hereaft": 20, "hermitian": [48, 137], "heroic": 63, "hesian": 155, "hesit": 23, "hess_inv": 42, "hessian": [35, 37, 42, 54, 96], "heurist": [74, 160], "hexp_err": 124, "hexp_err_sc": 124, "hexp_mean": 124, "hexp_mean_sc": 124, "hexp_std": 124, "hg": [1, 45, 131], "hi": [0, 24, 26, 38, 54, 63, 105, 122, 152, 155], "hi95": [78, 84], "hick": 144, "hidden": [17, 44, 52, 64, 66, 68, 69, 71, 72, 74, 76, 94, 118, 130, 131], "hidden1": 72, "hidden2": 72, "hidden3": 72, "hide": 0, "hierarch": 74, "hierarchi": [41, 74], "higdon": [122, 124], "higdon2004combin": 49, "higg": [20, 131, 155], "high": [1, 5, 9, 22, 32, 35, 39, 44, 45, 46, 47, 48, 50, 52, 57, 64, 65, 67, 68, 73, 74, 76, 97, 98, 103, 107, 114, 123, 128, 134, 145, 147, 149, 150, 154], "higher": [9, 16, 20, 24, 35, 41, 48, 64, 65, 67, 74, 78, 81, 96, 124, 134, 145, 149, 150, 157], "highest": [20, 47, 51, 52, 74, 77, 80, 97, 126, 131, 152, 164], "highli": [28, 42, 45, 48, 53, 65, 67, 74, 79, 83, 87, 107, 134, 135, 153, 160], "highlight": [0, 34, 44, 57, 64, 96, 126, 135], "hilbert": 48, "hill": 145, "him": [105, 118, 129], "himself": 54, "hinder": 106, "hint": [0, 16, 17, 32, 38, 40, 52, 78, 84, 89, 97, 143, 153, 157, 162], "hinton": [1, 108], "hist": [18, 30, 34, 40, 43, 51, 74, 83, 94, 127, 130, 131, 144, 145, 146, 152, 153, 163], "hist_kwarg": 124, "hist_norm": 127, "hist_pt": 127, "hist_pts_al": 127, "histogram": [18, 19, 20, 30, 34, 37, 40, 43, 44, 45, 51, 80, 83, 130, 131, 144, 145, 146, 147, 148, 152, 153, 154, 155, 157, 160, 162, 163], "histogram2d": 42, "histogram_ax": 34, "histor": [47, 49, 64, 89, 90, 105], "historam": 34, "historgram": 160, "histori": [1, 56, 68, 70, 77, 108, 111, 157, 162], "historian": [8, 63], "histplot": 145, "histtyp": [131, 145], "hit": [11, 18, 37, 131, 135], "hitchhik": 57, "hjorth": 57, "hmc": [45, 152, 155, 159, 160, 161], "hmodel_sc": 124, "hms21": [1, 118], "hmv": 149, "ho": 48, "hobson": 1, "hoc": 39, "hoffman": 1, "hogg": [1, 96, 160], "hold": [9, 11, 32, 35, 48, 49, 64, 67, 74, 76, 94, 124, 137, 149, 154, 157], "holdout": 67, "hole": [7, 52], "home": [0, 78], "homemad": 151, "homogen": [68, 137], "honest": [4, 62], "honesti": 62, "honor": 46, "hood": 72, "hope": [49, 59, 60, 62, 89], "hopefulli": [46, 70, 74, 128], "hopfield": 68, "hopkin": 1, "horizont": [18, 20, 51, 79, 83, 133, 137, 144], "horizontalalign": [9, 17, 43], "hors": [77, 89], "hospit": 64, "host": 16, "hour": 38, "hous": 16, "how": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 23, 24, 25, 26, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 48, 50, 51, 52, 54, 57, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 78, 79, 80, 81, 83, 86, 89, 92, 93, 94, 96, 101, 103, 114, 115, 116, 118, 122, 124, 125, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 143, 145, 146, 147, 148, 149, 150, 152, 153, 154, 155, 157, 162, 163, 164], "howard": 131, "howev": [4, 8, 11, 16, 17, 26, 35, 39, 40, 44, 45, 46, 47, 48, 49, 52, 54, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 78, 84, 86, 89, 93, 94, 98, 100, 101, 102, 105, 106, 107, 108, 111, 118, 120, 123, 131, 134, 135, 136, 137, 138, 145, 147, 148, 152, 153, 154, 157, 162], "hp_bound": 124, "hpd": [20, 152], "hspace": 134, "hsplit": 137, "htf09": [1, 67], "html": [0, 1, 9, 18, 42, 43, 51, 71, 74, 82, 94, 97, 123, 131, 133, 135, 152, 153, 164], "htmlmath": [5, 9, 133], "http": [0, 1, 18, 41, 42, 51, 52, 70, 74, 77, 78, 82, 94, 97, 105, 123, 128, 131, 136, 138, 141, 149, 152, 153, 155, 162, 164], "hu": 1, "huang": [1, 134], "hubbl": [17, 42], "huber_loss": 39, "huge": [4, 17, 61, 63, 74, 76], "hugh": 131, "human": [63, 64, 65, 68], "hump": 20, "humpti": 59, "hundr": [68, 128], "hungarian": 62, "hungri": 68, "hunt": 54, "hw": [79, 83], "hybrid": [1, 45, 48, 74], "hydrogen": [134, 145], "hyper": [49, 74, 152], "hyperbol": [68, 72], "hypercub": [48, 80, 154], "hyperlink": [0, 57], "hyperparamet": [9, 18, 44, 45, 48, 67, 68, 70, 72, 73, 76, 79, 81, 83, 84, 87, 89, 98, 107, 118, 120, 121, 122, 124, 159], "hyperparmet": 124, "hyperrectangl": 47, "hyperreduct": 48, "hypothes": [7, 26, 54, 64, 68, 112, 120], "hypothesi": [8, 11, 20, 26, 40, 53, 64, 148, 153], "hypothet": [20, 54], "i": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 19, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 159, 161, 162, 163, 164], "i1": 68, "i10": 162, "i3": 134, "i5": 134, "i6qkdaeacaaj": 1, "i_": [47, 87, 128, 157], "i_0": 157, "i_1": 157, "i_2": 157, "i_d": [0, 17, 87], "i_i": 47, "i_m": 47, "i_n": [154, 157], "i_num": 154, "i_rel_error": 154, "i_sort": 42, "i_unsort": 42, "ia": 17, "ian": [1, 57], "iax": 3, "ib": 97, "ichain": [51, 144], "iclass": 66, "iclass_mean": 66, "icol": [51, 144], "id": [1, 135], "idata": 66, "idea": [9, 20, 25, 31, 34, 39, 44, 45, 48, 52, 57, 64, 65, 67, 68, 74, 78, 80, 84, 86, 93, 95, 98, 118, 127, 128, 143, 145, 147, 149, 152, 160, 164], "ideal": [4, 35, 45, 63, 65, 97], "ideg": 96, "idenitfi": 157, "ident": [35, 48, 52, 54, 59, 63, 67, 73, 74, 97, 103, 122, 124, 134, 137, 149, 157], "identif": [47, 105, 131], "identifi": [4, 8, 20, 27, 35, 39, 42, 44, 45, 47, 49, 64, 65, 66, 68, 70, 87, 89, 95, 115, 126, 131, 135, 137, 147, 155, 157, 164], "idx": 82, "iexp": 154, "iexp_i_num": 154, "ignor": [3, 4, 8, 9, 13, 17, 18, 26, 30, 39, 42, 43, 45, 47, 49, 50, 54, 62, 74, 77, 94, 127, 131, 144, 145, 147, 154], "ii": [1, 35, 38, 39, 44, 53, 54, 60, 64, 83, 95, 96, 108, 122, 126, 128, 131, 134, 149, 157], "iia": 92, "iib": 92, "iib_how_many_lines_ptemce": 91, "iid": [54, 84, 97, 124, 144], "iii": [44, 54, 60, 95, 122, 157], "iiia": 92, "iiib": 92, "iint": 45, "ij": [30, 35, 48, 54, 68, 69, 83, 87, 96, 126, 128, 144, 157, 162], "ik": [66, 83, 126, 128], "il": 68, "ill": [126, 128], "illustr": [17, 32, 33, 42, 48, 49, 50, 52, 54, 67, 68, 78, 81, 83, 84, 88, 119, 121, 122, 131, 164], "ilogp": 39, "ils": 1, "im": [35, 66, 97], "imag": [64, 68, 70, 118, 126, 127, 135], "image_height": 77, "image_path": 134, "image_width": 77, "imagemagick": 127, "imagenet": 74, "imagin": [4, 16, 26, 32, 38, 41, 49, 66, 67, 74, 97, 127, 147, 154, 155, 160], "img": [70, 77, 128], "img2": 128, "img99": 128, "img995": 128, "img_orig": 128, "immedi": [4, 16, 20, 54, 59, 61], "imp": 93, "impact": [24, 44, 64, 65, 72, 91, 95], "imparti": 62, "imper": 44, "imperfect": [24, 49], "impi": 157, "implaus": [47, 73], "implement": [23, 28, 35, 37, 39, 43, 44, 45, 48, 49, 52, 59, 64, 71, 72, 73, 74, 75, 76, 78, 83, 84, 91, 93, 97, 107, 108, 134, 136, 137, 146, 147, 150, 151, 157, 160, 162, 163, 164], "impli": [3, 4, 7, 17, 20, 23, 24, 30, 32, 33, 35, 39, 40, 41, 42, 45, 46, 48, 49, 50, 54, 63, 65, 66, 67, 68, 73, 76, 77, 79, 83, 86, 96, 98, 100, 101, 108, 113, 120, 128, 131, 135, 136, 144, 145, 148, 153, 157, 162], "implic": [10, 60], "implicit": [9, 24, 31, 35, 40, 50, 79, 83, 86, 148, 153], "implicitli": [20, 30, 41, 43, 144], "import": [0, 1, 3, 6, 7, 8, 9, 12, 17, 18, 20, 25, 26, 29, 30, 31, 34, 35, 38, 40, 41, 42, 43, 44, 47, 48, 50, 54, 56, 57, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 79, 80, 81, 82, 83, 86, 89, 94, 98, 101, 103, 105, 106, 107, 120, 124, 126, 127, 130, 135, 136, 137, 139, 144, 146, 148, 150, 151, 153, 154, 155, 157, 160, 162, 163], "importantli": [26, 38, 44, 79, 83, 116], "impos": [47, 61, 67, 80, 162], "imposs": [17, 35, 48], "impract": 154, "impress": [148, 153], "imprint": [65, 157], "improv": [5, 7, 15, 16, 19, 44, 49, 51, 52, 54, 65, 67, 72, 74, 90, 93, 94, 97, 107, 108, 118, 136, 147, 149, 151, 152, 163], "imput": 63, "imread": 128, "imshow": [70, 77, 79, 83, 128], "in_featur": [72, 130], "inaccur": [64, 66, 122], "inaccuraci": 47, "inact": [47, 68], "inadequ": 155, "inadvert": 57, "inappropri": 127, "inch": 150, "includ": [0, 4, 8, 12, 15, 16, 17, 23, 25, 26, 27, 28, 29, 30, 34, 35, 37, 40, 42, 44, 47, 48, 49, 51, 52, 56, 57, 60, 65, 66, 67, 68, 71, 72, 73, 74, 75, 78, 83, 84, 86, 87, 89, 90, 93, 94, 97, 101, 103, 111, 116, 117, 118, 122, 123, 124, 126, 127, 131, 133, 134, 135, 138, 142, 145, 148, 152, 153, 154, 157, 162, 164], "include_group": 134, "inclus": [40, 44, 53, 64, 148, 153], "incom": 68, "incomplet": [8, 47, 54, 64, 154], "inconsist": 64, "incorpor": [0, 4, 7, 16, 17, 26, 44, 62, 67, 68, 120, 121, 122, 151], "incorrect": [70, 77, 122, 124, 137], "increas": [16, 18, 24, 26, 34, 35, 42, 47, 48, 50, 51, 65, 66, 67, 68, 72, 73, 83, 96, 97, 98, 103, 108, 121, 124, 143, 144, 145, 147, 152, 154, 155, 160, 162], "increasingli": [26, 34, 41, 48, 49, 52, 54, 64, 79, 121, 122, 135, 147, 148, 153], "incredibli": 65, "increment": [9, 11, 72, 160], "inde": [8, 9, 16, 20, 23, 26, 31, 35, 54, 59, 61, 65, 101, 102, 134, 154, 157, 162], "indent": [135, 139], "independ": [3, 4, 9, 12, 15, 16, 17, 20, 23, 24, 26, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 64, 66, 67, 68, 73, 79, 81, 86, 87, 89, 96, 97, 100, 101, 103, 110, 111, 113, 114, 121, 122, 124, 128, 144, 149, 154, 155, 157, 162], "index": [5, 34, 35, 38, 45, 66, 77, 83, 86, 87, 89, 103, 118, 121, 126, 127, 131, 134, 136, 150, 151, 152, 153, 157, 162, 164], "index_col": 134, "index_cv": 96, "index_max": 127, "indiana": 57, "indic": [0, 4, 9, 18, 26, 30, 35, 39, 41, 42, 45, 47, 50, 52, 54, 64, 66, 70, 72, 73, 83, 105, 111, 126, 127, 128, 131, 134, 137, 138, 144, 147, 148, 149, 152, 153, 155, 157, 162], "indiffer": [8, 17, 44, 63], "indigen": 64, "indirect": 54, "indirectli": [44, 45], "individu": [23, 33, 34, 35, 39, 41, 42, 44, 45, 47, 49, 50, 64, 68, 74, 80, 82, 89, 96, 138, 144, 150, 162], "induc": [47, 52, 118], "induct": [1, 7, 43, 62, 114], "industri": 68, "ineffici": [45, 68, 107], "inequ": 47, "inevit": 131, "inexpens": [32, 48], "inf": [6, 34, 38, 39, 41, 43, 97, 124, 131, 144, 148, 153], "infeas": [44, 45, 48], "infer": [1, 8, 16, 19, 25, 26, 28, 29, 31, 35, 43, 48, 54, 56, 57, 58, 59, 60, 65, 66, 72, 90, 92, 96, 97, 103, 116, 120, 122, 125, 131, 144, 147, 152, 162, 164], "inference_librari": 152, "inference_library_vers": 152, "inferenti": [16, 49], "infil": 134, "infin": [17, 20, 39, 118, 127, 144], "infinit": [17, 39, 54, 65, 78, 83, 84, 86, 87, 111, 118, 154, 157], "infinitesim": [17, 26, 31, 54, 108], "influenc": [4, 16, 26, 39, 44, 47, 64, 67, 78, 84, 86, 122], "influenti": [44, 63], "info": [37, 74, 94, 124, 127, 134, 137, 140, 152], "inform": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 16, 17, 19, 20, 23, 24, 25, 26, 30, 31, 32, 33, 35, 38, 39, 40, 41, 44, 45, 47, 48, 49, 50, 53, 54, 56, 57, 59, 60, 62, 63, 64, 66, 67, 68, 73, 74, 80, 86, 89, 95, 96, 102, 108, 112, 114, 118, 120, 122, 124, 128, 131, 133, 134, 136, 138, 144, 148, 152, 153, 155, 160], "informatik": [81, 82], "infrastructur": 64, "infti": [0, 4, 15, 17, 18, 20, 24, 25, 34, 35, 37, 38, 39, 42, 45, 49, 50, 54, 73, 103, 131, 144, 147, 154, 157, 162], "ingredi": [17, 21, 25, 28, 47, 48, 52, 60, 68, 143], "inher": [44, 45, 54, 67, 72, 73, 74, 120, 162], "inherit": [72, 101], "inhibit": 67, "init": [51, 72, 130, 160], "init_1": [74, 94], "init_2": [74, 94], "init_out": [74, 94], "init_weight": 72, "initi": [9, 11, 16, 24, 31, 38, 42, 43, 47, 48, 51, 52, 53, 54, 57, 67, 68, 74, 78, 80, 83, 84, 93, 94, 97, 98, 106, 108, 118, 122, 124, 128, 131, 136, 138, 144, 146, 147, 150, 151, 152, 153, 154, 155, 157, 159, 160, 162, 163, 164], "initial_text": [9, 133], "initial_text_w": [9, 133], "initialis": [51, 153], "initialize_model": 130, "initio": [1, 93], "initv": 152, "inlin": [5, 34, 38, 39, 40, 41, 42, 43, 50, 71, 74, 78, 79, 84, 93, 94, 96, 97, 128, 131, 134, 135, 144, 145, 146, 148, 150, 153, 163], "inner": [8, 69, 78, 84], "innov": 74, "innovi": 74, "input": [0, 5, 9, 35, 41, 44, 47, 49, 57, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 83, 86, 87, 89, 90, 93, 94, 97, 102, 105, 110, 111, 118, 120, 121, 122, 124, 132, 135, 137, 159, 160, 162], "input_dim": [78, 79, 84, 93], "input_shap": [70, 77], "input_v": 130, "inputs_i": [35, 65, 66, 67, 107], "inputs_j": 67, "inputt": [35, 100, 102, 103, 111, 113, 114, 115], "inputt_": 114, "inputt_1": [66, 68, 114], "inputt_2": [66, 68, 114], "inputt_i": 114, "inputt_p": 68, "inquiri": 120, "insensit": 66, "insert": [16, 23, 32, 33, 48, 69, 71, 78, 84, 93, 131, 135, 137, 157, 162], "insid": [72, 96, 134, 135, 136, 150, 154, 164], "insight": [7, 21, 25, 27, 35, 46, 47, 49, 54, 65, 72, 74, 78, 84, 101, 112, 120], "inspect": [8, 35, 39, 103], "inspir": [65, 67, 68, 73, 74, 137, 145], "instal": [71, 74, 135, 143], "instanc": [16, 17, 63, 64, 66, 68, 72, 86, 89, 107, 114, 131, 152, 157, 162], "instanti": [80, 124, 150, 152], "instead": [8, 16, 17, 20, 35, 39, 40, 44, 45, 47, 49, 50, 52, 53, 54, 59, 63, 66, 72, 73, 74, 75, 76, 78, 79, 80, 83, 84, 86, 98, 106, 107, 108, 131, 135, 136, 137, 138, 145, 147, 148, 152, 153, 157, 160, 162], "institut": [64, 65, 131], "instruct": [18, 26, 31, 44, 54, 65, 138, 143], "insuffici": 54, "insur": 57, "int": [4, 9, 17, 18, 20, 24, 26, 34, 35, 38, 42, 43, 45, 50, 52, 53, 54, 71, 73, 74, 82, 83, 86, 94, 96, 124, 127, 137, 144, 146, 150, 154, 155, 160, 163], "int64": 152, "int640": 152, "int8": [74, 94], "int_": [0, 3, 4, 16, 17, 20, 24, 25, 34, 39, 42, 49, 54, 131, 147, 154], "int_0": [4, 11, 13, 17, 26, 37, 39, 52, 131], "int_1": 131, "int_a": [18, 24, 131, 155], "int_v": 155, "integ": [9, 13, 34, 37, 38, 40, 45, 70, 105, 111, 124, 130, 135, 136, 144, 146, 155, 157, 163], "integr": [0, 4, 5, 16, 17, 18, 19, 20, 24, 25, 32, 33, 35, 37, 38, 39, 44, 45, 48, 51, 52, 53, 54, 61, 72, 73, 74, 94, 96, 124, 127, 131, 135, 148, 149, 150, 151, 153, 155, 160], "integrand": [25, 34, 35, 39, 50, 53, 131, 154, 155], "integrand_pt": 34, "integration_fig": 154, "intel": 138, "intellectu": 62, "intellig": [1, 64, 65, 90, 105], "intend": [52, 62, 72], "intens": [39, 57, 80, 91], "intent": 44, "interact": [0, 16, 17, 26, 28, 44, 46, 57, 68, 118, 133, 134, 135, 149, 154, 155, 160], "interactive_output": 9, "interc": [53, 80, 87, 126, 147, 149], "intercept": [3, 6, 24, 35, 37, 39, 41, 42, 54, 100, 101, 134, 144], "intercept_": 71, "intercept_limit": 41, "intercept_rang": 41, "intercept_sc": 71, "interchang": 157, "interdepend": 47, "interest": [4, 8, 16, 17, 18, 20, 24, 26, 32, 35, 41, 42, 44, 45, 46, 47, 48, 49, 54, 59, 61, 65, 67, 68, 69, 74, 78, 84, 89, 97, 106, 112, 117, 128, 131, 134, 136, 147, 149, 154, 162], "interestingli": 74, "interfac": [11, 135, 154], "interior": [105, 134], "interlaboratori": 127, "intermedi": [26, 80, 91, 145, 149], "intern": [0, 1, 68, 147], "internet": 154, "interoper": 44, "interplai": 68, "interplo": 46, "interpol": [38, 42, 46, 48, 49, 79, 80, 81, 87], "interpret": [4, 5, 7, 8, 11, 16, 20, 21, 22, 23, 24, 26, 27, 33, 35, 38, 40, 44, 47, 52, 54, 61, 62, 63, 69, 73, 78, 81, 84, 90, 95, 96, 118, 120, 125, 129, 131, 148, 153, 154, 157], "intersect": [22, 23, 164], "interv": [4, 11, 15, 17, 18, 26, 27, 37, 38, 42, 44, 52, 80, 81, 83, 87, 89, 93, 97, 127, 131, 148, 152, 153, 162, 164], "interview": [64, 129], "intial": [124, 157], "intimid": 134, "intp": [74, 94], "intract": [48, 73, 148, 153], "intric": 16, "intrins": [26, 61], "introduc": [4, 7, 16, 17, 19, 22, 23, 25, 26, 28, 35, 39, 41, 43, 44, 45, 46, 47, 49, 52, 54, 59, 60, 64, 65, 66, 67, 68, 72, 89, 96, 98, 101, 108, 114, 117, 119, 120, 121, 131, 135, 145, 147, 157, 164], "introduct": [1, 21, 28, 40, 48, 54, 56, 73, 90, 123, 126, 148, 153, 154, 155, 159, 161], "introductori": [88, 125, 134], "intrus": [46, 48], "intslid": [5, 9, 133], "intuit": [8, 11, 16, 17, 23, 32, 37, 39, 40, 43, 45, 52, 63, 67, 68, 73, 74, 94, 118, 128, 134, 135, 148, 153], "inv": [35, 50, 51, 66, 96, 103, 124, 137], "invalid": [135, 160], "invalu": 147, "invari": [1, 4, 8, 41, 42, 44, 45, 56, 86, 96, 118, 144, 147, 148, 149, 151, 153, 154, 157], "invcft": 34, "invent": [38, 95], "inventor": 108, "invers": [8, 17, 24, 34, 42, 50, 52, 54, 67, 86, 101, 102, 124, 126, 127, 128, 139, 154, 157], "invert": [35, 49, 66, 86, 89, 98, 101, 105, 126, 147, 149, 150], "invest": 67, "investig": [59, 62, 65, 78, 83, 84, 93, 143, 144, 159, 162], "invft": 34, "invft_uniform_pt": 34, "invgamma": 131, "invit": [22, 49], "invok": [0, 151, 152], "involv": [17, 23, 26, 35, 39, 40, 44, 47, 49, 54, 63, 64, 65, 67, 68, 72, 73, 74, 83, 89, 94, 105, 111, 112, 146, 148, 153, 154, 155, 162, 163], "io": [42, 74, 94, 123, 127, 128, 149, 152, 153, 155, 164], "ipad": 135, "ipr": 6, "ipsen": 1, "ipykernel_2750": 38, "ipykernel_2786": 39, "ipykernel_3708": 134, "ipykernel_3917": 152, "ipynb": [37, 39, 42, 52, 71, 91, 94, 95, 128, 135, 143, 144, 147, 149, 151, 155, 159, 160, 164], "ipython": [5, 9, 127, 134, 135], "ipywidget": [5, 9, 127, 135], "ironclad": 63, "irow": [51, 144], "irreduc": [67, 98, 145, 154, 157], "irregular": 44, "irrelev": [35, 38, 45], "irrespect": [26, 145], "irun": 162, "is_avail": 72, "is_first_col": 3, "isak": [1, 45, 57], "isbn": 1, "iscalar": [74, 94], "isinst": [34, 38, 72, 124, 130], "isn": [64, 74, 149], "isnet": 57, "iso": [54, 83], "isol": [57, 126, 128], "isotrop": 147, "issu": [39, 64, 72, 96, 98, 106, 114, 144, 152, 154, 157], "isupp": 152, "ital": [40, 43, 135], "item": [3, 72, 130, 137], "iter": [1, 15, 39, 44, 45, 51, 52, 67, 68, 71, 72, 73, 74, 80, 82, 93, 97, 98, 106, 107, 108, 134, 135, 139, 144, 145, 147, 149, 152, 153, 154, 157], "itila": 1, "its": [0, 4, 7, 8, 9, 11, 12, 17, 18, 20, 23, 25, 26, 35, 38, 39, 41, 42, 44, 47, 48, 50, 53, 54, 61, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 76, 78, 79, 81, 83, 84, 86, 89, 97, 101, 105, 106, 108, 120, 122, 126, 128, 131, 133, 134, 135, 136, 137, 139, 144, 145, 148, 150, 152, 153, 154, 157, 162], "itself": [4, 7, 9, 20, 32, 34, 40, 41, 44, 45, 48, 51, 54, 59, 60, 64, 65, 68, 87, 97, 98, 118, 128, 133, 148, 151, 153], "iv": [61, 157], "ix": [42, 78, 84], "ix1": 66, "ix2": 66, "j": [1, 4, 5, 16, 20, 30, 35, 38, 45, 47, 49, 50, 57, 67, 68, 69, 79, 80, 83, 97, 100, 101, 108, 118, 126, 128, 131, 134, 144, 147, 150, 152, 154, 157, 162], "j_": [73, 108], "jacob": 8, "jacobian": [3, 17], "jaiswal": [122, 124], "jake": [67, 81], "jame": [1, 78, 84], "jan": [81, 82], "januari": 22, "javascript": [154, 155], "jax": 106, "jay03": [1, 57], "jay2020": 49, "jay88": [1, 63], "jayn": [1, 4, 41, 57], "jb": [0, 57, 132], "jb_test": 0, "jefferi": 54, "jeffrei": [3, 8, 39, 41, 52, 54], "jen": 1, "jensen": 57, "jeopard": 62, "jet": 38, "jforssen22": [1, 45, 47], "jhm": [81, 82], "ji": [68, 69, 126, 157], "jiang": [1, 45, 57], "jimmi": 1, "jitter": [79, 152, 153], "jk": [69, 126, 128], "jmlr": 1, "joanna": 64, "job": [64, 91, 152, 153], "john": [1, 8, 105, 164], "johnson": 4, "join": [134, 137], "joint": [4, 7, 17, 18, 23, 32, 33, 35, 37, 42, 43, 45, 54, 79, 83, 86, 87, 121, 143, 147, 148, 149, 153, 154, 157, 162, 164], "jointli": [86, 149], "jonathan": 1, "jone": 1, "jordan": 57, "joukj": 1, "journal": [1, 15, 44, 64], "jpeg": 76, "jpg": 128, "jstor": 1, "judg": [30, 61, 67, 147], "judgement": [44, 47, 54], "judgment": [48, 111], "jul": 138, "juli": 124, "julia": 64, "julien": 1, "jump": [9, 11, 24, 37, 52, 127, 145, 155], "jump_w": 9, "june": [5, 39, 51, 78, 96, 144, 145], "junli": 1, "jupyt": [24, 27, 28, 71, 122, 124, 126, 130, 132, 133, 137], "jupytext": 0, "juri": 63, "just": [0, 6, 9, 11, 13, 17, 18, 20, 23, 24, 25, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 77, 78, 83, 84, 86, 87, 89, 91, 94, 96, 97, 98, 101, 103, 106, 112, 128, 131, 132, 133, 134, 135, 138, 145, 147, 148, 153, 154, 155, 157, 160, 164], "justic": 64, "justif": [15, 65], "justifi": [25, 43, 45, 120], "k": [1, 3, 4, 6, 9, 15, 16, 20, 30, 37, 38, 39, 41, 42, 43, 45, 49, 50, 52, 53, 54, 68, 69, 72, 73, 78, 80, 84, 86, 87, 89, 93, 95, 96, 97, 108, 118, 121, 124, 126, 128, 131, 134, 143, 146, 147, 149, 151, 154, 155, 157, 160, 162, 163], "k0": [146, 163], "k1": 83, "k1__constant_valu": 83, "k1__constant_value_bound": 83, "k2": 83, "k2__length_scal": 83, "k2__length_scale_bound": 83, "k99": 128, "k995": 128, "k_": [50, 79, 80, 87, 146, 163], "k_0": [68, 146, 163], "k_1": [68, 78, 84, 146, 163], "k_2": [53, 68, 78, 84, 146, 163], "k_3": [146, 163], "k_arrai": [146, 163], "k_b": [4, 52], "k_i": [68, 146, 163], "k_l": 68, "k_list": 66, "k_max": 50, "k_now": [146, 163], "k_order": 50, "k_rbf": [79, 83], "kaim": 72, "kaiming_normal_": 72, "kalman": 126, "kami\u0144ska": 64, "kangaroo": 4, "kappa": [80, 86, 87, 124, 126], "kappa_": 80, "karamani": 164, "karl": 63, "kaspar": 1, "kati": 137, "kavukcuoglu": 1, "kazantzidi": 52, "kb": [70, 138], "kb1": [78, 84], "kb2": [78, 84], "kbf": 87, "kde": [145, 153], "keegan": 1, "keep": [6, 15, 20, 23, 26, 34, 35, 38, 40, 41, 42, 44, 45, 46, 65, 70, 72, 74, 97, 103, 107, 108, 116, 126, 128, 135, 145, 146, 147, 148, 152, 153, 154, 160, 163], "kei": [9, 11, 22, 23, 24, 25, 35, 44, 45, 46, 49, 59, 63, 64, 66, 68, 70, 72, 78, 80, 83, 84, 86, 89, 118, 125, 126, 128, 135, 145, 147, 154, 155, 157, 160], "keith": 1, "kejzlar2019bayesian": 49, "kejzlar2020": 49, "kennedi": [1, 120], "kept": [9, 24, 31, 45, 57, 126, 128, 163], "kera": [65, 70, 71, 73, 77, 137], "kern": [78, 79, 80, 84, 93], "kern1": [78, 84], "kern2": [78, 84], "kernel": [48, 78, 80, 81, 84, 87, 88, 93, 118, 120, 121, 122, 124, 135, 145, 155], "kernel_": [81, 82, 83], "kernel_func": 124, "kernel_rbf": 83, "kernelspec": 0, "ket": 48, "kev": 134, "keyboard": 135, "keyword": [95, 135, 139, 151], "kg": [122, 124], "ki": [66, 126], "kick": 74, "kill": 34, "kilomet": 78, "kind": [8, 20, 35, 59, 65, 67, 68, 74, 77, 79, 83, 89, 98, 102, 111, 112, 153, 162], "kinet": [45, 46, 149, 152], "king": 1, "kingma": 1, "kingmaba14": [1, 108], "kj": [68, 69, 128], "kk": 126, "kl": 73, "km": [17, 42, 78], "kmax": 50, "knew": [40, 148, 153], "knn_classifi": 66, "know": [3, 4, 8, 9, 11, 13, 16, 17, 18, 19, 20, 22, 23, 24, 26, 31, 32, 35, 41, 42, 43, 48, 49, 57, 60, 64, 65, 66, 73, 74, 80, 82, 126, 132, 134, 135, 137, 146, 147, 154, 155, 157, 160, 163], "knowledg": [4, 7, 8, 9, 11, 13, 16, 17, 22, 26, 28, 35, 38, 40, 41, 42, 44, 45, 47, 48, 54, 57, 59, 60, 61, 62, 65, 68, 74, 91, 112, 120, 121, 122, 125, 131, 148, 152, 153], "known": [4, 7, 8, 16, 17, 18, 26, 30, 35, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 54, 61, 63, 64, 66, 67, 68, 69, 72, 73, 74, 76, 78, 79, 80, 81, 83, 84, 86, 89, 91, 96, 98, 100, 101, 105, 111, 112, 118, 128, 131, 143, 144, 145, 152, 154, 157, 162], "knuth": 154, "ko": 97, "kochurov": [74, 94], "koh": [49, 121, 122], "kohn": 48, "kolmogorov": [8, 26], "kondev": [1, 134], "korai": 1, "kp": [146, 163], "kr": 151, "kramer": 1, "krasser": 73, "krgb15": [1, 73], "krishak": 52, "kroneck": 17, "kucukelbir": [1, 73], "kullback": 4, "kutta": [149, 151], "kwarg": [35, 42, 51, 103, 127, 152, 153], "kwd": 127, "kx": [78, 84], "l": [1, 4, 7, 13, 17, 20, 35, 37, 39, 40, 42, 45, 54, 68, 74, 83, 86, 87, 89, 93, 94, 118, 124, 131, 148, 149, 150, 151, 153, 162, 164], "l1": [68, 74], "l1_ratio": 71, "l2": [71, 74, 75], "l_": 68, "l_1": 89, "l_2": 89, "l_cumsum": 42, "l_h": 124, "l_i": 86, "l_j": [68, 69], "l_opt": 83, "l_pt": 43, "l_v": 124, "l_x": 54, "l_y": 54, "la": [35, 128], "la_i": 69, "la_k": 69, "lab": [42, 52, 65, 124], "label": [3, 5, 9, 15, 17, 18, 20, 30, 31, 34, 35, 37, 38, 39, 41, 42, 43, 44, 47, 48, 49, 50, 51, 54, 64, 65, 66, 68, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 83, 89, 94, 96, 97, 98, 103, 108, 112, 118, 124, 127, 128, 130, 131, 133, 134, 135, 136, 144, 145, 148, 150, 151, 153, 154, 157, 162, 163], "labels": 34, "labels_corn": 97, "labor": 65, "laboratori": 16, "lack": [4, 8, 41, 67, 111, 118, 131], "ladder": [51, 52, 97], "lag": [45, 144, 145, 160], "lagrang": [4, 5], "lagrangian": [18, 150], "lai": [26, 35], "lam": 162, "lambda": [3, 5, 34, 37, 39, 54, 67, 71, 78, 124, 128, 134, 152, 157, 162], "lambda_": 54, "lambda_0": [4, 54, 157], "lambda_1": [4, 37], "lambda_2": 37, "lambda_i": 54, "lambda_mat": 50, "lambda_mat_inv": 50, "lambdas0": 5, "lambdas_min": 5, "land": 8, "landmark": 80, "landscap": 45, "lang": 1, "langermann": 93, "langevin": 155, "langl": [4, 20, 38, 43, 46, 52, 86, 147, 154, 160], "languag": [0, 35, 44, 59, 63, 64, 65, 66, 72, 77, 91, 97, 106, 135, 137, 153, 154], "lapack": 137, "laplac": [8, 35, 52, 63, 73, 96], "laplacepropos": 152, "laps": 57, "larg": [3, 4, 17, 18, 20, 26, 30, 34, 35, 38, 39, 41, 42, 45, 46, 47, 48, 49, 52, 54, 56, 59, 61, 63, 65, 68, 69, 72, 73, 74, 90, 98, 105, 106, 108, 111, 112, 114, 115, 125, 128, 130, 131, 145, 147, 150, 154, 155, 157, 162], "larger": [4, 24, 26, 30, 34, 37, 38, 39, 41, 42, 46, 47, 52, 54, 67, 76, 78, 79, 81, 83, 87, 122, 126, 127, 145, 155], "largest": [4, 42, 45, 64, 67, 70, 79, 83, 126, 128, 154, 164], "lasagn": 74, "laser": [52, 157], "last": [15, 16, 33, 35, 37, 38, 45, 49, 51, 52, 57, 65, 67, 69, 70, 71, 73, 74, 76, 77, 79, 93, 94, 96, 97, 101, 103, 124, 127, 128, 131, 134, 135, 138, 145, 150, 152, 155, 157, 159], "last_nam": 135, "lastli": 57, "later": [9, 10, 11, 20, 26, 34, 35, 37, 39, 41, 42, 47, 64, 65, 68, 74, 79, 83, 89, 94, 96, 98, 103, 114, 122, 134, 135, 136, 138, 143, 144, 145, 147, 155, 157, 160], "latest": [1, 42, 71, 72, 152, 153, 164], "latex": [0, 41, 42, 43, 50, 96, 127, 135, 136, 143], "latex_macro": 0, "latin": [48, 54, 73, 80], "latter": [25, 35, 43, 44, 49, 50, 52, 54, 63, 67, 86, 87, 108, 111, 121, 125, 126, 134, 145, 157], "lattic": [45, 68], "launch": 63, "laundri": 147, "law": [40, 52, 63, 64, 65, 77, 118, 131, 148, 153], "lawrenc": [78, 84], "lawyer": 63, "lay": 0, "layer": [68, 69, 70, 71, 72, 73, 74, 94, 118, 130], "layout": [5, 9, 137], "lbfg": [71, 82], "lbrace": 49, "lcb": 93, "ldot": [7, 15, 17, 18, 19, 20, 24, 30, 34, 35, 37, 38, 40, 47, 48, 49, 52, 53, 54, 67, 68, 83, 87, 89, 91, 93, 97, 101, 113, 114, 126, 131, 139, 146, 147, 148, 149, 153, 154, 155, 157, 160, 162, 163], "le": [4, 17, 26, 35, 97], "lead": [7, 15, 23, 24, 26, 38, 39, 41, 44, 47, 48, 49, 50, 54, 56, 57, 58, 60, 63, 64, 65, 67, 68, 69, 72, 73, 74, 76, 89, 95, 106, 107, 118, 120, 122, 124, 126, 131, 134, 135, 137, 144, 147], "leaki": [68, 71, 130], "leaky_relu": 130, "leakyrelu": [72, 130], "leap": 35, "leapfrog": [45, 149, 151], "leapfrog_energy_test_1": 151, "leapfrog_orbit_1": 151, "learn": [1, 8, 18, 24, 26, 30, 35, 37, 40, 42, 48, 51, 57, 58, 59, 60, 62, 63, 70, 73, 76, 82, 86, 87, 96, 100, 105, 106, 107, 108, 111, 112, 118, 120, 122, 125, 128, 132, 134, 135, 137, 144, 145, 148, 153, 154], "learnabl": 76, "learner": 74, "learning_curv": 98, "learning_r": 107, "learningfromdata": [123, 128, 138], "least": [4, 8, 9, 16, 17, 20, 24, 31, 38, 40, 44, 45, 47, 60, 63, 66, 67, 70, 89, 95, 96, 103, 111, 124, 128, 131, 133, 148, 152, 153, 162], "leav": [24, 26, 39, 45, 52, 53, 67, 69, 76, 96, 148, 149, 152, 153], "lebesgu": 4, "lec": [46, 48, 53], "lectur": [1, 3, 44, 46, 47, 54, 57, 64, 65, 67, 68, 69, 71, 73, 89, 93, 96, 98, 112, 128, 134, 135, 144, 160], "lecturenot": 128, "lee": [1, 74], "left": [0, 3, 4, 9, 10, 13, 16, 17, 18, 20, 23, 25, 26, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 57, 65, 66, 67, 68, 69, 73, 79, 82, 83, 86, 89, 93, 95, 96, 97, 98, 101, 104, 106, 107, 108, 115, 118, 121, 122, 126, 127, 128, 131, 144, 145, 146, 147, 148, 151, 152, 153, 154, 157, 160, 162, 163], "leftarrow": [69, 157], "leftmost": 126, "leftrightarrow": [17, 37, 105, 126, 157], "leg": 9, "legal": 8, "legend": [0, 5, 9, 17, 18, 30, 34, 35, 38, 39, 50, 71, 72, 74, 77, 78, 81, 82, 83, 84, 89, 94, 96, 103, 124, 127, 128, 130, 131, 134, 135, 136, 144, 145, 150, 151, 154, 162, 163], "legendr": [111, 150], "lemaitr": [81, 82], "lemaitre58": [81, 82], "len": [5, 26, 31, 35, 38, 39, 42, 43, 50, 51, 66, 71, 78, 79, 80, 83, 84, 96, 97, 103, 124, 128, 134, 137, 144, 145, 148, 151, 152, 153, 162], "lend": 44, "length": [1, 7, 8, 24, 35, 39, 43, 45, 48, 52, 66, 78, 79, 80, 83, 84, 86, 87, 89, 96, 97, 107, 121, 124, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 162], "length_scal": [81, 82, 83, 124], "length_scale_bound": [81, 82], "lengthscal": [78, 79, 80, 83, 84, 93], "lenp": 48, "leprechaun": 7, "leq": [9, 11, 13, 17, 18, 24, 30, 37, 39, 45, 47, 50, 52, 54, 66, 67, 83, 96, 97, 105, 122, 131, 146, 154, 155, 157, 160, 162, 163], "less": [4, 11, 22, 38, 39, 45, 53, 54, 59, 61, 63, 64, 67, 68, 81, 96, 101, 128, 131, 134, 137, 144, 145, 155, 160], "lesson": [12, 64], "lesssim": 46, "let": [4, 6, 8, 9, 11, 15, 16, 17, 20, 26, 31, 32, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 54, 60, 64, 65, 66, 67, 68, 69, 70, 72, 73, 77, 78, 79, 81, 83, 84, 86, 87, 89, 96, 97, 98, 102, 103, 108, 114, 121, 124, 128, 131, 134, 135, 136, 137, 144, 145, 147, 148, 149, 152, 153, 154, 155, 157, 160, 162], "lett": 1, "letter": [24, 89, 131], "level": [8, 9, 16, 20, 30, 37, 38, 41, 42, 44, 48, 54, 57, 60, 64, 66, 73, 74, 75, 81, 83, 131, 133, 137, 144, 147, 157], "level_1sigma": 42, "leverag": [49, 72, 120], "lewi": 59, "lfd": 123, "lfd_develop": 141, "lfd_for_physicist": 138, "li": [8, 9, 17, 26, 31, 47, 48, 54, 63, 64, 79, 83, 133, 137], "li6e_nnloopt_nmax10": [79, 83], "lib": [51, 82, 97, 127, 153], "libcxx": 138, "librari": [18, 27, 35, 57, 65, 73, 74, 77, 94, 106, 134, 135, 137, 138, 154], "licat": 44, "licens": [57, 77, 81, 82, 138, 154], "lie": [26, 52, 54, 67], "life": [38, 57, 65, 68, 99, 134], "light": [7, 18, 26, 31, 35, 48, 54, 57, 59, 74, 80, 94, 131], "lightest": 134, "lightgrai": 42, "lighthous": 155, "lighthouse_stat": 43, "like": [0, 4, 9, 11, 12, 16, 18, 19, 20, 22, 23, 24, 31, 32, 34, 35, 37, 38, 40, 42, 43, 44, 45, 48, 49, 51, 52, 53, 57, 59, 63, 64, 65, 66, 67, 68, 72, 74, 78, 79, 80, 83, 84, 87, 89, 93, 94, 106, 107, 108, 115, 118, 126, 128, 131, 132, 134, 135, 137, 138, 144, 145, 146, 147, 148, 149, 152, 153, 154, 157, 160, 163], "likelihoo": [51, 52], "likelihood": [4, 7, 8, 9, 10, 16, 17, 24, 26, 30, 31, 38, 40, 41, 43, 45, 47, 48, 50, 52, 53, 54, 67, 73, 74, 75, 78, 81, 82, 84, 86, 94, 95, 97, 124, 128, 131, 143, 144, 145, 148, 152, 153, 155, 159], "likewis": 127, "lim_": [17, 45, 157], "limit": [1, 4, 8, 9, 17, 18, 24, 27, 31, 35, 38, 41, 43, 44, 52, 54, 59, 62, 66, 67, 77, 79, 83, 90, 95, 103, 111, 114, 120, 127, 130, 131, 133, 154, 155, 162], "limits_": 45, "lin": [79, 83], "linalg": [35, 50, 51, 66, 78, 79, 83, 84, 96, 103, 124, 128, 137], "lindholm": 1, "lindsei": 1, "lindsten": 1, "line": [0, 4, 9, 10, 15, 17, 20, 22, 24, 35, 37, 38, 39, 45, 51, 54, 65, 66, 67, 70, 71, 73, 74, 77, 78, 79, 80, 83, 84, 87, 89, 92, 94, 95, 103, 104, 118, 127, 131, 133, 134, 135, 138, 139, 143, 145, 146, 147, 148, 150, 151, 152, 153, 155, 159, 160, 163], "line1": 9, "line2": 9, "line3": 9, "linear": [1, 3, 16, 17, 28, 29, 39, 41, 42, 46, 48, 49, 51, 54, 56, 65, 67, 71, 72, 73, 74, 76, 78, 79, 83, 84, 87, 89, 96, 98, 104, 105, 106, 114, 117, 118, 124, 126, 127, 130, 134, 135, 139, 147, 159], "linear_model": [71, 75, 134], "linearli": [30, 35, 47, 54, 74, 86, 94, 97, 100, 113], "linearregress": 134, "liner": [66, 136], "lineshap": 54, "linestyl": [9, 35, 38, 41, 43, 50, 72, 78, 81, 82, 84, 103, 135, 145, 150, 151], "linewidth": [18, 38, 39, 41, 43, 50, 51, 131, 153], "link": [0, 1, 8, 18, 44, 45, 57, 68, 131, 132, 133, 135, 149], "linspac": [0, 5, 9, 17, 18, 26, 30, 31, 34, 35, 39, 41, 42, 43, 50, 72, 78, 79, 80, 81, 82, 83, 84, 89, 96, 97, 103, 124, 127, 130, 131, 133, 135, 136, 137, 145, 151, 154, 162], "linux": [94, 124, 135, 138], "liouvil": [45, 149], "liouville_test": 150, "liouville_theorem_visu": 149, "liquid": 134, "list": [1, 7, 9, 17, 18, 26, 31, 38, 42, 43, 44, 45, 47, 57, 62, 63, 64, 66, 68, 76, 83, 94, 97, 121, 124, 127, 130, 131, 133, 134, 135, 138, 139, 141, 145, 147, 152, 154, 157, 159], "list_a": 136, "list_b": 136, "list_lik": 83, "liter": 39, "literatur": [10, 18, 24, 39, 44, 48, 49, 52, 57, 68, 69, 86, 89, 95, 123], "littl": [8, 41, 54, 69, 72, 73, 128, 144, 149], "liu": 1, "live": [41, 49, 64, 149, 154, 155], "liz": 137, "ll": [3, 6, 9, 10, 11, 15, 17, 18, 20, 22, 24, 26, 31, 32, 34, 35, 39, 40, 41, 42, 43, 46, 50, 53, 60, 66, 68, 72, 78, 79, 80, 83, 84, 86, 94, 95, 96, 120, 126, 127, 128, 131, 133, 135, 138, 144, 145, 146, 147, 148, 149, 153, 154, 155, 157, 160, 163], "ln": [4, 38, 45, 52, 68, 96, 97, 131], "lnlike": [51, 97], "lnpost": [39, 51, 144], "lnprob": [51, 97], "lnprobabl": [39, 42, 51, 144], "lnz": 97, "lnzl": 97, "lo95": [78, 84], "load": [70, 71, 78], "load_data": [70, 77], "load_model": 70, "loadtxt": [79, 83], "loc": [0, 9, 17, 18, 30, 34, 35, 39, 43, 51, 71, 77, 78, 81, 82, 83, 84, 89, 96, 97, 127, 131, 134, 151, 154, 162, 163], "local": [4, 18, 49, 52, 68, 74, 76, 89, 93, 98, 106, 118, 124, 131, 134, 138, 154], "locat": [6, 16, 35, 41, 43, 44, 54, 78, 83, 84, 93, 95, 96, 97, 131, 137, 138, 141, 147, 148, 153, 154], "log": [3, 5, 6, 18, 35, 37, 38, 39, 40, 41, 42, 43, 45, 50, 51, 52, 54, 67, 72, 73, 75, 78, 80, 82, 84, 89, 95, 96, 97, 124, 137, 144, 148, 149, 152, 153], "log10": 78, "log_evidence_estim": 97, "log_flat_prior": [6, 41], "log_jeffreys_prior": 6, "log_l_pt": 43, "log_likelihood": [38, 39, 41, 42, 43, 51, 78, 96, 97, 124, 143, 144, 148, 153], "log_likelihood_singl": 42, "log_likelihood_v": 124, "log_likelihood_valu": 124, "log_marginal_likelihood": 82, "log_p1": [41, 42], "log_p1_1": 42, "log_p2": 41, "log_posterior": [38, 39, 42, 51, 97, 124, 143, 144, 147, 148, 153], "log_posterior_cauchi": 39, "log_posterior_conserv": 39, "log_posterior_gaussian": 39, "log_prior": [6, 38, 39, 42, 43, 51, 97, 124, 143, 144, 148, 153], "log_prior_": 124, "log_prior_cbar": 124, "log_prior_l": 124, "log_prior_param": 124, "log_prior_phi": 124, "log_prior_pt": 43, "log_prior_r": 124, "log_prior_theta": 124, "log_prior_v": 124, "log_priors_mdgp": 124, "log_priors_model": 124, "log_priors_thetaphi": 124, "log_prob_cutoff": 42, "log_prob_max": 42, "log_symmetric_prior": [6, 41], "logaddexp": [39, 51], "logarithm": [3, 4, 20, 38, 39, 41, 42, 54, 72, 73, 89, 96, 97, 143], "logic": [1, 4, 8, 9, 11, 16, 21, 54, 57, 63, 65, 146, 163], "logical_and": [38, 131, 148, 153], "logist": [64, 66, 68, 69, 74, 90, 94], "logisticregressioncv": 71, "logisticregressioncvifit": 71, "logit": [66, 68, 89], "logl": [42, 51, 97, 124], "logl1": 39, "logl2": 39, "loglarg": [51, 97], "loglikelihood": 97, "loglkwarg": [51, 97], "loglog": [150, 154], "logp": [6, 39, 51, 97, 124, 152], "logparg": [51, 97], "logpkwarg": [51, 97], "logpr": 6, "logz": 124, "logz_err": 124, "long": [15, 16, 18, 22, 35, 38, 39, 44, 47, 48, 52, 53, 54, 57, 67, 68, 95, 131, 134, 137, 138, 145, 147, 153, 157], "longer": [8, 12, 48, 52, 67, 68, 89, 121, 144, 147, 152], "longleftarrow": [139, 149], "longrightarrow": [0, 3, 11, 12, 13, 15, 16, 18, 20, 25, 32, 33, 34, 35, 37, 38, 52, 53, 139, 147, 160], "loocv": 67, "look": [0, 2, 9, 11, 13, 16, 18, 19, 20, 21, 27, 28, 32, 34, 35, 37, 38, 39, 40, 43, 45, 50, 51, 52, 53, 54, 56, 59, 64, 68, 70, 77, 78, 79, 83, 84, 87, 91, 93, 97, 103, 107, 115, 126, 128, 131, 134, 135, 138, 142, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 157, 158, 160, 161, 163], "loop": [35, 69, 72, 107, 136, 146, 148, 153, 163], "loos": 68, "lorentzian": 54, "lose": [49, 54, 162], "loss": [8, 70, 72, 73, 76, 77, 83, 89, 94, 105, 117, 118, 128], "lost": [39, 126, 128], "lot": [7, 20, 23, 30, 34, 64, 74, 94, 136, 145, 155, 160], "love": 63, "low": [1, 11, 32, 35, 44, 45, 46, 47, 48, 51, 52, 64, 67, 73, 80, 92, 97, 103, 128, 137, 147, 150, 152, 154, 155], "lower": [20, 26, 35, 39, 43, 51, 52, 54, 64, 69, 72, 74, 77, 120, 122, 124, 130, 131, 136, 148, 152, 153, 157, 160], "lowest": [48, 95, 157], "lp": 124, "lr": 72, "lra": [0, 3, 4, 52, 53, 80, 87, 91, 126, 147, 149, 155, 160], "lstsq": 128, "lt": [79, 152, 160], "luck": 16, "lvert": [73, 105, 121], "lw": [9, 30, 35, 39, 43, 66, 89, 103, 128, 130, 131, 133, 134, 135, 145, 162], "lwahlstromlschon21": [1, 64], "m": [1, 4, 16, 17, 35, 37, 38, 39, 40, 41, 42, 45, 46, 47, 50, 51, 52, 53, 54, 67, 68, 71, 72, 73, 78, 79, 80, 83, 84, 86, 87, 91, 93, 96, 97, 100, 101, 102, 103, 105, 108, 115, 116, 119, 122, 124, 126, 128, 130, 131, 134, 135, 144, 148, 149, 150, 152, 153, 155, 157], "m_": [53, 69, 149], "m_0": 96, "m_1": [0, 7, 53, 80, 87, 96], "m_2": [7, 53, 80, 87], "m_h": 134, "m_i": [4, 7, 35, 47, 101, 149], "m_j": [4, 7], "m_k": [53, 66], "m_l": 69, "m_n": 134, "m_p": 134, "ma_theta0": 144, "ma_theta1": 144, "mac": [94, 135, 138], "mac03": [1, 57, 73], "mach": 1, "machin": [1, 35, 48, 51, 57, 58, 63, 67, 68, 72, 73, 86, 87, 88, 89, 94, 96, 100, 105, 108, 111, 112, 118, 125, 126, 128, 132, 134, 144, 145, 154, 159], "machineri": [42, 131], "mackai": [1, 57, 73], "mackei": [1, 148, 153, 160], "maco": [124, 138], "macosx": [74, 94], "macroscop": 4, "made": [9, 11, 17, 34, 35, 42, 44, 45, 52, 53, 54, 57, 62, 64, 65, 72, 73, 76, 81, 86, 89, 116, 117, 121, 128, 133, 134, 135, 136, 145, 154, 162], "mae": [66, 67, 68], "magazin": 129, "magic": [135, 136, 145], "magnifi": 126, "magnitu": 80, "magnitud": [7, 38, 47, 48, 50, 52, 54, 64, 72, 97, 98, 124, 128], "mahalanobi": 124, "mahlet": 1, "mai": [1, 7, 19, 20, 22, 23, 24, 35, 38, 44, 47, 48, 49, 50, 52, 54, 57, 59, 60, 62, 63, 64, 65, 67, 68, 69, 76, 77, 78, 84, 89, 95, 97, 105, 125, 127, 128, 132, 134, 135, 138, 146, 150, 155, 163], "main": [8, 44, 47, 48, 54, 73, 76, 80, 89, 91, 108, 128, 152, 154], "mainli": [44, 46, 64, 65, 74, 105, 111, 134, 145], "maintain": [37, 45, 49, 68, 72, 124, 137, 157], "maiti": 1, "major": [37, 39, 64, 66, 74, 105, 106, 134], "make": [0, 4, 6, 7, 8, 9, 11, 16, 17, 18, 19, 20, 24, 25, 30, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 63, 64, 65, 66, 67, 68, 71, 73, 74, 75, 76, 78, 79, 80, 83, 84, 86, 89, 90, 93, 94, 95, 96, 97, 98, 100, 102, 103, 105, 107, 111, 112, 128, 130, 131, 134, 135, 136, 139, 143, 144, 145, 146, 148, 149, 152, 153, 154, 155, 159, 162, 163], "make_blob": 75, "make_circl": 94, "make_data": [41, 144], "make_dataset": 38, "make_fig": 38, "make_matric": 50, "make_moon": [71, 74, 94], "make_plot": 130, "makedir": 134, "mala": 155, "male": [64, 131], "manag": [9, 45, 49, 64, 76, 127, 138, 159], "mandat": 60, "mani": [4, 7, 8, 9, 11, 12, 18, 20, 22, 24, 26, 28, 30, 31, 33, 34, 35, 37, 40, 41, 44, 45, 46, 48, 49, 50, 52, 54, 57, 58, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 78, 79, 80, 83, 84, 89, 92, 94, 98, 103, 105, 106, 108, 112, 118, 120, 121, 122, 123, 127, 130, 131, 134, 135, 136, 137, 138, 145, 146, 147, 148, 149, 152, 153, 154, 155, 157, 160, 162, 163], "manifest": 64, "manifestli": 48, "manifesto": 49, "manifold": 46, "manipul": [8, 21, 26, 35, 80, 87], "mankind": 8, "manner": 76, "manual": [18, 24, 44, 65, 131, 135, 139, 147, 148, 153], "manufactur": 74, "manzoni": 1, "map": [8, 17, 35, 39, 47, 49, 65, 66, 68, 73, 89, 97, 102, 111, 124, 136, 147, 149, 152, 160], "map_estim": 153, "mapsto": [49, 107], "mar": [1, 79, 134, 150], "marathon": 78, "march": [54, 134], "margin": [0, 7, 10, 15, 16, 18, 20, 23, 32, 33, 36, 37, 38, 39, 41, 44, 45, 50, 53, 54, 73, 78, 83, 84, 86, 95, 97, 124, 125, 127, 148, 149, 153, 154, 155, 157, 160, 162, 164], "margina": 38, "marin": 1, "marina": 1, "mark": [18, 66, 127, 128, 135, 146, 163], "markdown": [139, 143], "marker": [35, 39, 50, 73, 79, 81, 83, 103, 134, 145, 146, 152, 163], "markers": [50, 81, 124], "markov": [1, 16, 17, 39, 44, 52, 144, 145, 146, 147, 148, 149, 152, 153, 160, 161, 162, 163, 164], "markovprocessexampl": 157, "markovprocessexample_corner_fig": 157, "markovprocessexample_runs_fig": 157, "martin": 73, "masquerad": 7, "mass": [1, 7, 8, 20, 24, 34, 35, 38, 44, 45, 47, 49, 52, 73, 80, 83, 100, 105, 115, 116, 122, 124, 149, 150, 154, 155, 162], "mass16": 134, "mass16round": 134, "massag": 134, "masses2016": 134, "masseval2016": 134, "massiv": [45, 74], "master": [1, 16, 57], "match": [1, 39, 44, 56, 68, 78, 84, 122], "materi": [28, 67, 76, 125], "matern": [78, 80, 82, 84, 87], "matern32": [78, 84, 93], "matern52": [78, 80, 84], "math": [1, 5, 34, 38, 44, 74, 94, 133, 137, 146, 163], "mathbb": [0, 18, 25, 26, 35, 45, 67, 68, 73, 83, 86, 87, 89, 101, 105, 108, 114, 128, 131, 147, 149, 162], "mathbf": [24, 35, 66, 79, 83, 86, 93, 101, 122, 128, 151], "mathcal": [0, 3, 4, 7, 13, 16, 17, 20, 25, 30, 35, 39, 40, 41, 42, 45, 47, 48, 50, 54, 68, 73, 78, 80, 83, 84, 86, 89, 93, 96, 101, 103, 105, 118, 121, 131, 144, 145, 148, 150, 153, 154, 155, 157, 159, 160, 162], "mathemat": [1, 8, 9, 11, 18, 20, 24, 26, 41, 57, 59, 62, 63, 65, 66, 74, 79, 83, 89, 94, 114, 117, 118, 131, 134, 145, 154], "mathematica": [1, 38, 135], "mathematician": [0, 44, 62, 63], "mathop": [35, 101, 114], "mathrm": [3, 4, 7, 9, 17, 18, 26, 31, 34, 35, 38, 42, 45, 46, 47, 48, 49, 54, 65, 66, 67, 68, 73, 76, 79, 83, 86, 89, 96, 97, 101, 107, 114, 124, 128, 131, 134, 145, 157], "matlab": 135, "matmul": [35, 66, 72, 103, 154], "matplotlib": [0, 3, 5, 6, 9, 17, 26, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 50, 51, 66, 70, 71, 72, 74, 77, 78, 79, 81, 82, 83, 84, 89, 93, 94, 95, 96, 97, 103, 124, 127, 128, 130, 131, 133, 134, 136, 138, 139, 144, 145, 146, 148, 150, 151, 152, 153, 154, 157, 162, 163], "matric": [35, 46, 48, 50, 53, 68, 76, 78, 80, 83, 84, 86, 87, 89, 101, 126, 134, 154, 157], "matrix": [17, 37, 39, 42, 45, 46, 48, 50, 53, 54, 64, 66, 67, 69, 72, 73, 74, 76, 78, 79, 80, 81, 83, 84, 87, 89, 94, 96, 98, 102, 103, 104, 105, 107, 108, 118, 123, 124, 131, 134, 139, 147, 149, 154, 162], "matrix_larg": 137, "matrix_large_spars": 137, "matrix_rank": 137, "matshow": [78, 84], "matt": 57, "matter": [20, 37, 38, 45, 48, 54, 63, 155, 157], "matthew": 1, "matur": 48, "max": [4, 9, 17, 24, 30, 34, 37, 38, 41, 42, 43, 45, 50, 51, 54, 68, 70, 71, 76, 77, 79, 83, 93, 95, 96, 97, 127, 133, 134, 135, 137, 139, 146, 154, 162, 163], "max68": 131, "max90": 131, "max_": 47, "max_arg": 42, "max_height": [9, 133], "max_i_num": 154, "max_it": [51, 71], "max_lag": [144, 145], "max_lik": 124, "max_mode_theta": 42, "max_n": [34, 38], "max_n1": 38, "max_n2": 38, "max_norm_pt": 127, "max_of_mod": 42, "max_param": 124, "max_pooling2d": 77, "max_pooling2d_1": 77, "max_posterior": 43, "max_sigma_v": 127, "max_theta": [148, 153], "maxa": 17, "maxent": 5, "maxim": [8, 13, 37, 39, 40, 41, 42, 50, 52, 73, 74, 78, 84, 86, 89, 94, 96, 105, 148, 153], "maxima": [54, 134], "maximimum": 73, "maximum": [8, 9, 13, 16, 17, 18, 20, 26, 31, 34, 35, 37, 38, 39, 40, 41, 43, 44, 47, 48, 50, 52, 54, 56, 63, 73, 74, 76, 79, 80, 81, 91, 93, 97, 124, 127, 128, 130, 134, 143, 148, 152, 153], "maxlik": 37, "maxlike_result": [148, 153], "maxpooling2": 77, "maxpooling2d": 77, "may22": [1, 47], "mayb": [10, 32, 91, 131, 152, 155], "mb": [107, 138], "mb_k": 66, "mbgd": 107, "mbox": [9, 11, 13, 15, 18, 20, 31, 37, 38, 39, 43, 48, 79, 87, 126, 144, 146, 163], "mbpt": 48, "mbw": [1, 67, 118], "mc": [0, 135, 143, 147, 154], "mcculloch": 68, "mcelreath": [45, 149, 154, 155], "mchain": 144, "mcmc": [1, 6, 17, 39, 42, 43, 44, 46, 47, 51, 52, 73, 74, 94, 124, 142, 148, 149, 152, 153, 156, 161, 164], "mcmc_data0": 51, "mcmc_data_nt": 51, "mcmc_random_walk_and_sampl": 155, "mcmc_sampling_i": 160, "mcmc_sampling_ii": [149, 159], "mcmcsampl": [148, 153], "mcse_mean": [152, 153], "mcse_sd": [152, 153], "md": [0, 122, 124], "md2": 124, "md_kernel": 124, "mdc": 124, "mdf": [1, 46], "mdn": 74, "me": [22, 23, 79, 83, 130], "mead": 5, "mean": [0, 6, 9, 11, 12, 13, 16, 17, 18, 19, 20, 22, 24, 25, 26, 30, 31, 32, 35, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 54, 59, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 84, 87, 89, 94, 95, 96, 97, 98, 101, 102, 103, 111, 114, 118, 121, 122, 124, 126, 127, 128, 130, 134, 136, 137, 143, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 157, 159, 160, 162, 163, 164], "mean1000": 163, "mean100000": 163, "mean100000b": 163, "mean100000c": 163, "mean1000b": 163, "mean1000c": 163, "mean16000": 163, "mean16000b": 163, "mean16000c": 163, "mean4000": 163, "mean4000b": 163, "mean4000c": 163, "mean_": 124, "mean_68cr": 39, "mean_absolute_error": 134, "mean_dist": 43, "mean_k": 66, "mean_posterior": 43, "mean_predict": 81, "mean_squared_error": 134, "meaning": [44, 47, 70, 112, 120], "means_arrai": 34, "meant": 65, "meanwhil": 9, "measur": [4, 7, 8, 16, 17, 24, 26, 35, 38, 39, 40, 41, 42, 44, 47, 50, 52, 54, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 80, 97, 98, 103, 111, 114, 120, 121, 122, 124, 125, 127, 134, 136, 144, 148, 153, 157, 162], "mechan": [4, 16, 23, 24, 35, 44, 48, 63, 65, 68, 72, 102, 125, 129, 138, 146, 157, 160, 163], "medal": 78, "media": 1, "median": [9, 18, 19, 26, 31, 44, 127], "medic": [36, 64, 131], "medicin": [49, 65, 68, 127], "mediev": 7, "mediocr": 49, "medium": 133, "meet": [57, 64, 137], "mehta": [1, 67], "mel": 48, "melendez": [1, 57, 79], "member": [23, 52, 64, 144], "memor": 118, "memori": [68, 72, 134, 137], "men": [78, 131], "meng": 1, "mention": [8, 40, 44, 49, 52, 67, 68, 74, 98, 148, 153], "menu": 138, "mere": [48, 120], "merg": 7, "merger": 57, "merit": [8, 54], "mermim": 129, "mermin": 129, "merriam": 111, "mesh": [5, 9, 31, 48, 131], "meshgrid": [38, 51, 71, 79, 83, 131], "messag": [79, 124, 135, 138], "messeng": 63, "met": 44, "meta": 20, "metadata": [44, 127], "meterologist": 157, "method": [1, 4, 5, 8, 16, 17, 18, 20, 26, 35, 39, 40, 44, 48, 49, 51, 52, 57, 59, 61, 62, 63, 64, 65, 66, 67, 68, 73, 74, 78, 84, 89, 90, 93, 94, 96, 98, 101, 106, 108, 111, 113, 114, 117, 118, 123, 124, 125, 126, 128, 131, 134, 135, 137, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 157, 161, 162, 163, 164], "methodologi": 47, "metr": 8, "metric": [47, 64, 66, 67, 70, 77, 98, 101, 111, 131, 134, 136], "metropoli": [45, 51, 52, 144, 147, 149, 152, 161], "metropolis_poisson_exampl": [155, 160], "metropolis_r": [146, 163], "metzen": [81, 82], "mev": [48, 79, 83, 134], "mew": [78, 84], "mg": [116, 122], "mgl": 150, "mgrid": [35, 66, 74, 94], "mh": [52, 147, 149, 152], "mi": [44, 47], "michael": [1, 47, 76], "michigan": 57, "micro": [4, 134], "micron": 52, "microst": 4, "mid": [9, 31, 32, 33, 34, 38, 39, 41, 42, 50, 63, 79, 96, 121, 144], "middl": [12, 57, 131], "might": [3, 4, 7, 8, 17, 20, 22, 24, 26, 30, 32, 35, 39, 40, 41, 42, 44, 45, 46, 47, 49, 52, 53, 54, 57, 61, 63, 64, 65, 66, 67, 68, 72, 74, 82, 86, 93, 95, 96, 97, 101, 106, 111, 112, 126, 128, 131, 133, 135, 136, 137, 138, 144, 145, 148, 152, 153, 154, 155, 157, 162], "mild": 66, "mill": [59, 128], "millimet": 52, "million": [17, 64, 134], "mimic": [68, 89], "min": [4, 9, 17, 35, 42, 43, 45, 50, 52, 54, 71, 78, 79, 83, 96, 97, 101, 114, 133, 134, 135, 137, 139, 149, 154, 157, 162], "min68": 131, "min90": 131, "min_": 128, "min_height": [9, 133], "min_obj": 93, "min_param": 124, "min_theta": [148, 153], "min_val": 93, "min_x": 93, "mina": 164, "mind": [9, 26, 31, 41, 44, 45, 64, 65, 118, 148, 153], "mine": 1, "minfunc": [41, 42], "mini": [50, 67, 69, 98, 164], "minibatch": [74, 94], "minibatch_i": 74, "minibatch_x": 74, "miniconda": 138, "miniconda3": [51, 82, 97, 127, 153], "minim": [8, 11, 23, 30, 35, 39, 41, 42, 48, 50, 52, 63, 66, 67, 68, 69, 70, 72, 73, 92, 93, 98, 101, 102, 106, 117, 118, 124, 128, 155, 160], "minima": [74, 89, 98, 105, 106], "minimum": [4, 5, 7, 9, 35, 40, 43, 52, 66, 70, 79, 93, 98, 101, 105, 106, 107, 124, 130, 133, 148, 153, 155, 157], "minka": 96, "minor": [5, 37, 136], "minu": [20, 30, 41, 42, 45, 73, 149], "minut": [39, 54, 78, 80, 124, 145, 162], "mirror": [52, 157], "misclassif": [64, 67], "misclassifi": [66, 67], "misconcept": 57, "miser": 17, "misfit": 44, "misinterpret": 54, "mislead": [44, 49], "mismatch": [16, 35, 54, 119], "miss": [26, 44, 45, 47, 64, 111, 120, 154], "misspel": 135, "mistak": 17, "misus": 44, "mit": [1, 154], "mith": 137, "mitig": [46, 64], "mix": [45, 52, 55, 56, 67, 68, 144, 147, 152], "mixtur": [39, 51, 73], "mkdir": 134, "mkl": 35, "ml": [61, 64, 74, 78, 84, 89, 90, 98, 128], "mle": [39, 42, 52, 53, 73, 89, 126, 128], "mlmodel": [65, 66], "mloutput": [65, 66, 67], "mloutput_": 66, "mloutput_i": 66, "mltestoutput": [66, 67], "mm": 157, "mnemon": [0, 23], "mnist": 70, "mock": 122, "mod": [0, 137], "modal": [52, 164], "mode": [0, 9, 18, 19, 26, 30, 31, 35, 41, 42, 43, 47, 48, 51, 52, 54, 57, 68, 72, 97, 127, 135, 144, 154, 160], "model": [0, 1, 4, 8, 17, 20, 21, 24, 25, 29, 37, 40, 45, 47, 48, 51, 52, 53, 56, 59, 60, 61, 62, 63, 64, 66, 71, 72, 80, 81, 82, 89, 91, 92, 93, 97, 98, 102, 103, 105, 106, 107, 110, 114, 118, 121, 123, 125, 126, 128, 130, 131, 134, 145, 146, 147, 148, 153, 154, 155, 157, 159, 163], "model_func": 97, "model_height": 124, "model_i": 97, "model_param_bound": 124, "model_select": [74, 75, 94, 134], "model_typ": [35, 93, 103], "modeldiscrep": 124, "modeloutput": [35, 99, 100], "modeloutput_i": 35, "moder": 49, "modern": [1, 17, 52, 65, 89, 137, 144], "modif": [44, 52, 54, 73, 96, 145], "modifi": [10, 26, 31, 35, 38, 39, 41, 42, 43, 51, 52, 57, 64, 67, 68, 69, 71, 72, 73, 78, 84, 94, 96, 97, 101, 108, 124, 132, 135, 136, 145, 152], "modul": [6, 8, 51, 70, 71, 72, 74, 82, 94, 97, 124, 130, 131, 135, 137, 138, 141, 148, 153, 157, 162], "modulenotfounderror": [70, 71, 74, 94, 135], "modulu": 17, "molecular": 45, "mom": [45, 105], "mom_": 45, "mom_i": 45, "moment": [68, 72, 108, 162], "momenta": 149, "momentum": [45, 68, 108, 149, 150], "monetari": 44, "monitor": [44, 45, 63, 67, 68, 70, 72, 98, 147, 160], "monk": 54, "monoton": [4, 68, 108, 160], "mont": [1, 16, 17, 44, 65, 73, 97, 124, 146, 148, 152, 153, 158, 160, 161, 162, 163, 164], "montepython": 45, "monthli": 1, "monti": 16, "moo": 63, "mor": 48, "moral": 160, "more": [0, 3, 4, 7, 8, 9, 11, 13, 15, 16, 17, 18, 19, 20, 24, 26, 29, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 86, 90, 92, 94, 95, 96, 97, 98, 100, 103, 104, 105, 107, 111, 113, 117, 118, 120, 122, 124, 128, 129, 131, 132, 134, 135, 136, 137, 138, 142, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 157, 159, 160, 161, 162], "more_replac": [74, 94], "moreov": [16, 44, 49, 64, 74, 76, 112, 120], "morn": 8, "morten": 57, "most": [4, 8, 11, 12, 16, 19, 20, 26, 34, 35, 38, 41, 42, 44, 45, 47, 49, 50, 51, 54, 57, 58, 59, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 86, 87, 89, 94, 96, 97, 98, 106, 112, 114, 118, 126, 127, 128, 129, 131, 134, 135, 137, 144, 148, 149, 152, 153, 154, 162], "mostli": [35, 39, 69, 74, 100, 111, 157], "mot": 45, "motion": [16, 116, 122, 124, 149, 151, 162], "motiv": [16, 17, 20, 39, 45, 49, 61, 66, 74, 89, 118, 149, 154, 159], "mount": 52, "move": [4, 9, 15, 26, 43, 45, 49, 51, 68, 69, 72, 89, 106, 133, 135, 144, 145, 147, 152, 157, 164], "movement": 145, "moviewrit": 127, "mp4": 127, "mpc": [0, 17, 42], "mpl": [127, 134], "mpl_toolkit": [38, 51, 66], "mplot3d": [38, 51, 66], "mr": 54, "mr_k": 66, "mrg_randomstream": 74, "mse": [66, 67, 68, 72, 101], "mseloss": 72, "msg": 135, "mu": [4, 5, 17, 18, 20, 25, 34, 35, 37, 38, 40, 42, 45, 47, 53, 54, 73, 78, 79, 80, 83, 84, 86, 87, 93, 127, 128, 130, 131, 145, 146, 148, 151, 152, 153, 155, 159, 162, 163, 164], "mu0": 51, "mu1": [35, 51], "mu2": [18, 51, 127], "mu_": [54, 131, 159], "mu_0": [5, 40, 53, 54, 148, 153], "mu_est": [40, 148, 153], "mu_i": [4, 79, 83, 87, 162], "mu_interval__": 153, "mu_j": 4, "mu_k": 4, "mu_mean_prior": 152, "mu_new": 83, "mu_opt": 83, "mu_prior": 152, "mu_sampl": 93, "mu_sample_opt": 93, "mu_sd_prior": 152, "mu_tru": [37, 40, 148, 153], "mu_x": [79, 87], "mu_z": [68, 83], "much": [8, 12, 18, 26, 30, 32, 35, 37, 39, 44, 45, 46, 47, 48, 52, 53, 54, 57, 61, 63, 64, 65, 66, 67, 68, 69, 74, 94, 95, 96, 98, 103, 107, 113, 128, 131, 134, 135, 136, 143, 145, 148, 153, 154, 155, 162], "multi": [16, 27, 47, 51, 56, 60, 72, 74, 89, 92, 94, 96, 97, 137, 154, 162, 164], "multi_class": 71, "multiclass": [64, 89], "multidimension": [18, 35, 52, 68, 80, 96, 123, 134, 137, 149, 155], "multilay": [68, 72], "multimod": [19, 20, 52, 74, 97, 131, 149, 154, 155, 164], "multinest": [1, 52, 154], "multinomi": 89, "multipl": [1, 11, 16, 34, 35, 38, 40, 43, 44, 45, 47, 48, 52, 53, 56, 62, 65, 67, 68, 69, 72, 73, 80, 89, 96, 125, 126, 127, 128, 144, 147, 148, 152, 153, 154, 155, 162, 164], "multipli": [4, 5, 33, 34, 35, 39, 41, 42, 48, 50, 54, 68, 73, 78, 80, 84, 86, 128, 137, 139, 144, 147], "multiprocess": [124, 152, 153], "multivari": [4, 17, 44, 45, 50, 65, 80, 86, 152, 154, 155, 162], "multivariate_norm": [35, 66, 70, 78, 79, 83, 84, 93, 128, 131], "multivariatenormalpropos": 152, "multivers": 131, "mumv": 83, "mup": 51, "mus2": 5, "mus3": 5, "mus4": 5, "mus5": 5, "must": [4, 5, 8, 16, 17, 20, 26, 34, 35, 38, 39, 44, 45, 46, 49, 54, 59, 63, 64, 65, 66, 68, 79, 86, 93, 97, 105, 107, 122, 124, 128, 131, 136, 137, 148, 153, 154, 155, 157, 160, 162], "mutat": 89, "mutual": [23, 24, 32, 33, 67, 77], "muvec": [79, 87], "muz": 83, "mvec": 87, "mvec_1": [80, 87], "mvec_2": 87, "mvn": 83, "mx": [41, 42, 144], "my": [0, 9, 31, 74, 138, 145], "my_ax": [130, 135], "my_bin": 34, "my_fig": [130, 135], "my_funct": [133, 135, 139], "my_metropolis_model": 152, "my_model": 152, "my_mu": 130, "my_multinorm_rv": 131, "my_norm_rv": 131, "my_normal_rv": 131, "my_nuts_model": 152, "my_output": 130, "my_rv": 131, "my_sigma": 130, "my_student_t_rv": 131, "my_suptitl": 18, "my_titl": [78, 152], "mymodel": 72, "myst": 0, "myst_nb": [3, 17, 66, 89, 131, 154, 157, 162], "mysteri": 129, "m\u00e4rten": 1, "n": [1, 3, 4, 7, 8, 9, 11, 13, 15, 17, 18, 20, 25, 26, 30, 31, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 52, 54, 64, 66, 67, 68, 69, 73, 74, 78, 79, 80, 82, 83, 84, 89, 93, 96, 97, 98, 100, 103, 106, 108, 113, 118, 121, 124, 126, 127, 128, 131, 134, 136, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 157, 159, 162, 163], "n_": [30, 43, 45, 46, 48, 52, 65, 67, 68, 72, 76, 79, 83, 107, 118, 160], "n_0": [37, 38, 68], "n_1": [80, 87], "n_2": [80, 87], "n_a": 8, "n_activ": 124, "n_active_mltpl": 124, "n_b": 48, "n_col": 83, "n_color": 127, "n_d": [35, 101, 103, 107, 114], "n_dim": [50, 124], "n_eff": 124, "n_effect": 124, "n_effective_mltpl": 124, "n_epoch": 107, "n_evid": 124, "n_featur": 75, "n_gamma": 127, "n_h": 48, "n_hidden": [74, 94], "n_i": [4, 136], "n_in": 72, "n_job": 71, "n_k": [37, 38, 66], "n_l": 68, "n_max": 43, "n_max_step": 124, "n_max_valu": 43, "n_mean": 34, "n_means_arrai": 34, "n_new": 83, "n_p": [35, 100, 101, 103, 108], "n_prior": 124, "n_pt": [34, 38, 144, 146, 163], "n_restart": 93, "n_restarts_optim": [81, 83], "n_row": 83, "n_sampl": [74, 75, 82, 130], "n_step": 124, "n_steps_mltpl": 124, "n_total": 124, "n_trials_max": 9, "n_trials_max_w": 9, "n_uncertainty_digit": 131, "n_val": 34, "n_w": 9, "nabla": [35, 80, 97, 98, 101, 106, 107], "nabla_": 35, "naimi": [1, 134], "naiv": [17, 44, 54, 89], "name": [0, 4, 10, 17, 18, 24, 26, 35, 40, 42, 43, 45, 50, 52, 54, 64, 65, 68, 69, 70, 71, 74, 76, 77, 78, 80, 84, 92, 94, 95, 96, 97, 103, 105, 124, 126, 128, 131, 134, 135, 137, 138, 139, 145, 147, 148, 152, 153, 155], "namespac": 135, "nan": [39, 137], "narrow": [9, 11, 12, 15, 17, 26, 30, 31, 39, 42, 54, 74, 94, 122, 154], "nasti": [9, 31], "nat": 1, "nation": 64, "nativ": 64, "natur": [1, 7, 8, 16, 26, 35, 38, 39, 43, 44, 45, 48, 50, 53, 54, 61, 63, 65, 68, 70, 72, 73, 74, 81, 87, 97, 111, 118, 121, 131, 137, 150], "navier": 68, "navig": [106, 108], "nb": 48, "nbin": 42, "nbsp": 71, "nburn": [6, 39, 97, 124, 148, 153], "nburnin": [51, 97], "nbviewer": 71, "nc": 57, "nchain": 144, "ncol": [3, 26, 31, 34, 40, 79, 83, 89, 94, 96, 131, 135, 145, 153, 154, 162], "ncore": 124, "ncorr": 6, "ncross": 96, "ncsm": [79, 83], "nd": [35, 103], "ndarrai": [43, 83, 124], "ndata": [35, 97, 103], "ndiffer": 152, "ndim": [6, 18, 39, 42, 51, 97, 124, 144, 147, 148, 153], "ndimens": 95, "ndoubl": [26, 31], "neal": [45, 149], "nearbi": [20, 45], "nearest": 137, "nearli": [35, 122, 128], "neat": 134, "necess": [8, 40, 148, 153, 155], "necessari": [4, 16, 43, 54, 70, 72, 94, 131, 134, 138, 143], "necessarili": [0, 8, 22, 24, 26, 35, 40, 44, 47, 65, 67, 101, 131, 138, 145, 148, 153], "necessit": [149, 155], "need": [6, 7, 17, 18, 20, 23, 26, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 57, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78, 80, 86, 87, 89, 91, 93, 94, 95, 96, 97, 98, 101, 105, 111, 116, 120, 123, 124, 127, 128, 131, 132, 133, 134, 135, 137, 138, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 155, 157, 159, 160, 162, 163], "needless": 57, "neg": [4, 20, 22, 32, 34, 35, 38, 41, 42, 45, 51, 64, 65, 66, 72, 73, 78, 84, 89, 93, 97, 106, 134, 157, 160], "negat": 45, "neglect": [16, 20, 30, 46, 54, 115, 116, 122], "neglig": [35, 42, 52, 53, 86, 116], "negri": 1, "neighbor": [11, 20, 43], "neighborhood": [48, 66], "neighbourhood": 54, "neil": [78, 84], "neither": [59, 68, 72, 147], "neq": [0, 4, 17, 23, 32, 33, 35, 54, 67, 73, 126, 131, 157, 160, 162], "nest": [0, 52, 53, 54, 68, 154, 155], "net": [67, 68, 72, 74, 94, 130], "netherland": 1, "network": [1, 46, 48, 61, 89, 90, 92, 106, 107, 117, 118, 130, 137], "neumann": 105, "neural": [1, 46, 48, 61, 89, 90, 92, 106, 107, 117, 118, 137], "neural_network": [74, 94], "neural_network_minibatch": 74, "neuralnet": 71, "neuron": [1, 69, 70, 71, 72, 73, 74, 75, 89, 94, 118, 130], "neutral": 134, "neutron": [1, 35, 80, 100, 134, 155], "never": [16, 35, 54, 67, 69, 78, 84, 102, 135], "nevertheless": [16, 40, 101, 148, 153], "new": [0, 7, 9, 10, 11, 13, 15, 16, 17, 26, 35, 38, 39, 41, 44, 45, 47, 49, 50, 51, 52, 54, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 71, 72, 73, 74, 77, 78, 80, 83, 87, 89, 90, 94, 96, 118, 127, 128, 132, 134, 135, 136, 137, 138, 143, 144, 145, 146, 149, 151, 152, 154, 155, 157, 163, 164], "new_arr": 137, "new_data": 74, "new_data_button_w": 9, "new_hobbit": 134, "newarr": 137, "newaxi": [79, 83], "newcommand": [0, 9, 31, 41, 42, 43, 45, 50, 79, 96, 105, 128, 152], "newer": 52, "newli": [45, 135], "newton": [52, 115, 116], "newtonian": [16, 52], "next": [8, 9, 11, 16, 26, 31, 32, 35, 38, 40, 41, 42, 44, 48, 49, 52, 64, 65, 70, 76, 81, 93, 101, 103, 108, 118, 127, 134, 135, 137, 138, 144, 145, 146, 148, 152, 153, 157, 160, 163], "next_button_w": 9, "nfev": 124, "nframe": 127, "nh": 86, "ni": 47, "nice": [39, 49, 70, 96, 122, 145, 148, 153], "nicer": [18, 34, 39, 40, 134, 145, 146, 148, 153], "nicola": [78, 84], "niel": 26, "nielsen": 76, "nifti": 17, "nine": [78, 84, 154], "nist": 64, "nit": 124, "niter": [51, 97], "nk_pt": 38, "nll": 124, "nlp": 124, "nm": [68, 80], "nm_n": 134, "nmap": 124, "nmax": [43, 79, 83], "nmaximum": 124, "nn": [66, 72, 86, 130], "nnloopt": [79, 83], "no_grad": [72, 130], "no_of_chain": [51, 144], "no_of_head": [26, 31], "no_of_sampl": 145, "no_of_tail": [26, 31], "nobel": 68, "node": [68, 69, 70, 74, 94], "nois": [3, 7, 20, 30, 39, 41, 42, 50, 64, 67, 71, 73, 74, 78, 79, 80, 83, 84, 86, 87, 91, 93, 95, 96, 97, 124, 128, 143, 144, 153, 159], "noise_std": 81, "noise_var": 80, "noisi": [66, 67, 72, 89, 91, 92, 93, 96, 97, 98, 124], "nomin": [4, 145], "non": [6, 11, 24, 25, 30, 32, 34, 35, 38, 39, 41, 44, 46, 47, 48, 49, 64, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 83, 89, 90, 94, 97, 101, 102, 103, 114, 117, 118, 128, 131, 134, 137, 147, 157], "nonconvex": 105, "none": [4, 6, 18, 30, 34, 35, 38, 42, 43, 50, 51, 66, 70, 71, 77, 78, 79, 81, 83, 84, 93, 97, 103, 124, 127, 128, 130, 134, 144, 145, 148, 150, 153], "nonetheless": 64, "noninform": [40, 148, 153], "nonlinear": [35, 54, 68, 72, 103, 154], "nonlinearli": 48, "nonloc": 52, "nonneg": 67, "nonparametr": [79, 83, 87], "nonsens": [126, 131], "nonsequenti": 137, "nonstandard": 154, "nonstationari": 122, "nontreiv": 149, "nonumb": [49, 89], "nonzero": [20, 68, 137, 160], "nor": [8, 59, 65, 68, 72, 91], "norm": [5, 6, 9, 18, 26, 30, 31, 34, 35, 38, 40, 46, 50, 51, 66, 67, 74, 83, 93, 96, 101, 102, 127, 128, 131, 144, 145, 148, 152, 153], "norm1": 51, "norm1_dist": 18, "norm2": 51, "norm2_dist": [18, 127], "norm_dist": [18, 127], "norm_label": [18, 127], "norm_loc": 127, "norm_pt": 127, "norm_sampl": 18, "norm_scaled_v": 127, "norm_x_pt": 34, "norm_y_pt": 34, "normal": [0, 10, 13, 15, 16, 17, 19, 20, 24, 25, 27, 31, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 53, 67, 68, 70, 71, 73, 74, 77, 78, 80, 81, 84, 89, 93, 94, 96, 97, 98, 102, 103, 105, 111, 116, 124, 127, 128, 130, 131, 144, 145, 146, 148, 149, 152, 153, 154, 155, 157, 159, 160, 162, 163], "normal_": [72, 130], "normal_distribut": 35, "normaliz": 20, "normalize_i": 83, "normalized_posterior_funct": 145, "normalpropos": 152, "normp": 51, "northpoint": 64, "northwestern": 57, "notabl": 122, "notag": 48, "notat": [13, 16, 18, 21, 22, 24, 25, 32, 33, 35, 36, 37, 38, 39, 43, 48, 49, 50, 66, 67, 69, 73, 90, 102, 103, 105, 108, 118, 124, 145, 146, 154, 157, 159, 163], "note": [1, 3, 4, 5, 8, 9, 11, 13, 16, 17, 18, 19, 20, 23, 24, 26, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 57, 64, 65, 66, 67, 68, 69, 73, 74, 76, 77, 78, 80, 81, 83, 84, 86, 87, 89, 91, 93, 94, 95, 96, 97, 98, 100, 101, 103, 106, 107, 111, 112, 113, 114, 124, 126, 127, 128, 131, 133, 134, 135, 136, 137, 138, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 157, 159, 160, 162, 163], "notebook": [5, 9, 11, 14, 16, 18, 24, 27, 28, 32, 34, 35, 37, 38, 40, 42, 50, 51, 53, 57, 71, 72, 73, 74, 77, 87, 90, 91, 93, 94, 95, 96, 97, 103, 122, 124, 125, 126, 130, 132, 133, 136, 137, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 160, 163, 164], "noth": [3, 8, 20, 35, 37, 44, 48, 67, 68, 74, 94], "notic": [1, 4, 24, 40, 54, 69, 73, 79, 80, 83, 86, 89, 148, 153, 155, 160], "notin": [47, 131], "notion": [8, 9, 26, 31, 44], "notori": [45, 65, 136], "novel": 67, "novemb": [5, 78], "now": [0, 3, 4, 5, 9, 15, 16, 17, 18, 20, 22, 24, 26, 30, 31, 32, 34, 35, 37, 38, 39, 41, 42, 43, 47, 49, 50, 53, 54, 60, 64, 65, 66, 67, 68, 69, 74, 78, 79, 81, 83, 84, 86, 87, 89, 93, 94, 95, 97, 102, 103, 128, 130, 133, 134, 135, 136, 137, 138, 144, 145, 147, 148, 149, 150, 151, 152, 154, 155, 157], "nowadai": [8, 65, 154], "np": [0, 3, 5, 6, 9, 17, 18, 26, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 49, 50, 51, 66, 70, 71, 72, 74, 77, 78, 79, 80, 81, 82, 83, 84, 89, 93, 94, 95, 96, 97, 103, 107, 124, 127, 128, 130, 131, 133, 134, 135, 136, 137, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 157, 160, 162, 163], "np_random_numb": 131, "npl": 52, "nprop": [51, 97], "npropos": 145, "npy": [74, 94], "nrow": [3, 26, 31, 34, 40, 79, 82, 83, 89, 94, 96, 131, 135, 153, 154, 162], "nsampl": [18, 78, 80, 84, 95, 163], "nstep": [6, 39, 42, 51, 97, 124, 144, 148, 153], "nswap": [51, 97], "nswap_accept": [51, 97], "nt": 51, "ntemp": [51, 97], "ntemper": 51, "ntemps_hi": [51, 97], "ntemps_lo": [51, 97], "ntest": 70, "nthin": [51, 97], "nthread": [51, 97], "ntk": 118, "nu": [18, 30, 45, 82, 86, 127, 131], "nu1": 18, "nu2": 18, "nu3": 18, "nuclear": [1, 45, 47, 48, 49, 80, 92, 93, 127, 155], "nucleartal": [138, 141], "nuclei": [48, 80, 134], "nucleon": [1, 46, 127, 134], "nucleu": [48, 80, 134, 155], "nugget": [79, 80, 83, 87], "nuisanc": [7, 18, 24, 26, 37, 97, 147, 160], "null": [11, 20, 54, 134], "num": [30, 42, 81, 82, 89, 133, 136, 154, 162], "num_bin": [18, 127, 152], "num_burn": 124, "num_coin_toss": 31, "num_col": [70, 77], "num_cor": 124, "num_data": 96, "num_data_per_class": 66, "num_draw": 34, "num_imag": [70, 77], "num_it": 144, "num_mean": 66, "num_model_param": 124, "num_param": 124, "num_plot": 96, "num_pt": [18, 43], "num_row": [34, 70, 77], "num_run": 162, "num_sampl": [18, 43, 79, 83, 150, 152, 154], "num_step": [124, 146, 163], "num_t": [133, 150], "num_t_pt": 151, "num_t_w": 133, "num_walker_per_dim": 124, "num_x_pt": 50, "number": [4, 6, 7, 8, 9, 11, 16, 19, 20, 24, 26, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 82, 83, 84, 87, 89, 91, 92, 94, 95, 96, 97, 98, 100, 101, 103, 106, 107, 108, 111, 118, 124, 125, 126, 127, 128, 130, 133, 134, 135, 136, 137, 138, 143, 144, 145, 146, 148, 149, 152, 153, 154, 157, 160, 162, 163], "numer": [0, 8, 16, 17, 30, 35, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 54, 66, 68, 73, 78, 80, 84, 86, 87, 91, 95, 96, 97, 102, 106, 107, 126, 128, 131, 134, 144, 145, 157], "numpeak": [91, 97], "numpi": [0, 3, 5, 6, 9, 17, 18, 26, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 50, 51, 66, 70, 71, 72, 74, 77, 78, 79, 81, 82, 83, 84, 89, 93, 94, 96, 97, 103, 124, 127, 128, 130, 131, 133, 134, 138, 139, 144, 145, 146, 148, 150, 151, 152, 153, 154, 157, 162, 163], "numpt": 131, "numref": 0, "nut": [45, 74, 149, 152, 153, 155], "nwalker": [6, 39, 42, 51, 97, 124, 144, 147, 148, 153], "nwarmup": [39, 42, 51, 144], "nwe": 97, "nx": 50, "nx_iy_i": 128, "nz": 134, "o": [1, 3, 20, 35, 39, 41, 42, 50, 68, 70, 78, 79, 83, 96, 103, 118, 120, 124, 127, 131, 134, 144, 145, 146, 152, 157, 162, 163], "o1": 151, "ob": [7, 26, 31, 35, 152], "obei": [8, 13], "object": [6, 8, 9, 16, 18, 24, 31, 39, 44, 49, 51, 54, 72, 73, 74, 78, 79, 84, 93, 94, 97, 105, 106, 121, 127, 131, 133, 134, 135, 136, 137, 139, 150], "oblig": 54, "observ": [0, 1, 3, 4, 7, 9, 10, 11, 12, 16, 17, 20, 24, 26, 31, 32, 35, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 54, 59, 61, 62, 63, 64, 65, 66, 67, 68, 72, 74, 76, 78, 81, 82, 84, 86, 87, 93, 94, 97, 101, 106, 111, 112, 116, 118, 120, 121, 122, 125, 127, 128, 131, 143, 145, 146, 147, 148, 152, 153, 155, 157, 159, 162, 163], "observed_data": 152, "obtain": [4, 7, 8, 9, 14, 16, 17, 24, 26, 31, 35, 37, 42, 44, 45, 46, 48, 49, 59, 60, 64, 66, 67, 68, 69, 72, 73, 77, 78, 83, 84, 87, 89, 93, 98, 101, 121, 122, 126, 131, 145, 146, 147, 151, 152, 154, 155, 162, 163, 164], "obviou": [16, 20, 35, 66, 157], "obvious": [4, 8, 16, 17, 26, 34, 35, 46, 67, 73, 74, 86, 89, 95], "occam": [52, 53, 54], "occasion": [57, 138, 157], "occupi": [4, 149], "occur": [8, 23, 26, 57, 64, 66, 89, 131, 134, 157], "occurr": 8, "ockham": [7, 54, 91], "oct": [79, 152], "octob": 1, "od": [149, 150, 151], "odd": [25, 26, 35, 54, 89, 134], "odds_ratio": 96, "odeint": 124, "odot": [46, 67, 73], "ofeffect": 92, "off": [7, 9, 18, 34, 37, 43, 49, 50, 52, 53, 54, 74, 93, 94, 128, 131, 134, 149, 152, 162], "offenc": 64, "offend": 64, "offer": [7, 17, 42, 45, 47, 72, 114, 118, 135, 137, 152], "offici": 152, "offlin": [46, 48], "offset": [39, 42, 52, 54, 124, 134, 144], "often": [3, 4, 7, 13, 15, 16, 17, 19, 20, 24, 30, 35, 39, 40, 41, 42, 44, 45, 46, 47, 48, 54, 56, 59, 61, 63, 64, 65, 66, 67, 68, 69, 72, 74, 86, 87, 89, 96, 98, 101, 103, 105, 106, 107, 111, 112, 120, 123, 125, 127, 131, 135, 136, 137, 144, 145, 147, 148, 153, 154, 155, 160, 162], "ohio": [22, 57], "oin": 9, "ok": [0, 23, 38, 43, 97, 128, 135, 152, 155, 160], "okai": 20, "ol": [35, 66, 67, 103, 160], "old": 154, "older": [39, 135], "oliv": 57, "ols_cov": [35, 66, 103], "ols_d": [35, 103], "ols_ep": [35, 103], "ols_s2": [35, 103], "ols_theta": [35, 66, 103], "ols_xtd": [35, 66, 103], "olymp": 78, "olympic_marathon_men": 78, "olympicmarathontim": 78, "omega": [16, 20, 34, 35, 133, 154], "omega_0": 150, "omega_i": 45, "omega_j": 45, "omega_pt": 34, "omega_w": 133, "omit": [16, 23, 25, 50, 54, 57, 74, 86, 118, 145], "on_click": 9, "onc": [4, 8, 9, 12, 15, 16, 23, 26, 31, 37, 38, 39, 41, 43, 44, 48, 49, 54, 60, 67, 68, 74, 86, 98, 135, 138, 154, 155, 162], "one": [0, 4, 5, 7, 8, 9, 11, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 30, 32, 33, 35, 37, 38, 39, 40, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 76, 77, 78, 79, 80, 81, 83, 84, 87, 89, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 105, 107, 108, 111, 112, 116, 118, 120, 121, 122, 126, 127, 128, 130, 131, 134, 135, 136, 137, 138, 144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 155, 157, 159, 160, 162, 163, 164], "oned_arr": 137, "ones": [5, 20, 35, 38, 39, 44, 51, 54, 63, 66, 67, 68, 71, 74, 94, 96, 97, 103, 106, 118, 131, 134, 137, 154, 162], "ones_lik": [6, 39, 41, 97, 134, 137, 144], "onevariablenet": 72, "ongo": 8, "onli": [0, 4, 7, 8, 11, 15, 16, 17, 18, 19, 20, 24, 25, 26, 30, 32, 35, 37, 38, 39, 41, 42, 44, 45, 48, 49, 50, 51, 52, 53, 54, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 73, 74, 76, 77, 80, 81, 82, 83, 86, 87, 89, 97, 98, 101, 103, 105, 106, 108, 116, 120, 122, 124, 128, 130, 131, 134, 136, 137, 144, 145, 147, 149, 152, 154, 157], "onlin": [1, 48, 65, 71, 72, 78, 84, 86, 135, 136, 152], "onto": [17, 46, 128, 154, 160], "onu": 54, "op": 127, "opac": 45, "open": [8, 16, 26, 44, 62, 65, 74, 123, 134, 135], "openli": 65, "oper": [7, 8, 26, 35, 45, 48, 63, 64, 65, 67, 68, 74, 76, 78, 80, 84, 100, 102, 134, 135, 139, 145], "operation": 67, "operatornam": [67, 86, 105], "opinion": [64, 160], "opportun": [45, 48, 54, 59, 65], "oppos": [20, 52, 117, 135], "opposit": [4, 8, 20, 38, 69, 98, 106], "opt_r": 82, "optic": 47, "optim": [1, 4, 5, 16, 35, 37, 39, 41, 42, 48, 52, 54, 66, 67, 68, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 83, 84, 86, 92, 94, 96, 100, 101, 107, 111, 117, 118, 120, 124, 128, 160, 164], "optima": 93, "optimis": [78, 84], "optimum": [17, 35, 42, 68, 78, 83, 93, 101, 110], "option": [9, 11, 26, 35, 39, 41, 48, 51, 53, 57, 68, 71, 72, 91, 95, 96, 97, 124, 132, 137, 138, 151, 152, 157, 159], "optpar": [45, 105, 110], "optpara": 45, "optpars_i": 45, "optparslr": 35, "opvi": 74, "oracl": 49, "orang": 81, "orbit": 111, "orbit_gam": 151, "order": [5, 7, 20, 35, 42, 44, 45, 47, 48, 50, 53, 54, 57, 59, 63, 67, 68, 69, 72, 73, 74, 80, 89, 95, 97, 98, 101, 102, 103, 116, 134, 135, 138, 149, 151, 157, 162], "ordinari": [48, 52, 54, 66, 67, 76, 89, 97, 149, 151], "ordinarili": 128, "org": [1, 18, 41, 51, 70, 71, 77, 82, 94, 97, 105, 131, 149, 155], "organ": [9, 64, 68, 133, 137, 162], "orient": [37, 51, 54, 64, 133, 144], "origin": [4, 16, 27, 34, 39, 43, 44, 45, 47, 48, 49, 51, 52, 54, 57, 64, 66, 67, 73, 74, 76, 78, 80, 89, 92, 94, 97, 128, 137, 144, 145, 152, 154, 164], "orthogon": [23, 46, 48, 54, 126, 128, 147], "orthonorm": [23, 32, 33, 48, 126], "oscil": [48, 52], "oslo": 57, "osu": [0, 79, 133, 138, 150, 152], "osx": 138, "other": [1, 4, 7, 8, 9, 10, 12, 13, 16, 17, 18, 19, 20, 22, 24, 26, 28, 31, 32, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 57, 64, 65, 66, 67, 68, 69, 70, 72, 74, 76, 78, 79, 80, 83, 84, 87, 89, 93, 94, 95, 98, 101, 103, 106, 107, 111, 114, 118, 126, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 157, 159, 161, 162, 163], "otherwis": [7, 8, 17, 26, 31, 39, 42, 43, 45, 48, 54, 72, 82, 87, 89, 93, 96, 120, 131, 135, 146, 154, 157, 163], "ouput": 69, "our": [0, 4, 7, 8, 9, 10, 11, 13, 16, 17, 18, 20, 22, 23, 24, 26, 28, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 72, 74, 77, 78, 79, 80, 81, 83, 84, 86, 87, 89, 90, 94, 95, 96, 97, 98, 100, 101, 102, 103, 111, 114, 120, 122, 124, 128, 131, 137, 139, 144, 145, 146, 147, 148, 149, 151, 152, 153, 155, 157, 160, 162, 163], "ourselv": [47, 67, 68, 83, 105, 111, 131, 134, 154], "out": [1, 4, 5, 9, 13, 16, 17, 18, 20, 24, 30, 31, 32, 33, 34, 35, 38, 39, 40, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 60, 61, 62, 63, 64, 67, 69, 72, 73, 74, 77, 78, 84, 87, 89, 94, 95, 96, 101, 102, 116, 122, 124, 128, 133, 134, 135, 137, 138, 143, 145, 146, 147, 148, 149, 150, 152, 153, 154, 155, 162, 163], "out_featur": 72, "outcom": [8, 9, 11, 23, 24, 26, 31, 32, 44, 47, 54, 64, 89, 90, 111, 124, 131, 137, 154, 157, 159, 162], "outer": [0, 69], "outfil": 127, "outlier": [42, 56, 155], "outlin": [39, 42, 49, 108, 145, 154], "outperform": 48, "output": [0, 5, 9, 35, 42, 44, 46, 47, 48, 49, 59, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 86, 89, 90, 94, 97, 100, 102, 103, 110, 111, 118, 121, 131, 134, 135, 136, 137, 162], "output_": [66, 114], "output_1": 114, "output_2": 114, "output_i": [66, 67, 114], "outputlayer1": 68, "outputs_i": [65, 107], "outsid": [3, 20, 47, 54, 83, 96, 136, 145, 164], "outward": 20, "over": [0, 4, 16, 17, 18, 19, 20, 23, 24, 32, 35, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 56, 57, 64, 65, 66, 69, 72, 73, 74, 77, 78, 79, 83, 84, 86, 87, 89, 90, 94, 96, 97, 107, 118, 121, 125, 126, 127, 128, 131, 134, 136, 138, 143, 144, 145, 147, 148, 153, 154, 155, 162, 164], "overal": [9, 13, 32, 34, 38, 48, 49, 64, 74, 95, 97, 121, 133], "overall_titl": [38, 150, 151], "overarch": [65, 73], "overbrac": [9, 10, 24, 31], "overcom": 68, "overconfid": 122, "overestim": [67, 144], "overfit": [16, 30, 65, 66, 67, 68, 70, 72, 73, 74, 76, 95, 96, 98, 114], "overflow": 135, "overhead": 69, "overlai": 18, "overlaid": 130, "overlap": [17, 23, 45, 64, 67, 71, 77, 145, 160], "overli": [16, 39, 61], "overlin": [32, 43, 95, 144, 147, 155], "overlook": 64, "overrepres": 64, "overset": [13, 15, 20, 33, 87, 143], "overshoot": 107, "oversight": 64, "overview": [9, 16, 28, 29, 46, 57, 76, 90, 133, 138], "overview_text": [9, 133], "overweight": 64, "overwhelm": 54, "ow": 65, "own": [0, 4, 11, 23, 34, 38, 44, 57, 64, 65, 67, 70, 95, 128, 132, 134, 135, 140, 144, 162, 163], "oxford": [1, 57], "o\u02bchagan": 120, "p": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 24, 25, 26, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 64, 66, 67, 68, 71, 73, 74, 78, 79, 80, 83, 84, 86, 87, 89, 94, 96, 97, 100, 101, 103, 105, 114, 118, 126, 127, 128, 131, 133, 134, 143, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 157, 159, 162, 163, 164], "p0": [51, 97, 144, 147], "p1": [41, 42, 150], "p2": 41, "p2cread": 127, "p2cwrite": 127, "p_": [15, 17, 20, 49, 52, 73, 89, 131, 150, 157, 162], "p_0": 150, "p_1": [4, 15, 16], "p_2": [4, 15], "p_3": 4, "p_4": 4, "p_accept": 145, "p_current": 145, "p_h": [9, 11, 12, 13, 15, 20, 26, 31], "p_i": [3, 4, 16, 45, 149], "p_j": 4, "p_n": 15, "p_phi": 150, "p_phi_0": 150, "p_phi_now": 150, "p_phi_vs_time_label": 150, "p_propos": 145, "p_star": 96, "p_x": [26, 54, 131], "p_y": [54, 68], "p_z": [17, 68], "pa": 17, "pace": [78, 160], "pacif": 1, "pack": 134, "packag": [18, 24, 39, 42, 44, 51, 65, 74, 78, 82, 84, 94, 97, 124, 127, 131, 134, 135, 138, 147, 148, 153, 154], "pad": [71, 79, 96, 151], "page": [0, 1, 18, 24, 42, 57, 71, 78, 84, 85, 88, 95, 131, 134, 135, 138, 143, 147, 149, 154, 155], "pai": [23, 64, 68, 73], "painfulli": [106, 136], "painstak": 65, "pair": [35, 41, 44, 48, 49, 52, 79, 83, 96, 100, 128, 134, 136, 144, 147], "pairplot": 162, "palett": 135, "panda": [35, 103, 135, 144], "panel": [17, 26, 38, 42, 44, 57, 66, 73, 96, 98, 122, 131, 134, 145, 148, 153, 157, 162], "pankaj": 1, "papanicola": 5, "paper": [1, 35, 44, 45, 47, 50, 52, 62, 73, 87, 95, 96, 102, 127, 144], "par": [7, 16, 35, 37, 45, 46, 47, 48, 54, 65, 67, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 113, 114, 115, 118, 119, 121, 154], "para": [35, 44, 45, 131, 154], "para_": [67, 101, 108], "para_0": [100, 101, 102, 113, 115, 116], "para_1": [45, 48, 101, 102, 113, 115, 116, 154], "para_1f_1": [35, 101], "para_2": [45, 48, 101, 113, 115, 116, 154], "para_2f_2": 101, "para_3": 48, "para_i": [45, 46, 48, 108, 154], "para_j": [100, 101], "para_n": 48, "paradigm": [8, 16, 39, 44, 48, 65, 96, 120], "paradox": 129, "parallel": [22, 37, 51, 54, 57, 74, 91, 94, 118, 124, 149, 164], "paralr": 35, "paralr_": 35, "paralr_0": 35, "paralr_1": 35, "paralr_1f_1": 35, "paralr_2": 35, "paralr_2f_2": 35, "paralr_i": 35, "paralr_j": 35, "param": [35, 51, 70, 77, 83, 97, 103, 107, 124, 144], "param_bound": 124, "param_max": 124, "param_min": 124, "param_resc": 124, "paramet": [1, 3, 4, 6, 8, 9, 10, 11, 13, 18, 19, 20, 21, 24, 25, 26, 28, 30, 31, 35, 37, 38, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 57, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 86, 87, 91, 92, 93, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 131, 132, 133, 134, 135, 137, 144, 145, 146, 147, 149, 150, 151, 152, 154, 155, 159, 160, 162, 163, 164], "parameter": [47, 73, 79, 83, 86, 118, 147], "parameter_estim": 164, "parameter_estimation_fitting_straight_line_i": [39, 42, 144], "parameter_estimation_fitting_straight_line_ii": 144, "parameter_estimation_gaussian_nois": 143, "parameter_estimation_gaussian_noise_compare_sampl": 164, "parameters_text": 133, "parametr": [8, 29, 45, 46, 48, 73, 74, 78, 79, 80, 83, 87, 117, 123, 134], "params_gradi": 107, "params_mod": 51, "params_rbf": 83, "paranmet": 107, "paraphras": 118, "parenthes": 126, "pars_": [46, 106, 108], "pars_0": 106, "pars_1": 48, "pars_2": 48, "pars_i": [7, 45, 46, 48, 154], "pars_j": [45, 48], "pars_n": [48, 106, 107, 108], "parsec": [17, 18], "parslr": 35, "parslr_1": 35, "parslr_2": 35, "part": [0, 16, 24, 28, 32, 33, 34, 35, 37, 42, 44, 46, 52, 57, 59, 60, 61, 63, 64, 65, 66, 72, 73, 74, 76, 78, 87, 91, 92, 95, 96, 101, 111, 112, 114, 125, 128, 134, 137, 143, 144, 149, 155, 157, 160], "parti": 22, "partial": [1, 3, 4, 17, 30, 35, 37, 40, 45, 54, 69, 89, 96, 98, 101, 106, 108, 126, 128, 148, 149, 150, 153], "particl": [0, 1, 18, 20, 22, 24, 118, 124, 127, 134, 149, 157, 162], "particulali": 57, "particular": [0, 3, 4, 7, 8, 9, 16, 23, 25, 26, 30, 31, 32, 35, 39, 40, 42, 43, 45, 47, 48, 49, 51, 52, 53, 54, 57, 60, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 76, 78, 84, 86, 87, 89, 93, 95, 96, 98, 101, 105, 106, 111, 114, 117, 118, 121, 122, 123, 127, 131, 133, 134, 139, 146, 148, 153, 154, 155, 163], "particularli": [24, 25, 28, 39, 44, 52, 57, 63, 67, 72, 76, 120, 131, 135, 154, 155, 162], "partit": [5, 35, 86, 87, 131, 160], "partli": [44, 48, 54, 79, 83], "pass": [18, 24, 51, 68, 69, 72, 73, 76, 77, 79, 89, 97, 111, 118, 124, 127, 128, 130, 134, 135, 137, 147, 150, 152, 154, 157, 162], "pass_fd": 127, "passeng": 65, "past": [8, 9, 16, 18, 22, 25, 47, 54, 108, 136, 143, 157], "patent": 154, "path": [1, 49, 63, 71, 78, 84, 87, 124, 131, 134, 149, 157, 162], "patient": [57, 64, 89, 138], "pattern": [1, 16, 50, 52, 63, 65, 68, 72, 77, 90, 157], "pauciora": 54, "pauli": 134, "paus": 20, "pb": 1, "pc": 135, "pca": [80, 125], "pcg64": 131, "pcolor": 41, "pct": [38, 41, 42], "pd": [35, 103, 134, 144], "pd_d": [35, 103], "pd_design_matrix": [35, 103], "pd_m": [35, 103], "pd_m_ol": [35, 103], "pd_r": [35, 103], "pd_x": [35, 103], "pd_xmeasur": [35, 103], "pd_xrealiti": [35, 103], "pdf": [0, 1, 3, 7, 9, 10, 11, 12, 13, 16, 20, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 43, 45, 47, 50, 54, 56, 73, 75, 79, 83, 86, 87, 93, 97, 124, 127, 148, 149, 152, 153, 155, 157, 159, 160, 161, 162], "pdf_1": [0, 17], "pdf_2": [0, 17], "pdf_2_grid": [0, 17], "pdf_3": [0, 17], "pdf_3_grid": [0, 17], "pdf_4": [0, 17], "pdfy": 131, "peacock": 164, "peak": [9, 12, 17, 20, 34, 35, 37, 38, 40, 42, 50, 51, 52, 53, 54, 68, 91, 92, 96, 97, 131, 147, 148, 149, 153], "pen": [0, 24, 35, 102], "penal": 54, "penalti": [52, 53, 54, 67, 71], "pendleton": 1, "pendulum": 52, "peopl": [0, 4, 20, 23, 32, 54, 57, 63, 64, 65, 78, 99, 144, 152, 154], "per": [30, 42, 48, 54, 59, 68, 72, 78, 81, 96, 124, 127, 130, 134, 143, 150, 162], "perceiv": [64, 65], "percent": [18, 26, 50, 131], "percentag": [19, 20, 77, 127, 128, 149, 152], "percentil": [39, 95, 97], "perceptron": [68, 72, 74, 94], "peregrin": 134, "perfect": [35, 41, 42, 45, 49, 60, 66, 80, 87, 134, 144], "perfectli": [40, 45, 144, 148, 152, 153], "perfom": [66, 68], "perform": [4, 7, 8, 16, 17, 26, 31, 32, 35, 39, 42, 44, 45, 46, 47, 48, 49, 51, 52, 54, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 89, 93, 96, 98, 101, 103, 106, 107, 111, 112, 113, 120, 122, 126, 128, 131, 134, 135, 136, 137, 143, 144, 145, 147, 148, 153, 154, 157, 164], "perhap": [41, 63, 65], "perimet": 129, "period": [6, 35, 39, 45, 54, 78, 82, 84, 124, 146, 148, 153, 157, 163], "periodic_matern32": 78, "periodicexponenti": [78, 84], "periodicity_bound": 82, "perivolaropoulo": 52, "perm": [79, 83], "permeat": 73, "permiss": [45, 77, 122], "permit": [7, 44, 48, 54, 67], "permut": [79, 83, 89, 105], "persist": [44, 120], "person": [8, 9, 23, 31, 44, 64, 131], "perspect": [1, 8, 35, 48, 58, 60, 61, 62, 63, 78, 84, 87, 89, 90, 100, 111, 114], "persuad": 5, "pertain": [26, 31], "pertin": 69, "perturb": [59, 118], "pervers": 20, "pessimist": 39, "peter": 128, "petrov": 48, "petunin": 47, "pf": [17, 157], "ph": [26, 31], "phase": [44, 46, 48, 51, 52, 53, 68, 72, 97, 133, 149, 150], "phase_space_label": 150, "phd": 57, "phenomena": [7, 52, 123], "phenomenolog": [35, 49, 100], "phenomenon": [7, 41, 63, 111], "phi": [17, 52, 121, 124, 133, 150, 151, 154, 160], "phi_": [86, 151], "phi_0": [150, 151], "phi_and_p_high": 150, "phi_and_p_low": 150, "phi_i": 151, "phi_now": 150, "phi_pt": 151, "phi_pts_eul": 151, "phi_pts_lf": 151, "phi_vs_time_label": 150, "phi_w": 133, "phil": [1, 57], "phillip": [5, 57, 152], "philosoph": [7, 20, 21, 26, 40, 148, 153], "philosophi": [8, 40, 129, 148, 153], "phivec": [155, 160], "photon": 61, "phrase": 46, "phtrue": 31, "phy": [1, 5, 45, 50, 79, 83, 87], "physic": [0, 1, 4, 16, 17, 18, 20, 24, 35, 44, 47, 48, 49, 51, 52, 54, 57, 58, 60, 65, 66, 68, 73, 80, 89, 93, 95, 101, 103, 112, 118, 120, 122, 123, 127, 128, 129, 131, 134, 146, 154, 155, 160, 162, 163], "physicist": [1, 8, 18, 24, 28, 30, 54, 57, 58, 60, 61, 63, 68, 118, 127], "physrep": 1, "physrevc": 1, "physrevlett": 1, "pi": [4, 17, 20, 25, 34, 35, 38, 39, 40, 41, 42, 43, 45, 50, 51, 53, 54, 68, 71, 73, 78, 79, 84, 87, 93, 95, 96, 97, 103, 115, 124, 130, 131, 133, 135, 136, 144, 145, 147, 148, 151, 153, 157], "pi_": 157, "pi_1": 157, "pi_2": 157, "pi_3": 157, "pi_i": [154, 157], "pi_j": 157, "pi_jt_": 157, "pi_n": 157, "pick": [13, 16, 20, 30, 52, 54, 66, 94, 127, 135, 150], "pictur": [39, 41, 42, 74, 118, 128, 144], "piec": [9, 20, 30, 40, 48, 111, 148, 149, 153], "pierr": [8, 35], "pillar": 74, "pioneer": [0, 8, 24], "pipe": 127, "pipelin": 65, "pipenv": 138, "pipes": 127, "pippin": 134, "pitt": 68, "pivot": 8, "pixel": [70, 76, 77, 118], "place": [8, 16, 20, 23, 33, 40, 43, 44, 49, 52, 61, 63, 68, 72, 74, 76, 80, 97, 134, 135, 143, 144, 145, 148, 152, 153, 154, 162], "plai": [5, 9, 11, 18, 24, 28, 31, 35, 37, 53, 54, 65, 67, 68, 74, 87, 103, 128, 133], "plain": [69, 73], "plan": [20, 62, 97, 155], "plane": [20, 66, 75], "planetari": 16, "plate": 52, "plateau": [67, 98, 124], "platform": [45, 64], "plato": 157, "platon": 63, "plausibl": [1, 43, 62, 73, 124], "player": [16, 162], "pleas": [31, 50, 71, 96, 152], "plenti": [68, 147], "plethora": 68, "plot": [0, 3, 6, 7, 9, 11, 17, 20, 26, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 44, 50, 51, 52, 54, 66, 67, 70, 71, 72, 73, 74, 75, 77, 78, 80, 81, 82, 84, 87, 89, 93, 94, 95, 96, 97, 98, 103, 118, 128, 130, 131, 133, 134, 139, 143, 145, 146, 147, 148, 150, 153, 154, 157, 160, 162, 163, 164], "plot_autocorr": 152, "plot_conditional_distribut": 157, "plot_contour": 83, "plot_data": [35, 103], "plot_decision_boundari": 71, "plot_dens": 79, "plot_estim": 131, "plot_forest": 152, "plot_gaussian_contour": [79, 83], "plot_gpr_sampl": 82, "plot_hist": 18, "plot_imag": [70, 77], "plot_it": 135, "plot_limit": [78, 84], "plot_lin": 5, "plot_mcmc_model": 42, "plot_mcmc_trac": 42, "plot_num": 150, "plot_out": [9, 133], "plot_pair": 153, "plot_posterior": 152, "plot_process": [157, 162], "plot_propos": 145, "plot_result": 41, "plot_sample_dimens": [79, 83], "plot_sample_result": 34, "plot_sine_map": 136, "plot_start": [150, 151], "plot_stop": [150, 151], "plot_surfac": [38, 66, 131], "plot_titl": [41, 79, 144, 146, 163], "plot_trac": [152, 153], "plot_value_arrai": [70, 77], "plot_y_vs_x": 150, "plt": [0, 3, 5, 6, 9, 17, 18, 26, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 50, 51, 66, 70, 71, 72, 74, 77, 78, 79, 81, 82, 83, 84, 89, 93, 94, 96, 97, 103, 124, 127, 128, 130, 131, 133, 134, 135, 136, 144, 145, 146, 148, 150, 151, 152, 153, 154, 157, 162, 163], "plu": [20, 27, 35, 38, 53, 57, 67, 68, 73, 91, 94, 95, 97, 128, 131, 138, 149, 157, 158, 161], "plug": [32, 41, 145], "plumle": 57, "plura": 54, "pm": [4, 17, 20, 30, 35, 37, 41, 42, 54, 74, 82, 94, 152, 153, 155, 157, 159], "pm1": [73, 75], "pm2": [73, 75], "pm3": 152, "pmatrix": [35, 37, 46, 53, 54, 68, 80, 86, 87, 154, 157], "pmc": 124, "pmf": [18, 24, 25, 34], "pmm": 123, "pn": 45, "png": [0, 3, 4, 6, 26, 54, 73, 74, 98, 134, 135, 150, 151], "po": [39, 45, 51, 105, 124, 144, 153], "pocomc_sampl": 124, "pod": [48, 126], "pofm": 49, "pofm1": 49, "point": [0, 4, 6, 7, 8, 9, 11, 16, 17, 18, 20, 24, 26, 30, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 54, 62, 64, 66, 67, 70, 71, 72, 73, 74, 78, 79, 80, 81, 83, 84, 86, 87, 89, 91, 93, 95, 96, 97, 98, 102, 103, 104, 106, 108, 118, 120, 121, 122, 124, 126, 127, 128, 133, 134, 135, 137, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 155, 157, 163, 164], "point_alpha": 127, "pointer": [21, 73, 74, 94, 123], "pointestimates_fig": 131, "pointwis": [81, 108], "poisson": [20, 37, 44, 161], "poisson_plot": [34, 38], "poisson_pt": [34, 38, 146, 163], "poissonpropos": 152, "pol54a": [1, 63], "pol54b": [1, 63], "polar": 151, "poldeg": [35, 103], "polic": 15, "polit": 49, "polya": [1, 62], "polyfit": 96, "polym": 68, "polyni": 96, "polynomi": [5, 67, 80, 87, 89, 98, 102, 103], "polyv": [35, 96, 103], "pool": [51, 74, 76, 97, 124], "poor": [18, 20, 30, 35, 48, 54, 64, 67, 97, 118], "poorli": [44, 49, 67], "popen": 127, "popper": 63, "popul": [32, 33, 40, 64, 66, 74, 90, 131, 148, 153, 162], "popular": [48, 64, 65, 68, 96, 98, 106, 122, 131, 134, 135], "pos1": 66, "pos2": 66, "pos_": 45, "pos_i": 45, "pose": 64, "posit": [4, 6, 8, 17, 20, 26, 32, 35, 38, 39, 40, 42, 43, 45, 51, 52, 54, 62, 63, 64, 65, 66, 67, 72, 73, 78, 79, 83, 84, 86, 87, 89, 91, 97, 98, 101, 106, 108, 124, 126, 128, 131, 139, 143, 144, 145, 147, 148, 149, 153, 154, 157, 160, 162], "possibl": [4, 7, 8, 9, 13, 17, 20, 26, 32, 33, 35, 39, 41, 44, 45, 46, 47, 49, 50, 54, 57, 60, 62, 63, 65, 66, 67, 68, 69, 76, 78, 84, 89, 95, 96, 100, 104, 112, 115, 118, 121, 124, 126, 131, 137, 145, 148, 153, 154, 155, 157, 160, 162], "possibli": [35, 41, 42, 47, 49, 65, 66, 68, 72, 73, 89, 103, 105, 135, 145, 147, 162], "post": [39, 73, 74, 94, 108, 145, 153], "postdoc": 57, "postenti": 149, "posterior": [1, 9, 10, 12, 15, 17, 19, 20, 21, 24, 25, 26, 28, 30, 31, 38, 39, 40, 41, 42, 45, 47, 49, 50, 52, 53, 54, 60, 61, 73, 74, 75, 78, 80, 83, 84, 86, 87, 88, 91, 93, 94, 95, 96, 97, 121, 122, 143, 145, 146, 147, 148, 149, 152, 153, 154, 155, 159, 163], "posterior1": 35, "posterior_calc": 43, "posterior_func": 145, "posterior_funct": 145, "posterior_pt": 43, "posteriorbma": 49, "posteriori": [35, 73, 152], "postiv": 64, "postul": 16, "potenti": [44, 45, 46, 48, 49, 52, 62, 64, 65, 67, 68, 72, 83, 105, 120, 138, 144, 149, 152], "potest": 54, "pott": 68, "pound": 135, "pow": 72, "powel": 124, "power": [7, 26, 34, 35, 47, 56, 57, 61, 64, 66, 67, 68, 72, 74, 77, 112, 118, 122, 124, 126, 131, 135, 137], "pp": [131, 157, 162], "ppc": [74, 94], "ppd": [16, 35], "ppd_definition_b": 0, "ppf": 131, "pr": [18, 24, 31, 41, 42, 43, 45, 50, 96, 124, 152], "practic": [9, 15, 17, 28, 36, 38, 40, 41, 44, 45, 47, 49, 52, 54, 59, 60, 62, 63, 64, 67, 72, 86, 87, 89, 95, 101, 120, 126, 128, 146, 148, 149, 152, 153, 155, 157, 158, 160, 161, 162, 163], "practition": [60, 68, 89], "pradeep": 87, "pragmat": 114, "pratola": 57, "pre": [0, 44, 45, 46, 70, 74, 118], "preactiv": 118, "preced": [54, 68], "preceed": 135, "precent": 26, "precipic": 152, "precipit": 157, "precis": [5, 30, 35, 40, 41, 42, 44, 46, 47, 49, 52, 54, 64, 67, 68, 79, 80, 81, 83, 95, 97, 106, 112, 114, 126, 127, 128, 134, 148, 150, 151, 153, 154, 155, 159, 162], "preconceiv": [9, 31], "precondit": 124, "pred": [74, 94], "pred_func": 71, "predefin": [72, 135], "predetermin": [97, 154], "predic": 144, "predict": [1, 4, 7, 21, 25, 26, 30, 45, 46, 47, 49, 52, 54, 59, 61, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 93, 95, 103, 106, 111, 112, 120, 121, 122, 124, 128, 134, 146, 147, 154, 157, 159, 163], "predict_quantil": [78, 84], "predicted_label": [70, 77], "predicti": 45, "predictions_arrai": [70, 77], "predictor": [35, 65, 66, 86, 89, 102, 103, 110, 111, 134], "predispos": 64, "predominantli": 135, "preexec_fn": 127, "prefer": [3, 4, 35, 44, 54, 64, 66, 67, 72, 93, 136, 152], "preferenti": 54, "prejudic": 64, "preliminari": 32, "premis": [0, 7], "prepar": [26, 54, 70, 72, 127, 134, 138], "prepend": 89, "preprint": 95, "preprocess": [70, 74, 82, 94, 124], "prescrib": 34, "prescript": 151, "presenc": [8, 23, 39, 64], "present": [0, 8, 16, 23, 26, 35, 44, 49, 50, 54, 59, 63, 65, 66, 68, 74, 82, 93, 95, 102, 104, 108, 124, 127, 134, 135, 136, 157, 162], "preserv": [45, 52, 149], "presid": 26, "presidenti": 26, "press": [1, 9, 11, 57, 65, 135], "pressur": 4, "presum": [49, 72], "presumpt": 49, "pretti": [34, 63, 74, 134, 138, 162], "prettypleas": [131, 157, 162], "preval": 89, "prevent": [64, 65, 70, 72, 73, 78, 127, 154], "preview": 135, "previou": [9, 16, 24, 31, 35, 38, 39, 40, 41, 42, 44, 45, 57, 61, 68, 69, 72, 76, 78, 93, 96, 103, 107, 112, 118, 125, 128, 135, 144, 145, 146, 148, 152, 153, 155, 157, 161, 163], "previous": [7, 17, 49, 50, 72, 73, 78, 84], "prf": 0, "price": 73, "primari": [89, 95], "primarili": [68, 74], "prime": [41, 78, 84], "primer": [1, 44], "primit": 26, "princeton": 1, "princip": [37, 48, 54, 90, 125], "principl": [1, 7, 8, 17, 21, 29, 35, 39, 40, 41, 44, 45, 48, 49, 54, 58, 60, 62, 63, 68, 74, 81, 89, 98, 105, 118, 125, 126, 134, 148, 153], "print": [1, 5, 6, 9, 18, 31, 34, 35, 38, 39, 40, 41, 42, 43, 50, 51, 66, 70, 71, 72, 74, 75, 77, 78, 79, 82, 83, 84, 94, 96, 97, 103, 124, 127, 128, 130, 131, 134, 135, 136, 137, 139, 144, 145, 146, 148, 150, 151, 152, 153, 154, 162, 163], "print_frequentist_estim": [9, 31], "print_funct": 77, "print_likely_fair_prior_measur": [9, 31], "print_likely_unfair_prior_measur": [9, 31], "print_uniform_prior_measur": [9, 31], "printopt": [41, 42, 79, 83, 97], "prior": [0, 2, 3, 7, 8, 9, 10, 11, 15, 16, 17, 20, 24, 26, 30, 31, 37, 38, 39, 42, 43, 45, 47, 48, 49, 52, 53, 56, 59, 60, 61, 65, 73, 74, 75, 78, 79, 83, 84, 86, 87, 88, 94, 95, 96, 97, 118, 120, 121, 122, 127, 143, 144, 152, 159], "prior_func": 124, "prior_rang": 96, "priori": [48, 49, 54, 61, 87, 152], "priorit": [120, 122], "prioriti": [61, 65], "priors_text": 9, "priors_text_w": 9, "priorsamplesslop": 3, "privaci": 64, "privat": [64, 68, 129], "privileg": [23, 138], "prize": 68, "prng": 131, "pro": 64, "prob": [0, 8, 16, 18, 23, 24, 26, 32, 33, 39, 42, 47, 51, 66, 70, 89, 124, 131, 144, 145, 153, 157], "prob_": 157, "prob_head": 9, "prob_heads_w": 9, "probab": 35, "probabilist": [16, 23, 47, 56, 59, 60, 61, 63, 65, 81, 89, 90, 94, 153, 154], "probabilit": [131, 157], "probabilitii": 27, "probabilit\u00e9": 35, "probabl": [0, 1, 5, 7, 9, 10, 11, 12, 16, 17, 19, 20, 21, 22, 25, 28, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 49, 50, 51, 52, 54, 56, 57, 59, 60, 61, 63, 65, 66, 68, 70, 73, 75, 79, 80, 83, 86, 87, 90, 91, 96, 97, 98, 102, 106, 111, 118, 121, 124, 125, 127, 144, 146, 148, 149, 152, 153, 154, 155, 157, 159, 163, 164], "problem": [4, 7, 8, 9, 11, 15, 16, 26, 29, 32, 35, 37, 39, 40, 41, 45, 46, 48, 49, 50, 52, 54, 57, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 80, 86, 89, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 105, 111, 114, 118, 123, 124, 127, 131, 135, 138, 143, 144, 147, 148, 149, 150, 155, 157, 160], "problemat": [40, 44, 49, 68, 118, 148, 153, 154, 155], "proc": 52, "proce": [20, 28, 35, 47, 54, 67, 103, 135], "procedur": [7, 8, 15, 17, 39, 42, 45, 47, 48, 62, 64, 66, 67, 79, 83, 87, 98, 131, 135, 145, 154, 155], "proceed": 157, "process": [1, 8, 9, 16, 26, 31, 35, 44, 45, 46, 47, 48, 49, 60, 61, 63, 64, 65, 66, 67, 68, 70, 72, 74, 77, 80, 88, 90, 93, 94, 98, 101, 102, 103, 107, 111, 112, 118, 119, 120, 121, 124, 131, 137, 154, 161], "process_group": 127, "process_new_macros_for_config_fil": 0, "prod": [148, 153], "prod_": [4, 20, 35, 38, 39, 40, 41, 42, 49, 50, 89, 144, 148, 153], "prod_i": 73, "produc": [0, 5, 9, 11, 20, 26, 35, 39, 44, 45, 49, 52, 61, 64, 68, 89, 103, 114, 128, 131, 134, 135, 137, 145, 155, 157, 162], "product": [7, 8, 13, 15, 16, 20, 24, 32, 34, 35, 36, 40, 42, 44, 45, 46, 48, 50, 53, 54, 66, 69, 76, 78, 84, 89, 101, 118, 124, 131, 138, 148, 153, 154, 155, 157], "production_step1": 74, "production_step2": 74, "prof": 96, "profici": 135, "program": [35, 63, 64, 65, 66, 68, 73, 90, 94, 106, 134, 135, 136, 137, 138, 153, 155], "programdata": 138, "programm": 65, "progress": [8, 51, 65, 69, 72, 124, 138, 153], "progress_callback": 127, "progressbar": 74, "prohibit": [123, 125], "project": [1, 38, 46, 48, 50, 64, 66, 128, 131, 135, 147, 154, 155, 164], "project_root_dir": 134, "promin": [68, 118, 129], "promis": [74, 98], "promot": [44, 135, 154], "prompt": [135, 138], "prone": [114, 136], "pronounc": [74, 94, 129], "proof": [3, 23, 32, 33, 34, 35, 63, 67, 68, 101, 145, 157], "propag": [0, 1, 3, 7, 29, 44, 65, 71, 72, 76, 86, 89, 118, 150], "proper": [17, 44, 48, 65, 72, 106, 111, 126, 135], "properli": [4, 17, 44, 64, 72, 73, 89, 97, 131, 145, 148, 152, 153], "properti": [4, 17, 18, 26, 39, 45, 48, 49, 51, 54, 67, 68, 74, 76, 78, 79, 80, 81, 83, 84, 86, 98, 121, 128, 131, 145, 151, 154, 157, 162], "proport": [4, 17, 26, 30, 35, 40, 41, 67, 73, 94, 128, 134, 144, 147, 148, 149, 153, 155, 162], "proportion": [35, 44, 54, 64, 164], "propos": [8, 26, 39, 45, 52, 93, 97, 108, 118, 144, 145, 146, 147, 149, 154, 155, 157, 162, 163], "proposal_posit": 145, "proposal_width": [145, 160], "propose_loc": 93, "proposed_posit": 145, "proposit": [8, 26, 31, 63, 111], "propsal": [145, 154], "propto": [3, 4, 13, 15, 17, 26, 35, 37, 40, 41, 42, 45, 49, 52, 73, 86, 97, 147, 148, 149, 152, 153, 154, 157, 159, 160, 164], "protect": 138, "protocol": [48, 54, 62], "proton": [35, 80, 100, 134, 155], "prototyp": [16, 65, 78, 80, 92, 97, 159], "prove": [20, 34, 38, 54, 126, 128, 157], "proven": [12, 68, 112, 154], "provid": [3, 4, 7, 8, 9, 17, 23, 25, 26, 29, 31, 35, 44, 45, 47, 48, 49, 52, 54, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 76, 78, 84, 87, 90, 92, 101, 111, 114, 120, 133, 134, 136, 137, 147, 148, 152, 153, 154, 157, 162], "provis": 62, "provoc": 16, "proxi": [9, 31, 73, 133], "psd": [78, 84], "pseudo": [93, 101, 107, 160], "pseudoconverg": 45, "psi": [0, 18, 24, 46, 48, 144], "psi_": [46, 144], "psi_1": 46, "psi_2": 46, "psi_chain": 144, "psi_i": [46, 48], "psi_j": [46, 48], "psi_mean": 144, "psi_mean_al": 144, "psi_n": 46, "psub": 35, "psutil": 124, "psychologi": 65, "pt": 127, "pt_sampler_t0": 97, "ptemce": [51, 52, 91], "ptemse": 51, "ptmcmc": [51, 97], "ptsampler": 97, "public": [1, 64, 65], "publica": 64, "publicli": [45, 57], "publish": [1, 15, 45, 54, 92, 111, 134], "puk94": [1, 47], "pukelheim": 47, "pukelsheim": 1, "pull": [49, 52], "pulldown": [9, 135], "punish": 65, "pure": [16, 45, 49, 54, 62, 63, 148, 153, 154], "purport": 49, "purpos": [17, 45, 49, 50, 51, 67, 68, 72, 96, 112, 147, 157], "push": 152, "put": [0, 8, 20, 21, 24, 25, 28, 32, 33, 35, 40, 41, 48, 53, 54, 57, 67, 73, 86, 134, 135, 136, 137, 144, 148, 153, 160], "px": 5, "py": [0, 38, 39, 51, 82, 97, 124, 127, 134, 152, 153], "pylab": 134, "pymc": [65, 74, 94, 144, 147, 149, 161, 164], "pymc3": [94, 152], "pymc_docs_getting_started_upd": 159, "pymc_nam": 153, "pymcinference_library_vers": 152, "pypi": 44, "pyplot": [0, 3, 5, 6, 9, 17, 18, 26, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 50, 51, 66, 70, 71, 72, 74, 77, 78, 79, 81, 82, 83, 84, 89, 93, 94, 96, 97, 103, 124, 127, 128, 130, 131, 133, 134, 135, 136, 144, 145, 146, 148, 150, 151, 152, 153, 154, 157, 162, 163], "pytensor": 72, "python": [0, 1, 5, 11, 20, 24, 27, 35, 40, 41, 44, 53, 57, 67, 70, 73, 74, 79, 86, 94, 95, 97, 103, 106, 107, 126, 131, 132, 134, 137, 138, 140, 141, 148, 153, 154, 157, 159, 162, 164], "python3": [0, 51, 82, 97, 127, 138, 141, 153], "pytorch": [65, 130], "pytorch_thread": 124, "p\u00f3lya": 62, "q": [3, 4, 20, 37, 45, 47, 73, 79, 83, 86, 126, 145, 149, 150, 155, 157], "q_": 86, "q_0": 150, "q_i": [45, 149], "qbism": 125, "qcd": 45, "qfrsaikz4ric": 1, "qft": 118, "qmn15": [1, 46], "qoi": 49, "qquad": [4, 17, 37, 52, 53, 67, 79, 121, 122, 124, 131, 149, 151, 160], "quad": [0, 3, 4, 5, 11, 13, 15, 17, 18, 20, 24, 25, 34, 35, 37, 38, 43, 47, 48, 54, 67, 86, 87, 124, 126, 131, 144, 146, 149, 154, 157, 159, 163], "quadrat": [20, 35, 39, 54, 73, 78, 79, 82, 83, 84, 86, 101, 113, 116, 124], "quadratur": [52, 155], "qualifi": [64, 65], "qualit": [7, 63, 120, 131, 147], "qualiti": [35, 54, 61, 64, 73, 103], "quanta": 129, "quantif": [8, 46, 47, 48, 63, 86, 98, 123], "quantifi": [7, 8, 16, 17, 23, 44, 47, 54, 61, 63, 66, 89, 96, 112, 114, 118, 120, 121, 131, 145], "quantil": [18, 39, 42, 44, 51, 78, 84, 95, 97, 124, 131, 144, 148, 153], "quantit": [7, 8, 16, 47, 59, 63, 72, 111, 120], "quantiti": [4, 16, 17, 18, 23, 24, 26, 32, 35, 42, 45, 46, 47, 48, 49, 52, 54, 65, 67, 68, 69, 73, 89, 95, 96, 102, 108, 110, 118, 120, 122, 125, 127, 131, 134, 144, 145, 154], "quantum": [1, 16, 23, 24, 46, 48, 65, 68, 105, 118, 125, 157, 162], "quarteroni": 1, "que": 35, "queri": 135, "question": [7, 8, 11, 17, 18, 26, 27, 28, 34, 40, 43, 50, 51, 53, 54, 57, 61, 62, 67, 69, 72, 74, 93, 94, 128, 137, 143, 144, 148, 153, 157, 160, 162, 163], "questionnair": 64, "quick": [128, 135, 136, 147], "quickli": [41, 48, 67, 74, 76, 137], "quickstart": 70, "quiet": 68, "quirki": 39, "quit": [35, 39, 68, 69, 74, 94, 96, 136, 145], "quod": 54, "quot": [16, 20, 40, 52, 67, 96, 105, 135, 153], "r": [0, 1, 3, 5, 6, 9, 11, 13, 15, 16, 17, 18, 20, 30, 34, 35, 38, 39, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 66, 67, 68, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 94, 97, 101, 103, 105, 108, 114, 116, 121, 124, 127, 128, 130, 131, 133, 134, 135, 136, 137, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 160, 162, 163, 164], "r2": [39, 67, 79], "r2_score": 134, "r_": [86, 151], "r_0": 151, "r_dot": 151, "r_dot_0": 151, "r_dot_half": 151, "r_dot_pt": 151, "r_dot_pts_eul": 151, "r_dot_pts_lf": 151, "r_hat": [152, 153], "r_i": [39, 96, 151], "r_list": 136, "r_pt": 151, "r_pts_euler": 151, "r_pts_lf": 151, "r_sq": 39, "race": 64, "racial": 64, "radford": [45, 149], "radfriend": 155, "radial": [81, 86, 122], "radii": 48, "radio": 54, "radioact": [38, 155], "radioactive_lighthouse_exercis": 143, "radioactive_lighthouse_exercise_kei": 37, "radiu": [47, 48, 50, 116, 134, 151, 155], "rai": [43, 143], "rain": [0, 8, 16, 18, 23, 24, 131, 157], "raini": 16, "raio": 17, "rais": [34, 51, 97, 124, 127, 130, 137], "rajesh": 1, "ran_uniform_arrai": 34, "rand": [6, 18, 26, 41, 51, 72, 78, 79, 83, 84, 97, 124, 128, 137, 144, 145, 147, 148, 150, 153], "randint": [34, 137], "randn": [18, 41, 42, 74, 93, 94, 128, 134, 144, 152], "random": [3, 6, 9, 16, 18, 20, 24, 25, 26, 27, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 51, 52, 54, 61, 64, 66, 67, 68, 71, 72, 74, 75, 78, 79, 80, 81, 82, 83, 84, 87, 93, 94, 95, 96, 97, 98, 103, 106, 107, 111, 118, 121, 122, 124, 128, 130, 134, 137, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 161, 163], "random_st": [30, 71, 74, 75, 82, 94, 131, 157, 162], "randomcovariancematrix": 83, "randomli": [16, 33, 37, 41, 43, 45, 48, 50, 51, 66, 70, 72, 143, 144, 145, 149, 155], "randomst": [41, 81, 82, 144], "randomwalk": 162, "rang": [3, 5, 6, 17, 18, 26, 30, 31, 34, 35, 37, 38, 39, 42, 43, 44, 47, 48, 50, 51, 52, 59, 65, 66, 67, 70, 72, 77, 78, 79, 80, 83, 84, 86, 87, 89, 92, 96, 97, 103, 107, 118, 121, 123, 124, 127, 130, 131, 133, 135, 144, 145, 146, 148, 153, 154, 155, 157, 162, 163], "ranganath": [1, 73], "ranganathan": 87, "rangl": [4, 20, 38, 43, 46, 86, 147, 154, 160], "rangle_": 52, "rank": [35, 56, 101, 126, 128], "rapidli": [34, 65, 80, 138, 155], "rare": [34, 35, 64, 103, 120, 152], "rasmu": 127, "rasmussen": [1, 86, 87], "rasumu": 127, "rate": [1, 32, 38, 45, 48, 64, 67, 68, 69, 70, 71, 72, 89, 98, 106, 107, 108, 130, 145, 147, 149, 160, 162, 164], "rather": [4, 8, 23, 24, 26, 35, 38, 39, 40, 42, 44, 45, 47, 48, 53, 54, 56, 57, 59, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 89, 96, 107, 113, 120, 128, 134, 135, 136, 144, 148, 152, 153, 160], "ratio": [5, 7, 8, 17, 45, 51, 52, 53, 54, 79, 83, 86, 87, 97, 116, 118, 126, 131, 146, 152, 154, 155, 157, 163], "ratio_max": [79, 83], "ratio_min": [79, 83], "ration": [7, 8, 63], "rational": 62, "rationalquadrat": 82, "ravel": [38, 41, 42, 71, 81, 124], "ravin": 106, "raw": [76, 128], "razor": 54, "rbf": [78, 80, 81, 82, 84, 86, 93, 122, 124], "rbf_kernel": 124, "rbf_lengthscal": 83, "rbf_term": 124, "rbf_varianc": 83, "rbfco": 78, "rbfkernel": 83, "rbm": [48, 123], "rbrace": 49, "rc_context": 127, "rcparam": [5, 9, 38, 127, 133, 134, 150, 151], "rct1": 134, "rct2": 134, "rdbu": 71, "rdbu_r": 66, "rdot": 151, "rdylbu_r": 66, "re": [1, 3, 5, 8, 13, 16, 20, 23, 39, 41, 42, 43, 52, 64, 70, 72, 73, 79, 93, 96, 97, 135, 143, 144, 145, 147, 152, 160], "reach": [8, 16, 44, 45, 63, 64, 67, 68, 69, 89, 98, 106, 144, 152, 154, 157], "react": [26, 134], "reaction": 48, "read": [0, 11, 24, 33, 37, 60, 65, 68, 69, 73, 76, 87, 95, 96, 128, 135, 136, 137, 138, 139, 159], "read_fwf": 134, "readabl": 153, "reader": [44, 47, 60, 62, 80], "readi": [43, 62, 69, 70, 134], "readili": 42, "readm": 44, "readout": 133, "readout_format": 133, "readthedoc": [42, 153, 164], "real": [0, 7, 8, 9, 16, 24, 41, 48, 64, 68, 73, 74, 78, 83, 84, 89, 99, 105, 111, 126, 137, 147, 162], "realis": 157, "realist": [16, 35, 101, 103, 154, 155, 157], "realiti": [8, 35, 49, 62, 63, 102, 103, 111, 124, 129, 131], "realiz": [4, 8, 17, 23, 35, 42, 54, 66, 67, 68, 87, 101, 160, 162], "realli": [7, 13, 18, 19, 24, 32, 39, 40, 41, 43, 45, 68, 74, 86, 94, 97, 116, 118, 145, 148, 153, 154, 160], "realm": 63, "rearrang": [24, 32, 33], "reason": [0, 1, 8, 11, 16, 17, 20, 23, 26, 35, 41, 44, 54, 59, 62, 64, 72, 78, 80, 87, 97, 101, 102, 107, 131, 137, 145, 147, 148, 153, 154, 155], "recal": [4, 9, 31, 32, 35, 39, 45, 49, 50, 53, 54, 64, 69, 83, 86, 89, 93, 126, 128, 144, 149], "recalcul": 143, "recalculate_data": 9, "recalculate_data_w": 9, "recapitul": 157, "recast": [52, 105], "receiv": [68, 83], "recent": [49, 50, 51, 64, 67, 70, 71, 72, 74, 94, 97, 105, 127], "recept": 68, "recess": 131, "recession": [17, 42], "recip": [16, 35, 70, 89, 96, 160], "recogn": [22, 40, 44, 47, 48, 54, 61, 63, 120, 128, 147, 148, 153], "recognis": [4, 89], "recognit": [54, 62, 64, 65, 68, 74, 76], "recommend": [39, 41, 42, 44, 57, 64, 65, 72, 76, 108, 131, 134, 135, 140, 143, 145, 152, 153], "reconstrain": [78, 84], "reconstuct": 5, "record": [4, 5, 8, 38, 43, 51, 54, 94, 97, 122, 124, 143, 146, 162, 163], "recov": [35, 122], "recreat": [45, 67, 128], "rectangl": 150, "rectifi": [68, 72, 76], "recurr": [69, 74, 137, 145, 154, 157], "recurs": 63, "red": [5, 9, 18, 24, 31, 34, 35, 38, 39, 40, 43, 50, 66, 70, 73, 76, 77, 78, 79, 82, 89, 94, 96, 103, 122, 124, 127, 128, 131, 135, 145, 146, 147, 148, 149, 151, 153, 155, 160, 162, 163, 164], "redefin": 93, "redirect": [74, 94], "redo": 42, "redrawn": 133, "redshift": 17, "reduc": [1, 23, 30, 35, 39, 40, 44, 45, 47, 48, 54, 61, 64, 67, 73, 76, 80, 89, 98, 103, 107, 108, 118, 120, 123, 126, 128, 144, 147, 151], "reduct": [1, 45, 47, 48, 67, 125, 126, 144, 152], "redund": 126, "ref": [0, 43, 45, 46, 47, 48, 49, 164], "refactor": 127, "refer": [1, 2, 8, 16, 17, 18, 28, 35, 42, 44, 46, 47, 49, 53, 54, 57, 64, 67, 68, 73, 76, 77, 79, 82, 87, 89, 101, 103, 111, 112, 118, 119, 121, 123, 126, 131, 135, 152, 154, 164], "refin": [5, 8, 47, 60, 68], "refit": 71, "reflect": [8, 26, 44, 47, 54, 64, 65, 122, 128, 134, 148, 153, 154, 157], "reformat": 70, "refresh": [57, 132], "regain": 35, "regard": [4, 8, 9, 26, 47, 52, 57, 59], "regardless": [8, 20, 78, 84, 154, 157], "regener": 9, "regenerate_data": 9, "regim": [49, 120], "region": [18, 20, 42, 45, 47, 49, 51, 52, 53, 54, 66, 67, 68, 73, 74, 76, 78, 79, 81, 83, 84, 94, 95, 96, 147, 149, 150, 154, 155, 160], "regist": [44, 138], "registri": 44, "regress": [1, 16, 28, 29, 39, 46, 48, 56, 64, 68, 69, 72, 73, 74, 80, 87, 88, 90, 94, 96, 98, 100, 104, 105, 106, 113, 117, 134, 159], "regressor": [66, 83, 89], "regular": [61, 68, 71, 73, 74, 75, 78, 81, 84, 94, 152], "regularli": [72, 96], "reifi": 49, "reilli": 1, "reinforc": [33, 65], "reject": [4, 11, 20, 47, 54, 145, 146, 147, 149, 154, 155, 160, 163, 164], "rel": [8, 16, 32, 39, 44, 47, 48, 49, 50, 52, 54, 66, 89, 95, 97, 98, 116, 128, 135, 145, 154], "relat": [4, 15, 17, 18, 20, 24, 26, 35, 39, 41, 42, 43, 44, 47, 49, 54, 60, 62, 64, 65, 67, 68, 72, 78, 84, 90, 95, 97, 100, 111, 112, 115, 116, 128, 129, 154], "relationship": [17, 35, 47, 54, 60, 63, 65, 87, 111, 112, 118, 147], "relax": [48, 95], "releas": [44, 51, 57, 97], "relerr": [150, 151], "relev": [7, 9, 16, 17, 26, 35, 39, 48, 54, 62, 64, 66, 67, 68, 73, 86, 89, 95, 96, 97, 101, 103, 111, 112, 131, 135, 138, 143, 147, 157, 162, 164], "reli": [23, 26, 47, 52, 54, 65, 72, 74, 94, 111, 137], "reliabl": [37, 39, 48, 52, 89, 97, 112, 120, 123, 136], "relu": [68, 70, 71, 72, 76, 77, 118, 130], "remain": [4, 16, 45, 48, 50, 54, 57, 67, 68, 122, 152, 154], "remaind": [26, 106], "remark": [21, 26, 44, 45, 48, 68, 122, 134, 147, 154, 162], "remedi": 8, "rememb": [4, 18, 23, 35, 47, 50, 66, 67, 75, 93, 126, 136, 137, 152, 155, 157, 162], "remind": 67, "remov": [38, 39, 47, 62, 64, 71, 79, 96, 126, 128, 145, 154], "ren": 1, "renaiss": 74, "renam": [135, 152], "render": [45, 46, 71, 135], "renewcommand": 0, "renorm": [12, 118], "reoffend": 64, "reorder": 89, "reorgan": 134, "rep": [1, 44], "reparameter": 152, "repeat": [30, 34, 35, 40, 42, 43, 44, 47, 51, 54, 67, 68, 78, 79, 81, 83, 91, 93, 95, 96, 97, 118, 123, 127, 128, 131, 136, 144, 146, 148, 152, 153, 154, 155, 160, 163], "repeatadli": 74, "repeatedli": [11, 15, 40, 45, 60, 148, 153], "repercuss": 64, "repetit": 131, "rephras": 17, "replac": [16, 17, 26, 45, 46, 47, 52, 53, 64, 69, 72, 73, 78, 81, 84, 86, 96, 123, 134, 143, 154], "repli": 129, "replic": 44, "replica": 52, "replot": 18, "report": [8, 44, 48, 54, 135, 148, 153], "repositori": [41, 44, 57, 65, 132, 138, 140, 141], "repres": [3, 4, 8, 9, 16, 17, 22, 23, 24, 26, 39, 40, 42, 45, 47, 49, 50, 52, 54, 60, 61, 64, 65, 66, 67, 68, 69, 72, 76, 77, 89, 95, 96, 97, 106, 118, 120, 121, 124, 128, 131, 136, 137, 144, 145, 147, 148, 153, 154, 155, 157], "represent": [1, 4, 7, 20, 37, 48, 49, 67, 70, 71, 74, 76, 86, 111, 126, 136, 147, 154], "reproduc": [4, 13, 26, 31, 35, 45, 50, 54, 62, 64, 65, 66, 67, 69, 73, 92, 95, 97, 103, 114, 124, 128, 131, 134, 145, 155, 157, 162], "reproduct": [34, 35, 62, 67, 162], "repuls": 134, "request": [65, 78, 124, 157], "requir": [8, 17, 20, 34, 35, 38, 39, 41, 44, 45, 46, 47, 48, 50, 52, 54, 60, 61, 63, 65, 68, 72, 74, 76, 77, 86, 91, 97, 98, 101, 106, 123, 124, 125, 131, 134, 137, 138, 141, 143, 149, 154, 157, 160, 162], "requires_grad": 72, "rerun": [38, 71], "resampl": [1, 47, 67, 124, 149], "rescal": [45, 71, 124], "research": [0, 1, 8, 20, 29, 35, 49, 58, 60, 61, 62, 65, 73, 74, 105, 118, 120], "resembl": [49, 145], "reserv": [35, 69], "reset": [6, 9, 39, 51, 72, 97, 124, 144, 148, 153], "reset_button_w": 9, "reset_n": 9, "reshap": [3, 6, 18, 26, 31, 35, 39, 42, 51, 71, 74, 77, 78, 81, 82, 83, 84, 93, 94, 97, 103, 124, 128, 134, 144, 147, 148, 153], "resid": [46, 47, 137], "residenti": 16, "residu": [5, 30, 35, 39, 48, 52, 96, 97, 101, 102, 106], "residual_": [35, 101], "residual_1": [35, 101], "residual_2": [35, 101], "residual_3": [35, 101], "residual_i": 35, "resist": 122, "resiz": [127, 137], "resolut": 150, "resolv": [47, 49], "reson": 48, "resort": 35, "resourc": [38, 44, 47, 135, 137], "respect": [4, 5, 8, 16, 17, 25, 26, 35, 39, 44, 45, 46, 47, 48, 49, 54, 64, 65, 66, 67, 68, 69, 72, 73, 76, 86, 89, 98, 101, 107, 108, 118, 131, 134, 137, 145, 157], "respond": [8, 68], "respons": [35, 57, 64, 65, 66, 68, 72, 78, 86, 89, 103, 110, 111, 114, 129, 131, 135], "rest": [8, 47, 67, 74, 79, 83, 95, 96, 112, 115, 155], "restart": [93, 135, 138], "restore_sign": 127, "restraint": 62, "restrict": [44, 47, 48, 53, 54, 59, 68, 83, 105, 106, 135, 147, 162], "restructur": 137, "result": [3, 4, 6, 8, 9, 11, 13, 15, 16, 17, 20, 24, 26, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 48, 49, 51, 52, 53, 54, 56, 59, 60, 62, 63, 64, 65, 66, 67, 69, 72, 73, 76, 78, 79, 83, 84, 86, 89, 91, 92, 93, 94, 95, 96, 97, 101, 102, 103, 122, 124, 127, 128, 130, 131, 134, 135, 137, 143, 144, 146, 147, 148, 153, 157, 159, 160, 162, 163], "retain": [128, 136], "retriev": [70, 74], "return": [0, 4, 5, 6, 8, 9, 17, 18, 26, 30, 31, 34, 35, 37, 38, 39, 41, 42, 43, 47, 50, 51, 53, 66, 70, 71, 72, 73, 74, 75, 78, 79, 83, 86, 87, 89, 93, 94, 95, 96, 97, 98, 101, 103, 107, 124, 127, 128, 130, 131, 133, 134, 135, 136, 137, 139, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 160, 162, 163], "return_cov": 83, "return_inferencedata": [152, 153], "return_std": [81, 82], "reusabl": 44, "rev": [1, 79, 83, 87], "reveal": [46, 54, 64, 118, 139, 157], "revers": [23, 24, 26, 45, 73, 138, 149, 151, 162], "reversibil": 45, "reversiblemarkovprocessexampl": 157, "reversiblemarkovprocessexample_cprob_fig": 157, "reversiblemarkovprocessexample_runs_fig": 157, "review": [21, 25, 35, 37, 42, 46, 50, 64], "revis": [5, 16, 39, 51, 57, 59, 62, 78, 79, 138, 144, 150, 152], "revisit": [26, 51, 60, 67], "revolut": 52, "revolv": 111, "reward": 65, "reweight": 155, "reword": 32, "rewrit": [26, 67, 68, 69, 73, 86, 89, 144], "rewritten": [67, 157], "rf": [18, 34, 38, 41, 43, 66, 79, 83, 127, 136, 144, 146, 150, 151, 162, 163], "rg": 118, "rhat": 144, "rho": [45, 73, 79, 80, 87, 131, 145, 160], "rho_": [25, 53, 83, 131], "rich": [48, 65], "richard": [1, 45, 149, 154, 155], "richardson": 1, "ridg": [1, 89], "riemann": 147, "right": [0, 3, 4, 9, 13, 15, 16, 17, 18, 20, 23, 24, 25, 26, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 45, 48, 49, 50, 52, 53, 54, 57, 64, 65, 66, 67, 68, 69, 70, 73, 74, 77, 79, 83, 86, 89, 93, 95, 96, 97, 98, 101, 104, 106, 107, 108, 115, 118, 121, 122, 126, 127, 128, 131, 135, 138, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 157, 160, 162, 163], "rightarrow": [0, 3, 4, 7, 13, 15, 17, 20, 23, 24, 34, 35, 37, 38, 45, 49, 68, 73, 86, 87, 103, 147, 149, 155, 159], "rightli": [8, 54], "rightmost": 57, "rigidli": 57, "rigor": [44, 59, 60, 63, 65, 114, 127, 145], "rigour": 111, "ring": 52, "rise": [8, 35, 54, 128], "risk": [8, 44, 45, 47, 60, 64, 67], "ritz": 48, "rivalri": 46, "rjf": 123, "rk23": 151, "rlhick": 152, "rm": [9, 11, 16, 20, 30, 34, 38, 43, 45, 49, 50, 64, 67, 68, 72, 79, 80, 87, 95, 96, 121, 122, 131, 133, 151], "rmsprop": [68, 72], "rng": [31, 35, 81, 82, 103, 131], "rnn": 68, "roam": 160, "rob": 144, "rob21": [1, 118], "robert": [1, 118, 129, 145, 162], "roberto": 1, "robust": [1, 39, 44, 62, 64, 109, 122, 124, 152, 153, 164], "role": [44, 49, 54, 57, 65, 67, 68, 83, 87, 128, 131, 135], "roll": [4, 24, 66, 144], "rom": 48, "ron": 1, "ronald": 1, "rongzheng": 1, "rook": 80, "room": 135, "root": [25, 42, 57, 64, 65, 67, 72, 111, 131, 135, 137], "root_mean": 66, "rot": 134, "rotat": [47, 52, 128, 147], "rough": [19, 47], "roughli": [30, 34, 35, 40, 45, 52, 54, 64, 72, 126, 131, 145, 153], "round": [4, 124, 128, 134, 137], "routin": [51, 153], "row": [1, 26, 31, 33, 43, 68, 70, 79, 124, 128, 134, 135, 136, 145, 154, 157, 160], "roweth": 1, "royal": 1, "royalblu": 66, "rrapaj": 1, "rseed": [41, 144], "rsq": 39, "rst": [74, 94], "rstride": [38, 66], "rtol": [150, 151], "rub88": [1, 45], "rubin": [1, 147], "ruder": 108, "ruin": 8, "rule": [0, 1, 7, 13, 15, 16, 17, 21, 24, 28, 30, 35, 36, 38, 42, 52, 53, 54, 59, 62, 63, 64, 66, 72, 89, 108, 131, 147, 154, 157, 160, 162], "ruler": [17, 42], "rumelhart": 1, "rumelharthintonwilliams86": [1, 69], "run": [8, 9, 31, 35, 38, 39, 43, 44, 45, 47, 50, 51, 52, 57, 71, 72, 74, 77, 80, 84, 87, 94, 96, 97, 103, 107, 118, 124, 126, 127, 130, 131, 132, 134, 135, 136, 139, 144, 146, 151, 152, 153, 155, 157, 159, 160, 162, 163], "run_mcmc": [6, 39, 42, 51, 97, 124, 144, 148, 153], "run_model": 130, "rung": [149, 151], "runner": 78, "runtimeerror": 127, "runtimewarn": 39, "ruth": 1, "rutherford": 131, "rv": [9, 18, 30, 34, 38, 40, 43, 50, 66, 79, 83, 87, 127, 131, 145, 146, 148, 152, 153, 154, 163], "rvec": 52, "rvec_": 52, "rvec_i": 52, "rvert": [105, 121], "rw05": [1, 86], "rwidth": [146, 163], "ryh22": [1, 118], "r\u00e9duit": 35, "r\u00e9sum\u00e9": 64, "s1": 38, "s12918": 1, "s2": 38, "s41567": 1, "s43586": 1, "s_": 126, "s_eleph": 105, "s_i": 128, "s_j": [45, 128, 144, 152], "s_k": [126, 128], "s_n": 162, "s_shape": 128, "sa": 44, "saddl": [40, 54, 106, 148, 153], "safe": [51, 97], "safeti": [0, 64, 65], "sai": [0, 3, 4, 7, 8, 13, 16, 17, 18, 20, 23, 24, 26, 31, 32, 33, 35, 38, 39, 40, 41, 43, 44, 45, 49, 50, 54, 57, 59, 63, 67, 69, 76, 87, 89, 96, 128, 135, 137, 138, 144, 145, 147, 148, 153, 157, 160], "said": [16, 59, 66, 157], "sake": [49, 89, 134], "salutari": 17, "sam": [134, 137], "same": [0, 4, 5, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 23, 24, 26, 31, 32, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 48, 49, 50, 53, 54, 56, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 78, 80, 83, 84, 87, 93, 94, 95, 96, 97, 106, 108, 118, 122, 124, 126, 127, 128, 130, 131, 134, 135, 136, 137, 143, 144, 145, 146, 147, 148, 151, 152, 153, 154, 155, 157, 160, 162, 163, 164], "samp_label": 127, "sampl": [0, 1, 3, 6, 7, 16, 20, 24, 30, 35, 38, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 54, 60, 64, 67, 68, 70, 71, 73, 74, 80, 81, 82, 87, 89, 90, 93, 94, 95, 96, 97, 102, 103, 104, 118, 121, 122, 123, 125, 127, 128, 130, 131, 137, 143, 144, 148, 149, 159, 162, 164], "sample_i": 82, "sample_mean": 66, "sample_means_fixed_sample_s": 34, "sample_nod": [74, 94], "sample_posterior_predict": [74, 94], "sample_proba": [74, 94], "sample_s": 34, "sample_sort": 97, "sample_stat": 152, "sample_std": 66, "sampler": [1, 6, 17, 39, 42, 45, 52, 60, 74, 75, 94, 95, 144, 145, 147, 148, 149, 154, 155, 161], "sampler_object": 42, "samples_md": 124, "samples_md_poco": 124, "samples_save_dir": 124, "samples_spars": 6, "samples_unflatten": [51, 144], "samples_wmd": 124, "samples_wmd_poco": 124, "samplescor": [79, 83], "samplesuncor": [79, 83], "samplig": 155, "sampling_tim": 152, "samwis": 134, "sandbox": 87, "saniti": 137, "santayana": 47, "sarah": [1, 57], "satisfi": [3, 4, 17, 30, 32, 47, 52, 54, 96, 131, 149, 157, 160], "satur": [50, 53, 91, 97], "save": [6, 7, 20, 43, 45, 67, 70, 97, 124, 127, 134, 137, 139, 143, 148, 153], "save_fig": 134, "save_model": 70, "savefig": [6, 74, 127, 134, 135, 150, 151], "savefig_kwarg": 127, "saw": [50, 83], "sbn": 144, "scalabl": 74, "scalar": [45, 48, 51, 66, 72, 86, 87, 97, 126, 128, 130, 144, 147], "scale": [13, 18, 20, 34, 35, 38, 39, 41, 42, 43, 44, 45, 48, 51, 52, 66, 68, 70, 72, 73, 78, 79, 80, 81, 82, 83, 84, 87, 96, 97, 106, 114, 121, 124, 127, 128, 130, 131, 144, 146, 148, 152, 153, 154, 160, 163, 164], "scale_": 124, "scaled_sum": 30, "scaler": 124, "scan": 89, "scandinavian_entropi": 4, "scatter": [35, 39, 40, 42, 43, 46, 48, 66, 71, 72, 73, 74, 79, 81, 82, 83, 94, 103, 128, 134, 152, 153, 155], "scatter_joint_bnn_plot": 73, "scatterplot": 66, "scb": 131, "sccord": 131, "scenario": [4, 17, 44, 45, 49, 54, 65, 67, 68, 73, 122, 160, 162], "schack": 129, "sched_getaffin": 124, "schedul": [106, 108], "schemat": [48, 80, 118, 147, 160], "schematic_rbm": 48, "scheme": [47, 66, 117, 154], "school": [8, 23, 40, 54, 57, 64, 78, 84, 148, 153], "schoot": [1, 44], "schroding": [24, 48, 80], "schr\u00f6dinger": 46, "schwab": 1, "sch\u00f6n": 1, "sci": 1, "scienc": [0, 1, 8, 16, 44, 48, 49, 54, 57, 58, 59, 61, 62, 63, 64, 67, 68, 105, 118, 135, 146, 154, 163], "scientif": [7, 8, 15, 16, 26, 41, 44, 46, 47, 49, 54, 57, 59, 61, 62, 63, 65, 66, 68, 105, 111, 112, 120, 127, 129, 135, 138, 141, 162], "scientist": [1, 8, 54, 64, 65, 131], "scikit": [1, 65, 67, 82, 87, 94, 134, 137, 138], "scikitlearn": 134, "scipi": [0, 5, 6, 9, 13, 17, 20, 24, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 50, 66, 70, 79, 83, 93, 96, 97, 124, 127, 128, 135, 137, 138, 144, 145, 146, 148, 150, 151, 152, 153, 154, 155, 163], "scope": [8, 112], "score": [68, 70, 71, 76, 134, 152], "scorn": 59, "scott": 137, "scratch": [45, 70], "screen": [32, 45, 57, 64, 150], "script": [0, 44, 130, 155, 157, 162], "scroll": [18, 131, 135], "sd": [146, 152, 153, 163], "se": [1, 16, 48, 59, 79, 83, 144, 147], "seaborn": [5, 9, 18, 34, 38, 39, 40, 41, 42, 43, 50, 51, 71, 74, 78, 79, 93, 94, 96, 97, 134, 136, 144, 145, 146, 148, 153], "seali": [0, 24], "search": [1, 47, 57, 68, 105, 106, 131, 135, 157, 162], "searchsort": [38, 41, 42], "sebastian": 108, "sec": [0, 42, 124], "second": [8, 16, 17, 18, 20, 23, 24, 26, 32, 33, 35, 37, 39, 40, 42, 44, 45, 47, 49, 50, 53, 54, 65, 67, 68, 69, 70, 72, 73, 74, 86, 97, 103, 108, 111, 113, 126, 127, 131, 134, 135, 137, 145, 147, 148, 151, 152, 153, 157, 160], "secondari": 95, "secondli": 69, "section": [8, 9, 14, 24, 27, 31, 35, 37, 38, 43, 44, 49, 57, 59, 62, 66, 78, 82, 84, 87, 91, 92, 95, 97, 103, 113, 114, 119, 126, 133, 134, 138, 146, 156, 158, 163], "sector": [1, 65, 68], "sedol": 74, "see": [0, 3, 4, 5, 9, 11, 13, 15, 16, 17, 20, 24, 26, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 57, 60, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 81, 83, 84, 86, 87, 89, 93, 94, 95, 96, 97, 98, 101, 105, 106, 113, 114, 117, 119, 122, 128, 131, 132, 134, 135, 137, 138, 140, 141, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 157, 160, 163], "seed": [6, 9, 18, 26, 31, 39, 40, 41, 66, 67, 71, 79, 83, 93, 94, 96, 97, 124, 131, 134, 144, 145, 148, 153, 157, 160, 162], "seek": [9, 10, 16, 20, 24, 31, 35, 45, 46, 48, 50, 52, 56, 57, 63, 68, 86, 98, 101, 105, 108, 122, 148, 149, 153, 154], "seem": [0, 5, 20, 23, 26, 32, 39, 40, 45, 49, 50, 54, 63, 74, 76, 78, 84, 148, 152, 153, 155, 157, 161], "seen": [8, 17, 35, 54, 63, 64, 69, 73, 76, 79, 83, 87, 89, 103, 128, 135, 145, 147, 149, 154, 155, 157, 160], "sekstromforssen22": [1, 45], "selct": 131, "seldomli": 8, "select": [1, 9, 16, 44, 48, 53, 55, 56, 57, 60, 65, 66, 67, 73, 78, 79, 81, 83, 84, 87, 90, 91, 92, 93, 97, 104, 130, 134, 135, 138, 150, 158, 162], "selection_mini": 91, "self": [9, 51, 60, 65, 72, 80, 97, 124, 127, 150, 151, 157, 162], "semi": [35, 78, 84, 93, 128], "semicolon": 139, "semidefinit": [83, 87], "semilogi": [96, 128, 150, 151], "semilogx": 163, "sen": 35, "send": 68, "sens": [4, 8, 16, 17, 26, 35, 37, 39, 41, 42, 48, 53, 60, 63, 64, 67, 74, 94, 97, 101, 102, 131, 144, 145, 147, 152, 157], "sensibl": [4, 26, 76], "sensit": [0, 5, 8, 37, 39, 41, 44, 45, 47, 48, 50, 52, 67, 95, 96, 98, 123], "sentenc": [64, 68], "sentiment": 64, "sep": 134, "separ": [8, 35, 44, 45, 48, 51, 52, 54, 64, 65, 66, 74, 78, 84, 87, 94, 97, 100, 135, 136, 143, 144, 147], "septemb": 1, "sequenc": [1, 15, 31, 45, 68, 73, 76, 89, 93, 127, 131, 137, 139, 144, 157, 160, 162], "sequenti": [15, 26, 31, 68, 70, 71, 72, 77, 122, 130, 135, 137], "seri": [1, 8, 16, 34, 35, 38, 39, 40, 50, 57, 65, 92, 95, 113, 134, 144, 148, 153, 155, 163], "serif": 134, "seriou": [8, 64, 65, 135], "serv": [45, 76, 87, 89, 121, 122, 124, 134, 159], "server": [57, 132], "servic": 65, "set": [0, 1, 3, 4, 5, 7, 8, 11, 15, 16, 17, 18, 20, 22, 23, 24, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 77, 79, 80, 81, 83, 86, 87, 89, 92, 93, 94, 95, 96, 97, 98, 100, 101, 103, 105, 106, 107, 108, 111, 112, 116, 118, 121, 122, 127, 128, 130, 131, 132, 134, 135, 136, 138, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 157, 160, 161, 162, 163, 164], "set_alpha": 9, "set_aspect": [41, 51, 66, 79, 83, 128, 136, 150, 151], "set_axis_off": 128, "set_axisbelow": 41, "set_color": [70, 77], "set_context": [5, 9, 39, 40, 43, 71, 74, 78, 79, 93, 94, 144, 145, 148, 153], "set_data": 74, "set_limit": [79, 83], "set_printopt": 128, "set_size_inch": 18, "set_styl": [74, 79, 93, 144], "set_titl": [3, 6, 9, 18, 30, 34, 35, 38, 39, 41, 42, 43, 50, 51, 66, 78, 79, 82, 83, 84, 103, 127, 128, 130, 133, 135, 136, 144, 146, 150, 151, 162, 163], "set_tt_rng": [74, 94], "set_vis": 127, "set_xlabel": [0, 3, 5, 6, 9, 17, 18, 26, 31, 34, 35, 38, 40, 41, 42, 43, 50, 66, 71, 74, 79, 82, 83, 89, 94, 96, 97, 103, 127, 128, 130, 131, 133, 134, 135, 136, 144, 146, 150, 151, 153, 154, 162, 163], "set_xlim": [6, 30, 34, 38, 43, 50, 51, 71, 78, 79, 96, 97, 127, 130, 131, 146, 150, 151, 163], "set_xtick": [79, 83], "set_ylabel": [0, 3, 5, 6, 17, 18, 26, 31, 34, 35, 38, 40, 41, 42, 50, 51, 66, 71, 74, 79, 82, 83, 89, 94, 96, 97, 103, 127, 130, 131, 133, 134, 135, 136, 144, 146, 150, 151, 153, 154, 162, 163], "set_ylim": [3, 6, 38, 43, 50, 51, 71, 82, 96, 97, 127, 130, 131, 146, 150, 151, 162, 163], "set_ytick": [9, 43], "set_zlabel": [66, 131], "set_zlim": 66, "settl": [8, 157], "setup": [9, 26, 31, 35, 49, 51, 52, 72, 102, 103, 127, 133, 138, 144, 147, 148, 153], "setup_mod": 51, "setup_polynomial_design_matrix": [35, 103], "setup_rc_param": [124, 127], "setup_text": [9, 133], "seven": 64, "sever": [4, 8, 9, 16, 17, 18, 20, 30, 34, 39, 41, 43, 45, 47, 49, 54, 56, 57, 64, 65, 66, 67, 68, 73, 74, 76, 77, 86, 89, 93, 96, 97, 98, 105, 106, 108, 118, 128, 129, 130, 131, 134, 135, 138, 141, 151, 154, 157, 164], "sexual": 64, "sg92": [1, 45], "sgd": [68, 107], "shade": [18, 38, 54, 127, 131], "shall": [47, 93, 124], "shallow": 20, "shannon": [4, 63], "shape": [6, 13, 26, 34, 35, 38, 42, 44, 51, 54, 66, 68, 70, 71, 74, 77, 78, 79, 81, 83, 84, 89, 93, 94, 95, 96, 97, 124, 127, 128, 131, 139, 144, 146, 147, 148, 149, 150, 152, 153, 154, 155, 157, 159, 160, 163], "share": [7, 44, 51, 57, 62, 73, 74, 82, 94, 97, 127, 134, 153, 157], "sharei": [3, 6, 26, 31, 41, 66, 79, 82, 83, 89, 131, 144, 162], "sharex": [3, 6, 26, 31, 41, 42, 82], "sharp": [20, 54, 66], "sharpli": [20, 35, 52, 68], "shave": 7, "she": [63, 89], "shed": 54, "sheet": [52, 137], "shef": 78, "sheffield": [78, 84, 86], "shell": [48, 127, 134, 155], "shift": [3, 5, 16, 40, 45, 73, 80, 124, 128, 135, 137, 139, 144, 145, 148, 153, 160], "shifti": 129, "shine": [41, 52], "ship": 77, "shire": 134, "sho": 1, "shop": 138, "shore": 4, "short": [17, 23, 24, 32, 33, 41, 45, 52, 57, 64, 68, 70, 73, 97, 127, 129, 137, 153, 157, 162], "shortcut": 137, "shorten": [0, 44], "shorter": [45, 145], "shorthand": [17, 26, 31, 67, 105, 108, 134], "shortli": 8, "shoud": 31, "should": [4, 7, 8, 9, 10, 15, 16, 17, 19, 20, 22, 23, 24, 26, 28, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 44, 45, 46, 47, 49, 52, 54, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 76, 78, 79, 83, 84, 86, 87, 89, 94, 95, 96, 98, 103, 106, 107, 111, 112, 123, 124, 127, 128, 130, 131, 135, 137, 138, 144, 146, 148, 152, 153, 154, 155, 157, 160, 162, 163], "shouldn": [30, 138, 143], "show": [4, 9, 11, 13, 16, 17, 18, 25, 26, 31, 33, 34, 35, 37, 38, 39, 40, 41, 43, 45, 50, 51, 52, 63, 66, 67, 68, 70, 71, 72, 73, 74, 77, 78, 80, 83, 84, 86, 87, 91, 94, 95, 97, 98, 100, 121, 122, 124, 125, 126, 128, 131, 133, 134, 135, 136, 138, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 160, 162], "show_titl": [18, 39, 42, 51, 83, 95, 97, 124, 144, 148, 153], "shown": [4, 9, 17, 18, 20, 26, 35, 38, 39, 45, 48, 52, 66, 67, 68, 73, 74, 78, 82, 84, 96, 108, 122, 128, 131, 134, 135, 136, 137, 145, 152, 157, 162, 164], "shrink": [18, 38, 47, 77, 127, 143], "shrinkag": 67, "shuch": 131, "shuffl": [66, 107], "side": [3, 8, 10, 16, 17, 20, 23, 24, 26, 32, 35, 40, 45, 48, 54, 66, 73, 126, 131, 143, 146, 148, 150, 151, 153, 154, 157, 160, 162], "sig": [42, 51], "sig0": [39, 96], "sig_vm": 42, "siga": 17, "sigd": [0, 17], "sigf": 17, "sigh": [0, 17], "sight": 54, "sigma": [1, 3, 4, 9, 17, 18, 20, 25, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 45, 51, 53, 54, 67, 71, 73, 74, 79, 80, 83, 86, 87, 93, 94, 95, 96, 97, 98, 118, 126, 127, 128, 130, 131, 144, 145, 147, 148, 149, 152, 153, 154, 155, 159, 160, 162, 163], "sigma0": [39, 96], "sigma1": [51, 131], "sigma11_sq": 35, "sigma1inv": 51, "sigma2": [18, 35, 51, 127, 131], "sigma2inv": 51, "sigma_": [17, 25, 30, 35, 46, 47, 53, 67, 83, 86, 87, 91, 97, 103, 124, 126, 131, 159, 162], "sigma_0": [35, 39, 40, 53, 82, 96, 148, 153], "sigma_0_bound": 82, "sigma_1": [35, 39, 49, 73, 87, 131], "sigma_2": [73, 87, 131], "sigma_a": 17, "sigma_b": 39, "sigma_contour": 42, "sigma_error": [35, 103], "sigma_est": [40, 148, 153], "sigma_exp": 97, "sigma_f": [17, 83, 86], "sigma_f_opt": 83, "sigma_fn": 71, "sigma_h": [17, 124], "sigma_i": [17, 30, 35, 37, 39, 49, 54, 66, 79, 83, 87, 97, 98, 114, 121, 147], "sigma_interval__": 153, "sigma_j": 83, "sigma_k": 4, "sigma_mat": 50, "sigma_mat_inv": 50, "sigma_max": 127, "sigma_mean_prior": 152, "sigma_n": [48, 87, 154], "sigma_now": 127, "sigma_nu": 83, "sigma_prior": 152, "sigma_sampl": 93, "sigma_sd_prior": 152, "sigma_t": [17, 51, 97], "sigma_tild": 34, "sigma_tru": [37, 40, 148, 153], "sigma_v": [17, 42, 124, 127], "sigma_w": 73, "sigma_x": [17, 37, 54, 79, 87], "sigma_z": [17, 68, 83], "sigmacor": [79, 83], "sigmai": 35, "sigmamat": 128, "sigmamv": 83, "sigmap": 51, "sigmapinv": 51, "sigmar": 35, "sigmauncor": [79, 83], "sigmavec": [53, 80, 87, 126, 155], "sigmoid": [1, 68, 69, 71, 72, 74, 89, 94, 130], "sigmoid_functions_fig": 89, "sign": [4, 44, 52, 54, 66, 67, 89, 120, 135, 138, 144, 149, 162], "signal": [1, 7, 17, 26, 39, 45, 52, 54, 66, 71, 73, 74, 83, 86, 89, 91, 92, 97, 155], "signatur": [45, 52], "signific": [4, 51, 52, 54, 57, 106, 128, 137, 155], "significantli": [30, 46, 54, 67, 72, 98, 108, 122, 126, 137, 154, 155], "sigp": 51, "sigv": [0, 17], "silenc": [68, 134], "silicon": 138, "silver": 16, "sim": [3, 30, 35, 39, 41, 42, 45, 46, 50, 52, 73, 75, 78, 80, 83, 84, 86, 87, 96, 103, 121, 124, 127, 131, 144, 145, 146, 154, 155, 159, 160, 163], "similar": [40, 41, 44, 45, 47, 52, 54, 66, 68, 72, 74, 76, 81, 89, 97, 98, 108, 135, 143, 147, 149], "similarli": [15, 54, 73, 83, 134, 160], "simon": [8, 35], "simp": [38, 157], "simpl": [0, 1, 4, 5, 7, 17, 26, 33, 35, 36, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 54, 64, 65, 66, 67, 70, 72, 73, 74, 76, 77, 81, 89, 94, 96, 97, 99, 102, 103, 108, 118, 122, 131, 134, 135, 139, 144, 145, 148, 150, 151, 152, 154, 155, 164], "simpler": [7, 53, 54, 72, 122, 131, 133, 154], "simplest": [7, 15, 48, 54, 68, 70, 76, 86, 89, 131, 135, 162], "simpli": [7, 9, 13, 17, 18, 25, 26, 35, 39, 40, 41, 42, 44, 49, 54, 57, 64, 65, 66, 68, 72, 96, 118, 120, 124, 128, 131, 134, 137, 143, 145, 147, 148, 150, 153, 154, 155, 162], "simplic": [17, 35, 39, 45, 49, 68, 72, 87, 89, 111, 122, 157], "simplif": [116, 128], "simplifi": [25, 35, 43, 45, 50, 53, 54, 66, 96, 108, 147, 154, 155], "simpson": [38, 52, 155], "simul": [1, 11, 26, 31, 44, 45, 46, 52, 59, 68, 123, 125, 144, 147, 149, 154, 155, 157, 162], "simultan": [26, 48, 63, 67, 120], "sin": [35, 72, 78, 81, 82, 84, 93, 96, 113, 115, 128, 133, 135, 136, 137, 139, 150, 151], "sinc": [4, 6, 8, 13, 16, 17, 20, 26, 34, 35, 37, 42, 45, 49, 54, 65, 67, 72, 73, 78, 79, 84, 86, 96, 97, 101, 105, 107, 112, 116, 122, 124, 126, 131, 134, 135, 143, 144, 145, 152, 154, 157, 162], "sine": [35, 133, 135, 136, 137], "sine_and_exp": 135, "sine_and_exp_transpar": 135, "sine_map": 136, "singer": 1, "singl": [4, 17, 31, 35, 38, 39, 40, 41, 44, 47, 48, 49, 50, 64, 66, 67, 68, 71, 72, 73, 74, 75, 76, 83, 86, 89, 96, 97, 100, 101, 107, 116, 131, 134, 135, 136, 137, 144, 145, 148, 153, 155, 162], "single_cauchy_likelihood": 39, "single_conservative_likelihood": 39, "single_gaussian_likelihood": 39, "single_neuron": 71, "single_neuron_binary_classifi": 71, "single_prior": 82, "singular": [5, 48, 67, 125, 128], "singularli": 126, "sinh": 72, "sir": 1, "sit": 35, "site": [51, 65, 82, 97, 127, 152, 153, 155], "situat": [4, 7, 8, 16, 17, 34, 35, 39, 40, 41, 45, 47, 49, 52, 53, 54, 64, 67, 72, 78, 89, 91, 102, 103, 106, 131, 145, 148, 153, 154, 155, 160, 162], "sivia": [1, 2, 7, 9, 28, 38, 39, 40, 43, 54, 57, 91, 96, 97, 148, 153], "six": [3, 4, 48, 155], "sixth": 157, "size": [3, 4, 5, 9, 17, 18, 30, 35, 37, 38, 40, 41, 43, 44, 45, 47, 48, 50, 51, 67, 68, 70, 71, 74, 75, 76, 77, 78, 80, 81, 83, 84, 87, 93, 94, 96, 97, 98, 103, 107, 112, 118, 124, 127, 128, 131, 133, 134, 138, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 160, 162, 163, 164], "sk": 97, "skate": 152, "skater": 152, "skeleton": 135, "skew": [19, 37, 54, 64, 154], "ski": 157, "skill": [1, 4, 38, 57, 65], "skimag": 128, "skin": 1, "skip": [0, 37, 80, 128, 134, 143, 146, 160, 163], "skirt": [40, 148, 153], "skl": 134, "sklearn": [51, 71, 74, 75, 81, 82, 83, 94, 124, 128, 134], "sky": [0, 1, 23, 96, 157], "slab": 74, "slant": [54, 147], "slate": 72, "slice": [137, 150, 152, 153, 157], "slide": 76, "slider": [9, 11, 133, 135], "slider_bord": 133, "slight": [44, 72], "slightli": [5, 17, 35, 39, 41, 61, 67, 152, 162], "slope": [3, 6, 24, 35, 37, 38, 39, 41, 42, 54, 87, 106, 144], "slope_limit": 41, "slope_max": 42, "slope_prior": [3, 6], "slope_rang": [41, 42], "slope_sampl": 42, "slopesamples_fig": 3, "sloppi": [24, 128], "slow": [65, 74, 106, 127, 134, 136, 152], "slowli": [67, 69, 74, 80, 107, 155], "small": [0, 5, 7, 8, 9, 17, 18, 20, 24, 30, 35, 39, 40, 45, 47, 48, 49, 52, 54, 64, 67, 68, 69, 72, 73, 74, 76, 78, 79, 81, 83, 84, 86, 87, 98, 102, 106, 108, 115, 116, 122, 128, 137, 138, 145, 147, 148, 152, 153, 154, 155], "small_list_a": 136, "smaller": [4, 17, 30, 32, 34, 38, 45, 46, 47, 48, 54, 64, 67, 69, 97, 98, 106, 150, 151, 154, 162], "smallest": [42, 126, 128, 131, 134], "smartphon": 135, "smhi": 16, "smith": 1, "sml": 1, "smlbook": 1, "smooth": [4, 5, 9, 31, 46, 48, 79, 80, 83, 86, 87], "smoother": [48, 152], "sn": [5, 9, 18, 34, 38, 39, 40, 43, 51, 71, 74, 78, 79, 93, 94, 96, 97, 134, 145, 148, 153], "snapshot": [46, 48, 127], "snippet": [93, 97, 147], "snow": 157, "so": [3, 4, 5, 8, 9, 11, 13, 15, 16, 17, 18, 19, 20, 23, 24, 26, 27, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 76, 77, 78, 79, 80, 83, 84, 86, 87, 89, 90, 93, 94, 95, 96, 97, 98, 101, 103, 118, 120, 124, 126, 127, 128, 131, 133, 134, 135, 137, 138, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 160, 162, 163], "social": [8, 49, 64, 65], "societ": [64, 65], "societi": [1, 64], "soft": [44, 89], "softmax": [68, 70, 72, 76, 77], "softplu": [73, 118], "softwar": [44, 52, 64, 65, 74, 77, 78, 84, 90, 94, 106, 138, 144, 147], "sol": 124, "sold": 8, "sole": [8, 44, 50, 52, 57], "solid": [17, 38, 43, 45, 50, 65, 80, 87, 89, 133, 151], "solut": [4, 45, 46, 48, 49, 69, 80, 101, 105, 106, 118, 124, 128, 137, 138, 149, 150, 151, 155], "solv": [3, 17, 32, 35, 40, 45, 46, 47, 48, 62, 65, 66, 67, 68, 70, 80, 86, 97, 98, 101, 102, 105, 124, 126, 135, 148, 150, 153, 157, 162], "solvabl": 154, "solve_ivp": [150, 151], "solve_od": [150, 151], "solve_ode_eul": 151, "solve_ode_leapfrog": 151, "solver": [48, 71, 149], "some": [4, 5, 7, 8, 9, 10, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 29, 31, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 56, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 91, 92, 93, 94, 95, 96, 97, 98, 102, 103, 105, 106, 108, 109, 111, 114, 117, 118, 123, 128, 129, 131, 134, 135, 136, 137, 138, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 157, 160, 162, 163], "someon": [8, 49, 57], "someth": [3, 8, 16, 20, 22, 40, 43, 63, 64, 67, 72, 74, 107, 135, 138, 148, 149, 153], "sometim": [8, 16, 17, 19, 24, 35, 40, 44, 48, 49, 54, 61, 65, 68, 73, 86, 99, 120, 123, 127, 131, 135, 145, 148, 153, 154, 157], "somewhat": [8, 16, 20, 24, 35, 52, 54, 100, 108], "somewher": [35, 145], "son": 1, "soon": 54, "sophist": [47, 49, 96, 134, 145, 154], "sort": [20, 38, 41, 42, 54, 66, 68, 74, 79, 83, 97, 128, 135], "sorted_": [38, 41], "sorted_lnprob": 42, "sound": [64, 65, 135], "sourc": [0, 18, 34, 43, 44, 52, 57, 65, 67, 77, 88, 123, 134, 135, 136, 138, 143, 162], "sp": [70, 79, 93, 128, 157, 162], "space": [8, 18, 20, 22, 24, 34, 38, 39, 41, 45, 46, 47, 48, 52, 53, 54, 60, 63, 65, 66, 68, 72, 73, 74, 78, 79, 80, 83, 84, 86, 87, 94, 96, 97, 105, 120, 121, 127, 131, 135, 144, 145, 147, 149, 150, 151, 152, 154, 155, 157, 160, 162], "spacetim": 16, "span": [35, 48, 49, 67, 103, 128, 134], "spars": 72, "sparse_categorical_crossentropi": [70, 77], "sparsiti": 74, "spatial": [52, 68, 76, 118, 124, 128, 150], "speak": [8, 57, 60, 80, 131], "speci": 63, "special": [8, 16, 18, 24, 35, 39, 40, 48, 49, 54, 64, 66, 69, 74, 87, 89, 97, 131, 134, 147, 148, 149, 152, 153, 154, 155], "specif": [4, 17, 24, 26, 35, 39, 42, 44, 46, 47, 49, 51, 54, 59, 60, 62, 63, 64, 65, 66, 67, 68, 72, 73, 75, 76, 77, 79, 83, 87, 89, 97, 112, 120, 121, 124, 130, 131, 134, 137, 145, 154, 157, 162], "specifi": [3, 4, 5, 9, 10, 17, 18, 23, 24, 26, 35, 38, 39, 40, 41, 42, 43, 44, 47, 49, 50, 51, 52, 54, 56, 59, 60, 68, 70, 74, 79, 80, 81, 83, 86, 87, 89, 92, 95, 96, 118, 120, 121, 122, 124, 130, 131, 133, 137, 138, 144, 148, 150, 151, 152, 153, 154, 155, 159, 162], "specifii": 80, "speckl": 157, "spectacular": 49, "spectroscopi": 97, "spectrum": [48, 91, 97, 126], "speech": [65, 68], "speed": [48, 69, 72, 74, 94, 135, 137], "spell": [62, 135], "spend": [44, 63, 155], "spent": [7, 61], "sphere": 124, "spheric": 149, "spike": 74, "spin": [68, 118, 131], "spirit": [41, 47, 54, 59], "spite": 65, "split": [6, 44, 51, 65, 67, 68, 86, 94, 129, 144, 147, 162], "spot": [54, 64], "spread": [4, 67, 80, 131, 143, 147, 160], "springer": 1, "sqrt": [0, 4, 9, 17, 20, 25, 30, 31, 34, 35, 38, 39, 40, 41, 42, 45, 47, 49, 50, 51, 53, 54, 67, 68, 72, 79, 80, 83, 87, 96, 97, 108, 124, 127, 130, 131, 135, 137, 139, 144, 145, 147, 148, 150, 152, 153, 154, 155, 160, 163], "squar": [4, 18, 20, 24, 25, 27, 39, 42, 45, 47, 52, 53, 66, 67, 68, 72, 73, 76, 78, 79, 84, 87, 89, 95, 96, 97, 98, 102, 103, 106, 108, 111, 126, 128, 131, 134, 135, 136, 137, 155], "square_cube_list": 136, "square_loss": 39, "squared_loss": 39, "squeez": [81, 82], "sr": [148, 153], "ss06": [1, 2, 28, 37, 54, 57], "st": 64, "stabil": [6, 16, 39, 62, 73, 74, 86, 94, 124, 147, 148, 153], "stabl": [1, 38, 45, 66, 82, 94, 107, 134, 144], "stack": [0, 70, 74, 76, 77, 94, 135], "stacklevel": [51, 97], "stackoverflow": [74, 94, 139], "stackrel": [20, 34, 38], "staffwww": 78, "stage": [9, 11, 24, 35, 41, 45, 48, 64, 65, 144], "stai": [145, 146, 147, 155, 157, 163], "stan": [1, 41, 45, 73, 74, 154], "stanc": 8, "stand": [9, 11, 22, 39, 41, 65, 67, 134, 144, 149, 152], "standalon": 153, "standard": [3, 4, 15, 16, 20, 25, 26, 30, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 47, 49, 51, 54, 63, 64, 65, 66, 67, 68, 72, 73, 74, 75, 78, 79, 81, 82, 84, 86, 94, 95, 96, 102, 106, 108, 121, 122, 124, 127, 128, 130, 131, 134, 136, 139, 145, 146, 147, 148, 152, 153, 154, 159, 160, 162, 163], "standardize_data": 66, "standardscal": 124, "stanford": 76, "stapl": 16, "star": [49, 148, 153, 164], "start": [5, 6, 7, 9, 15, 16, 20, 26, 27, 31, 33, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 56, 66, 67, 68, 69, 72, 79, 80, 81, 82, 83, 87, 93, 94, 95, 96, 97, 98, 106, 111, 115, 118, 124, 126, 127, 130, 131, 134, 135, 136, 137, 138, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 155, 157, 160, 162, 163], "start_index": [150, 151], "start_new_sess": 127, "start_po": 145, "start_posit": 145, "start_stop_indic": [150, 151], "start_tim": 124, "starter": [17, 138], "starting_guess": [6, 39, 42, 97, 124, 148, 153], "startupinfo": 127, "startval": 152, "stat": [1, 5, 6, 9, 13, 20, 24, 30, 31, 34, 35, 38, 40, 43, 44, 50, 66, 70, 79, 83, 93, 97, 124, 127, 144, 145, 146, 148, 152, 153, 154, 155, 163], "state": [0, 4, 6, 7, 8, 9, 11, 17, 22, 23, 26, 32, 33, 39, 45, 46, 47, 48, 51, 54, 57, 62, 67, 68, 72, 74, 86, 89, 124, 125, 128, 131, 134, 144, 148, 149, 152, 153, 160, 162], "statement": [0, 8, 16, 18, 20, 21, 23, 32, 34, 35, 36, 44, 47, 54, 57, 63, 65, 66, 102, 111, 112, 131, 135, 136, 141, 159, 160], "static": [134, 135, 160], "stationar": [44, 45, 48, 144, 147, 162], "stationari": [44, 45, 46, 48, 72, 78, 80, 83, 84, 144, 147, 152, 154, 162], "statisc": 121, "statist": [1, 3, 4, 7, 9, 17, 18, 21, 24, 25, 26, 27, 28, 30, 31, 35, 37, 38, 40, 45, 46, 49, 52, 56, 57, 60, 61, 63, 65, 67, 68, 73, 74, 89, 90, 93, 95, 98, 103, 109, 114, 118, 119, 121, 125, 128, 134, 143, 146, 148, 153, 155, 157, 159, 160, 162, 163], "statistician": [0, 1, 44, 57, 122, 131, 160], "stats_random_numb": 131, "stats_titl": 43, "statu": [35, 82, 89, 124], "std": [17, 18, 34, 39, 42, 51, 66, 68, 72, 74, 79, 82, 83, 94, 127, 130, 131, 134, 137, 144, 146, 152, 162, 163], "std_predict": 81, "std_train_data": 66, "stddev": 130, "stderr": 127, "stdin": 127, "stdmv": 83, "stdout": 127, "stdperiod": [78, 84], "steadi": 160, "steadili": [67, 98], "stealthili": 64, "steep": 152, "steer": [65, 70], "stein": 155, "stem": [48, 54, 64, 65, 120], "step": [4, 6, 9, 15, 16, 17, 23, 25, 26, 31, 35, 37, 38, 39, 43, 45, 47, 50, 54, 61, 66, 68, 69, 70, 71, 73, 77, 80, 89, 91, 93, 97, 98, 106, 107, 108, 124, 126, 131, 133, 134, 135, 136, 137, 138, 139, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 160, 162, 163, 164], "step1": 152, "step2": 152, "step_fn": 71, "step_method": 152, "step_siz": 147, "stepfil": 145, "stepsiz": [51, 144, 147], "stereotyp": 64, "stern": 1, "stick": [8, 24, 45, 62, 135, 145, 155], "still": [3, 8, 32, 35, 42, 44, 46, 47, 48, 52, 65, 66, 67, 68, 74, 76, 86, 94, 111, 128, 133, 136, 143, 149, 151, 155], "stimuli": 68, "stirl": [4, 38], "stochast": [1, 35, 44, 49, 60, 68, 69, 72, 73, 74, 79, 83, 86, 87, 89, 98, 111, 117, 124, 131, 154, 161, 164], "stochasticprocess": [157, 162], "stochasticprocessexampl": 162, "stoke": 68, "stone": [8, 89], "stoner": 1, "stongli": [79, 83], "stop": [9, 20, 23, 81, 82, 135, 138, 149, 160], "stop_index": [150, 151], "stopiter": 127, "storag": 137, "store": [0, 35, 39, 46, 51, 70, 103, 108, 126, 134, 137, 138, 145], "stori": [96, 152], "storylin": 11, "str": [6, 70, 79, 83, 136], "straight": [24, 35, 37, 39, 54, 66, 71, 79, 95, 98, 103, 104, 106, 115, 147, 154, 155], "straightforward": [4, 17, 26, 34, 35, 39, 40, 44, 47, 48, 54, 68, 86, 113, 148, 153, 154], "straightforwardli": 39, "strainghtforward": 47, "strang": [26, 54], "strategi": [17, 32, 40, 44, 47, 48, 49, 52, 67, 72, 118, 147, 148, 149, 153], "street": 129, "strength": [7, 44, 47, 48, 52, 54, 63, 65, 81, 96, 97, 111, 118, 131, 134, 147, 155], "strerror": 127, "stress": [47, 67, 114, 118, 135, 157], "stretch": [128, 147], "strftime": 127, "strict": 20, "strictli": 68, "string": [22, 43, 78, 84, 124, 136, 139], "stringent": 154, "strive": 8, "stroke": 89, "strong": [17, 39, 44, 49, 52, 66, 68, 87, 122, 147], "strongli": [17, 44, 54, 64, 65, 66, 76, 79, 83, 134], "strprior": 6, "structur": [11, 16, 17, 35, 46, 47, 48, 52, 65, 66, 67, 68, 72, 76, 78, 80, 84, 118, 134, 137, 152, 154], "sts412": 1, "stuck": [32, 43, 52, 97, 128, 149, 154], "student": [0, 19, 20, 24, 33, 39, 42, 45, 57, 63, 122, 125, 131, 135], "student_t_animation_": 127, "student_t_animation_04sep2025": 127, "studi": [16, 17, 20, 41, 42, 44, 46, 47, 49, 54, 57, 63, 64, 65, 68, 90, 93, 98, 120, 145, 157, 162], "stumbl": 152, "sty": 0, "style": [0, 9, 43, 77, 97, 135, 150], "sub": [52, 63, 68, 74, 93, 137], "subclass": 77, "subdirectori": [0, 124, 138], "subfield": [65, 123], "subgradi": 1, "subject": [4, 8, 23, 39, 40, 44, 47, 62, 63, 73, 111, 131, 148, 153, 157, 162], "subplot": [0, 3, 6, 17, 18, 26, 30, 31, 34, 35, 39, 40, 41, 42, 45, 50, 51, 66, 70, 71, 74, 77, 78, 79, 82, 83, 84, 89, 94, 96, 103, 130, 131, 134, 135, 136, 139, 144, 145, 153, 154, 162, 163], "subplot2grid": 153, "subplot_kw": 131, "subplots_adjust": 34, "subprocess": 127, "subprocess_creation_flag": 127, "subroutin": 134, "subscript": [5, 25, 86, 151], "subsect": [21, 44, 49, 57, 135], "subsequ": [7, 26, 44, 46, 47, 57, 68, 72, 130, 157, 162], "subset": [45, 46, 47, 48, 49, 64, 67, 68, 75, 87, 90, 105, 131, 137, 145, 149, 155, 157, 162], "subshel": 134, "subspac": [1, 46, 48, 128], "substanti": [44, 64], "substitut": [4, 13, 17, 20, 48, 54, 72, 151], "subsum": 16, "subtask": 91, "subtl": [49, 64], "subtleti": [40, 148, 153], "subtract": [23, 43, 53, 67, 72, 98, 126, 137, 160], "succe": 16, "succeed": [73, 146, 163], "succes": 45, "success": [9, 11, 20, 31, 34, 38, 40, 66, 87, 89, 120, 124, 138, 146, 152, 155, 160, 163], "successfulli": [124, 143], "succinctli": [35, 101], "suffer": [48, 67, 69], "suffici": [5, 20, 39, 44, 48, 52, 71, 72, 74, 94, 152, 154, 159], "suggest": [43, 52, 57, 64, 67, 108, 128, 135, 138, 144, 145, 147, 154], "suit": [47, 68, 72, 124], "suitabl": [44, 46, 54, 72, 121], "sum": [5, 7, 9, 13, 15, 20, 24, 27, 31, 32, 35, 36, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 54, 66, 67, 68, 69, 70, 72, 73, 78, 79, 80, 84, 91, 93, 96, 97, 100, 101, 106, 107, 108, 118, 121, 124, 126, 127, 128, 131, 135, 136, 137, 144, 147, 148, 152, 153, 154, 157, 160, 162], "sum21": [1, 64], "sum_": [4, 13, 16, 20, 25, 30, 34, 35, 37, 39, 40, 41, 42, 45, 46, 48, 49, 50, 52, 53, 54, 66, 67, 68, 69, 73, 79, 83, 86, 89, 95, 96, 97, 98, 100, 101, 107, 108, 113, 114, 126, 128, 131, 144, 145, 147, 148, 152, 153, 154, 155, 157, 160, 162], "sum_0": 38, "sum_h": 86, "sum_i": [3, 4, 23, 26, 32, 33, 67, 73, 83, 155, 157], "sum_j": [23, 32, 33, 89, 128, 157], "sum_k": [15, 69, 128], "sum_n": 73, "sum_norm_squar": 30, "sum_of_squar": 136, "sum_xsq_val": 30, "summar": [4, 9, 17, 24, 25, 26, 31, 35, 44, 45, 47, 61, 67, 121, 131, 143, 160], "summari": [3, 4, 9, 18, 19, 28, 31, 39, 44, 45, 48, 52, 53, 57, 67, 69, 70, 71, 76, 77, 78, 84, 93, 95, 96, 118, 131, 132, 152, 153], "summaris": 47, "summat": [39, 45, 128, 145], "summer": [57, 78, 84], "sumpter": [1, 64], "sun": [8, 111], "sunil": [122, 124], "super": [72, 135], "superconductor": 131, "superfici": 76, "superflu": 48, "superior": [48, 136], "supermodel": 49, "supernova": 41, "superpos": [18, 34], "superposit": 1, "superscript": [68, 86], "supervis": [65, 67, 70, 89, 112, 134], "supplement": [63, 64, 89, 95, 117], "supplementari": [28, 39], "suppli": 68, "support": [1, 37, 44, 48, 52, 57, 64, 67, 74, 94, 96], "suppos": [4, 9, 13, 15, 16, 17, 20, 30, 32, 34, 38, 42, 49, 51, 53, 66, 68, 87, 89, 131, 135, 136, 147, 155, 157, 160], "supposedli": [65, 97], "suppress": [13, 20, 41, 49, 74, 79, 83, 87, 89, 94, 128, 133], "suptitl": [18, 34, 38, 43, 82, 145, 150, 151], "sure": [16, 18, 19, 25, 26, 30, 35, 38, 40, 83, 86, 93, 102, 126, 128, 133, 147, 148, 152, 153], "surf": 131, "surfac": [35, 38, 66, 98, 100, 106, 108, 131, 134, 149], "surmis": 123, "surpris": [17, 18, 31, 37, 40, 42, 52], "surprisingli": [148, 153], "surrog": [93, 123], "surround": [0, 44], "survei": 49, "susan": 99, "suspect": 39, "suspici": [9, 31], "suspicion": [9, 31, 39], "svd": [48, 80, 125], "svd_shape": 128, "svensson": [1, 45, 57], "svg": 128, "svgd": 155, "svisak": [45, 131, 162], "swap": 52, "swedish": 131, "swift": 65, "switch": [16, 34, 57, 74, 87, 94, 97, 126, 127, 128, 135, 139], "sword": 48, "sy": [39, 42, 51, 94, 124, 131, 144, 157, 162], "syllog": 63, "symbol": [9, 11, 35, 54, 73, 74, 86, 94, 100], "symmet": 149, "symmetr": [18, 19, 20, 37, 39, 41, 42, 45, 53, 54, 72, 73, 79, 83, 86, 128, 137, 144, 145, 149, 154, 155, 157], "symmetri": [16, 19, 24, 26, 44, 56, 72, 126, 149], "sympi": 38, "symplect": [45, 149], "synonym": 59, "syntax": [74, 94, 126, 135, 137], "syntaxerror": 135, "synthet": [18, 64, 81], "system": [1, 4, 8, 16, 47, 48, 52, 65, 68, 69, 89, 111, 112, 118, 120, 121, 122, 124, 149, 157, 162], "systemat": [7, 17, 49, 52, 61, 63, 64, 73, 98, 105, 118], "t": [1, 5, 8, 9, 11, 13, 15, 16, 17, 19, 20, 23, 24, 26, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 45, 46, 49, 50, 51, 52, 54, 57, 59, 62, 64, 65, 66, 67, 69, 71, 73, 74, 75, 78, 79, 82, 83, 84, 86, 87, 89, 94, 95, 96, 97, 98, 101, 102, 103, 104, 115, 116, 118, 122, 124, 125, 126, 128, 131, 133, 134, 135, 137, 138, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 160, 162, 163], "t0": 124, "t1_dist": 18, "t1_label": 18, "t2_dist": 18, "t2_label": 18, "t3_dist": 18, "t3_label": 18, "t_": [133, 157], "t_0": 124, "t_1": 162, "t_2": 162, "t_color": 127, "t_df": 127, "t_dist": 127, "t_dist_max": 127, "t_dist_pt": 127, "t_end": [150, 151], "t_eval": [150, 151], "t_i": [69, 162], "t_j": 69, "t_k": 162, "t_label": 127, "t_loc": 127, "t_max": 133, "t_max_w": 133, "t_min": 133, "t_min_w": 133, "t_n": 157, "t_nois": 124, "t_ob": 124, "t_old": 162, "t_pt": [133, 135, 150, 151], "t_scale": 127, "t_start": [150, 151], "t_test": 75, "t_train": 75, "t_x": 157, "t_y": 157, "tab": [5, 9, 11, 40, 57, 80, 81, 87, 128, 135, 137, 139, 148, 153, 160], "tab0": [9, 133], "tab1": [9, 133], "tab2": [9, 133], "tab3": [9, 133], "tab_height": [9, 133], "tabl": [1, 4, 21, 25, 33, 43, 50, 52, 54, 57, 64, 65, 80, 95, 96, 97, 134], "tablet": 135, "tabul": [134, 157], "tabular": 134, "tadess": 1, "tag": [0, 44, 74, 94, 124], "tail": [8, 9, 11, 12, 15, 16, 18, 19, 20, 26, 34, 39, 40, 43, 44, 45, 52, 53, 54, 127, 131, 153, 154, 162], "tak": 92, "take": [0, 4, 5, 6, 9, 11, 20, 23, 30, 32, 34, 35, 38, 39, 40, 41, 42, 43, 44, 48, 49, 50, 52, 53, 54, 57, 59, 61, 63, 64, 67, 68, 72, 73, 75, 76, 77, 79, 80, 82, 83, 87, 89, 92, 97, 118, 124, 128, 129, 130, 131, 132, 134, 135, 137, 138, 145, 146, 147, 148, 149, 152, 153, 154, 155, 157, 160, 162, 163], "taken": [4, 26, 30, 35, 38, 43, 48, 50, 57, 60, 61, 73, 79, 80, 87, 118, 121, 124, 137, 152], "taku": 74, "talent": [39, 40, 51, 57, 78, 96, 144, 145, 148, 153], "talk": [5, 9, 32, 39, 40, 41, 42, 43, 50, 51, 61, 71, 74, 78, 79, 87, 93, 94, 96, 123, 134, 135, 144, 145, 148, 152, 153], "tall": [17, 23, 32, 33, 111], "tan": [3, 35, 43, 50, 95, 103, 135], "tangent": [68, 118], "tangl": 20, "tanh": [68, 71, 72, 74, 89, 94, 130], "target": [45, 46, 47, 52, 65, 66, 68, 69, 71, 72, 73, 89, 124, 134, 137, 144, 147, 149, 155], "task": [7, 16, 18, 35, 38, 39, 43, 48, 50, 54, 63, 65, 66, 67, 68, 72, 73, 93, 94, 95, 96, 97, 111, 114, 128, 131, 135, 136, 137, 143, 154, 159], "tau": [45, 52, 145, 160], "tau_": 45, "tau_1": 52, "tau_2": 52, "tau_3": 52, "taught": [57, 60, 76, 128], "taylor": [1, 20, 35, 37, 50, 54, 92, 95, 150], "td": 43, "teach": 63, "teacher": 68, "tear": 1, "tech": [1, 68], "technic": 64, "techniqu": [1, 35, 52, 56, 65, 66, 67, 74, 95, 131, 149, 159], "technologi": [57, 64, 65, 105, 154], "techtarget": 90, "tediou": 17, "telescop": 63, "tell": [9, 10, 11, 16, 17, 18, 20, 23, 24, 26, 31, 32, 38, 50, 54, 59, 63, 67, 74, 80, 87, 94, 145, 147, 150, 155], "temp": [51, 97, 127], "temper": [51, 54, 91, 149, 164], "temperatur": [4, 45, 51, 52, 97, 131, 149], "tempering_ptemce": 52, "tempering_ptemcee_vs_zeu": 164, "tempor": 8, "temporarili": 24, "temps_hi": [51, 97], "temps_lo": [51, 97], "tempt": [41, 42, 116], "ten": [67, 73, 75, 93, 151, 154, 162], "tend": [9, 11, 20, 34, 43, 54, 65, 67, 69, 77, 108, 111, 131], "tendenc": [44, 64, 134, 154], "tension": [64, 67], "tensor": [74, 76, 77, 94, 130], "tensorflow": [1, 65, 67, 71, 72, 73, 74], "tensorflow_vers": 77, "term": [4, 9, 15, 16, 17, 20, 22, 26, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 59, 63, 64, 65, 66, 67, 68, 72, 73, 74, 86, 89, 90, 92, 100, 101, 102, 103, 107, 111, 116, 118, 119, 122, 124, 126, 128, 131, 134, 135, 137, 144, 145, 148, 149, 153, 157, 164], "termin": [35, 115, 124, 135, 162], "terminologi": [54, 64], "terribl": 32, "territori": 54, "test": [0, 5, 20, 23, 32, 33, 34, 35, 39, 44, 48, 50, 51, 52, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 83, 87, 94, 96, 97, 120, 121, 122, 128, 131, 135, 144, 146, 154, 157, 161, 162, 163], "test_acc": [70, 77], "test_f": 135, "test_imag": 77, "test_label": 77, "test_loss": [70, 77], "test_poisson_pt": 34, "test_siz": [74, 75], "test_valu": [74, 94], "testimoni": 8, "testinput": [65, 66, 67], "testinputs_i": 66, "testoutput": [65, 66, 67], "testval": [74, 94], "tex": 140, "text": [0, 1, 4, 9, 10, 11, 12, 13, 15, 16, 17, 20, 22, 24, 25, 26, 31, 32, 35, 37, 38, 39, 42, 43, 44, 45, 47, 48, 49, 52, 53, 54, 57, 58, 59, 61, 64, 66, 67, 68, 83, 91, 93, 96, 100, 105, 118, 127, 128, 131, 133, 135, 144, 147, 149, 154, 155, 157, 159, 160, 164], "text_i": [18, 127], "text_mod": 127, "text_represent": 0, "text_x": [18, 127], "text_x_mid": [18, 127], "textbf": [18, 79, 152], "textbook": [26, 47, 57, 67], "textbox0": [9, 133], "textbox1": [9, 133], "textiowrapp": 127, "textit": [37, 52], "textrm": [9, 18, 24, 31, 41, 42, 43, 50, 72, 96, 144, 152], "texttt": 122, "textur": 49, "tf": [70, 71, 77], "tf_cpp_min_log_level": 70, "th": [0, 3, 9, 11, 30, 34, 35, 37, 41, 43, 49, 50, 51, 67, 68, 69, 89, 95, 97, 108, 121, 131, 144, 155, 157, 159], "th0": 39, "th0_mcmc": 39, "th0neg": 39, "th0po": 39, "th1": [6, 39], "th1_mcmc": 39, "th1neg": 39, "th1po": 39, "than": [4, 7, 8, 9, 12, 17, 18, 19, 20, 23, 24, 26, 30, 31, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 61, 63, 64, 66, 67, 68, 72, 73, 74, 78, 79, 80, 83, 84, 89, 94, 96, 97, 98, 100, 103, 105, 106, 111, 118, 120, 121, 122, 124, 126, 128, 129, 131, 134, 135, 136, 137, 144, 145, 147, 148, 152, 153, 154, 155, 159, 160, 162], "thank": [57, 134, 138], "theano": [94, 159], "theanof": [74, 94], "theanorc": 74, "thei": [0, 7, 8, 9, 15, 16, 18, 19, 20, 22, 23, 24, 31, 32, 33, 35, 37, 44, 45, 46, 47, 48, 49, 52, 53, 60, 61, 62, 63, 64, 65, 67, 68, 69, 73, 74, 76, 77, 78, 79, 84, 87, 92, 99, 103, 105, 111, 115, 118, 120, 126, 127, 128, 130, 131, 134, 135, 137, 144, 145, 147, 149, 152, 154, 157, 160], "them": [4, 7, 16, 17, 20, 23, 24, 26, 30, 32, 35, 38, 39, 40, 41, 44, 45, 46, 48, 49, 51, 53, 54, 59, 60, 64, 65, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 83, 84, 93, 94, 96, 97, 120, 124, 128, 131, 134, 135, 137, 138, 139, 143, 145, 148, 149, 153, 157], "theme": [48, 73], "themselv": [26, 44, 48, 54, 63, 112, 134], "theorem": [7, 8, 9, 10, 13, 16, 17, 21, 25, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 43, 44, 45, 50, 52, 53, 54, 59, 63, 68, 73, 86, 130, 143, 148, 149, 152, 153, 154, 155, 157, 159], "theoret": [0, 3, 7, 18, 24, 26, 30, 39, 40, 41, 42, 44, 50, 52, 56, 60, 63, 112, 118, 120, 121, 122, 124, 125, 144, 148, 153, 155], "theori": [1, 4, 7, 8, 16, 20, 22, 25, 30, 34, 35, 41, 42, 44, 45, 47, 50, 52, 54, 57, 59, 60, 61, 62, 63, 65, 66, 68, 73, 80, 89, 90, 92, 95, 116, 118, 120, 122, 125, 127, 129, 131, 144, 148, 153, 155, 158, 161, 162], "theorist": 54, "thereaft": 134, "therebi": [46, 47, 48, 65, 66, 83, 89, 120, 134], "therefor": [4, 8, 17, 22, 24, 26, 30, 32, 35, 40, 42, 44, 46, 47, 49, 53, 54, 59, 63, 65, 66, 67, 68, 73, 79, 86, 87, 89, 97, 101, 105, 108, 111, 112, 114, 116, 131, 134, 137, 154, 157], "thermodynam": [52, 54, 145, 149], "thesi": 1, "theta": [0, 3, 6, 7, 9, 17, 20, 31, 35, 39, 41, 42, 43, 45, 49, 50, 54, 66, 67, 73, 78, 79, 82, 84, 86, 93, 96, 98, 103, 124, 128, 131, 144, 148, 152, 153, 155], "theta0": [39, 144], "theta1": [39, 144], "theta2": 39, "theta3": 39, "theta_": [17, 51, 86, 96, 128, 144, 154, 155], "theta_0": [3, 39, 41, 42, 51, 54, 102, 103, 144, 147, 154], "theta_1": [3, 39, 41, 42, 51, 102, 103, 144, 154, 155], "theta_2": 155, "theta_and_phi": 124, "theta_dist": 43, "theta_hat": 96, "theta_i": [54, 67, 96, 155, 160], "theta_j": [30, 54, 96, 128, 152], "theta_k": [43, 49, 128, 160], "theta_max": 96, "theta_min": 96, "theta_ml": [39, 42], "theta_n": 155, "theta_ol": [35, 66, 103], "theta_tru": [35, 41, 50, 103, 144], "thetavec": [9, 10, 24, 31, 52, 53, 80, 87, 126, 128, 147, 149, 155], "thetavec_": [52, 126, 128, 155, 160], "thetavec_0": 160, "thetavec_1": 155, "thetavec_2": 155, "thetavec_a": 155, "thetavec_b": 155, "thetavec_i": 155, "thetavec_j": 126, "thetavec_k": [126, 160], "thetavechat": 126, "thetavechat_": 126, "thetavechat_j": 126, "thi": [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 161, 162, 163, 164], "thick": 52, "thicker": 52, "thim": 57, "thin": [51, 52, 97, 153], "thing": [0, 5, 8, 9, 10, 11, 16, 18, 20, 23, 30, 31, 32, 34, 44, 52, 54, 59, 63, 72, 74, 87, 94, 135, 149], "think": [4, 8, 11, 15, 16, 26, 32, 34, 35, 41, 49, 54, 63, 64, 65, 67, 68, 70, 74, 78, 84, 87, 96, 102, 118, 131, 143, 145, 146, 155, 157, 162, 163], "third": [0, 1, 4, 16, 17, 18, 26, 33, 35, 47, 57, 65, 72, 74, 76, 79, 83, 94, 134, 145, 151, 157], "thirteenth": 54, "thisplot": [70, 77], "thoma": [8, 74, 94, 145], "thorough": [30, 47, 62], "those": [7, 8, 9, 18, 24, 26, 31, 35, 38, 44, 45, 47, 49, 52, 57, 60, 61, 63, 64, 67, 68, 72, 75, 79, 86, 95, 98, 106, 122, 128, 131, 148, 153], "though": [0, 5, 12, 23, 40, 63, 65, 73, 122, 148, 153, 160], "thought": [7, 8, 17, 53, 54, 67, 86, 126], "thousand": [46, 65, 68, 73], "thread": [51, 97, 124], "three": [0, 1, 3, 6, 8, 9, 11, 16, 17, 18, 19, 24, 30, 33, 35, 37, 38, 42, 44, 45, 48, 49, 52, 54, 57, 62, 66, 67, 68, 69, 72, 73, 75, 76, 78, 84, 89, 94, 96, 97, 113, 116, 118, 122, 126, 127, 128, 131, 134, 135, 137, 145, 152, 157], "threlkeld": 1, "threshold": [44, 54, 68, 76, 89, 128, 162], "through": [0, 4, 7, 9, 14, 16, 17, 18, 23, 24, 26, 28, 31, 34, 35, 37, 39, 42, 43, 44, 47, 48, 49, 50, 54, 57, 59, 68, 69, 70, 72, 76, 77, 78, 79, 80, 83, 84, 86, 87, 89, 90, 91, 96, 97, 104, 118, 121, 126, 135, 138, 144, 145, 146, 147, 149, 151, 155, 159, 163], "throughout": [16, 24, 45, 49, 57, 59, 63, 96, 134], "throw": [4, 42, 45, 128, 152], "thu": [11, 17, 24, 35, 39, 42, 45, 48, 49, 53, 54, 59, 64, 65, 67, 68, 69, 74, 106, 121, 128, 131, 147, 150], "thumb": 30, "thursdai": 8, "thusfar": 16, "th\u00e9ori": 35, "tibshirani": 1, "tick": [9, 43, 44], "tick_param": 34, "tight": [9, 74, 94, 127, 150, 151], "tight_layout": [5, 17, 18, 30, 34, 38, 40, 41, 42, 43, 50, 51, 66, 70, 74, 77, 78, 79, 82, 83, 84, 94, 96, 127, 128, 130, 136, 144, 145, 146, 150, 151, 153, 163], "tighter": [47, 122], "tikhonov": 81, "tild": [17, 35, 45, 46, 53, 66, 67, 80, 87, 89, 98], "tildecovparslr": 35, "tile": [83, 97], "time": [4, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 20, 23, 24, 26, 30, 31, 32, 33, 34, 35, 37, 38, 39, 42, 43, 45, 46, 48, 50, 51, 52, 53, 54, 57, 64, 66, 67, 68, 70, 74, 76, 77, 78, 79, 80, 81, 83, 84, 86, 87, 89, 93, 94, 95, 97, 100, 101, 107, 108, 115, 116, 118, 121, 122, 123, 124, 126, 127, 128, 131, 133, 134, 136, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 155, 157, 162, 163, 164], "timeit": [74, 136], "times_overview_text": 133, "times_overview_text_w": 133, "times_text": 133, "timestep": [45, 137], "titl": [0, 20, 57, 72, 74, 77, 78, 81, 82, 84, 94, 135, 145, 148, 150, 152, 153], "title_fmt": 97, "title_kwarg": [18, 39, 51, 97, 124, 144, 148, 153], "title_loc": 131, "title_str": [18, 34, 43], "tmax": [51, 97], "tmp": [38, 39, 78, 83, 134, 152], "tmp2": [79, 83], "tn": [64, 65], "to_numer": 134, "to_numpi": [35, 103], "toal": 19, "toc": 57, "todai": [16, 50, 65, 127, 129, 131, 157], "togeth": [20, 26, 28, 32, 39, 40, 41, 42, 49, 50, 67, 70, 73, 74, 75, 78, 83, 84, 87, 96, 97, 134, 144, 148, 153, 160], "toggl": [57, 124], "toi": [40, 48, 74, 91, 92, 94, 148, 153], "token": 54, "tol": [5, 51, 71], "told": [4, 16, 23, 32, 149], "toler": 5, "tolist": 137, "tomorrow": [8, 16, 18, 24, 131, 157], "tone": 59, "tonight": 22, "too": [20, 30, 32, 44, 45, 54, 63, 64, 72, 80, 95, 106, 145, 147, 149, 155, 160], "took": [134, 152, 153], "tool": [1, 7, 23, 35, 41, 42, 49, 57, 59, 60, 64, 65, 74, 96, 103, 106, 118, 126, 134, 135, 144], "toolbar": 135, "tooltip": 9, "top": [0, 1, 4, 9, 20, 26, 34, 43, 45, 52, 54, 57, 74, 78, 84, 95, 96, 128, 133, 135, 145, 150, 157, 162], "topic": [8, 44, 56, 65, 89, 90, 95, 148, 153, 162], "topologi": [68, 155], "tor": 57, "torch": [72, 130], "torchvis": 72, "torqu": 52, "torsion": 52, "toss": [8, 12, 13, 15, 20, 24, 162], "toss_coin_text": 9, "tot_val": 30, "total": [6, 20, 26, 32, 33, 35, 38, 39, 42, 45, 47, 49, 51, 64, 68, 69, 70, 72, 76, 77, 89, 94, 107, 118, 124, 128, 131, 134, 135, 144, 148, 149, 152, 153], "total_count": 38, "total_draw": 34, "total_huber_loss": 39, "total_length": 152, "total_s": [74, 94], "total_sampl": 51, "totalenergi": 134, "touch": [16, 95], "tough": 155, "tour": 135, "toward": [16, 54, 59, 63, 69, 73, 79, 89, 111, 144, 152], "tower": [122, 124], "tp": [64, 65], "tr": 43, "trace": [39, 42, 44, 45, 48, 51, 72, 74, 97, 139, 144, 145, 146, 147, 152, 155, 160, 163], "trace1": 42, "trace2": 42, "trace_2_sampl": 152, "trace_arrai": 152, "trace_inferencedata": 152, "trace_mh": 152, "trace_nut": [152, 153], "trace_titl": [146, 163], "trace_two_param": 152, "trace_unord": 97, "traceabl": 61, "traceback": [51, 70, 71, 74, 94, 97, 127], "traceplot": 74, "track": [23, 46, 54], "tractabl": [7, 35], "traction": 65, "trade": [93, 149], "tradeoff": 98, "tradit": [8, 65, 74, 117], "tradition": [63, 120], "train": [48, 61, 63, 65, 68, 69, 71, 72, 74, 75, 76, 79, 80, 81, 82, 83, 87, 89, 90, 92, 94, 96, 98, 107, 112, 114, 118, 124, 130], "train_data": 66, "train_imag": 77, "train_label": 77, "train_test_split": [74, 75, 94, 134], "trainabl": [68, 70, 77], "training_err": 96, "training_indic": 81, "trainingdata": [65, 66, 67], "trainingdata_n": 67, "trajectori": [45, 46, 48, 51], "tran": [35, 73, 74], "tranform": 147, "transact": 138, "transax": [17, 26, 31, 96], "transfer": 74, "transform": [3, 4, 17, 26, 31, 49, 54, 66, 68, 70, 73, 89, 96, 128, 147, 150, 154], "transit": [38, 39, 48, 68, 96, 145, 154, 155, 157, 160, 162], "translat": [4, 18, 20, 23, 36, 38, 43, 44, 47, 54, 118, 120, 131, 147, 149], "translation": 86, "transmiss": [66, 89], "transmit": 68, "transpar": [8, 44, 62, 64, 67, 74, 93, 94, 95, 135], "transpos": [126, 128, 137, 139, 157], "trapezoid": [97, 147], "trapz": [26, 31, 34, 97], "travel": [116, 149, 162], "travers": [67, 68, 137], "treat": [16, 29, 39, 44, 48, 56, 105, 118, 124, 149], "treatment": [29, 47, 54, 90, 97, 117, 118, 125], "tree": [68, 74], "tremend": [48, 57], "trend": [34, 44, 64, 73, 80, 122, 160], "trevor": 67, "tri": [16, 152], "trial": [9, 20, 22, 30, 46, 48, 65], "triangular": 34, "tribal": 74, "trick": [73, 74, 78, 84, 94, 145, 154], "tricki": 52, "trickier": 155, "trig": 135, "trigger": [68, 157], "trigonometr": [72, 113, 135], "trivia": [0, 24], "trivial": [8, 16, 34, 41, 66, 131, 155], "tro08": [1, 28, 52], "trotta": [1, 28, 52, 96], "troubl": [5, 64, 69, 149, 160], "troublesom": 54, "truck": [65, 77], "true": [3, 5, 6, 9, 11, 12, 15, 16, 17, 18, 20, 22, 23, 24, 26, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 51, 54, 59, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 77, 78, 79, 81, 82, 83, 84, 86, 89, 91, 93, 94, 95, 96, 97, 103, 111, 112, 121, 122, 124, 127, 128, 130, 131, 133, 135, 136, 137, 143, 144, 145, 147, 148, 151, 152, 153, 154, 157, 159, 162], "true_func": 96, "true_height": 124, "true_label": [70, 77], "true_model": 49, "true_param": [35, 103], "truli": [35, 40, 44, 49, 57, 64, 148, 153], "truncat": [16, 17, 35, 54, 113, 126, 128], "trunk": 105, "trust": [9, 31, 44, 71], "trustworthi": 64, "truth": [8, 22, 26, 54, 65, 83, 97, 111, 122, 148, 153], "truths_corn": 97, "try": [4, 8, 9, 11, 13, 15, 16, 18, 20, 24, 31, 32, 34, 35, 37, 38, 40, 41, 42, 49, 52, 54, 66, 67, 71, 77, 78, 80, 84, 87, 89, 91, 93, 95, 96, 97, 103, 120, 124, 127, 128, 133, 135, 136, 137, 143, 144, 145, 147, 148, 150, 151, 152, 153, 154, 155, 159, 160, 163], "tumor": 89, "tune": [45, 48, 67, 68, 72, 98, 106, 108, 118, 144, 147, 149, 152, 153, 154, 155, 160, 164], "tungsten": 52, "tuning_step": 152, "tupl": [130, 136, 137], "turn": [1, 4, 9, 17, 18, 20, 35, 40, 43, 45, 53, 64, 65, 69, 74, 94, 96, 97, 101, 112, 116, 125, 128, 131, 134, 135, 145, 148, 149, 151, 152, 153, 154, 155, 160], "tutori": [1, 38, 40, 43, 57, 70, 72, 74, 77, 79, 83, 137, 148, 153], "tweak": [43, 72, 98, 127], "twentieth": 63, "twice": [32, 126, 144, 145], "twiecki": [74, 94], "twist": 52, "two": [0, 1, 3, 4, 7, 8, 9, 11, 13, 15, 16, 18, 20, 23, 25, 26, 27, 30, 38, 39, 40, 41, 44, 45, 46, 48, 50, 52, 53, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 81, 83, 84, 86, 87, 93, 94, 95, 96, 97, 102, 103, 104, 105, 111, 118, 121, 122, 126, 131, 134, 135, 136, 137, 138, 141, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 159, 162, 163, 164], "two_param_model": 152, "tx": 128, "txt": [79, 83, 134], "ty": 128, "type": [0, 11, 16, 35, 44, 46, 48, 51, 52, 61, 70, 72, 74, 76, 77, 78, 84, 86, 90, 94, 95, 96, 97, 103, 111, 120, 124, 133, 134, 135, 136, 138, 149, 155, 162], "typeerror": 66, "typic": [4, 24, 35, 39, 44, 45, 48, 49, 50, 52, 61, 64, 68, 72, 76, 77, 83, 86, 89, 103, 106, 107, 111, 119, 120, 126, 127, 128, 146, 149, 152, 155, 160, 163], "u": [1, 4, 6, 7, 8, 9, 10, 16, 17, 18, 20, 23, 24, 26, 31, 32, 35, 38, 39, 40, 42, 45, 46, 47, 49, 50, 51, 52, 54, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 76, 78, 79, 80, 82, 83, 84, 86, 87, 89, 94, 96, 97, 98, 102, 103, 108, 114, 122, 126, 128, 131, 134, 135, 137, 138, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 160, 162, 163], "u_": [87, 126, 128], "u_0": 87, "u_1": [52, 87, 131], "u_deriv": 151, "u_i": [54, 154], "u_n": 131, "u_pt": 151, "u_shap": 128, "ua": 134, "ucf": 151, "ucf_deriv": 151, "ucf_pt": 151, "ud": 32, "udat": 74, "ueff": 151, "ueff_deriv": 151, "ueff_pt": 151, "ui": 139, "ui_box": [9, 133], "uid": 127, "uint8": [70, 77], "uk": [1, 51, 57, 78, 144, 145], "ul": [9, 133], "ultim": [24, 32, 49, 98, 107], "umask": 127, "un": 44, "unabl": 71, "unaccept": 45, "unaffect": 128, "unambigu": 62, "unawar": [16, 64], "unbalanc": 67, "unbias": [40, 144, 148, 153, 162], "unbow": 63, "unc": 134, "uncertain": [7, 8, 16, 35, 73, 74, 102, 127, 131, 162], "uncertainti": [0, 1, 4, 8, 16, 17, 18, 24, 26, 35, 42, 44, 45, 46, 47, 48, 49, 50, 52, 54, 57, 80, 81, 86, 111, 112, 114, 120, 121, 123, 124, 127, 143, 144, 147, 155], "unchalleng": 80, "unchang": [69, 76, 149], "unchart": 54, "uncheck": 138, "uncolor": 155, "uncom": 124, "uncontrain": 53, "uncontrol": 64, "uncorrel": [37, 42, 51, 73, 79, 80, 83, 121, 124, 131, 147, 149, 160], "uncov": 44, "under": [3, 4, 8, 9, 10, 16, 17, 19, 20, 30, 45, 46, 49, 52, 54, 57, 65, 67, 72, 77, 87, 96, 97, 98, 122, 130, 133, 135, 138, 144, 157, 160, 164], "underappreci": 74, "underbrac": [4, 9, 10, 24, 31, 53], "underestim": [42, 112, 144], "underfit": [72, 96, 98], "undergird": 49, "undergo": 65, "underground": 63, "underli": [7, 30, 35, 44, 45, 46, 48, 49, 50, 61, 64, 66, 67, 68, 78, 80, 84, 91, 95, 103, 120, 144, 147], "underrepresent": 64, "underscor": 135, "underset": [53, 67, 86, 93, 105], "underst": 26, "understand": [8, 11, 18, 43, 44, 46, 48, 50, 54, 59, 61, 63, 65, 66, 67, 68, 72, 76, 105, 118, 120, 126, 128, 143, 146, 157, 162, 163], "understood": [24, 35, 44, 49, 59, 64, 65, 68, 74, 118, 124, 131, 154, 157], "undetect": 65, "undoubtedli": 63, "undul": 48, "unduli": 49, "unemploy": 26, "unequ": 136, "unessenti": 125, "unexpect": [41, 54, 147], "unexpected": 54, "unfair": [9, 15, 26, 31, 64], "unfairli": 47, "unfortun": [8, 45, 69, 73, 74, 111], "uni": [81, 82], "uni_dist": 34, "uni_dist_pt": 34, "uni_gauss_pt": 34, "uni_max": 34, "uni_min": 34, "unicode_liter": 77, "unif": 62, "uniform": [3, 4, 5, 6, 9, 11, 12, 17, 20, 26, 30, 31, 34, 37, 38, 39, 41, 42, 43, 44, 45, 50, 51, 52, 54, 72, 80, 82, 93, 96, 97, 103, 121, 124, 144, 145, 146, 150, 153, 155, 157, 160, 162, 163, 164], "uniform_1": [146, 163], "uniform_2": [146, 163], "uniformli": [6, 34, 37, 43, 48, 72, 78, 83, 84, 131, 143, 154, 155, 164], "uniformpropos": 152, "uniformsampl": 3, "unifrompdf": 131, "unimod": [19, 20, 47], "uninform": [11, 38, 50], "uninterest": 131, "union": [23, 49, 67, 131], "uniqu": [17, 19, 26, 45, 111, 114, 118, 131, 154, 157], "unit": [24, 35, 41, 43, 45, 61, 68, 69, 70, 72, 74, 94, 97, 131, 134, 154], "uniti": [16, 38, 54, 79, 96, 131], "unitless": [121, 122, 127], "univari": [44, 45, 83, 86, 111, 131, 152, 157, 162], "univers": [1, 8, 17, 48, 49, 57, 65, 68, 76, 80, 128, 131], "universal_newlin": 127, "unknown": [20, 23, 32, 35, 38, 44, 47, 54, 67, 86, 97, 102, 103, 121, 125, 130, 152, 159], "unknowwn": 69, "unlabel": 68, "unless": [4, 16, 47, 48, 53, 54, 72, 77, 105, 125, 134, 144, 145, 152, 154, 157, 160], "unlik": [24, 34, 38, 41, 54, 76, 135, 143, 154], "unlock": 74, "unlov": 46, "unnecessarili": [68, 148, 153], "unnorm": [13, 37, 43, 45, 54, 145, 160], "unobserv": 35, "unpack": [49, 79, 83], "unreason": [54, 118], "unrol": 77, "unround": 134, "unsatisfi": 63, "unscal": 96, "unseen": 89, "unshift": [144, 145], "unsort": 42, "unspecifi": 70, "unsqueez": 72, "unstabl": [66, 69, 80, 87], "unstack": 70, "unsupervis": [65, 68, 74], "unsur": 43, "until": [20, 64, 68, 69, 72, 89, 98, 106, 122, 145, 146, 152, 154, 155, 160, 163], "unverifi": 62, "unwant": 26, "up": [0, 4, 8, 11, 12, 16, 20, 24, 27, 34, 37, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 57, 61, 63, 64, 65, 66, 70, 72, 73, 74, 83, 94, 102, 103, 108, 112, 118, 121, 126, 127, 128, 130, 131, 132, 134, 135, 137, 138, 139, 144, 145, 146, 147, 148, 152, 155, 159, 160, 161, 163], "updat": [1, 5, 11, 12, 13, 15, 24, 26, 28, 34, 35, 38, 44, 45, 49, 50, 57, 59, 60, 63, 67, 68, 69, 70, 71, 72, 73, 74, 78, 79, 84, 93, 94, 106, 107, 108, 121, 133, 135, 145, 147, 149, 150, 151, 154, 157, 162], "update_n": 9, "update_plot": [9, 133], "update_prob_head": 9, "update_t_max": 133, "uphil": [98, 152], "uphold": 62, "upon": [16, 20, 22, 39, 44, 48, 49, 59], "upper": [9, 18, 34, 43, 50, 52, 54, 57, 73, 82, 124, 127, 138, 151, 153], "uq": [48, 123], "url": 1, "us": [0, 1, 3, 5, 6, 8, 9, 10, 11, 13, 15, 16, 18, 19, 24, 25, 26, 27, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 77, 78, 79, 80, 81, 82, 83, 87, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 111, 113, 115, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 130, 131, 132, 133, 134, 135, 136, 137, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 162, 163, 164], "usag": [0, 72, 134], "usecol": 134, "usefulli": 49, "uselatex": 127, "user": [11, 39, 42, 45, 51, 64, 82, 87, 94, 108, 127, 130, 135, 138, 144, 152, 154, 162], "user_nam": 137, "userwarn": [51, 124, 153], "usetex": 124, "usr": [51, 82, 97, 127, 153], "usual": [0, 2, 4, 17, 20, 23, 25, 26, 30, 33, 35, 39, 44, 46, 47, 48, 49, 50, 53, 54, 61, 65, 66, 67, 68, 72, 73, 74, 83, 86, 89, 94, 98, 101, 107, 111, 112, 126, 128, 131, 134, 135, 145, 147, 149, 154], "util": [45, 65, 68, 78, 83, 105, 113, 120, 127, 131, 157, 162], "utmost": 65, "uvec": 87, "v": [17, 18, 34, 37, 39, 42, 48, 53, 79, 83, 97, 105, 115, 116, 122, 124, 126, 128, 135, 136, 139, 150, 152, 153, 155], "v0": [0, 17, 42, 124], "v1": [97, 128, 133], "v12": 1, "v2": [44, 128], "v3": 97, "v5": [152, 153], "v_": [17, 42, 48, 49, 126, 128], "v_0": [17, 46, 80, 122, 124], "v_1": 49, "v_1v_2": 49, "v_2": 49, "v_d": 154, "v_i": 46, "v_shape": 128, "v_t": [115, 116], "v_tran": 128, "va": [18, 34, 96, 150, 151], "vaiidat": 67, "vain": 54, "val": [65, 67], "val_accuraci": 77, "val_loss": 77, "vale": 4, "valid": [0, 30, 44, 45, 48, 52, 59, 60, 64, 65, 68, 78, 79, 83, 84, 86, 98, 105, 120, 122, 124, 154, 155], "validation_data": 77, "vallei": 106, "valu": [3, 4, 5, 9, 10, 11, 13, 16, 17, 18, 19, 23, 26, 28, 31, 34, 35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 83, 84, 86, 87, 89, 90, 93, 95, 96, 102, 103, 104, 105, 108, 111, 112, 114, 118, 120, 121, 122, 124, 125, 127, 128, 130, 134, 135, 136, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 155, 157, 160, 162, 163, 164], "valuabl": [126, 135, 137], "valueconstraintsprior": 79, "valueerror": [38, 124, 130, 148, 153], "van": [1, 44, 67], "van16": [1, 67], "vander": [35, 103], "vandermond": [35, 101, 103], "vanderpla": [1, 67, 81], "vandschootdk": [1, 44], "vanish": [69, 72, 118], "vannucci": 1, "var": [17, 18, 25, 45, 46, 47, 67, 78, 84, 97, 131, 137, 144, 152, 154], "var2": 18, "var_chain": 144, "var_lnl": 97, "var_nam": 153, "var_theta": 144, "varabl": 47, "varepsilon": [17, 41, 45, 49, 86, 97, 108], "varepsilon_": 49, "varepsilon_i": [41, 42, 50, 144], "vari": [20, 37, 38, 44, 46, 48, 52, 65, 66, 80, 96, 116, 121, 127, 130, 155], "variabl": [3, 4, 7, 11, 16, 20, 23, 24, 25, 26, 27, 32, 33, 35, 38, 39, 40, 44, 45, 53, 54, 60, 62, 64, 65, 66, 67, 68, 73, 74, 79, 81, 83, 87, 89, 92, 94, 100, 101, 103, 105, 108, 110, 111, 113, 114, 115, 116, 120, 122, 127, 128, 134, 135, 136, 137, 144, 146, 148, 149, 152, 153, 154, 157, 159, 162, 163, 164], "varianc": [1, 17, 18, 20, 25, 30, 34, 35, 38, 39, 40, 42, 44, 47, 49, 51, 66, 68, 72, 73, 78, 79, 80, 81, 83, 84, 86, 87, 89, 93, 96, 97, 98, 101, 102, 103, 104, 107, 121, 124, 125, 127, 128, 130, 134, 144, 146, 147, 148, 149, 152, 153, 154, 155, 159, 163], "variance3": 79, "variant": [24, 68, 96, 151, 154], "variat": [1, 4, 35, 39, 45, 46, 47, 48, 52, 65, 66, 67, 80, 98, 106, 111, 120, 128, 134, 144, 147, 152, 154, 155], "varieti": [39, 56, 68, 137, 152], "variou": [0, 16, 19, 26, 32, 34, 36, 47, 48, 57, 59, 65, 71, 72, 74, 75, 89, 95, 105, 111, 112, 132, 134, 161], "varphi": 7, "varz": 83, "vast": [46, 64], "vastli": 76, "vbox": [5, 9, 133], "vdot": [35, 53, 101, 128, 157, 162], "ve": [11, 18, 28, 30, 32, 39, 41, 53, 78, 79, 84, 128, 146, 147, 149, 152, 155, 163], "vec": [24, 86, 97], "vecor": 101, "vector": [5, 7, 9, 10, 24, 31, 35, 37, 39, 41, 42, 45, 46, 48, 50, 51, 53, 54, 66, 67, 69, 71, 73, 74, 76, 77, 78, 79, 83, 84, 86, 87, 89, 93, 94, 96, 97, 98, 101, 102, 106, 107, 108, 111, 118, 121, 124, 126, 128, 130, 131, 134, 136, 137, 139, 144, 147, 148, 149, 150, 151, 153, 154, 155, 157, 162], "vee": [74, 94], "veen": 1, "vega": 155, "vehicl": 65, "vehtari": [1, 52], "veloc": [17, 42, 115, 116, 122, 124], "venn": 8, "ventur": 65, "venv": 138, "verbos": [35, 66, 70, 71, 77, 103], "verdict": [8, 63], "veri": [4, 7, 8, 9, 16, 26, 33, 34, 35, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 54, 57, 63, 65, 66, 67, 68, 72, 73, 74, 76, 77, 79, 80, 83, 86, 87, 95, 97, 98, 101, 102, 105, 106, 111, 112, 131, 134, 136, 144, 145, 148, 149, 152, 153, 154, 155, 157, 160, 162, 164], "verif": 44, "verifi": [3, 13, 17, 20, 35, 38, 40, 43, 44, 54, 64, 70, 128, 131, 137, 138, 143, 151, 153, 154, 157], "vernon": [1, 57], "versa": [131, 157], "version": [16, 20, 24, 25, 29, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 50, 51, 52, 63, 65, 67, 68, 70, 71, 74, 77, 86, 89, 94, 108, 122, 124, 127, 128, 134, 135, 138, 140, 144, 145, 146, 147, 149, 152, 153, 154, 155, 163], "versu": [39, 53, 64, 79, 83], "vert": [31, 35, 46, 67, 89, 128, 131, 157, 160, 162], "vert_1": 67, "vert_2": 67, "vertic": [4, 9, 18, 38, 54, 95, 145], "verticalalign": [9, 43], "vgb10": [1, 47], "vgb14": [1, 47], "via": [4, 17, 28, 35, 42, 44, 45, 46, 47, 48, 49, 65, 67, 68, 69, 72, 73, 76, 89, 91, 92, 96, 103, 111, 124, 126, 131, 136, 138, 139, 143, 144, 152, 154, 155, 157], "viabl": 64, "vice": [131, 157], "vicin": 52, "video": [64, 68, 127], "vien": 57, "view": [9, 24, 26, 31, 39, 40, 41, 44, 54, 57, 62, 65, 67, 68, 73, 77, 129, 134, 137, 148, 153, 157], "view_init": 66, "viewpoint": [46, 117, 131], "vincent": 81, "violat": [8, 20], "virtu": [17, 58, 60], "virtual": [69, 138], "viru": 138, "visibl": 17, "vision": [65, 72], "visit": [145, 154], "visual": [17, 20, 27, 35, 38, 39, 40, 42, 44, 45, 48, 52, 54, 65, 66, 68, 71, 72, 74, 76, 78, 84, 87, 89, 103, 127, 128, 134, 144, 145, 147, 153, 157, 162], "vlg": [1, 47], "vline": [40, 42, 153], "vm": 42, "vmatrix": 3, "vmax": 66, "vmeasur": 42, "vmin": 66, "vocabulari": [18, 33, 41], "volum": [1, 4, 6, 35, 37, 42, 45, 47, 52, 63, 100, 114, 134, 148, 149, 150, 153, 154, 155], "volume_theta": [148, 153], "von": 105, "von_neumann": 105, "vote": 66, "vp": 79, "vp_mat": 50, "vp_mat_inv": 50, "vp_tran": 128, "vsigma": 42, "vstack": 18, "vt": 128, "vulner": 64, "vw15": [1, 67], "vysochanskii": 47, "w": [1, 4, 37, 38, 45, 68, 69, 71, 73, 75, 89, 96, 97, 118, 128, 134, 144, 152], "w_": [68, 69, 89], "w_0": [66, 68, 71, 73, 75, 89], "w_1": [66, 68, 71, 73, 75, 89], "w_1_2": [74, 94], "w_1x": 89, "w_2": [66, 68, 73, 75, 89], "w_2_out": [74, 94], "w_i": [73, 154], "w_in_1": [74, 94], "w_j": 89, "w_jx_j": 68, "w_p": [68, 89], "w_pad": 34, "w_std": 130, "wa": [0, 4, 7, 8, 15, 20, 22, 24, 26, 35, 40, 41, 45, 47, 48, 49, 50, 51, 52, 54, 57, 62, 63, 64, 67, 68, 72, 73, 74, 75, 78, 80, 82, 89, 94, 96, 97, 98, 108, 111, 115, 118, 120, 124, 130, 131, 134, 138, 144, 145, 146, 148, 151, 152, 153, 154, 155, 157, 162, 163], "wahlstr\u00f6m": 1, "wai": [0, 4, 5, 7, 8, 9, 12, 13, 16, 17, 18, 19, 20, 23, 24, 26, 30, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 52, 54, 56, 60, 63, 64, 65, 66, 68, 69, 70, 72, 74, 76, 79, 81, 83, 87, 89, 96, 98, 106, 107, 111, 118, 128, 131, 133, 134, 135, 143, 145, 146, 154, 155, 157, 162, 163], "waic": 52, "wak": [1, 134], "walk": [15, 37, 45, 51, 144, 149, 154, 161], "walker": [6, 37, 39, 42, 51, 52, 97, 124, 143, 144, 147, 148, 153, 160, 164], "wall": [39, 42, 51, 94, 144, 145], "wang": [1, 134], "want": [0, 9, 11, 12, 13, 16, 17, 19, 20, 23, 31, 32, 35, 37, 38, 40, 41, 42, 43, 44, 45, 49, 51, 52, 57, 59, 60, 64, 69, 70, 72, 73, 74, 78, 79, 80, 82, 83, 84, 87, 91, 93, 95, 97, 99, 105, 127, 132, 135, 136, 137, 138, 141, 143, 144, 145, 147, 148, 150, 152, 153, 155, 157, 160], "wantonli": 62, "ware": 44, "warm": [39, 42, 51, 102, 128, 144, 146, 147, 155, 160, 163], "warm_up_step": [146, 163], "warmup": [39, 42, 51, 104, 144], "warn": [17, 51, 54, 70, 74, 78, 84, 93, 94, 97, 124, 134, 144, 145], "warnup": 39, "warrant": 67, "warranti": 77, "wash": 52, "washington": [52, 81], "wasn": 152, "wasserman": 54, "wast": [49, 53, 67, 76, 155], "wave": [7, 18, 24, 46, 47, 48, 133, 135], "wavelength": 121, "we": [0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 86, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 111, 112, 113, 114, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 131, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 161, 162, 163], "weak": [17, 44, 47, 48, 53, 54, 79, 83, 108, 147], "weaker": 83, "weakli": [41, 44, 53, 79, 83, 118], "wear": [1, 154], "weather": [16, 68], "web": [18, 135], "webpag": 50, "websit": [64, 88], "webster": 111, "week": [57, 93], "weigh": [39, 54], "weight": [1, 20, 26, 34, 35, 39, 41, 45, 49, 54, 61, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 86, 94, 96, 118, 120, 124, 130, 144, 147, 152, 154, 155], "weight_0": [65, 66], "weight_1": 66, "weight_2": 66, "weight_std": 130, "weights_1_2": [74, 94], "weights_2_out": [74, 94], "weights_in_1": [74, 94], "weiguang": [1, 45, 57], "welcom": 8, "well": [0, 3, 7, 8, 12, 17, 20, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 52, 54, 59, 60, 64, 65, 67, 68, 72, 73, 74, 78, 81, 84, 86, 89, 94, 96, 97, 98, 106, 114, 118, 124, 128, 134, 135, 138, 144, 145, 147, 148, 149, 152, 153, 154, 155, 159, 162], "went": 63, "were": [4, 16, 17, 19, 24, 26, 32, 33, 35, 39, 42, 44, 45, 48, 49, 51, 52, 54, 64, 72, 74, 76, 77, 89, 97, 130, 134, 143, 145, 153, 157], "wesolowski": [57, 127], "wessel": [1, 67], "what": [0, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 22, 23, 24, 26, 30, 31, 32, 33, 34, 35, 38, 39, 41, 42, 43, 44, 48, 50, 51, 53, 54, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 76, 78, 79, 83, 84, 86, 87, 89, 91, 93, 95, 97, 115, 126, 127, 128, 131, 132, 133, 135, 136, 138, 143, 144, 145, 146, 149, 151, 152, 155, 157, 159, 162, 163, 164], "whatev": [22, 23, 38, 43, 65, 133], "when": [4, 8, 15, 16, 17, 18, 23, 24, 26, 28, 30, 31, 32, 35, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 51, 52, 53, 54, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 83, 84, 86, 87, 89, 93, 96, 97, 98, 101, 104, 107, 111, 112, 113, 114, 115, 118, 122, 123, 124, 125, 128, 131, 134, 135, 137, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 157, 160, 162, 163, 164], "whenev": [64, 81, 124, 131], "where": [3, 4, 5, 8, 9, 10, 13, 16, 17, 18, 20, 24, 26, 30, 31, 33, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 80, 82, 83, 84, 86, 87, 89, 91, 93, 94, 95, 96, 97, 98, 101, 102, 103, 105, 106, 107, 108, 111, 113, 114, 115, 116, 118, 121, 122, 124, 126, 127, 128, 131, 134, 135, 136, 138, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 160, 162, 163, 164], "wherea": [8, 32, 35, 44, 54, 66, 67, 136, 137], "wherebi": 16, "wherein": [49, 63, 68], "whether": [16, 18, 23, 30, 33, 35, 38, 39, 41, 44, 50, 52, 54, 59, 64, 89, 95, 105, 131, 135, 145, 149, 154, 155, 160], "which": [0, 4, 5, 8, 9, 12, 16, 17, 18, 19, 20, 22, 23, 24, 26, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 76, 77, 78, 79, 80, 81, 83, 86, 87, 89, 90, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 106, 107, 108, 111, 112, 113, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 133, 134, 135, 136, 137, 138, 141, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 161, 162, 164], "while": [0, 4, 17, 20, 23, 24, 26, 33, 35, 39, 45, 47, 48, 49, 52, 54, 59, 64, 66, 67, 68, 69, 72, 74, 77, 79, 80, 82, 86, 87, 89, 90, 92, 106, 108, 111, 126, 131, 133, 135, 136, 137, 138, 145, 147, 148, 152, 153, 154, 155, 160, 162, 164], "whilst": [78, 84], "whistl": 135, "white": [64, 78, 83, 84, 86, 87, 118, 144], "who": [16, 44, 47, 49, 54, 57, 62, 63, 64, 65, 136], "whoever": 26, "whole": [71, 74, 76, 94, 136, 137], "whose": [18, 32, 35, 37, 54, 59, 66, 67, 86, 111, 127, 131, 155, 157], "why": [1, 5, 8, 9, 12, 15, 20, 24, 26, 27, 31, 32, 33, 35, 40, 41, 43, 45, 49, 66, 67, 71, 72, 74, 77, 78, 79, 80, 83, 89, 94, 96, 101, 102, 118, 127, 128, 134, 135, 137, 145, 148, 152, 153, 154, 157, 162], "wide": [35, 37, 44, 49, 52, 54, 65, 69, 72, 76, 86, 118, 123, 137, 155], "widehat": [45, 53, 155], "wider": [39, 74], "widespread": [149, 154, 155], "widetild": [35, 80, 87], "widget": [5, 11, 20, 31, 127, 139], "width": [9, 18, 26, 30, 34, 35, 38, 39, 43, 44, 51, 53, 54, 66, 68, 72, 76, 77, 83, 90, 91, 97, 127, 130, 133, 134, 143, 144, 145, 147, 154, 155, 160, 164], "wiecki": [74, 94, 145], "wieringen": [1, 67], "wierstra": 1, "wiggl": 105, "wigner": 118, "wiki": 105, "wikimedia": 44, "wikipedia": [20, 50, 53, 78, 90, 105, 122, 129], "wild": 50, "wildli": 38, "wilei": 1, "willemsen": 1, "william": [0, 1, 7, 24, 54, 86, 87], "willing": 8, "win": [16, 26, 78, 149], "window": [94, 124, 135, 138, 144], "wine": 7, "winner": 63, "wisdom": [49, 67], "wise": [62, 68, 72, 73, 74, 78, 79, 83, 84, 128, 137], "wish": [9, 31, 44, 45, 62, 78, 79, 83, 84, 89, 131, 134], "with_errorbar": [35, 103], "within": [3, 6, 16, 17, 20, 39, 40, 44, 45, 47, 48, 49, 52, 54, 59, 61, 63, 64, 65, 67, 72, 80, 89, 95, 96, 97, 101, 105, 118, 124, 131, 134, 138, 144, 145, 147, 148, 149, 152, 153, 154, 157, 162], "without": [1, 8, 35, 41, 45, 46, 47, 48, 50, 54, 57, 60, 62, 63, 65, 68, 70, 77, 80, 81, 83, 86, 87, 89, 90, 93, 94, 96, 97, 112, 116, 118, 120, 122, 128, 131, 135, 136, 144, 152, 157, 160, 164], "wm": 152, "wmap": 41, "wno": [74, 94], "women": [64, 131], "won": [39, 64, 74, 126, 133, 134, 145, 148, 149, 153], "wooff": [1, 47], "word": [22, 23, 32, 39, 41, 42, 43, 47, 50, 54, 59, 67, 76, 78, 79, 83, 84, 128, 131, 134, 136, 143, 144, 145, 157, 162], "work": [1, 3, 5, 9, 12, 13, 14, 17, 18, 20, 24, 28, 30, 33, 34, 35, 38, 39, 44, 45, 49, 50, 51, 52, 54, 57, 62, 64, 66, 68, 69, 72, 73, 74, 80, 81, 83, 87, 89, 91, 93, 94, 96, 97, 98, 102, 103, 118, 121, 122, 124, 128, 129, 131, 134, 135, 136, 137, 138, 143, 144, 145, 148, 149, 152, 153, 154, 155, 160], "worker": [64, 124], "workflow": [28, 29, 48, 58, 61, 135, 159], "workhors": 161, "world": [8, 16, 22, 41, 48, 64, 74, 78, 99, 135, 136], "worldwid": 134, "worri": [41, 44, 54], "wors": [66, 67, 76], "worsen": 64, "worst": 48, "worth": [24, 52, 62, 96, 98, 106], "worthwhil": 24, "would": [0, 3, 4, 8, 15, 16, 17, 18, 19, 20, 22, 24, 26, 30, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 52, 54, 57, 64, 66, 67, 68, 69, 71, 72, 73, 74, 76, 86, 89, 93, 94, 96, 100, 101, 107, 115, 116, 118, 126, 131, 134, 135, 145, 146, 148, 149, 152, 153, 154, 155, 157, 162, 163], "wreck": 64, "write": [9, 16, 20, 24, 25, 26, 31, 33, 35, 41, 42, 43, 48, 49, 50, 53, 57, 59, 65, 66, 67, 68, 69, 72, 74, 77, 78, 79, 83, 84, 86, 87, 94, 101, 103, 124, 126, 127, 128, 131, 134, 135, 145, 154], "writer": 127, "writervideo": 127, "written": [0, 3, 4, 5, 17, 23, 35, 45, 46, 49, 52, 54, 64, 65, 69, 74, 78, 79, 83, 84, 86, 87, 94, 100, 124, 134, 137, 151, 154, 157, 159], "wrong": [12, 16, 17, 20, 30, 35, 37, 45, 49, 60, 64, 68, 77, 98, 99, 101, 102, 109, 147, 160], "wrote": [23, 24, 60, 63, 160], "wrt": [34, 72], "wt": 48, "wvar": 34, "www": [1, 52, 70, 77, 138], "x": [0, 1, 3, 4, 5, 6, 9, 13, 18, 20, 23, 24, 25, 26, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 86, 87, 89, 93, 94, 95, 96, 97, 100, 101, 102, 103, 105, 118, 121, 122, 124, 126, 127, 128, 130, 131, 134, 135, 136, 137, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 157, 160, 162, 163, 164], "x0": [41, 42, 43, 93, 97, 154], "x0_max": [43, 71], "x0_min": [43, 71], "x0_pt": 43, "x0_true": [37, 43, 143], "x1": [24, 66, 71, 79, 93, 94, 97, 124, 131], "x1_max": 71, "x1_min": 71, "x1_orig": 66, "x1sq": 79, "x1x2": [66, 131], "x1x2_grid": 66, "x2": [24, 41, 66, 71, 79, 94, 124, 131], "x27": [71, 152], "x2_orig": 66, "x2givenx0_fig": 157, "x2sq": 79, "x_": [3, 4, 17, 35, 42, 43, 45, 66, 79, 83, 86, 95, 97, 101, 118, 145, 157, 160, 162], "x_0": [3, 4, 17, 18, 20, 24, 37, 38, 54, 66, 71, 89, 91, 97, 121, 143, 157, 162, 164], "x_1": [0, 17, 18, 20, 24, 34, 35, 40, 49, 53, 66, 68, 71, 73, 75, 79, 80, 83, 87, 89, 91, 97, 101, 102, 124, 128, 131, 148, 153, 157, 159, 162, 164], "x_2": [0, 17, 18, 20, 24, 34, 35, 53, 66, 68, 71, 73, 75, 79, 80, 83, 87, 89, 101, 102, 128, 131, 157, 159, 162], "x_3": [35, 68, 87, 162], "x_arang": 136, "x_arr": 42, "x_beta": 18, "x_co": 72, "x_col": 83, "x_cosh": 72, "x_cv": 96, "x_d": [34, 79], "x_data": 66, "x_data_pt": 50, "x_dist": [18, 43, 127], "x_exp": 72, "x_fit": 96, "x_gamma": 127, "x_i": [3, 4, 23, 25, 26, 30, 32, 33, 34, 35, 37, 39, 40, 41, 42, 45, 49, 50, 54, 66, 68, 73, 83, 87, 96, 101, 121, 124, 128, 131, 144, 147, 148, 153, 154, 157, 162], "x_ip": 25, "x_j": [4, 17, 20, 49, 83, 89, 97, 121, 147, 157, 162], "x_k": [4, 37, 38, 40, 43, 83, 97, 143, 148, 153, 162], "x_l": 68, "x_label": 43, "x_list": 136, "x_log": 72, "x_m": [17, 40, 148, 153, 157], "x_max": [34, 38, 42, 43, 50, 96, 127, 144], "x_max_index": [9, 18, 31, 127], "x_mean": 42, "x_min": [34, 38, 42, 43, 96], "x_n": [20, 34, 49, 53, 68, 83, 124, 128, 131, 154, 157, 162], "x_new": 83, "x_norm": [18, 127], "x_norm_val": 30, "x_p": 89, "x_posterior": 42, "x_pt": [5, 34, 38, 41, 43, 50, 79, 135, 136], "x_pts_all": 50, "x_rang": 136, "x_row": 83, "x_row_til": 83, "x_sampl": 93, "x_sin": 72, "x_sinh": 72, "x_sort": 97, "x_sqrt": 72, "x_squar": 72, "x_t": [18, 45, 127, 145, 160, 162], "x_tensor": 130, "x_test": [70, 72, 74, 75, 94], "x_train": [66, 70, 72, 74, 75, 81, 82, 94, 96], "x_true": 82, "x_valu": 38, "x_with_fixedh": 42, "xarrai": [134, 152], "xavier": 72, "xaxi": 127, "xbar": [128, 160], "xbin": 42, "xdata": [35, 42, 66, 103], "xfit": [39, 42], "xi": [78, 84, 93, 148, 153], "xilin": 1, "xing": 1, "xk": 97, "xk_pt": 38, "xlabel": [17, 39, 70, 72, 74, 77, 78, 79, 81, 82, 83, 94, 96, 97, 124, 135, 145], "xlim": [74, 79, 83, 94, 130, 152], "xlinspac": 3, "xmax": [35, 42, 43, 97, 103], "xmeasur": [35, 103], "xmgivenx0_fig": 157, "xmin": [35, 42, 43, 97, 103], "xmode": 131, "xnew": [78, 84], "xp": [25, 78, 79, 83, 84], "xposterior": 42, "xposterior_fixedh": 42, "xposterior_pdfh": 42, "xrealiti": [35, 103], "xrightarrow": [45, 118], "xsq": 79, "xstar": 66, "xt": [79, 83], "xtick": [70, 77], "xtrue": 78, "xu": [1, 134], "xv": 51, "xvec": [24, 79, 80, 87, 147], "xvec_1": [80, 87], "xvec_2": [80, 87], "xx": [128, 131], "xx0": 71, "xx1": 71, "xx_j": 17, "xy": [9, 17, 18, 25, 37, 38, 43, 79, 127, 128, 131, 145], "xycoord": [9, 43], "xytext": [18, 127, 145], "y": [0, 3, 4, 5, 6, 9, 13, 18, 23, 24, 25, 26, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 49, 51, 53, 54, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 86, 89, 93, 94, 95, 96, 97, 98, 102, 103, 118, 121, 124, 126, 127, 128, 130, 131, 135, 136, 144, 146, 147, 150, 151, 153, 154, 157, 159, 162, 163, 164], "y0": [43, 162], "y0_true": [37, 43, 143], "y1": [83, 131], "y2": [41, 83, 131], "y_": [0, 3, 30, 35, 41, 83, 89, 101, 118, 126, 128, 144, 157, 159, 160], "y_0": [17, 37, 43, 54, 143, 157, 160, 162, 164], "y_1": [9, 17, 33, 35, 49, 53, 68, 80, 83, 89, 101, 102, 131, 157, 160], "y_2": [9, 17, 33, 35, 53, 68, 80, 83, 89, 101, 102, 131], "y_3": 9, "y_cv": 96, "y_d": 83, "y_data_pt": 50, "y_determinist": 162, "y_fit": 96, "y_i": [3, 17, 30, 35, 39, 41, 42, 49, 50, 52, 53, 66, 67, 68, 69, 83, 96, 98, 101, 126, 128, 144, 154, 162], "y_j": [17, 23, 32, 33, 67, 68, 83, 89, 147], "y_k": 83, "y_logit": 89, "y_m": [17, 39, 41, 42, 50, 96, 144], "y_max": [9, 162], "y_mean": [82, 162], "y_model": [41, 42, 50, 144], "y_n": [49, 53, 157], "y_ob": [152, 153], "y_obs_dim_0": 152, "y_obs_dim_0pandasindexpandasindex": 152, "y_perceptron": 89, "y_pt": [34, 38, 50, 135], "y_reconstruct": 5, "y_run": 162, "y_sampl": [82, 93], "y_sort": 66, "y_std": 82, "y_stochast": 162, "y_t": 160, "y_tanh": 89, "y_test": [70, 72, 74, 94], "y_train": [66, 70, 72, 74, 81, 82, 94, 96], "y_train_noisi": 81, "y_true": [5, 82], "y_vec": 50, "y_x": 83, "yaida": 1, "yau": 1, "yaxi": 127, "ybar": 128, "ybin": 42, "ydata": [35, 42, 103], "ye": [23, 35, 37, 65, 89, 157], "year": [26, 57, 63, 64, 78, 118], "yellow": 155, "yerr": [42, 97, 124], "yerror": [35, 103], "yet": [8, 16, 32, 35, 44, 50, 103, 122, 128, 157], "yexp": 0, "yfit": [39, 42], "yfunc": 78, "yhat_hard_grid": 66, "yhat_knn_grid": 66, "yhat_soft_grid": 66, "yhi95": [78, 84], "yhii": [78, 84], "yi": [79, 83, 131, 148, 153], "yield": [7, 23, 24, 26, 32, 33, 35, 39, 47, 48, 53, 54, 66, 67, 68, 87, 104, 118, 121, 127, 134], "ylabel": [17, 39, 72, 74, 77, 78, 79, 81, 82, 83, 84, 94, 96, 97, 124, 144, 145], "ylim": [70, 74, 77, 79, 82, 83, 94, 130, 144, 145, 152], "ylo95": [78, 84], "yloi": [78, 84], "ymean": [78, 84], "ymeani": [78, 84], "ymin": 97, "yml": [0, 71, 94, 138, 141], "ynew": [78, 84], "yoram": 1, "york": [51, 57, 144, 145], "yoshioka": 74, "you": [0, 3, 4, 5, 8, 9, 11, 12, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 60, 63, 64, 65, 66, 67, 68, 70, 72, 74, 75, 77, 78, 80, 82, 84, 87, 89, 91, 93, 94, 95, 96, 97, 98, 101, 102, 103, 107, 118, 120, 126, 127, 128, 131, 132, 134, 135, 136, 137, 138, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 157, 162, 163], "young": [64, 65], "your": [0, 7, 8, 11, 12, 15, 16, 18, 20, 23, 32, 33, 35, 37, 38, 40, 41, 43, 50, 57, 63, 64, 65, 66, 67, 68, 70, 72, 74, 75, 77, 78, 86, 91, 94, 95, 96, 98, 127, 128, 131, 132, 135, 140, 141, 143, 144, 145, 146, 147, 148, 152, 153, 154, 159, 162, 163], "yourself": [16, 17, 19, 23, 31, 32, 38, 91, 97, 135], "yp": 79, "yt": [79, 83], "yth": 0, "ytick": [70, 77], "ytrue": 78, "yvar": [78, 84], "yvari": [78, 84], "yvec": [128, 147], "z": [5, 34, 35, 38, 45, 47, 51, 52, 65, 66, 68, 69, 71, 72, 73, 78, 79, 80, 83, 84, 86, 89, 93, 97, 100, 118, 122, 128, 131, 134, 149, 152, 160], "z_": [69, 89, 118], "z_0": 17, "z_1": [47, 89], "z_2": [47, 89], "z_grid": [38, 66], "z_i": [39, 47], "z_j": [47, 68, 89], "z_k": 69, "z_m": [47, 73], "z_n": 86, "z_p": [54, 96], "z_q": 54, "z_w": 73, "zdir": 66, "zdist": 83, "zeiler": 1, "zeiler12": [1, 108], "zenodo": 44, "zero": [3, 6, 9, 17, 20, 24, 25, 26, 30, 34, 35, 38, 39, 41, 43, 49, 50, 51, 54, 57, 66, 67, 68, 69, 72, 73, 76, 78, 79, 83, 84, 86, 87, 89, 96, 97, 98, 103, 108, 118, 121, 126, 127, 128, 130, 131, 132, 134, 135, 144, 145, 146, 147, 149, 151, 155, 157, 159, 160, 162, 163], "zero_grad": 72, "zeros_lik": [0, 17, 26, 31, 42, 66, 97, 131], "zeta": [48, 121], "zeta_i": 48, "zeus_multimod": 164, "zhang": 1, "zip": [34, 39, 66, 78, 84, 97, 124, 128, 131], "zm_h": 134, "zoom": 43, "zorder": [35, 82, 103], "zrang": 83, "\u00b2": 124, "\u00e9": 1, "\u03bc": [39, 51, 130], "\u03c3": 130}, "titles": ["<span class=\"section-number\">34. </span>Guide to Jupyter Book markdown", "<span class=\"section-number\">33. </span>Bibliography", "<span class=\"section-number\">12. </span>Assigning probabilities", "<span class=\"section-number\">12.1. </span>Assigning probabilities (I): Indifferences and translation groups", "<span class=\"section-number\">12.2. </span>Assigning probabilities (II): The principle of maximum entropy", "<span class=\"section-number\">12.3. </span>\ud83d\udce5 Maximum Entropy for reconstructing a function from its moments", "\ud83d\udce5 Demonstration: Prior PDFs for straight lines", "<span class=\"section-number\">7.1. </span>Advantages of the Bayesian approach", "<span class=\"section-number\">4.7. </span>*Aside: Bayesian epistemology", "<span class=\"section-number\">6.7. </span>\ud83d\udce5 Demonstration: Coin tossing (with widget)", "<span class=\"section-number\">6. </span>Updating via Bayes\u2019 rule", "<span class=\"section-number\">6.1. </span>Coin tossing: Frequentists and Bayesaians", "<span class=\"section-number\">6.2. </span>When do priors matter? When don\u2019t they matter?", "<span class=\"section-number\">6.3. </span>Computing the posterior analytically", "<span class=\"section-number\">6.4. </span>Degree of belief/credibility intervals vs frequentist 1-sigma intervals", "<span class=\"section-number\">6.5. </span>Take-aways and follow-up questions from coin flipping:", "<span class=\"section-number\">4.6. </span>Data, models, and predictions", "<span class=\"section-number\">8. </span>Error propagation", "<span class=\"section-number\">5.1. </span>\ud83d\udce5 Exploring PDFs", "Follow-up questions and answers to the <em>Exploring PDFs</em> section.", "<span class=\"section-number\">5.2. </span>Gaussians: A couple of frequentist connections", "<span class=\"section-number\">4. </span>Inference and PDFs", "<span class=\"section-number\">4.1. </span>Statements", "<span class=\"section-number\">4.2. </span>Manipulating probabilities: Bayesian rules of probability as principles of logic", "<span class=\"section-number\">4.3. </span>Probability density functions", "<span class=\"section-number\">4.4. </span>Looking ahead", "<span class=\"section-number\">4.5. </span>Review of Bayes\u2019 theorem", "<span class=\"section-number\">5. </span>Bayesian posteriors", "<span class=\"section-number\">3. </span>Bayesian methods for scientific modeling", "<span class=\"section-number\">7. </span>Bayes in practice", "<span class=\"section-number\">5.4. </span>\ud83d\udce5 Demonstration: Sum of normal variables squared", "<span class=\"section-number\">6.6. </span>\ud83d\udce5 Demonstration:  Bayesian Coin Tossing", "<span class=\"section-number\">9.2. </span>Exercise: Standard medical example using Bayes", "<span class=\"section-number\">9.1. </span>Exercise: Checking the sum and product rules", "\ud83d\udce5 Visualization of the Central Limit Theorem", "<span class=\"section-number\">7.3. </span>Bayesian Linear Regression (BLR)", "<span class=\"section-number\">9. </span>Exercises for Part I", "<span class=\"section-number\">5.3. </span>Interpreting 2D posteriors", "<span class=\"section-number\">9.5. </span>\ud83d\udce5 Amplitude of a signal in the presence of background", "<span class=\"section-number\">13. </span>\ud83d\udce5 Dealing with outliers", "<span class=\"section-number\">9.3. </span>\ud83d\udce5 Parameter estimation example: Gaussian noise and averages I", "<span class=\"section-number\">9.6. </span>Parameter estimation example: fitting a straight line", "<span class=\"section-number\">9.7. </span>\ud83d\udce5 Parameter estimation example: fitting a straight line II", "<span class=\"section-number\">9.4. </span>\ud83d\udce5 Radioactive lighthouse problem", "<span class=\"section-number\">7.2. </span>Bayesian research workflow", "<span class=\"section-number\">19.1. </span>Advanced Markov chain Monte Carlo sampling", "<span class=\"section-number\">29.1. </span>Bayes goes fast: Emulators", "<span class=\"section-number\">14. </span>Bayes goes linear: History matching", "<span class=\"section-number\">29.2. </span>Emulators", "<span class=\"section-number\">15.2. </span>Model mixing", "Evidence calculation for EFT expansions", "Demo: Multimodal distributions with two samplers", "Computing the Bayesian evidence", "Evidence for an expansion", "<span class=\"section-number\">15.1. </span>Model Selection", "<span class=\"section-number\">15. </span>Multi-model inference with Bayes", "<span class=\"section-number\">10. </span>Overview of Part II: Advanced Bayesian methods", "About this Jupyter Book", "<span class=\"section-number\">2. </span>Introduction", "<span class=\"section-number\">2.1. </span>Physicist\u2019s perspective", "<span class=\"section-number\">2.2. </span>Bayesian workflow", "<span class=\"section-number\">2.3. </span>Machine learning", "<span class=\"section-number\">2.4. </span>Virtues", "<span class=\"section-number\">1. </span>Invitation to inductive inference", "<span class=\"section-number\">24.9. </span>Data bias and fairness in machine learning", "<span class=\"section-number\">24. </span>Machine learning: Overview and notation", "<span class=\"section-number\">23.5. </span>Machine Learning: First Examples", "<span class=\"section-number\">24.8. </span>Model validation", "<span class=\"section-number\">24.5. </span>Artifical neural networks", "<span class=\"section-number\">24.10. </span>*Neural networks: Backpropagation", "<span class=\"section-number\">24.6. </span>Demonstration: Neural network classifier", "<span class=\"section-number\">23.6. </span>Exercise: Logistic Regression and neural networks", "<span class=\"section-number\">24.7. </span>Feed-forward neural network for a function in PyTorch", "<span class=\"section-number\">26. </span>Bayesian neural networks", "<span class=\"section-number\">26.4. </span>Demonstration: Variational Inference and Bayesian Neural Networks", "<span class=\"section-number\">26.5. </span>Exercise: Bayesian neural networks", "<span class=\"section-number\">27. </span>*Convolutional Neural Networks", "<span class=\"section-number\">27.6. </span>Demonstration: Image recognition with Convolutional Neural Networks", "Exercise: Gaussian Process models with GPy", "Gaussian processes demonstration", "Lecture 20", "Gaussian Processes regression: basic introductory example", "Illustration of prior and posterior Gaussian process for different kernels", "Demonstration: Gaussian processes", "Exercise: Gaussian processes using <code class=\"docutils literal notranslate\"><span class=\"pre\">GPy</span></code>", "<span class=\"section-number\">22.6. </span>GPy demo notebooks", "<span class=\"section-number\">22.4. </span>Gaussian processes", "<span class=\"section-number\">22. </span>Overview of Gaussian process", "<span class=\"section-number\">22.5. </span>Scikit-learn demo notebooks", "<span class=\"section-number\">23. </span>Logistic Regression", "<span class=\"section-number\">21. </span>Machine Learning", "Overview of Mini-project IIb: How many lines?", "Overview of TALENT mini-projects", "Mini-project IIIa: Bayesian Optimization", "Mini-project IIIb: Bayesian Neural Networks", "Mini-project I: Parameter estimation for a toy model of an EFT", "Mini-project IIa: Model selection basics", "Mini-project IIb: How many lines are there?", "<span class=\"section-number\">36. </span>Gradient-descent optimization", "<span class=\"section-number\">39. </span>Linear models", "<span class=\"section-number\">39.1. </span>Definition of linear models", "<span class=\"section-number\">39.2. </span>Regression analysis with linear models", "<span class=\"section-number\">39.3. </span>Ordinary linear regression: warmup", "<span class=\"section-number\">39.4. </span>Ordinary linear regression in practice", "<span class=\"section-number\">39.5. </span>Solutions", "<span class=\"section-number\">40. </span>Mathematical optimization", "<span class=\"section-number\">40.1. </span>Gradient-descent optimization", "<span class=\"section-number\">40.2. </span>Batch, stochastic and mini-batch gradient descent", "<span class=\"section-number\">40.3. </span>Adaptive gradient descent algorithms", "<span class=\"section-number\">38. </span>Overview of modeling", "<span class=\"section-number\">38.1. </span>Notation", "<span class=\"section-number\">38.2. </span>Models in science", "<span class=\"section-number\">38.3. </span>Parametric versus non-parametric models", "<span class=\"section-number\">38.4. </span>Linear versus non-linear models", "<span class=\"section-number\">38.5. </span>Regression analysis: optimization versus inference", "<span class=\"section-number\">38.6. </span>Exercises", "<span class=\"section-number\">38.7. </span>Solutions", "<span class=\"section-number\">37. </span>Overview of scientific modeling material", "<span class=\"section-number\">25. </span>ANNs in the large-width limit", "<span class=\"section-number\">11. </span>Bayesian approach to model discrepancy", "<span class=\"section-number\">11.1. </span>KOH and BOH discrepancy models", "<span class=\"section-number\">11.2. </span>Framework", "<span class=\"section-number\">11.3. </span>The ball-drop model", "<span class=\"section-number\">29. </span>Emulators", "<span class=\"section-number\">11.4. </span>\ud83d\udce5 Model discrepancy example: The ball-drop experiment", "<span class=\"section-number\">28. </span>Overview of other topics", "<span class=\"section-number\">31. </span>PCA, SVD, and all that", "<span class=\"section-number\">30. </span>Student t distribution as a mixture of Gaussians", "<span class=\"section-number\">31.5. </span>\ud83d\udce5 Linear algebra games including SVD for PCA", "<span class=\"section-number\">32. </span>Quantum Bayesianism (QBism)", "<span class=\"section-number\">25.3. </span>\ud83d\udce5 Distributions of Randomly-Initialized ANNs", "<span class=\"section-number\">35. </span>Statistics concepts and notation", "<span class=\"section-number\">41. </span>Overview of getting started materials", "<span class=\"section-number\">43.7. </span>\ud83d\udce5 Making a simple widget-based UI", "<span class=\"section-number\">43.6. </span>\ud83d\udce5 Demonstration: Reading Data and fitting", "<span class=\"section-number\">42. </span>\ud83d\udce5 Exercise: Jupyter Notebooks and Python", "<span class=\"section-number\">43.4. </span>\ud83d\udce5 Exercise: Python lists and iterations", "<span class=\"section-number\">43.5. </span>\ud83d\udce5 Exercise: Linear algebra operations with NumPy", "<span class=\"section-number\">44.1. </span>Using Anaconda", "<span class=\"section-number\">43. </span>More on Python and using Jupyter notebooks", "<span class=\"section-number\">44. </span>Setting up to use this Jupyter book", "<span class=\"section-number\">44.2. </span>Using GitHub", "<span class=\"section-number\">19. </span>Advanced Markov Chain Monte Carlo", "<span class=\"section-number\">18.4. </span>Assignment: 2D radioactive lighthouse location using MCMC", "<span class=\"section-number\">19.2. </span>Overview: MCMC Diagnostics", "<span class=\"section-number\">17.11. </span>Exercise: Random walk", "<span class=\"section-number\">17.7. </span>Metropolis-Hasting MCMC sampling of a Poisson distribution", "<span class=\"section-number\">19.4. </span>Lecture 12", "<span class=\"section-number\">17.10. </span>Parameter estimation example: Gaussian noise and averages II", "<span class=\"section-number\">20.1. </span>Hamiltonian Monte Carlo (HMC) overview and visualization", "Liouville Theorem Visualization", "Solving orbital equations with different algorithms", "<span class=\"section-number\">20.3. </span>PyMC Introduction", "<span class=\"section-number\">20.4. </span>Comparing samplers for a simple problem", "<span class=\"section-number\">18.2. </span>Markov chain Monte Carlo sampling", "<span class=\"section-number\">18.3. </span>MCMC Intro from BUQEYE", "<span class=\"section-number\">18. </span>Overview of Markov Chain Monte Carlo", "<span class=\"section-number\">18.1. </span>Markov chains", "<span class=\"section-number\">20. </span>HMC and other samplers", "Overview of Intro to PyMC notebook", "<span class=\"section-number\">17.9. </span>Recaps", "<span class=\"section-number\">16. </span>Overview of Part III: Sampling", "<span class=\"section-number\">17. </span>Stochastic processes", "<span class=\"section-number\">17.8. </span>Demonstration: Metropolis-Hasting MCMC sampling of a Poisson distribution", "<span class=\"section-number\">20.2. </span>The Zeus Ensemble Slice Sampler"], "titleterms": {"": [7, 45, 47, 54, 59, 66, 94, 133, 137], "0": [87, 94], "05": 94, "06068": 160, "1": [0, 14, 17, 32, 33, 34, 35, 39, 42, 66, 67, 68, 75, 78, 80, 84, 86, 87, 93, 94, 104, 116, 130, 131, 133, 144, 145, 157, 162], "10": [34, 157], "100": 94, "1000": 94, "11": [144, 157], "12": [147, 155, 157], "13": 157, "14": 157, "15": 157, "16": 154, "17": [154, 162], "1710": 160, "18": [154, 157], "1d": [18, 137], "2": [5, 30, 32, 33, 35, 39, 42, 68, 75, 78, 84, 93, 94, 116, 130, 131, 133, 145, 155, 157, 162], "20": 80, "2025": 138, "23": 66, "24": [67, 68], "2d": [37, 137, 143], "3": [5, 16, 17, 32, 33, 39, 42, 68, 75, 78, 84, 93, 94, 104, 116, 131, 133, 145, 157, 162], "30000": 94, "34": 0, "35": 131, "38": 116, "39": 104, "3d": 76, "4": [5, 16, 17, 32, 33, 39, 42, 66, 68, 72, 78, 84, 93, 94, 116, 131, 133, 157], "5": [5, 16, 17, 32, 33, 66, 67, 78, 94, 131, 133, 145, 157], "50": 34, "6": [16, 17, 32, 67, 131, 133, 157], "60000": 94, "7": [16, 17, 32, 67, 133, 157], "8": [17, 32, 67, 157], "9": [32, 67, 147, 157], "A": [17, 20, 39, 49, 54, 71, 75, 78, 84, 86, 89, 93, 97, 134, 157, 160], "But": [40, 148, 153], "For": 160, "In": [35, 152, 160], "No": [79, 83], "One": [8, 41, 54], "The": [0, 4, 16, 17, 20, 26, 35, 39, 41, 42, 44, 45, 47, 50, 54, 64, 66, 67, 73, 76, 78, 79, 83, 84, 86, 89, 96, 101, 122, 124, 131, 135, 144, 154, 157, 164], "To": [18, 20, 94, 134], "With": 124, "_": 86, "ab": 46, "about": [20, 40, 57, 61, 72, 139, 147, 148, 153], "abov": 160, "acceler": 72, "accept": [144, 152, 160], "accumul": 128, "accuraci": 70, "acknowledg": [57, 74], "activ": [68, 69, 89], "ad": [34, 137], "adagrad": 108, "adam": 108, "adapt": 108, "add": [77, 133], "addendum": 35, "addit": 95, "adjust": 54, "admonit": 0, "advanc": [45, 56, 135, 142], "advantag": 7, "advi": 74, "agre": 160, "ahead": 25, "ai": 64, "aka": [18, 79, 83], "al": [80, 87, 144], "aleator": 73, "algebra": [50, 53, 86, 128, 137], "algorithm": [47, 64, 65, 68, 69, 89, 93, 108, 144, 145, 149, 151, 154, 155, 160], "all": [20, 32, 33, 126, 133, 153], "amplitud": 38, "an": [24, 53, 57, 95, 160, 162], "anaconda": 138, "analogi": 160, "analys": 20, "analysi": [97, 101, 111, 114, 143], "analyt": 13, "analyz": [38, 152], "ani": [133, 160], "ann": [118, 130], "anoth": [5, 18], "answer": [0, 3, 11, 12, 15, 16, 19, 20, 23, 24, 25, 32, 33, 35, 37, 48, 96, 97, 101, 160], "appli": [24, 128, 143, 148, 153], "applic": [52, 80, 126], "approach": [7, 39, 40, 42, 86, 119, 144, 148, 153], "approxim": [17, 37], "ar": [37, 80, 97, 137, 160], "architectur": [68, 76], "argument": 4, "arrai": [135, 136, 137], "art": 154, "artif": 68, "artifici": 68, "arxiv": 160, "asid": [8, 87, 128, 135, 136], "ask": 72, "aspect": 65, "aspir": 62, "assess": [30, 144, 147], "assign": [2, 3, 4, 143], "assum": 160, "assumpt": 49, "atom": 160, "attribut": 64, "autocorrel": [45, 144, 152, 160], "autom": 64, "avail": 152, "averag": [40, 49, 137, 148], "awai": [15, 26], "axiom": 26, "b": [33, 54, 160], "back": [69, 70], "background": [35, 37, 38, 87, 153], "backprop": 73, "backpropag": [69, 72], "bad": 39, "balanc": [145, 157, 160], "ball": [122, 124], "base": [53, 77, 133, 137, 160], "basi": [35, 82, 100], "basic": [54, 72, 73, 81, 89, 96, 128, 152, 155], "batch": [74, 107], "bay": [10, 23, 24, 26, 29, 32, 46, 47, 52, 55, 73, 143], "bayesaian": 11, "bayesian": [0, 7, 8, 9, 16, 18, 20, 23, 27, 28, 31, 32, 33, 35, 39, 40, 42, 44, 49, 52, 54, 56, 60, 62, 73, 74, 75, 93, 94, 96, 119, 129, 148, 153, 154], "bayesopt": 93, "bda3": 144, "befor": 97, "behavior": [34, 53], "belief": [9, 14, 31], "benchmark": 5, "beta": [13, 18], "between": [51, 160], "beyond": 62, "bia": [31, 64, 67], "bias": 64, "bibliographi": [0, 1], "binari": [66, 71, 89], "bind": [35, 100, 134], "bivari": [79, 93, 131], "blr": 35, "bma": 49, "bmm": 49, "boh": 120, "boldsymbol": [30, 86], "bonu": [95, 96], "book": [0, 57, 138, 139, 140], "bound": 73, "boundari": 66, "breakout": 42, "bridg": 74, "brief": [25, 44, 45, 57, 60, 76, 87, 134], "bring": 69, "build": [70, 76, 93], "buqey": 155, "c": [33, 86], "calcul": [37, 50, 52, 54], "call": 160, "callback": 133, "can": [20, 160], "cancel": 160, "carlo": [45, 142, 149, 154, 155, 156], "case": [4, 5, 13, 20, 42, 79, 162], "cauchi": 39, "cell": [0, 135], "central": [20, 34, 86, 131], "certain": 53, "chain": [45, 51, 69, 142, 144, 154, 155, 156, 157], "challeng": [69, 106, 154], "chang": [17, 53, 138], "characterist": [19, 23], "chart": 160, "chatgpt": [72, 130], "cheat": 139, "check": [7, 33, 44, 51, 53, 151, 155], "checklist": [0, 44], "checkpoint": [0, 3, 15, 16, 20, 23, 24, 25, 35, 48, 101], "chi": [30, 54], "choic": 94, "choos": 86, "cifar10": 77, "class": [0, 11, 18, 20, 37, 89, 124, 150, 152], "classif": [65, 66, 71, 75, 89], "classifi": [66, 70, 71, 74, 89, 94], "close": 49, "clt": 20, "cluster": 65, "cnn": [76, 77], "code": [0, 9, 66, 69, 70, 72, 130, 131, 135, 155], "coin": [9, 11, 15, 20, 26, 31], "collect": 160, "color": 0, "colorblind": 131, "combin": [78, 84], "command": 141, "comment": 95, "common": [4, 72, 153], "compa": 64, "compact": 89, "compar": [34, 37, 153], "comparison": [7, 30, 54, 136], "compil": 77, "complex": [67, 72, 74, 94], "compon": 128, "comprehens": 136, "compress": 128, "comput": [13, 52, 72, 78, 84], "concaten": 137, "concept": 131, "conda": 138, "condit": [131, 155, 157, 160, 162], "confid": [19, 20], "conjug": [13, 50], "connect": 20, "consequ": 20, "conserv": [39, 151], "continu": [4, 35, 46, 105, 131], "continuum": 26, "contrast": [20, 49], "control": 133, "converg": [45, 51, 144, 147], "convers": 137, "convert": 35, "convolut": [68, 76, 77], "cookbook": 82, "core": [79, 83], "correct": 39, "correl": [17, 37, 54, 80, 131, 147], "cost": [66, 69, 89], "could": 41, "coupl": 20, "cours": 128, "covari": [78, 79, 83, 84, 86, 128, 131], "cow": 63, "creat": [71, 77, 133, 136, 137, 138], "credibl": [14, 20, 131], "criteria": 52, "crocodil": 63, "cross": [67, 89, 96], "current": 74, "curv": [67, 98], "custom": 72, "d": [34, 160], "data": [16, 35, 38, 39, 41, 42, 50, 53, 64, 65, 66, 70, 74, 75, 77, 78, 84, 94, 97, 128, 134, 137, 138, 143, 144, 153], "dataset": [76, 77, 81, 82], "deal": 39, "debug": 135, "decis": 66, "decomposit": 126, "deep": [68, 74, 89], "default": 72, "defin": [5, 43, 124], "definit": [35, 69, 100, 131, 162], "degre": [9, 14, 31], "delta": [17, 155], "demo": [51, 85, 88], "demolit": 63, "demonstr": [6, 9, 30, 31, 70, 74, 77, 79, 83, 134, 163], "dens": 77, "densiti": [18, 24, 131, 160], "depend": [54, 79, 83, 115, 116], "derbi": 63, "deriv": [4, 69, 160], "descent": [98, 106, 107, 108], "design": [35, 101, 157], "detail": [72, 145, 155, 157, 160], "determin": [31, 44, 80, 89, 137], "develop": [70, 71], "deviat": 137, "diagnost": [45, 144, 152], "diagon": 126, "differ": [0, 5, 54, 82, 97, 151], "dimens": 155, "dimension": [65, 79, 83, 137], "dirac": 17, "discrep": [115, 116, 119, 120, 124], "discret": [3, 105, 131, 154, 157], "discuss": [8, 35, 39, 54, 131, 148, 153, 162], "displai": 133, "dissect": 128, "distanc": 17, "distribut": [4, 16, 18, 34, 35, 38, 44, 51, 72, 79, 83, 86, 87, 127, 130, 131, 146, 147, 154, 157, 160, 163], "diverg": 73, "do": [12, 20, 34, 41, 50, 70, 87, 93, 94, 96, 124, 128, 144, 146, 147, 160], "doe": [37, 53], "dof": 30, "don": [12, 76], "donut": 155, "dot": [82, 137], "download": 77, "dr": 54, "draw": [34, 87, 136], "drawn": 34, "drop": [35, 100, 122, 124], "duke": 128, "e": 160, "each": [20, 34, 54, 72, 133], "edwin": 63, "effect": 5, "eft": [50, 95], "eigendecomposit": 128, "eigenvalu": 137, "eigenvector": [46, 137], "elabor": 133, "eleg": 86, "element": 137, "elementwis": 137, "elicit": 44, "ellips": 37, "emce": [97, 124, 153, 154], "emul": [46, 48, 80, 123], "energi": [35, 53, 100, 134, 151], "ensembl": 164, "entropi": [4, 5, 89], "env": 138, "environ": 138, "epistem": 73, "epistemologi": 8, "equal": 13, "equat": [0, 35, 69, 101, 128, 151], "equilibrium": 160, "errat": 39, "error": [17, 35, 42, 64, 66, 67, 144], "estim": [0, 7, 16, 19, 40, 41, 42, 54, 78, 84, 95, 97, 131, 148, 153, 154], "et": [80, 87, 144], "ethic": [64, 65], "evalu": [70, 77], "event": 131, "everi": 147, "everyth": 18, "evid": [50, 52, 53, 54, 73, 96], "evolut": 127, "exampl": [3, 24, 26, 32, 34, 35, 37, 39, 40, 41, 42, 52, 64, 66, 71, 72, 76, 78, 79, 81, 83, 93, 115, 116, 124, 131, 137, 148, 152, 155, 160, 162], "exchang": 160, "exercis": [0, 11, 16, 17, 20, 32, 33, 35, 36, 41, 66, 67, 68, 71, 75, 78, 80, 84, 104, 115, 116, 126, 128, 131, 135, 136, 137, 145, 152, 154, 157, 162], "exp": 82, "expans": [50, 53], "expect": [25, 68, 131], "experi": [53, 124], "experiment": [44, 124], "explan": 72, "explicit": 133, "explor": [18, 19, 37, 70, 96, 97, 135], "exponenti": [4, 162], "express": [72, 89, 135, 143], "extend": 89, "extern": 0, "f": 155, "factor": 52, "failur": 5, "fair": [26, 64], "falsifi": 20, "fast": 46, "favorit": 97, "featur": [57, 89, 135], "feed": [68, 72, 130], "feedback": 68, "fft": 34, "fig": 144, "figur": [0, 38, 133, 135, 143, 147], "file": 0, "fill": 160, "final": 69, "find": [128, 137], "first": [13, 34, 66, 69, 133, 134, 153], "fit": [41, 42, 96, 134, 144], "fix": [34, 42], "flat": 13, "flip": [9, 15, 20, 157], "flop": 157, "fold": 67, "follow": [15, 19, 32, 38, 71, 78, 147], "foreman": 147, "form": [35, 128], "formal": 44, "formul": [39, 124], "forward": [68, 72, 130], "four": [44, 60], "fourier": 34, "fourth": 34, "framework": 121, "free": 81, "frequentist": [8, 11, 14, 20, 39, 54, 148, 153], "friend": 26, "from": [5, 15, 34, 72, 75, 78, 80, 84, 87, 97, 128, 137, 138, 141, 147, 152, 154, 155, 160], "frontmatt": 0, "full": [42, 76], "function": [5, 13, 17, 18, 24, 35, 41, 44, 64, 66, 69, 71, 72, 78, 79, 82, 83, 84, 86, 89, 100, 131, 133, 135, 150, 155], "further": 137, "g": 160, "galact": 17, "game": [87, 128], "gaussian": [4, 17, 18, 20, 34, 35, 37, 40, 50, 54, 78, 79, 81, 82, 83, 84, 86, 87, 127, 131, 148, 153, 162], "gelman": [45, 144, 152], "gener": [35, 65, 74, 81, 82, 94, 97, 124, 131, 133, 143, 153, 154], "get": [57, 78, 84, 132, 135, 155, 159], "github": [138, 141], "given": [78, 84], "global": 105, "goal": [95, 97, 143], "goe": [46, 47], "good": [39, 139], "gothenburg": 157, "gp": [79, 80, 83, 86, 87], "gpu": 72, "gpy": [78, 84, 85], "gpyopt": 93, "gradient": [72, 98, 106, 107, 108], "graphic": 135, "gregori": 155, "group": [3, 64], "growth": 162, "guid": [0, 57, 139], "guidelin": 64, "h_0": 42, "ha": [74, 94, 144], "hamiltonian": [45, 149], "handl": [42, 65], "happen": 160, "harmon": 20, "hast": [145, 146, 154, 155, 163], "have": 53, "hbar": [79, 83], "height": 124, "help": [7, 57, 135], "helper": [18, 82], "here": 97, "hick": 152, "hidden": 0, "higdon": 80, "high": [83, 155], "higher": [53, 160], "highli": 80, "hint": [20, 33, 35, 68], "histogram": 127, "histori": 47, "hmc": [149, 158], "hogg": 147, "how": [7, 41, 53, 72, 87, 91, 95, 97, 144, 160], "huber": 39, "hybrid": 7, "hydrogen": 160, "hyperparamet": 86, "hypothesi": 54, "i": [3, 13, 17, 18, 20, 26, 34, 36, 40, 61, 80, 95, 157, 160], "icon": 57, "idea": 54, "ii": [4, 13, 17, 42, 56, 148], "iia": 96, "iib": [91, 97], "iii": [17, 161], "iiia": 93, "iiib": 94, "illustr": [45, 82], "imag": [76, 77, 128], "implement": [41, 67, 152, 154], "implicit": 64, "import": [5, 39, 45, 51, 74, 77, 78, 84, 93, 96, 97, 128, 131, 133, 134, 143, 145, 152], "improv": 41, "includ": [64, 128], "independ": [54, 115, 116, 131], "index": [128, 137], "indiffer": 3, "induct": 63, "infer": [0, 7, 17, 21, 42, 44, 49, 55, 62, 63, 73, 74, 75, 86, 94, 111, 114, 154], "inferencedata": 152, "infinit": 79, "info": 87, "inform": [52, 72], "infti": 53, "ingredi": [26, 65], "initi": [72, 130], "initio": 46, "input": [78, 84, 130, 133], "insert": 0, "instal": [72, 138, 141], "integr": [34, 50, 97, 147, 154], "interactive_output": 133, "interfac": [9, 133], "interlud": 147, "interpret": 37, "interv": [9, 14, 19, 20, 31], "intial": 72, "intro": [155, 159], "introduct": [18, 58, 70, 87, 131, 152, 162], "introductori": 81, "intuit": [79, 147, 160], "invari": 3, "invers": [35, 137], "invit": 63, "ipython": 133, "ipywidget": 133, "ir": 45, "issu": 57, "iter": [47, 94, 136], "its": 5, "jayn": 63, "joint": [24, 131], "jupyt": [0, 6, 9, 57, 134, 135, 138, 139, 140, 141], "justifi": 20, "k": [66, 67, 79, 83], "kernel": [79, 82, 83, 86, 138], "knn": [66, 67], "know": [87, 139, 144], "known": 97, "koh": 120, "kraken": 133, "kullback": 73, "l": 69, "l1": 4, "label": 0, "langl": 155, "laplac": 54, "larg": [67, 118], "lasso": 67, "law": 154, "layer": [76, 77], "layout": 133, "learn": [61, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 88, 89, 90, 94, 95, 97, 98, 138, 143], "learningfromdata": 141, "least": [35, 101], "lectur": [80, 147], "leibler": 73, "length": 137, "let": [74, 94], "lighthous": [37, 43, 143], "like": 5, "likelihood": [13, 35, 37, 39, 42, 44, 51, 89, 96], "limit": [20, 26, 34, 45, 53, 64, 68, 118, 157], "line": [3, 6, 41, 42, 91, 97, 136, 141, 144], "linear": [35, 47, 50, 53, 66, 68, 86, 99, 100, 101, 102, 103, 113, 115, 116, 128, 137], "liouvil": 150, "liquid": [35, 100], "list": [136, 137], "ll": 38, "local": 105, "locat": [3, 143], "log": [4, 20, 145], "logic": 23, "logist": [71, 75, 89], "look": [5, 25, 74, 94, 159], "lorentzian": 145, "loss": 39, "lower": 73, "m": 49, "machin": [61, 64, 65, 66, 74, 90], "mackei": 147, "macro": 0, "main": [9, 65], "major": 137, "make": [70, 72, 77, 87, 127, 133, 147, 150, 160], "mani": [39, 86, 91, 97], "manipul": [23, 128, 137], "margin": [17, 24, 26, 35, 42, 131, 147], "mark": 0, "markdown": [0, 135], "markov": [45, 142, 154, 155, 156, 157], "mass": [131, 134], "match": [47, 127], "materi": [57, 117, 132], "mathbf": [78, 84], "mathcal": [49, 87], "mathemat": [68, 72, 105, 135], "matplotlib": [18, 135], "matric": [128, 137], "matrix": [35, 68, 86, 101, 126, 128, 137, 157], "matter": 12, "mat\u00e9rn": 82, "maxent": 4, "maxim": 4, "maximum": [4, 5, 42, 89, 96, 137], "mc": 155, "mcmc": [45, 75, 97, 143, 144, 145, 146, 147, 154, 155, 160, 163], "mean": [4, 34, 37, 45, 83, 86, 131, 144], "measur": 131, "mechan": 20, "median": 131, "medic": [23, 32], "meet": 134, "melendez": 87, "memori": 157, "menu": [57, 135], "method": [28, 45, 46, 47, 54, 56, 72, 133, 154], "metropoli": [145, 146, 154, 155, 157, 160, 163], "mh": [51, 144, 155, 160], "mini": [74, 91, 92, 93, 94, 95, 96, 97, 107], "minim": [5, 89, 105, 133], "minimum": 137, "misclassif": 66, "mix": 49, "mixtur": 127, "mnist": 76, "mode": 131, "model": [3, 6, 7, 16, 28, 30, 35, 39, 41, 42, 44, 46, 49, 50, 54, 55, 65, 67, 68, 69, 70, 73, 74, 77, 78, 79, 83, 84, 86, 94, 95, 96, 99, 100, 101, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 124, 144, 152, 162], "modul": [39, 78, 84, 93, 96, 134, 145], "moment": [5, 25, 131], "monkei": 4, "mont": [45, 142, 149, 154, 155, 156], "moor": 35, "moral": 62, "more": [53, 67, 89, 115, 116, 133, 139, 155], "move": 160, "movi": 127, "multi": [49, 55], "multilay": 69, "multimod": 51, "multipl": [49, 136, 137], "multivari": [35, 54, 79, 83, 87, 93, 131], "n": [5, 34, 53, 86, 87, 94, 137, 160], "n_a": 160, "n_b": 160, "n_sampl": 94, "naiv": 155, "name": 6, "ndarrai": 137, "nearest": 66, "need": [5, 38], "neighbor": 66, "net": 71, "network": [68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 94], "neural": [68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 94], "neuron": [68, 76], "new": 86, "newcommand": 30, "next": [47, 74], "nn": [67, 76], "nois": [37, 40, 81, 94, 148], "noisi": [68, 81], "non": [86, 112, 113, 115, 116], "norm": 4, "normal": [4, 18, 26, 30, 35, 54, 66, 72, 79, 83, 86, 87, 101], "notat": [65, 68, 86, 89, 110, 131, 162], "note": [0, 30, 50, 155], "notebook": [20, 80, 85, 88, 134, 135, 138, 139, 141, 152, 159], "now": [51, 72, 124, 153, 160], "nuclear": [35, 46, 100, 134], "nuisanc": [17, 39, 42], "number": [17, 131], "numer": [34, 137, 154], "numpi": [135, 136, 137], "object": [86, 152], "observ": [124, 133], "obtain": [86, 157], "occam": 7, "odd": 96, "omega": [79, 83], "one": [34, 72], "onli": [34, 133, 160], "onlin": [57, 139], "open": [49, 57], "oper": [72, 136, 137], "optic": 157, "optim": [89, 93, 98, 105, 106, 114], "option": [93, 133, 145], "orbit": 151, "order": [46, 96, 137], "ordinari": [35, 101, 102, 103], "organ": 134, "origin": [130, 153], "oscil": 20, "other": [125, 158, 160], "our": 134, "out": 160, "outlier": 39, "output": [69, 130, 133], "over": [67, 160], "overfit": 64, "overgener": 64, "overview": [56, 65, 87, 91, 92, 109, 117, 125, 132, 144, 149, 156, 159, 161], "own": [53, 71, 93], "p": [20, 160], "pair": 80, "panda": 134, "paper": 80, "par": 30, "parallel": [52, 97], "paramet": [0, 7, 16, 17, 39, 40, 41, 42, 54, 78, 84, 89, 94, 95, 97, 136, 148, 153], "parametr": [7, 86, 112], "part": [36, 56, 84, 145, 161], "pass": 133, "pca": [126, 128], "pdf": [4, 6, 17, 18, 19, 21, 24, 38, 42, 131, 143, 145, 154], "pendulum": 150, "penros": 35, "penultim": 13, "perceptron": [66, 69, 89], "perform": 97, "permut": 3, "perspect": 59, "philosoph": 8, "physic": [61, 124, 149], "physicist": 59, "pi": 154, "pick": 151, "plausibl": 63, "plot": [5, 18, 43, 79, 83, 124, 127, 135, 136, 144, 151, 152], "plu": [93, 96], "pocomc": 124, "point": [19, 34, 131, 160], "poisson": [4, 34, 38, 146, 155, 160, 163], "polya": 63, "polynomi": [35, 96, 100, 101], "popul": 23, "possibl": [0, 11, 23, 52], "posterior": [13, 16, 18, 27, 35, 37, 43, 44, 51, 82, 124, 144, 160], "potenti": [5, 151], "power": 154, "practic": [23, 29, 35, 73, 103], "predict": [16, 35, 44, 53, 70, 74, 77, 86, 94], "preliminari": [126, 127, 128], "prelud": 35, "prepar": [38, 77], "presenc": 38, "princip": 128, "principl": [4, 23, 64], "prior": [6, 12, 13, 35, 40, 41, 44, 50, 51, 54, 80, 82, 124, 148, 153], "probabilist": [73, 74], "probabl": [2, 3, 4, 8, 18, 23, 24, 26, 32, 33, 74, 89, 94, 131, 145, 160, 162], "problem": [23, 43, 71, 75, 97, 153, 154], "proce": 95, "process": [78, 79, 81, 82, 83, 84, 86, 87, 157, 162], "product": [17, 23, 26, 33, 82, 137], "prof": 54, "program": 74, "project": [18, 91, 92, 93, 94, 95, 96, 97], "prompt": 130, "proof": [13, 20], "propag": [17, 42, 68, 69, 70], "properti": [35, 137, 160], "propos": 160, "prove": 35, "pseudo": [35, 131, 155], "pt": [51, 97], "ptemce": 97, "pukelsheim": 47, "pump": 157, "put": 97, "pymc": [152, 153, 159], "pymc3": [73, 74, 154], "pymultinest": 154, "pystan": 154, "python": [6, 9, 18, 39, 51, 65, 128, 135, 136, 139, 143], "pytorch": 72, "q": 160, "qbism": 129, "quadradt": 82, "quadrat": 37, "quadratur": 154, "qualiti": 62, "quantum": 129, "question": [0, 3, 4, 5, 12, 15, 16, 19, 20, 23, 24, 25, 32, 33, 35, 37, 42, 48, 71, 84, 86, 89, 96, 101, 145, 146, 155], "quick": [18, 131], "quot": 152, "r2": 66, "radial": 82, "radioact": [43, 143], "random": [17, 86, 131, 145, 155, 157, 160, 162], "randomli": 130, "rang": [54, 136], "rangl": 155, "rank": 137, "rate": [144, 152], "rather": 34, "ratio": [96, 160], "ration": 82, "razor": 7, "rbf": [79, 83], "read": 134, "real": 134, "reason": 63, "recal": [13, 155, 160], "recap": [50, 80, 160], "recognit": 77, "reconstruct": 5, "recurr": 68, "reduc": 46, "reduct": [46, 65, 76, 128], "refer": [0, 32, 33, 86, 129], "referenc": 0, "region": [72, 131, 145], "regress": [35, 65, 66, 67, 71, 75, 78, 79, 81, 83, 84, 86, 89, 101, 102, 103, 111, 114], "regular": [67, 76, 89], "relat": 160, "releas": 133, "remark": [0, 8, 67], "remind": 134, "remnant": 157, "remov": 137, "report": 64, "reproduc": 44, "request": 97, "requir": 64, "resampl": 45, "research": 44, "reshap": 137, "result": [5, 37, 44, 50, 152], "return": 80, "revers": 157, "review": [18, 26, 45, 79], "revisit": [17, 144], "rewrit": 35, "rewritten": 89, "ridg": 67, "rightarrow": 53, "rmsprop": 108, "rob": 152, "root": 17, "routin": 137, "row": 137, "rubin": [45, 144, 152], "rule": [10, 20, 23, 26, 32, 33, 47, 68, 69, 143, 155], "run": [78, 138, 143, 147], "sampl": [17, 18, 19, 34, 37, 39, 45, 51, 75, 78, 79, 83, 84, 124, 145, 146, 147, 152, 153, 154, 155, 157, 160, 161, 163], "sampler": [51, 97, 124, 152, 153, 158, 164], "save": 135, "scalar": 137, "scale": [3, 74, 76, 94], "scandinavian": 4, "scienc": [7, 65, 111], "scientif": [28, 117], "scientist": 62, "scikit": [71, 75, 88], "scipi": [18, 131], "score": [66, 67], "second": [34, 133], "sect": 147, "section": [0, 19, 96, 155], "select": [35, 54, 64, 80, 96, 137], "sens": 87, "sensit": 35, "set": [6, 9, 49, 69, 75, 76, 78, 84, 124, 133, 140, 153], "setup": [124, 152], "shape": 137, "sheet": 139, "shell": [79, 83], "shortcut": 135, "should": [97, 139], "sigma": [14, 47], "sigmoid": 66, "signal": [37, 38, 68], "signific": 20, "simpl": [68, 71, 75, 133, 153, 157, 162], "sine": 82, "singl": [34, 42], "singular": 126, "sivia": 37, "size": [34, 137], "slant": 37, "slice": 164, "societi": 65, "soft": 66, "softmax": 89, "solut": [0, 16, 17, 35, 41, 66, 67, 68, 97, 104, 116, 131, 154, 157, 162], "solv": [128, 151], "some": [18, 127], "sort": 137, "sound": [0, 44], "space": 49, "spars": 137, "sparsiti": 118, "special": [20, 61, 137, 162], "specif": [74, 94], "specifi": 72, "spectral": 97, "speed": 136, "split": 137, "spot": 35, "squar": [17, 30, 35, 54, 82, 101], "standard": [17, 18, 23, 32, 39, 89, 137, 144], "start": [57, 78, 84, 132, 159], "stat": [18, 131], "state": [20, 154, 157], "statement": [22, 97, 128], "stationari": [86, 157, 160], "statist": [0, 20, 44, 47, 50, 54, 111, 124, 131, 137, 154], "step": [20, 42, 44, 60, 72, 74], "stochast": [107, 157, 162], "stori": 54, "straight": [3, 6, 41, 42, 144], "strategi": 97, "string": 135, "structur": 155, "student": [18, 127], "studi": 67, "style": 124, "sub": 71, "subtask": [95, 97], "suggest": [72, 95], "sum": [17, 23, 26, 30, 33, 34, 86], "summari": [8, 17, 25, 42, 86, 134, 160], "supervis": 68, "surfac": [74, 94], "svd": [126, 128], "switch": 72, "symmetr": [126, 160], "symmetri": 3, "system": 64, "systemat": [42, 76], "t": [12, 18, 76, 127], "tab": 133, "tabl": 37, "take": [15, 17, 26], "taken": 128, "tale": 49, "talent": 92, "target": [81, 86], "task": [71, 75, 78, 145], "tell": 72, "temper": [52, 97], "tensor": 72, "tensorflow": [70, 77], "term": [69, 160], "terminologi": 68, "test": [30, 45, 54, 93], "test_siz": 94, "text": 30, "than": 34, "theano": 74, "thei": 12, "them": 0, "theorem": [20, 23, 24, 26, 34, 150], "theori": [26, 46, 124], "thermodynam": [97, 160], "theta": 30, "thetavec": 160, "thetavec_i": 160, "thi": [26, 41, 53, 57, 72, 87, 93, 96, 139, 140, 144, 160], "thing": [41, 50, 96, 128, 130, 146], "think": [20, 160], "third": [34, 133], "those": 160, "three": [47, 65], "through": 136, "time": [147, 160], "tip": 0, "togeth": 69, "toi": [50, 95], "top": [37, 77], "topic": 125, "toss": [9, 11, 26, 31], "total": 160, "trace": 137, "tradeoff": 67, "train": [64, 66, 67, 70, 73, 77], "transform": [34, 35, 76], "translat": 3, "trend": 74, "trick": 86, "true": 50, "try": [5, 51, 130, 134], "two": [17, 34, 35, 37, 49, 51, 54, 89, 157], "type": [64, 65, 68, 131, 137], "ubiqu": 20, "ui": [9, 133], "uncertainti": [7, 73, 74, 94], "uncorrel": 4, "underfit": [64, 67], "uniform": [13, 35, 131, 154], "univari": [93, 144], "up": [6, 9, 15, 19, 32, 35, 38, 69, 71, 76, 78, 133, 140, 153], "updat": [9, 10, 31, 138], "uphil": 160, "url": 0, "us": [4, 17, 20, 23, 32, 42, 49, 50, 71, 72, 75, 76, 84, 86, 97, 128, 138, 139, 140, 141, 143, 145, 160], "user": [9, 133], "util": [72, 150], "v": [14, 137], "valid": [66, 67, 96], "valu": [20, 25, 74, 94, 97, 126, 131, 133, 137], "variabl": [17, 30, 34, 37, 72, 86, 131], "varianc": [4, 45, 67, 131, 137], "variat": [51, 73, 74, 75, 94], "vector": 68, "verbatim": 152, "verif": 72, "verifi": [19, 77, 160], "versu": [112, 113, 114, 136, 137], "via": 10, "view": [8, 35], "virtu": 62, "visual": [18, 24, 34, 149, 150, 154, 155], "volum": 76, "walk": [145, 155, 157, 160, 162], "wamb": 44, "want": 133, "warm": 35, "warmup": [35, 102], "warn": 0, "we": [5, 38, 53, 87, 144, 155, 160], "weather": 157, "websit": [72, 87], "weight": [68, 89], "well": [76, 80], "went": 160, "were": 160, "what": [5, 20, 37, 40, 47, 61, 74, 80, 94, 96, 137, 139, 147, 148, 153, 160], "when": [12, 20, 138], "why": [4, 68, 155, 160], "wide": 68, "widget": [9, 133, 135], "width": 118, "winter": 157, "without": 124, "workflow": [35, 44, 60], "would": 160, "x": [17, 78, 84], "x_0": 43, "x_a": 160, "x_b": 160, "y": 17, "yet": 5, "you": [20, 50, 57, 133, 139, 147, 160], "your": [53, 71, 93, 97, 138], "yourself": 134, "z": 17, "z_j": 69, "zero": 137, "zeu": [51, 153, 164]}})