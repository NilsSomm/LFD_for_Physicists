Search.setIndex({"alltitles": {"": [[0, "exercise:ppd_definition_b"], [16, "exercise:ppd_definition"], [16, "exercise:pdf_normalization"], [16, "exercise:rain"], [16, "exercise:monty_hall"], [16, "exercise:coin_ppd"], [39, "exercise:ols_example_1_b"], [39, "exercise:ols_example_2_b"], [39, "exercise:ols_example_3_b"], [39, "exercise:ols_example_4_b"], [39, "exercise:ols_example_5_b"], [53, "id1"], [106, "exercise:ols_example_1"], [106, "exercise:ols_example_2"], [106, "exercise:ols_example_3"], [107, "exercise:ols_example_4"], [107, "exercise:ols_example_5"], [166, "exercise:StochasticProcess:first-example"], [166, "exercise:conditional-probabilities-stochastic-process"], [166, "exercise:construct-stochastic-process"]], " (A reversible Markov chain)": [[161, "exercise:MarkovChains:reversible-chain"]], " (A reversible Markov process)": [[161, "example:reversible-markov-process"]], " (A simple Markov process)": [[161, "example:simple-markov-process"]], " (An exponential growth model)": [[166, "example:exponential-growth-models"]], " (Bayes\u2019 rule/theorem)": [[30, "property:bayes_rule"]], " (Binary classification)": [[70, "example:MLexamples:binary-classification"]], " (Bivariate pdf)": [[135, "exercise:Statistics:bivariate-pdf"]], " (Checklist for statistically sound Bayesian inference)": [[0, "remark:BayesianWorkflow:buqeye-checklist_b"], [48, "remark:BayesianWorkflow:buqeye-checklist"]], " (Conditional discrete probability mass function)": [[135, "exercise:Statistics:conditional-discrete-pmf"]], " (Conditional distributions)": [[161, "exercise:MarkovChains:conditional-distributions"]], " (Conditional expectation)": [[135, "exercise:Statistics:conditional-expectation"]], " (Conditional probabilities of a stochastic process)": [[166, "example:conditional-stochastic-process"]], " (Conditional probability for continuous variables)": [[135, "exercise:Statistics:conditional-probability-continuous"]], " (Conditional probability)": [[135, "definition:conditional-probability"]], " (Conditional probability-distribution)": [[135, "definition:conditional-probability-distribution"]], " (Correlated errors)": [[18, "exercise:BayesianAdvantage:correlated-errors"]], " (Covariance and correlation)": [[135, "definition:covariance-correlation"]], " (Detailed balance)": [[161, "exercise:detailed-balance"]], " (Eigenvector continuation in ab initio nuclear theory)": [[50, "example-0"]], " (Expectation value)": [[135, "definition:expectation-value"]], " (Expected signal)": [[72, "exercise:NeuralNet:expected-signal"]], " (Flip-flop)": [[161, "exercise:flip-flop"]], " (Gaussian process)": [[166, "definition:gaussian-process"]], " (Gaussian product of errors)": [[20, "exercise:BayesianAdvantages:gaussian-product-of-errors"]], " (Gaussian sum of errors)": [[20, "exercise:BayesianAdvantages:gaussian-sum-of-errors"]], " (Generalized normal equation)": [[39, "exercise:BayesianLinearRegression:GeneralizedNormalEquation"]], " (Global minimization)": [[109, "definition:MathematicalOptimization:global-minimization"]], " (Gothenburg winter weather)": [[161, "exercise:MarkovChains:gothenburg-winter-weather"]], " (Gradient descent optimization)": [[110, "algorithm:MathematicalOptimization:gradient-descent"]], " (Illustration of S/IR)": [[49, "example-3"]], " (Implement k-fold cross validation)": [[71, "exercise:ModelValidation:kfold-cross-validation"]], " (Independence)": [[135, "property:independence"]], " (Independent and dependent)": [[119, "exercise:OverviewModeling:independent-dependent"]], " (Independent events)": [[135, "definition:independent-events"]], " (Inferring galactic distances)": [[18, "example:BayesianAdvantage:inferring-galactic-distances"], [18, "exercise:BayesianAdvantages:inferring-galactic-distances-ex"]], " (Inferring galactic distances\u2014revisited)": [[20, "example:BayesianAdvantage:inferring-galactic-distances-revisited"]], " (Is it reversible?)": [[161, "exercise:is-it-reversible"]], " (Joint probability distribution)": [[135, "definition:joint-probability-distribution"]], " (Large training error)": [[71, "exercise:ModelValidation:large-training-error"]], " (Limiting distribution)": [[161, "definition:limiting-distribution"], [161, "exercise:limiting-distribution"]], " (Linear models)": [[117, "example:OverviewModeling:linear-models"]], " (Linear or non-linear)": [[119, "exercise:OverviewModeling:linear-nonlinear"]], " (Linear or non-linear; more examples)": [[119, "exercise:OverviewModeling:linear-nonlinear-examples"]], " (Linear signals)": [[72, "exercise:NeuralNet:linear-signal"]], " (Liquid-drop model for nuclear binding energies)": [[39, "example:LinearModels:liquid-drop-model_b"], [104, "example:LinearModels:liquid-drop-model"]], " (Local minimization)": [[109, "definition:MathematicalOptimization:local-minimization"]], " (Marginal density functions)": [[135, "property:marginal-density-functions"]], " (Markov chains)": [[161, "definition:markov-chains"]], " (Metropolis sampling of a uniform distribution)": [[158, "exercise:metropolis-sampling-uniform"]], " (Misclassification cost function)": [[70, "exercise:MLexamples:misclassification-cost-function"]], " (Model discrepancy)": [[119, "exercise:OverviewModeling:model-discrepancy"]], " (Monte Carlo estimation of \\pi)": [[158, "example-0"]], " (Non-linear models)": [[117, "example:OverviewModeling:nonlinear-models"]], " (Optical pumping)": [[161, "exercise:optical-pumping"]], " (Ordinary least squares (the normal equation))": [[39, "theorem:BayesianLinearRegression:normal-equation_b"], [105, "theorem:LinearModels:normal-equation"]], " (Polynomial basis functions)": [[39, "example:polynomial-linear-model_b"], [104, "example:polynomial-linear-model"]], " (Power-law distributions)": [[158, "exercise:power-law-distribution-sampling"]], " (Practicing the sum and product rule with population characteristics)": [[27, "exercise:Inferenceandpdfs:sumandproductrule"]], " (Prior and posterior predictive checking)": [[48, "remark:BayesianWorkflow:predictive-checking"]], " (Probability density function)": [[135, "definition:probability-density-function"]], " (Probability mass function)": [[135, "definition:probability-mass-function"]], " (Probability measure)": [[135, "definition:probability-measure"]], " (Product rule)": [[30, "property:product_rule"]], " (Prove the Gaussian likelihood)": [[39, "exercise:BayesianLinearRegression:likelihood_pars_b"]], " (R2 score)": [[70, "exercise:MLexamples:R2-score"]], " (Random and colorblind)": [[135, "exercise:Statistics:colorblind"]], " (Random variable and distribution function)": [[135, "definition:random-variable"]], " (Regression analysis)": [[115, "definition:OverviewModeling:regression-analysis"]], " (Remnant memory)": [[161, "exercise:MarkovChains:memory"]], " (Reversibility)": [[161, "exercise:MarkovChains:reversibility"]], " (Scipy.stats)": [[135, "exercise:Statistics:scipy-stats"]], " (Sigmoid decision boundary)": [[70, "exercise:MLexamples:sigmoid-decision-boundary"]], " (Simple random walk)": [[161, "exercise:MarkovChains:simple-random-walk"], [166, "example:simple-random-walk"]], " (Stationary Gothenburg winter weather)": [[161, "exercise:stationary-gothenburg-winter-weather"]], " (Stationary distribution of \u201cA simple Markov process\u201d)": [[161, "example:stationary-simple-markov-process"]], " (Stationary distribution)": [[161, "definition:stationary-distribution"], [161, "exercise:MarkovChains:stationary-distribution"]], " (Stationary processes)": [[161, "definition:stationary-processes"]], " (Stationary two-state distribution)": [[161, "exercise:stationary-2x2"]], " (Statistical inference)": [[115, "definition:OverviewModeling:statistical-inference"]], " (Stochastic matrix)": [[161, "exercise:MarkovChains:stochastic-matrix"]], " (Study of model bias and variance)": [[71, "exercise:ModelValidation:study-model-bias-variance"]], " (Sum of two Gaussian  PDFs)": [[18, "exercise:BayesianAdvantage:complete-the square"]], " (Sum rule)": [[30, "property:sum_rule"]], " (Taking the square root of a number)": [[20, "example:BayesianAdvantage:taking-square-root"]], " (The Gelman-Rubin diagnostic)": [[49, "algorithm:AdvancedMCMC:gelman-rubin"]], " (The Hamiltonian Monte Carlo method)": [[49, "algorithm:AdvancedMCMC:HMC"]], " (The Metropolis algorithm for a discrete distribution)": [[158, "exercise:MCMC:discrete-metropolis"]], " (The Metropolis design for obtaining a discrete limiting distribution)": [[161, "remark:MCMC:Metropolis-discrete"]], " (The Metropolis-Hastings algorithm)": [[158, "algorithm-1"]], " (The Sampling/Importance Resampling method)": [[49, "algorithm:AdvancedMCMC:SIR"]], " (The WAMBS checklist)": [[48, "remark:BayesianWorkflow:wambs-checklist"]], " (The bias-variance tradeoff)": [[71, "theorem:ModelValidation:bias-variance"]], " (The design matrix for polynomial models)": [[39, "example:design-matrix-polynomial-models_b"], [105, "example:design-matrix-polynomial-models"]], " (The history-matching algorithm)": [[51, "algorithm:BayesLinear:History-Matching"]], " (The square root of a number)": [[19, "exercise:BayesianAdvantages:square-root-of-a-number"]], " (The standard random variable)": [[19, "exercise:BayesianAdvantages:standard-random-variable"]], " (Using Bayesian rules of probability on a standard medical problem)": [[27, "exercise:Inferenceandpdfs:medicalexample"]], " (Validation errors)": [[70, "exercise:MLexamples:validation-errors"]], " (Variance)": [[135, "definition:variance"]], " (Warm-up Bayesian linear regression (data errors))": [[39, "exercise:BayesianLinearRegression:warmup_errors"]], " (Warm-up Bayesian linear regression (prior sensitivity))": [[39, "exercise:BayesianLinearRegression:warmup_priors"]], " (Warm-up Bayesian linear regression)": [[39, "exercise:BayesianLinearRegression:warmup"]], " (Weights and signal propagation of a simple neural network)": [[72, "exercise:NeuralNet:simple-network"]], " (Weights and signal propagation of a wide neural network)": [[72, "exercise:NeuralNet:wide-network"]], " (Z = X + Y)": [[18, "example:BayesianAdvantage:Z=X+Y"]], " (k-fold cross-validation)": [[71, "algorithm:ModelValidation:cross-validation"]], " (k=1 NN training error)": [[71, "exercise:ModelValidation:kNN-training-error"]], " (kNN for regression)": [[70, "exercise:MLexamples:kNN-regression"]], " (kNN model complexity)": [[71, "exercise:ModelValidation:kNN-model-complexity"]], " (\u201cIn practice\u201d Bayesian linear regression)": [[39, "exercise:BayesianLinearRegression:in_practice"]], "(Pseudo) random number generator": [[135, "pseudo-random-number-generator"]], "*Aside: Bayesian epistemology": [[8, null]], "*Convolutional Neural Networks": [[80, null]], "*Marking a section in a different color": [[0, "marking-a-section-in-a-different-color"]], "*Neural networks: Backpropagation": [[73, null]], "1 Getting started: The Covariance Function": [[82, "getting-started-the-covariance-function"]], "1. A univariate example with GPyOpt": [[97, "a-univariate-example-with-gpyopt"]], "1. Import ipywidgets and Ipython.display": [[137, "import-ipywidgets-and-ipython-display"], [137, "id1"], [137, "id7"]], "1. n_samples = 1000, noise = 0.2, test_size = 0.5, iterations n = 30000": [[98, "n-samples-1000-noise-0-2-test-size-0-5-iterations-n-30000"]], "1D vs 2D Array": [[141, "d-vs-2d-array"]], "2 Sampling from a Gaussian Process": [[82, "sampling-from-a-gaussian-process"]], "2. Build your own BayesOpt algorithm (optional or for your project)": [[97, "build-your-own-bayesopt-algorithm-optional-or-for-your-project"]], "2. Create a function with all inputs that makes the output figure(s).": [[137, "create-a-function-with-all-inputs-that-makes-the-output-figure-s"], [137, "id8"]], "2. Create a function with all inputs to generate the output figure(s).": [[137, "create-a-function-with-all-inputs-to-generate-the-output-figure-s"]], "2. n_samples = 1000, noise = 0.2, test_size = 0.5, iterations n = 60000": [[98, "n-samples-1000-noise-0-2-test-size-0-5-iterations-n-60000"]], "3 A Gaussian Process Regression Model": [[82, "a-gaussian-process-regression-model"]], "3. Make a widget for each value you want to control.": [[137, "make-a-widget-for-each-value-you-want-to-control"], [137, "id2"], [137, "id9"]], "3. Test on bivariate example (Do this for a plus)": [[97, "test-on-bivariate-example-do-this-for-a-plus"]], "3. n_samples = 1000, noise = 0.05, test_size = 0.5, iterations n = 60000": [[98, "n-samples-1000-noise-0-05-test-size-0-5-iterations-n-60000"]], "3D volumes of neurons": [[80, "d-volumes-of-neurons"]], "4 A Running Example": [[82, "a-running-example"]], "4.  Make any explicit callback functions and add .observe methods.": [[137, "make-any-explicit-callback-functions-and-add-observe-methods"], [137, "id3"], [137, "id10"]], "4. Multivariate test examples (optional)": [[97, "multivariate-test-examples-optional"]], "4. n_samples = 1000, noise = 0.5, test_size = 0.5, iterations n = 60000": [[98, "n-samples-1000-noise-0-5-test-size-0-5-iterations-n-60000"]], "5. Set up the interactive_output function.": [[137, "set-up-the-interactive-output-function"], [137, "id4"], [137, "id11"]], "5. n_samples = 100, noise = 0.2, test_size = 0.5, iterations n = 60000": [[98, "n-samples-100-noise-0-2-test-size-0-5-iterations-n-60000"]], "6. Make the layout of the widgets.": [[137, "make-the-layout-of-the-widgets"], [137, "id5"], [137, "id12"]], "7. Release the Kraken!": [[137, "release-the-kraken"], [137, "id6"], [137, "id13"]], "<a name=\"Python\">Python/Jupyter set up</a>": [[6, "python-jupyter-set-up"]], "A Gaussian Process Regression Model": [[88, "a-gaussian-process-regression-model"]], "A binary classifier with two parameters": [[93, "a-binary-classifier-with-two-parameters"]], "A first summary": [[138, "a-first-summary"]], "A learning algorithm": [[93, "a-learning-algorithm"]], "A more compact expression": [[93, "a-more-compact-expression"]], "A new target prediction using a GP": [[90, null]], "A simple classification problem": [[75, "a-simple-classification-problem"], [79, "a-simple-classification-problem"]], "A spectral line problem": [[101, "a-spectral-line-problem"]], "A tale of two models: contrasting BMA with BMM}": [[53, "a-tale-of-two-models-contrasting-bma-with-bmm"]], "ANNs in the large-width limit": [[122, null]], "About this Jupyter Book": [[61, null]], "Acceptance Rate for the MH Algorithm": [[148, "acceptance-rate-for-the-mh-algorithm"]], "Acceptance rate": [[156, "acceptance-rate"]], "Acknowledgements": [[78, "acknowledgements"]], "Acknowledgments": [[61, "acknowledgments"]], "Activation outputs": [[73, null]], "Activation rule": [[72, null]], "Activation rules": [[72, "activation-rules"]], "Adagrad": [[112, "adagrad"]], "Adam": [[112, "adam"]], "Adaptive gradient descent algorithms": [[112, null]], "Add Dense layers on top": [[81, "add-dense-layers-on-top"]], "Addendum: Ordinary linear regression in practice": [[39, "addendum-ordinary-linear-regression-in-practice"]], "Adding n variables drawn from a distribution": [[38, "adding-n-variables-drawn-from-a-distribution"]], "Adding/removing elements": [[141, "adding-removing-elements"]], "Admonitions": [[0, "admonitions"]], "Advanced Markov Chain Monte Carlo": [[146, null]], "Advanced Markov chain Monte Carlo sampling": [[49, null]], "Advanced feature: Widgets for graphical exploration": [[139, "advanced-feature-widgets-for-graphical-exploration"]], "Advantages of the Bayesian approach": [[7, null]], "Aleatoric uncertainties": [[77, null]], "Algorithm pseudo-code:": [[159, null]], "Anaconda and github": [[142, "anaconda-and-github"]], "Anaconda environments": [[142, "anaconda-environments"]], "Analysis": [[147, "analysis"]], "Analyze sampling results": [[156, "analyze-sampling-results"]], "Another standard class of pdf:  Student t": [[22, "another-standard-class-of-pdf-student-t"]], "Answer": [[0, null], [3, null], [11, null], [12, null], [12, null], [12, null], [15, null], [16, null], [23, null], [23, null], [23, null], [23, null], [23, null], [24, null], [24, null], [28, null], [28, null], [28, null], [29, null], [29, null], [36, null], [36, null], [36, null], [36, null], [36, null], [36, null], [36, null], [36, null], [36, null], [36, null], [36, null], [37, null], [37, null], [37, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [41, null], [41, null], [52, null], [52, null]], "Answer (a)": [[37, null], [37, null]], "Answer (b)": [[37, null], [37, null]], "Answer (c)": [[37, null]], "Answer all the questions": [[36, "answer-all-the-questions"], [37, "answer-all-the-questions"]], "Answer these questions": [[100, "answer-these-questions"]], "Answers": [[41, null], [105, null]], "Application 1: GP emulator from Higdon et al. paper": [[84, "application-1-gp-emulator-from-higdon-et-al-paper"]], "Application of Information Criteria and Bayes factors": [[56, "application-of-information-criteria-and-bayes-factors"]], "Applications of SVD": [[130, "applications-of-svd"]], "Applying the Bayesian approach": [[152, "applying-the-bayesian-approach"], [157, "applying-the-bayesian-approach"]], "Architecture": [[72, null]], "Array Manipulation Routines": [[141, "array-manipulation-routines"]], "Array shape manipulations": [[141, "array-shape-manipulations"]], "Array to/from List conversion": [[141, "array-to-from-list-conversion"]], "Arrays vs Lists": [[141, "arrays-vs-lists"]], "Artifical neural networks": [[72, null]], "Artificial neurons": [[72, "artificial-neurons"]], "Aside: List comprehensions": [[140, "aside-list-comprehensions"]], "Aside: dissection of the Python statement to find the index for accumulation": [[132, "aside-dissection-of-the-python-statement-to-find-the-index-for-accumulation"]], "Aside: how do we make draws from a multivariate     Gaussian (normal) distribution if we know how to make draws from     \\mathcal{N}(0,1)?": [[91, null]], "Aspirational virtues for Bayesian inference and beyond": [[66, null]], "Assigning probabilities": [[2, null]], "Assigning probabilities (I): Indifferences and translation groups": [[3, null]], "Assigning probabilities (II): The principle of maximum entropy": [[4, null]], "Assignment: 2D radioactive lighthouse location using MCMC": [[147, null]], "Autocorrelation": [[49, "autocorrelation"], [164, "autocorrelation"]], "Autocorrelation Plots": [[148, "autocorrelation-plots"]], "Autocorrelation plots": [[156, "autocorrelation-plots"]], "Automation bias": [[68, null]], "Available samplers": [[156, "available-samplers"]], "Average, Variance, and Standard Deviation": [[141, "average-variance-and-standard-deviation"]], "Axioms of probability theory": [[30, "axioms-of-probability-theory"]], "BDA3: Gelman et al, Fig. 11.1": [[148, "bda3-gelman-et-al-fig-11-1"]], "Background info on GPs": [[91, "background-info-on-gps"]], "Background on linear models": [[39, "background-on-linear-models"]], "Basic Mathematical Operations": [[76, "basic-mathematical-operations"]], "Basic idea": [[58, "basic-idea"]], "Basic neural network": [[77, "basic-neural-network"]], "Basic setup of a model": [[156, "basic-setup-of-a-model"]], "Basic structure of MCMC algorithm": [[159, "basic-structure-of-mcmc-algorithm"]], "Basics and notation": [[93, "basics-and-notation"]], "Batch, stochastic and mini-batch gradient descent": [[111, null]], "Bayes by Backprop": [[77, "bayes-by-backprop"]], "Bayes goes fast: Emulators": [[50, null]], "Bayes goes linear: History matching": [[51, null]], "Bayes in practice": [[33, null]], "Bayes linear methods": [[51, "bayes-linear-methods"]], "Bayes linear statistics": [[51, null]], "Bayesian Approach to Outliers #1: A conservative formulation": [[43, "bayesian-approach-to-outliers-1-a-conservative-formulation"]], "Bayesian Approach to Outliers #2: Good-and-bad data": [[43, "bayesian-approach-to-outliers-2-good-and-bad-data"]], "Bayesian Approach to Outliers #3: The Cauchy formulation": [[43, "bayesian-approach-to-outliers-3-the-cauchy-formulation"]], "Bayesian Approach to Outliers #4: Many nuisance parameters": [[43, "bayesian-approach-to-outliers-4-many-nuisance-parameters"]], "Bayesian Linear Regression (BLR)": [[39, null]], "Bayesian Neural Networks in PyMC3": [[78, "bayesian-neural-networks-in-pymc3"]], "Bayesian approach to Gaussian parameter estimation": [[44, "bayesian-approach-to-gaussian-parameter-estimation"], [152, "bayesian-approach-to-gaussian-parameter-estimation"], [157, "bayesian-approach-to-gaussian-parameter-estimation"]], "Bayesian approach to model discrepancy": [[123, null]], "Bayesian approaches to erratic data": [[43, "bayesian-approaches-to-erratic-data"]], "Bayesian credible intervals and frequentist confidence intervals": [[24, "bayesian-credible-intervals-and-frequentist-confidence-intervals"]], "Bayesian evidence": [[100, "id1"]], "Bayesian evidence:": [[100, "bayesian-evidence"]], "Bayesian handling of nuisance parameters": [[46, "bayesian-handling-of-nuisance-parameters"]], "Bayesian inference for multiple models": [[53, "bayesian-inference-for-multiple-models"]], "Bayesian inference in the multi-model setting": [[53, "bayesian-inference-in-the-multi-model-setting"]], "Bayesian linear regression: warmup": [[39, "bayesian-linear-regression-warmup"]], "Bayesian methods for scientific modeling": [[32, null]], "Bayesian model averaging and the \\mathcal{M}-closed assumption": [[53, "bayesian-model-averaging-and-the-mathcal-m-closed-assumption"]], "Bayesian model selection": [[58, "bayesian-model-selection"]], "Bayesian neural networks": [[77, null]], "Bayesian neural networks in PyMC3": [[77, "bayesian-neural-networks-in-pymc3"]], "Bayesian neural networks in practice": [[77, "bayesian-neural-networks-in-practice"]], "Bayesian parameter estimation": [[16, "bayesian-parameter-estimation"]], "Bayesian posteriors": [[31, null]], "Bayesian probability": [[8, "bayesian-probability"]], "Bayesian research workflow": [[48, null]], "Bayesian updating": [[9, "bayesian-updating"], [35, "bayesian-updating"]], "Bayesian workflow": [[64, null]], "Bayes\u2019 theorem": [[27, "bayes-theorem"], [30, "bayes-theorem"]], "Bayes\u2019 theorem applied to PDFs": [[28, "bayes-theorem-applied-to-pdfs"]], "Behavior of the mean of a fixed-size sample": [[38, "behavior-of-the-mean-of-a-fixed-size-sample"]], "Benchmark case: questions": [[5, "benchmark-case-questions"]], "Bibliography": [[1, null]], "Bibliography references": [[0, "bibliography-references"]], "Binary classification": [[93, "binary-classification"]], "Bonus:  Do this section for a plus": [[100, "bonus-do-this-section-for-a-plus"]], "Bonus: additional subtasks": [[99, "bonus-additional-subtasks"]], "Breakout questions": [[46, "breakout-questions"]], "Bridging Deep Learning and Probabilistic Programming": [[78, "bridging-deep-learning-and-probabilistic-programming"]], "Brief guide to online Jupyter Book features": [[61, "brief-guide-to-online-jupyter-book-features"]], "Brief introduction to GPs from Melendez et al.": [[91, "brief-introduction-to-gps-from-melendez-et-al"]], "Brief review of the method": [[49, "brief-review-of-the-method"]], "Brief summary of expectation values and moments": [[29, null]], "Bringing it together, first back propagation equation": [[73, "bringing-it-together-first-back-propagation-equation"]], "Build the network": [[74, "build-the-network"]], "But what about the prior?": [[44, "but-what-about-the-prior"], [152, "but-what-about-the-prior"], [157, "but-what-about-the-prior"]], "CNNs in brief": [[80, "cnns-in-brief"]], "Calculating the evidence": [[56, "calculating-the-evidence"]], "Case 1: Fixed H_0": [[46, "case-1-fixed-h-0"]], "Case 2: Using the inferred pdf for H_0": [[46, "case-2-using-the-inferred-pdf-for-h-0"]], "Case I: uniform (flat) prior": [[13, "case-i-uniform-flat-prior"]], "Case II: conjugate prior": [[13, "case-ii-conjugate-prior"]], "Central moments: Variance and Covariance": [[135, "central-moments-variance-and-covariance"]], "Challenges for gradient descent": [[110, null]], "Challenges in MCMC sampling": [[158, "challenges-in-mcmc-sampling"]], "Changing to the 2025-book-env env kernel when running a Jupyter notebook": [[142, "changing-to-the-2025-book-env-env-kernel-when-running-a-jupyter-notebook"]], "Characteristics of PDFs": [[23, null]], "ChatGPT prompts for original code": [[134, "chatgpt-prompts-for-original-code"]], "Check for between chain variations": [[55, "check-for-between-chain-variations"]], "Check that with the delta functions we get the rule for \\langle f\\rangle.": [[159, null]], "Check the N\\rightarrow \\infty limit": [[57, null]], "Checklists": [[48, "checklists"]], "Checkpoint Question": [[24, null]], "Checkpoint question": [[0, null], [0, null], [3, null], [15, null], [16, null], [24, null], [27, null], [28, null], [28, null], [28, null], [29, null], [29, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [52, null], [52, null], [105, null]], "Checkpoint questions": [[0, "checkpoint-questions"]], "Choosing the GP model hyperparameters": [[90, "choosing-the-gp-model-hyperparameters"]], "Class exercises": [[11, null]], "Class probabilities: The Softmax function": [[93, "class-probabilities-the-softmax-function"]], "Class: state the rule used to justify each step": [[24, null]], "Classification algorithms": [[69, null]], "Clustering algorithms": [[69, null]], "Code": [[134, "code"]], "Code and Markdown cells": [[139, "code-and-markdown-cells"]], "Code example": [[135, "code-example"]], "Code examples: binary classifiers": [[70, "code-examples-binary-classifiers"]], "Coin tossing: Frequentists and Bayesaians": [[11, null]], "Combining Covariance Functions": [[82, "combining-covariance-functions"], [88, "combining-covariance-functions"]], "Combining Covariance Functions in GPy": [[82, "combining-covariance-functions-in-gpy"], [88, "combining-covariance-functions-in-gpy"]], "Comments and suggestions": [[99, "comments-and-suggestions"]], "Common Initialization Methods": [[76, "common-initialization-methods"]], "Common set up and generating data for all samplers": [[157, "common-set-up-and-generating-data-for-all-samplers"]], "Compare Gaussian noise sampling to lighthouse calculation": [[41, "compare-gaussian-noise-sampling-to-lighthouse-calculation"]], "Compare a sum of D Poisson draws with mean 1 to a single Poisson distribution with mean D": [[38, "compare-a-sum-of-d-poisson-draws-with-mean-1-to-a-single-poisson-distribution-with-mean-d"]], "Comparing samplers for a simple problem": [[157, null]], "Comparison with parameter estimation": [[58, "comparison-with-parameter-estimation"]], "Compile and train the model": [[81, "compile-and-train-the-model"]], "Complex Expressions": [[76, "complex-expressions"]], "Computational possibilities for evidence": [[56, "computational-possibilities-for-evidence"]], "Computing the Bayesian evidence": [[56, null]], "Computing the Covariance Function given the Input Data, \\mathbf{X}": [[82, "computing-the-covariance-function-given-the-input-data-mathbf-x"], [88, "computing-the-covariance-function-given-the-input-data-mathbf-x"]], "Computing the posterior analytically": [[13, null]], "Concatenate arrays": [[141, "concatenate-arrays"]], "Confidence intervals": [[23, null]], "Consequences:": [[24, "consequences"]], "Continuing \u2026": [[39, "continuing"]], "Continuous case": [[4, "continuous-case"]], "Contrast Bayesian and significance analyses for coin flipping": [[24, "contrast-bayesian-and-significance-analyses-for-coin-flipping"]], "Convergence tests for MCMC sampling": [[49, "convergence-tests-for-mcmc-sampling"]], "Converting linear models to matrix form": [[39, "converting-linear-models-to-matrix-form"]], "Convolutional Neural Network": [[72, "convolutional-neural-network"]], "Convolutional Neural Network (CNN)": [[81, "convolutional-neural-network-cnn"]], "Correlated posteriors": [[41, "correlated-posteriors"]], "Correlations": [[58, "correlations"]], "Covariance Function Parameter Estimation": [[82, "covariance-function-parameter-estimation"], [88, "covariance-function-parameter-estimation"]], "Covariance Functions in GPy": [[82, "covariance-functions-in-gpy"], [88, "covariance-functions-in-gpy"]], "Covariance functions, aka kernels": [[83, "covariance-functions-aka-kernels"], [87, "covariance-functions-aka-kernels"]], "Covariance, PCA and SVD": [[132, "covariance-pca-and-svd"]], "Create Arrays": [[141, "create-arrays"]], "Create special ndarray": [[141, "create-special-ndarray"]], "Create the convolutional base": [[81, "create-the-convolutional-base"]], "Creating a Sparse Matrix": [[141, "creating-a-sparse-matrix"]], "Creating a conda environment": [[142, "creating-a-conda-environment"]], "Creating a list, range, numpy array": [[140, "creating-a-list-range-numpy-array"]], "Credible regions": [[135, "credible-regions"]], "Cross validation": [[100, "cross-validation"]], "Cross-validation": [[71, "cross-validation"]], "Current trends in Machine Learning": [[78, "current-trends-in-machine-learning"]], "Customizing Initialization in PyTorch": [[76, "customizing-initialization-in-pytorch"]], "Data bias and fairness in machine learning": [[68, null]], "Data bias types in machine learning, including examples": [[68, "data-bias-types-in-machine-learning-including-examples"]], "Data handling, machine learning  and ethical aspects": [[69, "data-handling-machine-learning-and-ethical-aspects"]], "Data normalization": [[70, null], [70, "data-normalization"]], "Data reduction": [[132, "data-reduction"]], "Data sets from scikit-learn": [[79, "data-sets-from-scikit-learn"]], "Data, models, and predictions": [[16, null]], "Dataset and Gaussian process generation": [[86, "dataset-and-gaussian-process-generation"]], "Dataset generation": [[85, "dataset-generation"]], "Debugging aside \u2026": [[139, "debugging-aside"], [139, "id1"]], "Deep Learning": [[78, "deep-learning"]], "Define and plot the posterior for x_0": [[47, "define-and-plot-the-posterior-for-x-0"]], "Define model discrepancy class": [[128, "define-model-discrepancy-class"]], "Define physics model": [[128, "define-physics-model"]], "Define priors": [[128, "define-priors"]], "Define the functions we will need": [[5, "define-the-functions-we-will-need"]], "Definition and examples": [[39, "definition-and-examples"]], "Definition of a stochastic process": [[166, "definition-of-a-stochastic-process"]], "Definition of linear models": [[104, null]], "Definitions": [[73, "definitions"]], "Degree of belief intervals": [[9, "degree-of-belief-intervals"], [35, "degree-of-belief-intervals"]], "Degree of belief/credibility intervals vs frequentist 1-sigma intervals": [[14, null]], "Demo: Multimodal distributions with two samplers": [[55, null]], "Demolition derbies, cows, and crocodiles": [[67, "demolition-derbies-cows-and-crocodiles"]], "Demonstration: Gaussian processes": [[87, null]], "Demonstration: Image recognition with Convolutional Neural Networks": [[81, null]], "Demonstration: Metropolis-Hasting MCMC sampling of a Poisson distribution": [[167, null]], "Demonstration: Neural network classifier": [[74, null]], "Demonstration: Variational Inference and Bayesian Neural Networks": [[78, null]], "Derivation of common pdfs using MaxEnt": [[4, "derivation-of-common-pdfs-using-maxent"]], "Derivative of the cost function": [[73, "derivative-of-the-cost-function"]], "Derivatives and the chain rule": [[73, "derivatives-and-the-chain-rule"]], "Derivatives in terms of z_j^L": [[73, "derivatives-in-terms-of-z-j-l"]], "Deriving the back propagation code for a multilayer perceptron model": [[73, "deriving-the-back-propagation-code-for-a-multilayer-perceptron-model"]], "Detailed Explanation of Each Step:": [[76, "detailed-explanation-of-each-step"]], "Determinant": [[141, "determinant"]], "Determination of weights": [[93, "determination-of-weights"]], "Determining the bias of a coin": [[35, "determining-the-bias-of-a-coin"]], "Determining the likelihood function": [[48, "determining-the-likelihood-function"]], "Developing a code for doing neural networks with back propagation": [[74, "developing-a-code-for-doing-neural-networks-with-back-propagation"]], "Diagnostics": [[156, "diagnostics"]], "Diagonalization of symmetric matrix": [[130, "diagonalization-of-symmetric-matrix"]], "Dimensionality reduction algorithms": [[69, null]], "Dirac delta functions": [[18, null]], "Discrete or continuous optimization": [[109, null]], "Discrete permutation invariance": [[3, "discrete-permutation-invariance"]], "Discuss": [[8, null], [39, null], [58, null], [135, null], [135, null], [135, null], [166, null]], "Discussion": [[43, "discussion"], [152, "discussion"], [157, "discussion"]], "Doing Fourier transforms by numerical integration (rather than FFT)": [[38, "doing-fourier-transforms-by-numerical-integration-rather-than-fft"]], "Dot product versus elementwise multiplication": [[141, "dot-product-versus-elementwise-multiplication"]], "Dot-product kernel": [[86, "dot-product-kernel"]], "Download and prepare the CIFAR10 dataset": [[81, "download-and-prepare-the-cifar10-dataset"]], "Edwin Jaynes and plausible reasoning": [[67, null]], "Eigendecomposition of the covariance matrix": [[132, "eigendecomposition-of-the-covariance-matrix"]], "Eigenvalues and eigenvectors": [[141, "eigenvalues-and-eigenvectors"]], "Eigenvector continuation": [[50, "eigenvector-continuation"]], "Elegant linear algebra tricks to obtain \\boldsymbol{C}_{N+1}^{-1}": [[90, "elegant-linear-algebra-tricks-to-obtain-boldsymbol-c-n-1-1"]], "Emulators": [[52, null], [127, null]], "Epistemic uncertainties": [[77, null]], "Equation references": [[0, "equation-references"]], "Error propagation": [[17, null]], "Error propagation (I): Nuisance parameters and marginalization": [[18, null]], "Error propagation (II): Changing variables": [[19, null]], "Error propagation (III): A useful approximation": [[20, null]], "Ethical principles": [[68, null]], "Ethics guidelines": [[68, "ethics-guidelines"]], "Evaluate the model": [[81, "evaluate-the-model"]], "Evidence Lower Bound": [[77, "evidence-lower-bound"]], "Evidence calculation": [[54, "evidence-calculation"]], "Evidence calculation for EFT expansions": [[54, null]], "Evidence calculations": [[58, "evidence-calculations"]], "Evidence for an expansion": [[57, null]], "Evidence using conjugate prior": [[54, "evidence-using-conjugate-prior"]], "Evidence using linear algebra and Gaussian integrals": [[54, "evidence-using-linear-algebra-and-gaussian-integrals"]], "Evidence with linear algebra": [[57, "evidence-with-linear-algebra"]], "Example of a Complex Expression": [[76, "example-of-a-complex-expression"]], "Example of parallel tempering": [[56, "example-of-parallel-tempering"]], "Example with noise-free target": [[85, "example-with-noise-free-target"]], "Example with noisy targets": [[85, "example-with-noisy-targets"]], "Example: CNN architecture": [[80, "example-cnn-architecture"]], "Example: GP models for regression": [[83, "example-gp-models-for-regression"], [87, "example-gp-models-for-regression"]], "Example: Is this a fair coin?": [[30, "example-is-this-a-fair-coin"]], "Example: Random walk": [[166, "example-random-walk"]], "Example: Straight-line model": [[3, "example-straight-line-model"]], "Example: The Compas algorithm": [[68, "example-the-compas-algorithm"]], "Example: The MNIST dataset": [[80, "example-the-mnist-dataset"]], "Example: good data / bad data": [[43, "example-good-data-bad-data"]], "Examples": [[159, null]], "Examples from Rob Hicks": [[156, "examples-from-rob-hicks"]], "Examples of classifier functions used in logistic regression and neural networks": [[75, "examples-of-classifier-functions-used-in-logistic-regression-and-neural-networks"]], "Examples of information criteria": [[56, "examples-of-information-criteria"]], "Exercise": [[24, null], [24, null], [75, "exercise"]], "Exercise 1": [[82, "exercise-1"], [88, "exercise-1"]], "Exercise 2": [[82, "exercise-2"], [88, "exercise-2"]], "Exercise 3": [[82, "exercise-3"], [88, "exercise-3"]], "Exercise 4": [[82, "exercise-4"], [88, "exercise-4"]], "Exercise 5": [[82, "exercise-5"]], "Exercise: Bayesian neural networks": [[79, null]], "Exercise: Checking the sum and product rules": [[37, null]], "Exercise: Create a neural net binary classifier": [[75, "exercise-create-a-neural-net-binary-classifier"]], "Exercise: Develop your own logistic regression binary classifier": [[75, "exercise-develop-your-own-logistic-regression-binary-classifier"]], "Exercise: Gaussian Process models with GPy": [[82, null]], "Exercise: Gaussian processes using GPy": [[88, null]], "Exercise: Logistic Regression and neural networks": [[75, null]], "Exercise: Random walk": [[149, null]], "Exercise: Standard medical example using Bayes": [[36, null]], "Exercises": [[16, "exercises"], [45, "exercises"], [70, "exercises"], [71, "exercises"], [72, "exercises"], [119, null], [135, "exercises"], [158, "exercises"], [161, "exercises"]], "Exercises and solutions": [[0, "exercises-and-solutions"]], "Exercises for Part I": [[40, null]], "Exercises: covariance matrix manipulations in Python (taken from the Duke course)": [[132, "exercises-covariance-matrix-manipulations-in-python-taken-from-the-duke-course"]], "Exp-Sine-Squared kernel": [[86, "exp-sine-squared-kernel"]], "Expectation values and moments": [[135, "expectation-values-and-moments"]], "Experimentation (of the statistical model)": [[48, "experimentation-of-the-statistical-model"]], "Explorations:  Things to do and Questions to answer": [[100, "explorations-things-to-do-and-questions-to-answer"]], "Explore the data": [[74, "explore-the-data"]], "Explore!": [[41, null]], "Expressions": [[147, "expressions"]], "Extending to more classes": [[93, "extending-to-more-classes"]], "Extending to more features": [[93, "extending-to-more-features"]], "External URL references": [[0, "external-url-references"]], "Fairness and error functions": [[68, "fairness-and-error-functions"]], "Feed-forward neural network for a function in PyTorch": [[76, null]], "Feed-forward neural networks": [[72, "feed-forward-neural-networks"]], "Feedback networks": [[72, "feedback-networks"]], "Figures to analyze!": [[42, "figures-to-analyze"]], "Figures to make every time you run MCMC (following Hogg and Foreman-Mackey sect. 9)": [[151, "figures-to-make-every-time-you-run-mcmc-following-hogg-and-foreman-mackey-sect-9"]], "Fill in the chart based on the Metropolis algorithm we are using and verify that the ratio of p(X_B|X_A) to p(X_A|X_B) agrees with the answer derived above.": [[164, null]], "Final back-propagating equation": [[73, "final-back-propagating-equation"]], "Final outputs": [[73, null]], "Find the Maximum and Minimum Values": [[141, "find-the-maximum-and-minimum-values"]], "First example: each sample is only one point": [[38, "first-example-each-sample-is-only-one-point"]], "First pass: only minimal controls": [[137, "first-pass-only-minimal-controls"]], "First sample with emcee": [[157, "first-sample-with-emcee"]], "First the likelihood": [[13, "first-the-likelihood"]], "Fitting a straight line - revisited": [[148, "fitting-a-straight-line-revisited"]], "Follow-up question on 2.": [[36, null]], "Follow-up question on 5.": [[36, null]], "Follow-up questions and answers to the Exploring PDFs section.": [[23, null]], "Follow-up questions to the medical example": [[36, "follow-up-questions-to-the-medical-example"]], "Follow-up task": [[82, "follow-up-task"]], "Follow-ups": [[42, "follow-ups"]], "Formalizing prior distributions": [[48, "formalizing-prior-distributions"]], "Four-step Bayesian workflow in brief": [[48, null], [64, null]], "Fourth example: each sample is 50 points": [[38, "fourth-example-each-sample-is-50-points"]], "Framework": [[125, null]], "Frequentist Correction for Outliers: Huber Loss": [[43, "frequentist-correction-for-outliers-huber-loss"]], "Frequentist approach to Gaussian parameter estimation": [[152, "frequentist-approach-to-gaussian-parameter-estimation"], [157, "frequentist-approach-to-gaussian-parameter-estimation"]], "Frequentist hypothesis testing": [[58, "frequentist-hypothesis-testing"]], "Frequentist probability": [[8, "frequentist-probability"]], "Frontmatter for markdown files": [[0, "frontmatter-for-markdown-files"]], "Functions": [[139, "functions"]], "Further examples with numpy": [[141, null]], "GP models for regression": [[90, "gp-models-for-regression"]], "GPy demo notebooks": [[89, null]], "Games with Gaussian process websites": [[91, "games-with-gaussian-process-websites"]], "Gaussian Processes regression: basic introductory example": [[85, null]], "Gaussian distribution": [[135, "gaussian-distribution"]], "Gaussian processes": [[90, null]], "Gaussian processes as high-dimensional Gaussian distributions": [[87, "gaussian-processes-as-high-dimensional-gaussian-distributions"]], "Gaussian processes as infinite-dimensional Gaussian distributions": [[83, "gaussian-processes-as-infinite-dimensional-gaussian-distributions"]], "Gaussian processes demonstration": [[83, null]], "Gaussians: A couple of frequentist connections": [[24, null]], "Gelman Rubin Diagnostic": [[148, "gelman-rubin-diagnostic"]], "Gelman Rubin Diagnostic (quoted verbatim from the Hicks notebook)": [[156, "gelman-rubin-diagnostic-quoted-verbatim-from-the-hicks-notebook"]], "General problems in Bayesian inference": [[158, "general-problems-in-bayesian-inference"]], "Generate data": [[101, "generate-data"]], "Generate figures": [[147, "generate-figures"]], "Generate \u201cexperimental\u201d observations for height": [[128, "generate-experimental-observations-for-height"]], "Generating data": [[78, "generating-data"], [98, "generating-data"]], "Generating the data": [[147, "generating-the-data"]], "Generative models": [[69, null]], "Getting help": [[139, "getting-help"]], "Getting started: The Covariance Function": [[88, "getting-started-the-covariance-function"]], "Good online cheat-sheets:": [[143, "good-online-cheat-sheets"]], "Gradient Computations": [[76, "gradient-computations"]], "Gradient-descent optimization": [[102, null], [110, null]], "Group Attribution Biases": [[68, null]], "Guide to Jupyter Book markdown": [[0, null]], "Guides in this Jupyter Book": [[143, "guides-in-this-jupyter-book"]], "HMC algorithm": [[153, "hmc-algorithm"]], "HMC and other samplers": [[162, null]], "HMC physics": [[153, "hmc-physics"]], "Hamiltonian Monte Carlo": [[49, "hamiltonian-monte-carlo"]], "Hamiltonian Monte Carlo (HMC) overview and visualization": [[153, null]], "Helper function": [[86, "helper-function"]], "Hidden code cell": [[0, "hidden-code-cell"]], "Hint": [[24, null], [37, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null], [39, null]], "Hint (a)": [[37, null]], "Hint (b)": [[37, null]], "Hint-1": [[39, null]], "Hint-2": [[39, null]], "Hints": [[39, null], [72, null]], "Histograms matching a t distribution": [[131, "histograms-matching-a-t-distribution"]], "How are N_A and N_B related to the total N and the posteriors p(X_A|D,I) and p(X_B|D,I)?": [[164, null]], "How do we know this chain has converged to the posterior?": [[148, "how-do-we-know-this-chain-has-converged-to-the-posterior"]], "How the Bayesian approach helps in science": [[7, null]], "Hybrid Uncertainty:": [[7, null]], "Hypothesis testing with the chi-squared statistic": [[58, "hypothesis-testing-with-the-chi-squared-statistic"]], "Icons and menus": [[61, null]], "Illustration of prior and posterior Gaussian process for different kernels": [[86, null]], "Implementation": [[45, "implementation"]], "Implicit Biases": [[68, null]], "Import Python modules": [[43, "import-python-modules"]], "Import TensorFlow": [[81, "import-tensorflow"]], "Import functions": [[5, "import-functions"]], "Import modules": [[82, "import-modules"], [88, "import-modules"], [97, "import-modules"], [138, "import-modules"]], "Import of modules": [[100, "import-of-modules"], [149, "import-of-modules"]], "Import statements": [[101, "import-statements"]], "Import theano and pymc3": [[78, "import-theano-and-pymc3"]], "Important definitions": [[135, "important-definitions"]], "Important distributions": [[135, "important-distributions"]], "Imports": [[156, "imports"]], "In terms of p(X_A|X_B), p(X_B|X_A), N_A, and N_B, what is the condition that the exchanges between A and B cancel out? (For now assume a symmetric proposal distribution q.)": [[164, null]], "In-class exercise": [[156, "in-class-exercise"]], "Inference and PDFs": [[25, null]], "Inference using Gaussian processes": [[90, "inference-using-gaussian-processes"]], "Inference with parametric models": [[7, "inference-with-parametric-models"]], "InferenceData object": [[156, "inferencedata-object"]], "Information from ChatGPT about backpropagation": [[76, "information-from-chatgpt-about-backpropagation"]], "Information from ChatGPT about how to switch to normal distributions to intialize": [[76, "information-from-chatgpt-about-how-to-switch-to-normal-distributions-to-intialize"]], "Information from ChatGPT about tensor operations": [[76, "information-from-chatgpt-about-tensor-operations"], [76, "id1"]], "Information from ChatGPT about the default initialization": [[76, "information-from-chatgpt-about-the-default-initialization"]], "Ingredients of Bayes\u2019 theorem": [[30, null]], "Inserting figures and references to them": [[0, "inserting-figures-and-references-to-them"]], "Installation of LearningFromData Jupyter notebooks from GitHub by command line": [[145, "installation-of-learningfromdata-jupyter-notebooks-from-github-by-command-line"]], "Installation of PyTorch": [[76, "installation-of-pytorch"]], "Installing Anaconda": [[142, "installing-anaconda"]], "Integration": [[151, "integration"]], "Integration and marginalization by sampling: intuition": [[151, "integration-and-marginalization-by-sampling-intuition"]], "Interpreting 2D posteriors": [[41, null]], "Introduction": [[62, null], [166, "introduction"]], "Introduction to tensorflow": [[74, "introduction-to-tensorflow"]], "Intuition by sampling and plotting multivariate Gaussians": [[83, "intuition-by-sampling-and-plotting-multivariate-gaussians"]], "Intuition for detailed balance and the MH algorithm": [[164, "intuition-for-detailed-balance-and-the-mh-algorithm"]], "Inverse": [[141, "inverse"]], "Invitation to inductive inference": [[67, null]], "Iterating through a list of parameters to draw multiple lines on a plot": [[140, "iterating-through-a-list-of-parameters-to-draw-multiple-lines-on-a-plot"]], "Iteration versus array operation": [[140, "iteration-versus-array-operation"]], "Iterative history matching": [[51, "iterative-history-matching"]], "Joint PDFs, marginal PDFs, and an example of marginalization": [[28, "joint-pdfs-marginal-pdfs-and-an-example-of-marginalization"]], "KOH and BOH discrepancy models": [[124, null]], "Kernel cookbook": [[86, "kernel-cookbook"]], "Labeling and referencing a section": [[0, "labeling-and-referencing-a-section"]], "Laplace\u2019s method": [[58, "laplaces-method"]], "Large-width limit": [[122, "large-width-limit"]], "Layers used to build CNNs": [[80, "layers-used-to-build-cnns"]], "Learning algorithm": [[72, null], [72, "learning-algorithm"]], "Learning challenges": [[73, "learning-challenges"]], "Learning curves": [[71, "learning-curves"], [102, "learning-curves"]], "Learning goals:": [[99, "learning-goals"], [101, "learning-goals"], [147, "learning-goals"]], "Lecture 12": [[151, null]], "Lecture 20": [[84, null]], "Lets look at what the classifier has learned": [[78, "lets-look-at-what-the-classifier-has-learned"]], "Let\u2019s look at what the classifier has learned": [[98, "lets-look-at-what-the-classifier-has-learned"]], "Likelihood": [[55, "likelihood"]], "Likelihoods (or posteriors) with two variables with quadratic approximation": [[41, "likelihoods-or-posteriors-with-two-variables-with-quadratic-approximation"]], "Limit of Poisson distribution is Gaussian": [[38, "limit-of-poisson-distribution-is-gaussian"]], "Limitations of supervised learning with deep networks": [[72, "limitations-of-supervised-learning-with-deep-networks"]], "Limitations of training data": [[68, "limitations-of-training-data"]], "Linear algebra and numerical operations": [[141, "linear-algebra-and-numerical-operations"]], "Linear classification": [[70, "linear-classification"]], "Linear classifier(s)": [[70, "linear-classifier-s"]], "Linear models": [[103, null]], "Linear regression": [[70, "linear-regression"]], "Linear versus non-linear models": [[117, null]], "Liouville Theorem Visualization": [[154, null]], "Location invariance": [[3, "location-invariance"]], "Log normal distribution": [[4, "log-normal-distribution"]], "Logistic Regression": [[93, null]], "Logistic regression using scikit-learn": [[75, "logistic-regression-using-scikit-learn"]], "Looking ahead": [[29, null]], "Looking at PyMC getting started notebook": [[163, "looking-at-pymc-getting-started-notebook"]], "MCMC Intro from BUQEYE": [[159, null]], "MCMC Sampling Interlude: Assessing Convergence": [[151, "mcmc-sampling-interlude-assessing-convergence"]], "MCMC diagnostics: assessing convergence": [[148, "mcmc-diagnostics-assessing-convergence"]], "MCMC random walk and sampling example": [[164, "mcmc-random-walk-and-sampling-example"]], "MH Sampling and convergence": [[55, "mh-sampling-and-convergence"]], "Machine Learning": [[94, null]], "Machine Learning: First Examples": [[70, null]], "Machine learning": [[65, null]], "Machine learning in science and society": [[69, "machine-learning-in-science-and-society"]], "Machine learning: Overview and notation": [[69, null]], "Macros": [[0, "macros"]], "Main code for coin-flipping UI": [[9, "main-code-for-coin-flipping-ui"]], "Make Liouville theorem visualization": [[154, "make-liouville-theorem-visualization"]], "Make predictions": [[81, "make-predictions"]], "Make predictions and evaluate accuracy": [[74, "make-predictions-and-evaluate-accuracy"]], "Make some plots": [[131, "make-some-plots"]], "Making a movie of the evolution of the distribution": [[131, "making-a-movie-of-the-evolution-of-the-distribution"]], "Making predictions": [[81, "making-predictions"]], "Manipulating probabilities: Bayesian rules of probability as principles of logic": [[27, null]], "Many new target predictions using a GP": [[90, null]], "Marginal posterior distributions": [[39, "marginal-posterior-distributions"]], "Marginalization": [[46, "marginalization"], [151, "marginalization"]], "Marginalization using samples": [[18, null]], "Markov Chain Monte Carlo (MCMC)": [[159, "markov-chain-monte-carlo-mcmc"]], "Markov chain Monte Carlo sampling": [[158, null]], "Markov chains": [[161, null]], "Materials to help you get started": [[61, "materials-to-help-you-get-started"]], "Mathematical functions with numpy": [[139, "mathematical-functions-with-numpy"]], "Mathematical model": [[72, "mathematical-model"]], "Mathematical optimization": [[109, null]], "Matplotlib plotting helper functions": [[22, "matplotlib-plotting-helper-functions"]], "Matrix  Operations": [[141, "matrix-operations"]], "Matrix-vector notation": [[72, "matrix-vector-notation"]], "Mat\u00e9rn kernel": [[86, "matern-kernel"]], "Maximum likelihood": [[93, "maximum-likelihood"]], "Maximum likelihood fits": [[100, "maximum-likelihood-fits"]], "Mean and covariance function": [[87, "mean-and-covariance-function"]], "Mean and the Exponential pdf": [[4, "mean-and-the-exponential-pdf"]], "Mean, median, mode": [[135, "mean-median-mode"]], "Meet the Pandas": [[138, "meet-the-pandas"]], "Metropolis Poisson example (Gregory, section 12.2)": [[159, "metropolis-poisson-example-gregory-section-12-2"]], "Metropolis condition": [[159, null]], "Metropolis design": [[161, "metropolis-design"]], "Metropolis-Hasting MCMC sampling of a Poisson distribution": [[150, null]], "Mini-batch ADVI": [[78, "mini-batch-advi"]], "Mini-project I: Parameter estimation for a toy model of an EFT": [[99, null]], "Mini-project IIIa: Bayesian Optimization": [[97, null]], "Mini-project IIIb: Bayesian Neural Networks": [[98, null]], "Mini-project IIa: Model selection basics": [[100, null]], "Mini-project IIb: How many lines are there?": [[101, null]], "Minimize the effective potential and plot results for benchmark case": [[5, "minimize-the-effective-potential-and-plot-results-for-benchmark-case"]], "Minimizing the cross entropy": [[93, "minimizing-the-cross-entropy"]], "Model Selection": [[58, null]], "Model checking:": [[7, null]], "Model comparison:": [[7, null]], "Model mixing": [[53, null]], "Model specification": [[78, "model-specification"], [98, "model-specification"]], "Model validation": [[71, null], [71, "id7"]], "Model-order reduction": [[50, null]], "Models in science": [[115, null]], "Monte Carlo integration": [[158, "monte-carlo-integration"]], "Monte Carlo integration in statistics": [[158, "monte-carlo-integration-in-statistics"]], "Moral qualities of the scientist": [[66, null]], "More details on naive MC": [[159, null]], "More on Python and using Jupyter notebooks": [[143, null]], "More on Ridge Regression": [[71, "more-on-ridge-regression"]], "Multi-model inference with Bayes": [[59, null]], "Multivariate Gaussian distribution": [[135, "multivariate-gaussian-distribution"]], "Multivariate normal distributions": [[87, "multivariate-normal-distributions"]], "N dimensional arrays": [[141, "n-dimensional-arrays"]], "N=2 moments": [[5, "n-2-moments"]], "N=3 moments": [[5, "n-3-moments"]], "N=4 moments": [[5, "n-4-moments"]], "N=5 moments": [[5, "n-5-moments"]], "Network training": [[77, "network-training"]], "Neural network architecture": [[72, "neural-network-architecture"]], "Neural network types": [[72, "neural-network-types"]], "Next steps": [[78, "next-steps"]], "No-core shell model \\hbar\\omega dependence": [[83, "no-core-shell-model-hbar-omega-dependence"], [87, "no-core-shell-model-hbar-omega-dependence"]], "Noisy networks": [[72, null]], "Non-parametric approach: Mean and covariance functions": [[90, "non-parametric-approach-mean-and-covariance-functions"]], "Normalization and marginalization": [[30, null]], "Normalization and marginalization in the continuum limit": [[30, null]], "Normalization of a multivariate Gaussian": [[58, "normalization-of-a-multivariate-gaussian"]], "Notation": [[69, "notation"], [90, null], [93, null], [114, null], [135, "notation"], [166, "notation"]], "Note on \\chi^2/\\text{dof} for model assessment and comparison  \\newcommand{\\pars}{\\boldsymbol{\\theta}}": [[34, "note-on-chi-2-text-dof-for-model-assessment-and-comparison-newcommand-pars-boldsymbol-theta"]], "Note on donuts in high dimensions": [[159, null]], "Notebook:": [[24, "notebook"]], "Notes": [[0, "notes"], [54, "notes"]], "Now ask ChatGPT to use this code to learn a specified function in a specified region": [[76, "now-ask-chatgpt-to-use-this-code-to-learn-a-specified-function-in-a-specified-region"]], "Now do the sampling and plot the posteriors": [[128, "now-do-the-sampling-and-plot-the-posteriors"]], "Now sample with PyMC": [[157, "now-sample-with-pymc"]], "Now sample with zeus": [[157, "now-sample-with-zeus"]], "Now try it with zeus!": [[55, "now-try-it-with-zeus"]], "Numerical integration": [[158, "numerical-integration"]], "Occam\u2019s razor": [[7, null]], "Odds-ratios": [[100, "odds-ratios"]], "One adjustable parameter each": [[58, "one-adjustable-parameter-each"]], "One adjustable parameter each; different prior ranges": [[58, "one-adjustable-parameter-each-different-prior-ranges"]], "One solution (how could these functions be improved?)": [[45, "one-solution-how-could-these-functions-be-improved"]], "One solution (how could this solution be improved?)": [[45, "one-solution-how-could-this-solution-be-improved"]], "One view": [[8, null]], "Open an issue": [[61, null]], "Operating on matrices with special properties": [[141, null]], "Optimization and Deep learning": [[93, "optimization-and-deep-learning"]], "Optional task: log probabilities": [[149, "optional-task-log-probabilities"]], "Ordinary linear regression in practice": [[107, null]], "Ordinary linear regression: warmup": [[106, null]], "Organizing our data": [[138, "organizing-our-data"]], "Original background": [[157, "original-background"]], "Output Distribution of Randomly-Initialized feed-forward ANN (1 Input \u2192 1 Output)": [[134, "output-distribution-of-randomly-initialized-feed-forward-ann-1-input-1-output"]], "Output Distribution of Randomly-Initialized feed-forward ANN (2 Inputs \u2192 1 Output)": [[134, "output-distribution-of-randomly-initialized-feed-forward-ann-2-inputs-1-output"]], "Over- and underfitting": [[71, "over-and-underfitting"]], "Overfitting and underfitting the data": [[68, null]], "Overgeneralization Bias": [[68, null]], "Overview of Gaussian process": [[91, null]], "Overview of Intro to PyMC notebook": [[163, null]], "Overview of Markov Chain Monte Carlo": [[160, null]], "Overview of Mini-project IIb: How many lines?": [[95, null]], "Overview of Part II: Advanced Bayesian methods": [[60, null]], "Overview of Part III: Sampling": [[165, null]], "Overview of TALENT mini-projects": [[96, null]], "Overview of getting started materials": [[136, null]], "Overview of modeling": [[113, null]], "Overview of other topics": [[129, null]], "Overview of scientific modeling material": [[121, null]], "Overview: MCMC Diagnostics": [[148, null]], "PCA (from Duke course)": [[132, "pca-from-duke-course"]], "PCA, SVD, and all that": [[130, null]], "PDFs for applying Bayes\u2019 rule": [[147, "pdfs-for-applying-bayes-rule"]], "PT Sampler": [[55, "pt-sampler"]], "Parallel tempering": [[56, "parallel-tempering"]], "Parameter Estimation:": [[0, null], [7, null]], "Parameter choices": [[98, "parameter-choices"]], "Parameter estimation example: Gaussian noise and averages II": [[152, null]], "Parameter estimation example: fitting a straight line": [[45, null]], "Parameter estimation with your favorite MCMC sampler (emcee here!)": [[101, "parameter-estimation-with-your-favorite-mcmc-sampler-emcee-here"]], "Parameters known before the analysis (explore different values for these as requested)": [[101, "parameters-known-before-the-analysis-explore-different-values-for-these-as-requested"]], "Parameters that should be learned from the data": [[101, "parameters-that-should-be-learned-from-the-data"]], "Parametric approach": [[90, "parametric-approach"]], "Parametric versus non-parametric models": [[116, null]], "Part 1": [[88, "part-1"]], "Part 1: Random walk in [-5,5] region": [[149, "part-1-random-walk-in-5-5-region"]], "Part 2": [[88, "part-2"]], "Part 2: MCMC sampling of a Lorentzian pdf using the random walk Metropolis algorithm": [[149, "part-2-mcmc-sampling-of-a-lorentzian-pdf-using-the-random-walk-metropolis-algorithm"]], "Part 3": [[88, "part-3"]], "Part 3: Detailed balance and the Metropolis-Hastings algorithm": [[149, "part-3-detailed-balance-and-the-metropolis-hastings-algorithm"]], "Pendulum class and utility functions": [[154, "pendulum-class-and-utility-functions"]], "Perform thermodynamic integration from PT sampler": [[101, "perform-thermodynamic-integration-from-pt-sampler"]], "Philosophical remarks on probabilities": [[8, "philosophical-remarks-on-probabilities"]], "Physicist\u2019s perspective": [[63, null]], "Pick a potential": [[155, "pick-a-potential"]], "Plot orbit and check energy conservation": [[155, "plot-orbit-and-check-energy-conservation"]], "Plotting with Matplotlib": [[139, "plotting-with-matplotlib"]], "Point estimates": [[23, null]], "Point estimates and credible regions": [[135, "point-estimates-and-credible-regions"]], "Poisson distribution": [[4, "poisson-distribution"], [42, "poisson-distribution"]], "Polya and Jaynes": [[67, "polya-and-jaynes"]], "Polya and plausible inference": [[67, null]], "Possible answers": [[0, null], [11, null], [27, null]], "Posterior": [[55, "posterior"]], "Posterior with a Gaussian prior": [[39, "posterior-with-a-gaussian-prior"]], "Posterior with a uniform prior": [[39, "posterior-with-a-uniform-prior"]], "Predict based on your own experience: How does this behavior change if we have more data (higher energy) or more certain data?": [[57, null]], "Preliminaries": [[131, "preliminaries"]], "Preliminary exercise: manipulations using the index form of matrices": [[132, "preliminary-exercise-manipulations-using-the-index-form-of-matrices"]], "Preliminary exercises": [[130, "preliminary-exercises"]], "Prelude: ordinary linear regression": [[39, "prelude-ordinary-linear-regression"]], "Preparing data and the pdfs we\u2019ll need": [[42, "preparing-data-and-the-pdfs-well-need"]], "Principal components": [[132, "principal-components"]], "Prior": [[55, "prior"]], "Prior PDFs for straight line model": [[6, "prior-pdfs-for-straight-line-model"]], "Prior elicitation.": [[48, "prior-elicitation"]], "Probabilistic Programming at scale": [[78, "probabilistic-programming-at-scale"]], "Probabilistic model": [[77, "probabilistic-model"]], "Probability density functions": [[28, null]], "Probability surface": [[78, "probability-surface"], [98, "probability-surface"]], "Product rule": [[27, "product-rule"]], "Projected posterior plots": [[22, "projected-posterior-plots"]], "Proof of penultimate equality": [[13, null]], "Proof of the CLT in a special case:": [[24, "proof-of-the-clt-in-a-special-case"]], "Pukelsheim\u2019s three-sigma rule": [[51, "pukelsheims-three-sigma-rule"], [51, null]], "PyMC Introduction": [[156, null]], "PyMC implementation": [[156, "pymc-implementation"]], "PyMC3:": [[158, null]], "PyMultiNest:": [[158, null]], "PyStan:": [[158, null]], "PyTorch Default Initialization": [[76, "pytorch-default-initialization"]], "Python expressions and strings": [[139, "python-expressions-and-strings"]], "Python for machine learning": [[69, null]], "Python imports": [[55, "python-imports"], [132, "python-imports"], [147, "python-imports"]], "Python/Jupyter set up": [[9, "python-jupyter-set-up"]], "QBism references": [[133, "qbism-references"]], "Quadrature methods": [[158, "quadrature-methods"]], "Quantum Bayesianism (QBism)": [[133, null]], "Question": [[4, null], [12, null], [41, null], [88, "question"], [90, null], [93, null], [93, null], [100, "question"], [159, null]], "Question 1": [[36, null], [37, null]], "Question 2": [[36, null], [37, null]], "Question 3": [[36, null], [37, null]], "Question 4": [[36, null], [37, null]], "Question 5": [[36, null], [37, null]], "Question 6": [[36, null]], "Question 7": [[36, null]], "Question 8": [[36, null]], "Question 9": [[36, null]], "Questions": [[149, "questions"]], "Questions / tasks": [[149, "questions-tasks"], [149, "id2"]], "Questions and things to do": [[150, "questions-and-things-to-do"]], "Questions for the class": [[41, null]], "Questions:": [[149, "id1"]], "Quick introduction to  scipy.stats": [[22, "quick-introduction-to-scipy-stats"], [135, "quick-introduction-to-scipy-stats"]], "Quick review: To a Bayesian, everything is a PDF (probability density function)": [[22, "quick-review-to-a-bayesian-everything-is-a-pdf-probability-density-function"]], "RMSprop": [[112, "rmsprop"]], "Radial Basis Function kernel": [[86, "radial-basis-function-kernel"]], "Random Walk Metropolis-Hasting (MH)": [[159, "random-walk-metropolis-hasting-mh"]], "Random variables: probability distribution and density": [[135, "random-variables-probability-distribution-and-density"]], "Rank": [[141, "rank"]], "Rational Quadradtic kernel": [[86, "rational-quadradtic-kernel"]], "Recall Beta function": [[13, null]], "Recall Metropolis algorithm for p(\\thetavec | D, I) (or any other posterior).": [[164, null]], "Recall the basic structure of Metropolis-Hastings": [[159, null]], "Recap of GPs": [[84, "recap-of-gps"]], "Recap of Poisson MCMC example": [[164, "recap-of-poisson-mcmc-example"]], "Recaps": [[164, null]], "Recurrent neural networks": [[72, "recurrent-neural-networks"]], "Reduced-order methods": [[50, "reduced-order-methods"]], "Reference: Bayesian rules of probability": [[36, "reference-bayesian-rules-of-probability"], [37, "reference-bayesian-rules-of-probability"]], "References:": [[90, "references"]], "Regression algorithms": [[69, null]], "Regression analysis with linear models": [[105, null]], "Regression analysis: optimization versus inference": [[118, null]], "Regular NNs don\u2019t scale well to full images": [[80, "regular-nns-dont-scale-well-to-full-images"]], "Regularization": [[93, "regularization"]], "Regularization: Ridge and Lasso": [[71, "regularization-ridge-and-lasso"]], "Remarks": [[0, "remarks"]], "Remarks on bias and variance": [[71, "remarks-on-bias-and-variance"]], "Reporting Biases": [[68, null]], "Reproducibility": [[48, "reproducibility"]], "Requirements for AI systems": [[68, null]], "Reshape": [[141, "reshape"]], "Results": [[48, "results"]], "Reversibility": [[161, "reversibility"]], "Review of Bayes\u2019 theorem": [[30, null]], "Review of bivariate normal case": [[83, "review-of-bivariate-normal-case"]], "Rewriting the likelihood": [[39, "rewriting-the-likelihood"]], "Row-major order": [[141, null]], "Run MCMC": [[147, "run-mcmc"]], "S/IR limitations": [[49, "s-ir-limitations"]], "SVD applied to images for compression": [[132, "svd-applied-to-images-for-compression"]], "SVD basics": [[132, "svd-basics"]], "Sampling": [[23, null], [43, "sampling"], [156, "sampling"]], "Sampling / Importance Resampling": [[49, "sampling-importance-resampling"]], "Sampling a distribution": [[161, null]], "Sampling and plotting multivariate Gaussians": [[87, "sampling-and-plotting-multivariate-gaussians"]], "Sampling from a Gaussian Process": [[88, "sampling-from-a-gaussian-process"]], "Sampling from a PDF": [[158, "sampling-from-a-pdf"]], "Sampling of 1d pdfs in Python": [[22, "sampling-of-1d-pdfs-in-python"]], "Saving a figure": [[139, "saving-a-figure"]], "Scalar operations": [[141, "scalar-operations"]], "Scale invariance": [[3, "scale-invariance"]], "Scikit-learn demo notebooks": [[92, null]], "Second example: each sample is two points": [[38, "second-example-each-sample-is-two-points"]], "Second pass: More elaborate controls and options": [[137, "second-pass-more-elaborate-controls-and-options"]], "Select element(s)": [[141, "select-element-s"]], "Selected exercises from notebook": [[84, "selected-exercises-from-notebook"]], "Selection bias": [[68, null]], "Set plot style": [[128, "set-plot-style"]], "Setting Covariance Function Parameters": [[82, "setting-covariance-function-parameters"], [88, "setting-covariance-function-parameters"]], "Setting it up": [[80, "setting-it-up"]], "Setting up the back-propagation algorithm": [[73, "setting-up-the-back-propagation-algorithm"]], "Setting up to use this Jupyter book": [[144, null]], "Setup sampling with emcee and pocomc samplers": [[128, "setup-sampling-with-emcee-and-pocomc-samplers"]], "Shape, size, length and data type": [[141, "shape-size-length-and-data-type"]], "Singular value decomposition (SVD)": [[130, "singular-value-decomposition-svd"]], "Sivia example on \u201csignal on top of background\u201d": [[41, "sivia-example-on-signal-on-top-of-background"]], "Solution strategy:": [[101, "solution-strategy"]], "Solution to": [[39, "solution:BayesianLinearRegression:likelihood_pars"], [39, "solution:ols_example_1_b"], [39, "solution:ols_example_3_b"]], "Solution to Exercise 17.1": [[166, "solution:StochasticProcess:first-example"]], "Solution to Exercise 17.2": [[166, "solution:conditional-probabilities-stochastic-process"]], "Solution to Exercise 17.3": [[166, "solution:construct-stochastic-process"]], "Solution to Exercise 18.1 (Stochastic matrix)": [[161, "solution:MarkovChains:stochastic-matrix"]], "Solution to Exercise 18.10 (Flip-flop)": [[161, "solution:flip-flop"]], "Solution to Exercise 18.11 (Gothenburg winter weather)": [[161, "solution:MarkovChains:gothenburg-winter-weather"]], "Solution to Exercise 18.12 (Stationary Gothenburg winter weather)": [[161, "solution:stationary-gothenburg-winter-weather"]], "Solution to Exercise 18.13 (Is it reversible?)": [[161, "solution:is-it-reversible"]], "Solution to Exercise 18.14 (Optical pumping)": [[161, "solution:optical-pumping"]], "Solution to Exercise 18.15 (Detailed balance)": [[161, "solution:detailed-balance"]], "Solution to Exercise 18.16 (Metropolis sampling of a uniform distribution)": [[158, "solution:metropolis-sampling-uniform"]], "Solution to Exercise 18.17 (Power-law distributions)": [[158, "solution:power-law-distribution-sampling"]], "Solution to Exercise 18.18 (The Metropolis algorithm for a discrete distribution)": [[158, "solution:MCMC:discrete-metropolis"]], "Solution to Exercise 18.2 (Simple random walk)": [[161, "solution:MarkovChains:simple-random-walk"]], "Solution to Exercise 18.3 (Remnant memory)": [[161, "solution:MarkovChains:memory"]], "Solution to Exercise 18.4 (Conditional distributions)": [[161, "solution:MarkovChains:conditional-distributions"]], "Solution to Exercise 18.5 (Stationary distribution)": [[161, "solution:MarkovChains:stationary-distribution"]], "Solution to Exercise 18.6 (Reversibility)": [[161, "solution:MarkovChains:reversibility"]], "Solution to Exercise 18.7 (A reversible Markov chain)": [[161, "solution:MarkovChains:reversible-chain"]], "Solution to Exercise 18.8 (Stationary two-state distribution)": [[161, "solution:stationary-2x2"]], "Solution to Exercise 18.9 (Limiting distribution)": [[161, "solution:limiting-distribution"]], "Solution to Exercise 23.1 (Sigmoid decision boundary)": [[70, "solution:MLexamples:sigmoid-decision-boundary"]], "Solution to Exercise 23.4 (kNN for regression)": [[70, "solution:MLexamples:kNN-regression"]], "Solution to Exercise 23.5 (R2 score)": [[70, "solution:MLexamples:R2-score"]], "Solution to Exercise 24.1 (Weights and signal propagation of a simple neural network)": [[72, "solution:NeuralNet:simple-network"]], "Solution to Exercise 24.2 (Weights and signal propagation of a wide neural network)": [[72, "solution:NeuralNet:wide-network"]], "Solution to Exercise 24.3 (Linear signals)": [[72, "solution:NeuralNet:linear-signal"]], "Solution to Exercise 24.4 (Expected signal)": [[72, "solution:NeuralNet:expected-signal"]], "Solution to Exercise 24.5 (k=1 NN training error)": [[71, "solution:ModelValidation:kNN-training-error"]], "Solution to Exercise 24.6 (kNN model complexity)": [[71, "solution:ModelValidation:kNN-model-complexity"]], "Solution to Exercise 24.7 (Study of model bias and variance)": [[71, "solution:ModelValidation:study-model-bias-variance"]], "Solution to Exercise 24.8 (Implement k-fold cross validation)": [[71, "solution:ModelValidation:kfold-cross-validation"]], "Solution to Exercise 24.9 (Large training error)": [[71, "solution:ModelValidation:large-training-error"]], "Solution to Exercise 34.1": [[0, "solution:ppd_definition_b"]], "Solution to Exercise 35.1 (Random and colorblind)": [[135, "solution:Statistics:colorblind"]], "Solution to Exercise 35.2 (Conditional discrete probability mass function)": [[135, "solution:Statistics:conditional-discrete-pmf"]], "Solution to Exercise 35.3 (Conditional probability for continuous variables)": [[135, "solution:Statistics:conditional-probability-continuous"]], "Solution to Exercise 35.4 (Conditional expectation)": [[135, "solution:Statistics:conditional-expectation"]], "Solution to Exercise 35.5 (Scipy.stats)": [[135, "colution:Statistics:scipy-stats"]], "Solution to Exercise 35.6 (Bivariate pdf)": [[135, "solution:Statistics:bivariate-pdf"]], "Solution to Exercise 38.1 (Independent and dependent)": [[120, "solution:OverviewModeling:independent-dependent"]], "Solution to Exercise 38.2 (Linear or non-linear)": [[120, "solution:OverviewModeling:linear-nonlinear"]], "Solution to Exercise 38.3 (Linear or non-linear; more examples)": [[120, "solution:OverviewModeling:linear-nonlinear-examples"]], "Solution to Exercise 38.4 (Model discrepancy)": [[120, "solution:OverviewModeling:model-discrepancy"]], "Solution to Exercise 39.1": [[108, "solution:ols_example_1"]], "Solution to Exercise 39.3": [[108, "solution:ols_example_3"]], "Solution to Exercise 4.3": [[16, "solution:ppd_definition"]], "Solution to Exercise 4.4": [[16, "solution:pdf_normalization"]], "Solution to Exercise 4.5": [[16, "solution:rain"]], "Solution to Exercise 4.6": [[16, "solution:monty_hall"]], "Solution to Exercise 4.7": [[16, "solution:coin_ppd"]], "Solution to Exercise 8.1 (Correlated errors)": [[21, "solution:BayesianAdvantage:correlated-errors"]], "Solution to Exercise 8.3 (Inferring galactic distances)": [[21, "solution:BayesianAdvantages:inferring-galactic-distances-ex"]], "Solution to Exercise 8.4 (The standard random variable)": [[21, "solution:BayesianAdvantages:standard-random-variable"]], "Solution to Exercise 8.5 (The square root of a number)": [[21, "solution:BayesianAdvantages:square-root-of-a-number"]], "Solution to Exercise 8.6 (Gaussian sum of errors)": [[21, "solution:BayesianAdvantages:gaussian-sum-of-errors"]], "Solution to Exercise 8.7 (Gaussian product of errors)": [[21, "solution:BayesianAdvantages:gaussian-product-of-errors"]], "Solutions": [[16, "solutions"], [21, null], [70, "solutions"], [71, "solutions"], [72, "solutions"], [108, null], [120, null], [135, "solutions"], [158, "solutions"], [161, "solutions"], [166, "solutions"]], "Solutions to selected exercises": [[39, "solutions-to-selected-exercises"]], "Solving matrix equations with SVD": [[132, "solving-matrix-equations-with-svd"]], "Solving orbital equations with different algorithms": [[155, null]], "Some standard pdfs: the normal (aka Gaussian) and beta distributions": [[22, "some-standard-pdfs-the-normal-aka-gaussian-and-beta-distributions"]], "Sorting": [[141, "sorting"]], "Sparsity": [[122, "sparsity"]], "Special case: Gaussian process": [[166, "special-case-gaussian-process"]], "Speed comparisons": [[140, "speed-comparisons"]], "Splitting arrays": [[141, "splitting-arrays"]], "Spot the error!": [[39, null]], "Standard Error of the Mean": [[148, "standard-error-of-the-mean"]], "Standard Likelihood Approach": [[43, "standard-likelihood-approach"]], "Standard activation functions": [[93, "standard-activation-functions"]], "State-of-the-art MCMC implementations": [[158, "state-of-the-art-mcmc-implementations"]], "Statements": [[26, null]], "Stationary and limiting distributions": [[161, "stationary-and-limiting-distributions"]], "Stationary kernels": [[90, "stationary-kernels"]], "Stationary processes": [[161, "stationary-processes"]], "Statistical Operations": [[141, "statistical-operations"]], "Statistical formulation": [[128, "statistical-formulation"]], "Statistics concepts and notation": [[135, null]], "Step 1: Maximum likelihood estimate": [[46, "step-1-maximum-likelihood-estimate"]], "Step 2: Single-parameter model": [[46, "step-2-single-parameter-model"]], "Step 3: Full Bayesian approach": [[46, "step-3-full-bayesian-approach"]], "Step 4: Error propagation": [[46, "step-4-error-propagation"]], "Stochastic processes": [[166, null]], "Student t distribution as a mixture of Gaussians": [[131, null]], "Sub-task": [[75, "sub-task"]], "Sub-tasks and follow-up questions": [[75, "sub-tasks-and-follow-up-questions"]], "Subtasks (put your answers here):": [[101, "subtasks-put-your-answers-here"]], "Suggestions for how to proceed:": [[99, "suggestions-for-how-to-proceed"]], "Sum of normally distributed random variables.": [[90, null]], "Sum rule": [[27, "sum-rule"]], "Summary": [[8, "summary"], [19, null], [46, "summary"], [90, null]], "Summary points from arXiv:1710.06068": [[164, null]], "Symmetry invariance": [[3, "symmetry-invariance"]], "Systematic error example": [[46, "systematic-error-example"]], "Systematic reduction": [[80, "systematic-reduction"]], "Systemic biases": [[68, null]], "Table of results": [[41, null]], "Take aways: Coin tossing": [[30, "take-aways-coin-tossing"]], "Take-aways and follow-up questions from coin flipping:": [[15, null]], "Task 1: Logistic regression using scikit-learn": [[79, "task-1-logistic-regression-using-scikit-learn"]], "Task 2: Bayesian logistic regression using MCMC sampling": [[79, "task-2-bayesian-logistic-regression-using-mcmc-sampling"]], "Task 3: Bayesian logistic regression using Variational Inference": [[79, "task-3-bayesian-logistic-regression-using-variational-inference"]], "Telling ChatGPT 4 to make a network for a function of one variable": [[76, "telling-chatgpt-4-to-make-a-network-for-a-function-of-one-variable"]], "Terminology": [[72, "terminology"]], "Test the sum of normal variables squared": [[34, "test-the-sum-of-normal-variables-squared"]], "The Central Limit Theorem": [[24, "the-central-limit-theorem"]], "The Data": [[45, "the-data"], [148, "the-data"]], "The Data and the question": [[46, "the-data-and-the-question"]], "The Data and the true result": [[54, "the-data-and-the-true-result"]], "The Gaussian is to statistics what the harmonic oscillator is to mechanics": [[24, "the-gaussian-is-to-statistics-what-the-harmonic-oscillator-is-to-mechanics"]], "The Gelman-Rubin test": [[49, "the-gelman-rubin-test"]], "The Jupyter Notebook menu and shortcuts": [[139, "the-jupyter-notebook-menu-and-shortcuts"]], "The Kullback-Leibler divergence": [[77, "the-kullback-leibler-divergence"]], "The Metropolis-Hastings algorithm": [[158, "the-metropolis-hastings-algorithm"]], "The Model": [[43, "the-model"], [45, "the-model"], [46, "the-model"], [100, "the-model"], [148, "the-model"]], "The Prior": [[45, "the-prior"]], "The RBF kernel (a.k.a Gaussian)": [[83, "the-rbf-kernel-a-k-a-gaussian"], [87, "the-rbf-kernel-a-k-a-gaussian"]], "The Story of Dr. A and Prof. B": [[58, "the-story-of-dr-a-and-prof-b"]], "The Zeus Ensemble Slice Sampler": [[168, null]], "The ball-drop model": [[126, null]], "The bias-variance tradeoff": [[71, "the-bias-variance-tradeoff"]], "The continuum limit": [[30, "the-continuum-limit"]], "The cost function rewritten as cross entropy": [[93, "the-cost-function-rewritten-as-cross-entropy"]], "The covariance matrix as the central object": [[90, "the-covariance-matrix-as-the-central-object"]], "The entropy of Scandinavians": [[4, "the-entropy-of-scandinavians"]], "The friends of Bayes\u2019 theorem": [[30, "the-friends-of-bayes-theorem"]], "The likelihood": [[39, "the-likelihood"]], "The logistic function": [[93, "the-logistic-function"]], "The monkey argument": [[4, "the-monkey-argument"]], "The near ubiquity of Gaussians": [[24, "the-near-ubiquity-of-gaussians"]], "The normal distribution": [[4, null]], "The normal equation": [[39, "the-normal-equation"], [105, "the-normal-equation"]], "The perceptron": [[93, "the-perceptron"]], "The perceptron classifier": [[70, "the-perceptron-classifier"]], "The posterior": [[39, "the-posterior"]], "The posterior predictive": [[39, "the-posterior-predictive"]], "The posterior predictive distribution": [[16, "the-posterior-predictive-distribution"]], "The prior": [[39, "the-prior"]], "The probability measure": [[135, "the-probability-measure"]], "The pseudo-inverse (or Moore-Penrose inverse)": [[39, null]], "The soft classifier": [[70, "the-soft-classifier"]], "The statistical model (recap)": [[54, "the-statistical-model-recap"]], "The tip class": [[0, "the-tip-class"]], "The toy model": [[54, "the-toy-model"]], "The uniform distribution": [[135, "the-uniform-distribution"]], "Theory": [[128, "theory"]], "Things for you to do:": [[54, "things-for-you-to-do"]], "Things to do and Questions to answer": [[100, "things-to-do-and-questions-to-answer"]], "Things to do:": [[45, "things-to-do"], [132, "things-to-do"]], "Things to try:": [[134, "things-to-try"]], "Third example: each sample is 10 points": [[38, "third-example-each-sample-is-10-points"]], "Third pass:  a more elaborate user interface with tabs": [[137, "third-pass-a-more-elaborate-user-interface-with-tabs"]], "This makes sense:": [[91, null]], "Three main ingredients of machine learning": [[69, null]], "To do": [[98, "to-do"]], "To our real data: nuclear binding energies. Brief reminder on masses and binding energies": [[138, "to-our-real-data-nuclear-binding-energies-brief-reminder-on-masses-and-binding-energies"]], "To think about \u2026": [[24, null]], "Trace": [[141, "trace"]], "Train and evaluate the model:": [[74, "train-and-evaluate-the-model"]], "Training and validation scores": [[71, null]], "Training scores": [[70, "training-scores"]], "Transformation property of multivariate normal distributions": [[39, null]], "Transforming images": [[80, "transforming-images"]], "Try it yourself with the Jupyter notebook": [[138, null]], "Trying a different function": [[5, "trying-a-different-function"]], "Two dependent parameters": [[58, "two-dependent-parameters"]], "Two independent parameters": [[58, "two-independent-parameters"]], "Two views on the likelihood": [[39, null]], "Types of Machine Learning": [[69, "types-of-machine-learning"]], "Types of probability": [[135, "types-of-probability"]], "Uncertainty in predicted value": [[78, "uncertainty-in-predicted-value"], [98, "uncertainty-in-predicted-value"]], "Uncorrelated assignments": [[4, null]], "Univariate Approaches": [[148, "univariate-approaches"]], "Updating via Bayes\u2019 rule": [[10, null]], "Updating your conda environment for Learning from Data": [[142, "updating-your-conda-environment-for-learning-from-data"]], "User-interface for coin-flipping": [[9, "user-interface-for-coin-flipping"]], "Using Anaconda": [[142, null]], "Using Bayesian model mixing to open the model space": [[53, "using-bayesian-model-mixing-to-open-the-model-space"]], "Using GitHub": [[145, null]], "Using SVD for PCA": [[132, "using-svd-for-pca"]], "Using parallel tempering: ptemcee": [[101, "using-parallel-tempering-ptemcee"]], "Utilizing GPU Acceleration": [[76, "utilizing-gpu-acceleration"]], "Variance and the Gaussian pdf": [[4, "variance-and-the-gaussian-pdf"]], "Variance of the mean": [[49, "variance-of-the-mean"]], "Variational Inference: Bayesian Neural Networks": [[98, "variational-inference-bayesian-neural-networks"]], "Variational Inference: Scaling model complexity": [[78, "variational-inference-scaling-model-complexity"], [98, "variational-inference-scaling-model-complexity"]], "Variational inference for Bayesian neural networks": [[77, "variational-inference-for-bayesian-neural-networks"]], "Verification of PyTorch installation (suggested in PyTorch website)": [[76, "verification-of-pytorch-installation-suggested-in-pytorch-website"]], "Verify the data": [[81, "verify-the-data"]], "Verifying sampling": [[23, null]], "Virtues": [[66, null]], "Visualization of MCMC sampling": [[159, "visualization-of-mcmc-sampling"]], "Visualization of PDFs": [[22, "visualization-of-pdfs"]], "Visualizations of MCMC": [[158, "visualizations-of-mcmc"]], "Visualizing PDFs": [[28, "visualizing-pdfs"]], "Warnings": [[0, "warnings"]], "What are arrays?": [[141, "what-are-arrays"]], "What does it mean that the ellipses are slanted?": [[41, null]], "What failure looks like": [[5, "what-failure-looks-like"]], "What if the only moves accepted were those that went uphill (i.e., to higher probability density)? What would happen to N_A and N_B over time? Is this stationary?": [[164, null]], "What is p(\\thetavec_i|D,I)?": [[164, null]], "What is special about machine learning in physics?": [[65, null]], "What is the ratio of p(X_B|X_A) to p(X_A|X_B) in terms of p(X_A|D,I) and p(X_B|D,I)?": [[164, null]], "What is well determined?": [[84, null]], "What next?": [[51, "what-next"]], "What order polynomial?": [[100, "what-order-polynomial"]], "What pairs are highly correlated?": [[84, null]], "What returns the prior?": [[84, null]], "What to do about sampling from correlated distributions?": [[151, "what-to-do-about-sampling-from-correlated-distributions"]], "What you should know about Python and using Jupyter notebooks": [[143, "what-you-should-know-about-python-and-using-jupyter-notebooks"]], "When do priors matter? When don\u2019t they matter?": [[12, null]], "Why MCMC?": [[159, "why-mcmc"]], "Why deep neural networks?": [[72, "why-deep-neural-networks"]], "Why do you think that this property is called detailed balance? Can you make an analogy with thermodynamic equilibrium for e.g. a collection of hydrogen atoms?": [[164, null]], "Why maximize the entropy?": [[4, "why-maximize-the-entropy"]], "With model discrepancy": [[128, "with-model-discrepancy"]], "Without model discrepancy": [[128, "without-model-discrepancy"]], "Workflow for Bayesian linear regression": [[39, "workflow-for-bayesian-linear-regression"]], "Yet another function": [[5, "yet-another-function"]], "Zero-based indexing": [[141, null]], "emcee": [[101, "emcee"]], "emcee:": [[158, null]], "k nearest neighbors classification": [[70, "k-nearest-neighbors-classification"]], "kNN classifier": [[70, "knn-classifier"]], "l1-norm": [[4, "l1-norm"]], "numpy arrays": [[139, "numpy-arrays"]], "p or \\log p?": [[24, null]], "p-values: when all you can do is falsify": [[24, "p-values-when-all-you-can-do-is-falsify"]], "\ud83d\udce5 Amplitude of a signal in the presence of background": [[42, null]], "\ud83d\udce5 Dealing with outliers": [[43, null]], "\ud83d\udce5 Demonstration:  Bayesian Coin Tossing": [[35, null]], "\ud83d\udce5 Demonstration: Coin tossing (with widget)": [[9, null]], "\ud83d\udce5 Demonstration: Prior PDFs for straight lines": [[6, null]], "\ud83d\udce5 Demonstration: Reading Data and fitting": [[138, null]], "\ud83d\udce5 Demonstration: Sum of normal variables squared": [[34, null]], "\ud83d\udce5 Distributions of Randomly-Initialized ANNs": [[134, null]], "\ud83d\udce5 Exercise: Jupyter Notebooks and Python": [[139, null]], "\ud83d\udce5 Exercise: Linear algebra operations with NumPy": [[141, null]], "\ud83d\udce5 Exercise: Python lists and iterations": [[140, null]], "\ud83d\udce5 Exploring PDFs": [[22, null]], "\ud83d\udce5 Linear algebra games including SVD for PCA": [[132, null]], "\ud83d\udce5 Making a simple widget-based UI": [[137, null]], "\ud83d\udce5 Maximum Entropy for reconstructing a function from its moments": [[5, null]], "\ud83d\udce5 Model discrepancy example: The ball-drop experiment": [[128, null]], "\ud83d\udce5 Parameter estimation example: Gaussian noise and averages I": [[44, null]], "\ud83d\udce5 Parameter estimation example: fitting a straight line II": [[46, null]], "\ud83d\udce5 Radioactive lighthouse problem": [[47, null]], "\ud83d\udce5 Visualization of the Central Limit Theorem": [[38, null]]}, "docnames": ["LearningFromData-content/Backmatter/JB_tests", "LearningFromData-content/Backmatter/bibliography", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/Assigning", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/IgnorancePDF", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt2", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt_Function_Reconstruction", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/demo-straight_lines", "LearningFromData-content/BayesianStatistics/BayesianBasics/BayesianAdvantages", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_epistemology", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_updating_coinflip_interactive", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-01-coin-tossing-frequentists-and-bayesaians", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-02-when-do-priors-matter-when-don-t-they-matter", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-03-computing-the-posterior-analytically", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-04-degree-of-belief-credibility-intervals-vs-frequentist-1-sigm", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-05-take-aways-and-follow-up-questions-from-coin-flipping", "LearningFromData-content/BayesianStatistics/BayesianBasics/DataModelsPredictions", "LearningFromData-content/BayesianStatistics/BayesianBasics/ErrorPropagation", "LearningFromData-content/BayesianStatistics/BayesianBasics/ErrorPropagation/sec-01-error-propagation-i-nuisance-parameters-and-marginalization", "LearningFromData-content/BayesianStatistics/BayesianBasics/ErrorPropagation/sec-02-error-propagation-ii-changing-variables", "LearningFromData-content/BayesianStatistics/BayesianBasics/ErrorPropagation/sec-03-error-propagation-iii-a-useful-approximation", "LearningFromData-content/BayesianStatistics/BayesianBasics/ErrorPropagation/sec-04-solutions", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs_followups", "LearningFromData-content/BayesianStatistics/BayesianBasics/Gaussians", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-01-statements", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-02-manipulating-probabilities-bayesian-rules-of-probability-as", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-03-probability-density-functions", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-04-summary", "LearningFromData-content/BayesianStatistics/BayesianBasics/MoreBayesTheorem", "LearningFromData-content/BayesianStatistics/BayesianBasics/Posteriors", "LearningFromData-content/BayesianStatistics/BayesianBasics/RootBayesianBasics", "LearningFromData-content/BayesianStatistics/BayesianBasics/UsingBayes", "LearningFromData-content/BayesianStatistics/BayesianBasics/chi_squared_tests", "LearningFromData-content/BayesianStatistics/BayesianBasics/demo-BayesianBasics", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_medical_example_by_Bayes", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_sum_product_rule", "LearningFromData-content/BayesianStatistics/BayesianBasics/visualization_of_CLT", "LearningFromData-content/BayesianStatistics/BayesianLinearRegression/BayesianLinearRegression_rjf", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/Exercises_parameter_estimation", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/Interpreting2Dposteriors", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/amplitude_in_presence_of_background", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/dealing_with_outliers", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_Gaussian_noise", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_I", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_II", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/radioactive_lighthouse_exercise", "LearningFromData-content/BayesianStatistics/BayesianWorkflow/BayesianWorkflow", "LearningFromData-content/BayesianStatistics/ComputationalBayes/AdvancedMCMC", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesFast", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesLinear", "LearningFromData-content/BayesianStatistics/ComputationalBayes/extra_RBM_emulators", "LearningFromData-content/BayesianStatistics/ModelMixing/model_mixing", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/Evidence_for_model_EFT_coefficients", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/MCMC-parallel-tempering_ptemcee_vs_zeus", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/computing_evidence", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/two_model_evidence", "LearningFromData-content/BayesianStatistics/ModelSelection/ModelSelection", "LearningFromData-content/BayesianStatistics/Multimodel_inference", "LearningFromData-content/BayesianStatistics/RootAdvancedMethods", "LearningFromData-content/Intro/About", "LearningFromData-content/Intro/Introduction", "LearningFromData-content/Intro/Introduction/sec-01-physicist-s-perspective", "LearningFromData-content/Intro/Introduction/sec-02-bayesian-workflow", "LearningFromData-content/Intro/Introduction/sec-03-machine-learning", "LearningFromData-content/Intro/Introduction/sec-04-virtues", "LearningFromData-content/Intro/Invitation", "LearningFromData-content/MachineLearning/ANN/DataBiasFairness", "LearningFromData-content/MachineLearning/ANN/MachineLearning", "LearningFromData-content/MachineLearning/ANN/MachineLearningExamples", "LearningFromData-content/MachineLearning/ANN/ModelValidation", "LearningFromData-content/MachineLearning/ANN/NeuralNet", "LearningFromData-content/MachineLearning/ANN/NeuralNet/NeuralNetBackProp", "LearningFromData-content/MachineLearning/ANN/NeuralNet/demo-NeuralNet", "LearningFromData-content/MachineLearning/ANN/NeuralNet/exercises_LogReg_NeuralNet", "LearningFromData-content/MachineLearning/ANN/Neural_Network_for_simple_function_in_PyTorch", "LearningFromData-content/MachineLearning/BNN/bnn", "LearningFromData-content/MachineLearning/BNN/demo-bnn", "LearningFromData-content/MachineLearning/BNN/exercises_BNN", "LearningFromData-content/MachineLearning/CNN/cnn", "LearningFromData-content/MachineLearning/CNN/demo-cnn", "LearningFromData-content/MachineLearning/GP/BUQ/Gaussian_processes_exercises", "LearningFromData-content/MachineLearning/GP/BUQ/demo-GaussianProcesses", "LearningFromData-content/MachineLearning/GP/BUQ/lecture_20", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_noisy_targets", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_prior_posterior", "LearningFromData-content/MachineLearning/GP/CF/demo-GaussianProcesses", "LearningFromData-content/MachineLearning/GP/CF/exercise_GP_GPy", "LearningFromData-content/MachineLearning/GP/GPy_demos", "LearningFromData-content/MachineLearning/GP/GaussianProcesses", "LearningFromData-content/MachineLearning/GP/RootGP", "LearningFromData-content/MachineLearning/GP/Sklearn_demos", "LearningFromData-content/MachineLearning/LogReg/LogReg", "LearningFromData-content/MachineLearning/RootML", "LearningFromData-content/Mini-projects/Mini-project_IIb_overview", "LearningFromData-content/Mini-projects/RootMiniProjects", "LearningFromData-content/Mini-projects/mini-project_IIIa_bayesian_optimization", "LearningFromData-content/Mini-projects/mini-project_IIIb_Bayesian_neural_networks_from_demo", "LearningFromData-content/Mini-projects/mini-project_I_toy_model_of_EFT", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIa", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIb_How_many_lines_ptemcee", "LearningFromData-content/ModelingOptimization/GradientDescent", "LearningFromData-content/ModelingOptimization/LinearModels", "LearningFromData-content/ModelingOptimization/LinearModels/sec-01-definition-of-linear-models", "LearningFromData-content/ModelingOptimization/LinearModels/sec-02-regression-analysis-with-linear-models", "LearningFromData-content/ModelingOptimization/LinearModels/sec-03-ordinary-linear-regression-warmup", "LearningFromData-content/ModelingOptimization/LinearModels/sec-04-ordinary-linear-regression-in-practice", "LearningFromData-content/ModelingOptimization/LinearModels/sec-05-solutions", "LearningFromData-content/ModelingOptimization/MathematicalOptimization", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-01-gradient-descent-optimization", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-02-batch-stochastic-and-mini-batch-gradient-descent", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-03-adaptive-gradient-descent-algorithms", "LearningFromData-content/ModelingOptimization/OverviewModeling", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-01-notation", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-02-models-in-science", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-03-parametric-versus-non-parametric-models", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-04-linear-versus-non-linear-models", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-05-regression-analysis-optimization-versus-inference", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-06-exercises", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-07-solutions", "LearningFromData-content/ModelingOptimization/RootScientificModeling", "LearningFromData-content/OtherTopics/ANNFT", "LearningFromData-content/OtherTopics/DiscrepancyModels", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-01-koh-and-boh-discrepancy-models", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-02-framework", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-03-the-ball-drop-model", "LearningFromData-content/OtherTopics/Emulators", "LearningFromData-content/OtherTopics/MD_balldrop_v1", "LearningFromData-content/OtherTopics/RootOtherTopics", "LearningFromData-content/OtherTopics/SVD", "LearningFromData-content/OtherTopics/Student_t_distribution_from_Gaussians", "LearningFromData-content/OtherTopics/linear_algebra_games_including_SVD", "LearningFromData-content/OtherTopics/qbism", "LearningFromData-content/OtherTopics/random_initialized_ANN_vs_width", "LearningFromData-content/Reference/Statistics", "LearningFromData-content/Setup/RootGettingStarted", "LearningFromData-content/Setup/Simple_widgets_v1", "LearningFromData-content/Setup/demo-Intro", "LearningFromData-content/Setup/exercise_Intro_01_Jupyter_Python", "LearningFromData-content/Setup/exercise_Intro_02_Jupyter_Python", "LearningFromData-content/Setup/exercise_Intro_03_Numpy", "LearningFromData-content/Setup/installing_anaconda", "LearningFromData-content/Setup/more_python_and_jupyter", "LearningFromData-content/Setup/setting_up", "LearningFromData-content/Setup/using_github", "LearningFromData-content/StochasticProcesses/Advanced_MCMC", "LearningFromData-content/StochasticProcesses/BUQ/Assignment_extending_radioactive_lighthouse", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-diagnostics", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-random-walk-and-sampling", "LearningFromData-content/StochasticProcesses/BUQ/Metropolis_Poisson_example", "LearningFromData-content/StochasticProcesses/BUQ/intuition_sampling", "LearningFromData-content/StochasticProcesses/BUQ/parameter_estimation_Gaussian_noise-2", "LearningFromData-content/StochasticProcesses/BUQ2/HMC_intro_BUQ", "LearningFromData-content/StochasticProcesses/BUQ2/Liouville_theorem_visualization", "LearningFromData-content/StochasticProcesses/BUQ2/Orbital_eqs_with_different_algorithms", "LearningFromData-content/StochasticProcesses/BUQ2/PyMC_intro_updated", "LearningFromData-content/StochasticProcesses/BUQ2/parameter_estimation_Gaussian_noise_compare_samplers", "LearningFromData-content/StochasticProcesses/MCMC", "LearningFromData-content/StochasticProcesses/MCMC_intro_BUQ", "LearningFromData-content/StochasticProcesses/MCMC_overview", "LearningFromData-content/StochasticProcesses/MarkovChains", "LearningFromData-content/StochasticProcesses/Other_samplers", "LearningFromData-content/StochasticProcesses/OverviewIntroPyMC", "LearningFromData-content/StochasticProcesses/Recap_BUQ", "LearningFromData-content/StochasticProcesses/RootMCMC", "LearningFromData-content/StochasticProcesses/StochasticProcesses", "LearningFromData-content/StochasticProcesses/demo-MCMC", "LearningFromData-content/StochasticProcesses/zeus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["LearningFromData-content/Backmatter/JB_tests.md", "LearningFromData-content/Backmatter/bibliography.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/Assigning.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/IgnorancePDF.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt2.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt_Function_Reconstruction.ipynb", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/demo-straight_lines.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/BayesianAdvantages.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_epistemology.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_updating_coinflip_interactive.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-01-coin-tossing-frequentists-and-bayesaians.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-02-when-do-priors-matter-when-don-t-they-matter.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-03-computing-the-posterior-analytically.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-04-degree-of-belief-credibility-intervals-vs-frequentist-1-sigm.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-05-take-aways-and-follow-up-questions-from-coin-flipping.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/DataModelsPredictions.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/ErrorPropagation.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/ErrorPropagation/sec-01-error-propagation-i-nuisance-parameters-and-marginalization.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/ErrorPropagation/sec-02-error-propagation-ii-changing-variables.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/ErrorPropagation/sec-03-error-propagation-iii-a-useful-approximation.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/ErrorPropagation/sec-04-solutions.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs_followups.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Gaussians.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-01-statements.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-02-manipulating-probabilities-bayesian-rules-of-probability-as.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-03-probability-density-functions.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-04-summary.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/MoreBayesTheorem.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Posteriors.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/RootBayesianBasics.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/UsingBayes.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/chi_squared_tests.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/demo-BayesianBasics.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_medical_example_by_Bayes.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_sum_product_rule.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/visualization_of_CLT.ipynb", "LearningFromData-content/BayesianStatistics/BayesianLinearRegression/BayesianLinearRegression_rjf.md", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/Exercises_parameter_estimation.md", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/Interpreting2Dposteriors.md", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/amplitude_in_presence_of_background.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/dealing_with_outliers.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_Gaussian_noise.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_I.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_II.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/radioactive_lighthouse_exercise.ipynb", "LearningFromData-content/BayesianStatistics/BayesianWorkflow/BayesianWorkflow.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/AdvancedMCMC.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesFast.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesLinear.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/extra_RBM_emulators.md", "LearningFromData-content/BayesianStatistics/ModelMixing/model_mixing.md", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/Evidence_for_model_EFT_coefficients.ipynb", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/MCMC-parallel-tempering_ptemcee_vs_zeus.ipynb", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/computing_evidence.md", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/two_model_evidence.md", "LearningFromData-content/BayesianStatistics/ModelSelection/ModelSelection.md", "LearningFromData-content/BayesianStatistics/Multimodel_inference.md", "LearningFromData-content/BayesianStatistics/RootAdvancedMethods.md", "LearningFromData-content/Intro/About.md", "LearningFromData-content/Intro/Introduction.md", "LearningFromData-content/Intro/Introduction/sec-01-physicist-s-perspective.md", "LearningFromData-content/Intro/Introduction/sec-02-bayesian-workflow.md", "LearningFromData-content/Intro/Introduction/sec-03-machine-learning.md", "LearningFromData-content/Intro/Introduction/sec-04-virtues.md", "LearningFromData-content/Intro/Invitation.md", "LearningFromData-content/MachineLearning/ANN/DataBiasFairness.md", "LearningFromData-content/MachineLearning/ANN/MachineLearning.md", "LearningFromData-content/MachineLearning/ANN/MachineLearningExamples.md", "LearningFromData-content/MachineLearning/ANN/ModelValidation.md", "LearningFromData-content/MachineLearning/ANN/NeuralNet.md", "LearningFromData-content/MachineLearning/ANN/NeuralNet/NeuralNetBackProp.md", "LearningFromData-content/MachineLearning/ANN/NeuralNet/demo-NeuralNet.ipynb", "LearningFromData-content/MachineLearning/ANN/NeuralNet/exercises_LogReg_NeuralNet.ipynb", "LearningFromData-content/MachineLearning/ANN/Neural_Network_for_simple_function_in_PyTorch.ipynb", "LearningFromData-content/MachineLearning/BNN/bnn.md", "LearningFromData-content/MachineLearning/BNN/demo-bnn.ipynb", "LearningFromData-content/MachineLearning/BNN/exercises_BNN.ipynb", "LearningFromData-content/MachineLearning/CNN/cnn.md", "LearningFromData-content/MachineLearning/CNN/demo-cnn.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/Gaussian_processes_exercises.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/demo-GaussianProcesses.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/lecture_20.md", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_noisy_targets.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_prior_posterior.ipynb", "LearningFromData-content/MachineLearning/GP/CF/demo-GaussianProcesses.ipynb", "LearningFromData-content/MachineLearning/GP/CF/exercise_GP_GPy.ipynb", "LearningFromData-content/MachineLearning/GP/GPy_demos.md", "LearningFromData-content/MachineLearning/GP/GaussianProcesses.md", "LearningFromData-content/MachineLearning/GP/RootGP.md", "LearningFromData-content/MachineLearning/GP/Sklearn_demos.md", "LearningFromData-content/MachineLearning/LogReg/LogReg.md", "LearningFromData-content/MachineLearning/RootML.md", "LearningFromData-content/Mini-projects/Mini-project_IIb_overview.md", "LearningFromData-content/Mini-projects/RootMiniProjects.md", "LearningFromData-content/Mini-projects/mini-project_IIIa_bayesian_optimization.ipynb", "LearningFromData-content/Mini-projects/mini-project_IIIb_Bayesian_neural_networks_from_demo.ipynb", "LearningFromData-content/Mini-projects/mini-project_I_toy_model_of_EFT.ipynb", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIa.ipynb", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIb_How_many_lines_ptemcee.ipynb", "LearningFromData-content/ModelingOptimization/GradientDescent.md", "LearningFromData-content/ModelingOptimization/LinearModels.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-01-definition-of-linear-models.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-02-regression-analysis-with-linear-models.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-03-ordinary-linear-regression-warmup.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-04-ordinary-linear-regression-in-practice.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-05-solutions.md", "LearningFromData-content/ModelingOptimization/MathematicalOptimization.md", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-01-gradient-descent-optimization.md", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-02-batch-stochastic-and-mini-batch-gradient-descent.md", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-03-adaptive-gradient-descent-algorithms.md", "LearningFromData-content/ModelingOptimization/OverviewModeling.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-01-notation.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-02-models-in-science.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-03-parametric-versus-non-parametric-models.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-04-linear-versus-non-linear-models.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-05-regression-analysis-optimization-versus-inference.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-06-exercises.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-07-solutions.md", "LearningFromData-content/ModelingOptimization/RootScientificModeling.md", "LearningFromData-content/OtherTopics/ANNFT.md", "LearningFromData-content/OtherTopics/DiscrepancyModels.md", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-01-koh-and-boh-discrepancy-models.md", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-02-framework.md", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-03-the-ball-drop-model.md", "LearningFromData-content/OtherTopics/Emulators.md", "LearningFromData-content/OtherTopics/MD_balldrop_v1.ipynb", "LearningFromData-content/OtherTopics/RootOtherTopics.md", "LearningFromData-content/OtherTopics/SVD.md", "LearningFromData-content/OtherTopics/Student_t_distribution_from_Gaussians.ipynb", "LearningFromData-content/OtherTopics/linear_algebra_games_including_SVD.ipynb", "LearningFromData-content/OtherTopics/qbism.md", "LearningFromData-content/OtherTopics/random_initialized_ANN_vs_width.ipynb", "LearningFromData-content/Reference/Statistics.md", "LearningFromData-content/Setup/RootGettingStarted.md", "LearningFromData-content/Setup/Simple_widgets_v1.ipynb", "LearningFromData-content/Setup/demo-Intro.ipynb", "LearningFromData-content/Setup/exercise_Intro_01_Jupyter_Python.ipynb", "LearningFromData-content/Setup/exercise_Intro_02_Jupyter_Python.ipynb", "LearningFromData-content/Setup/exercise_Intro_03_Numpy.ipynb", "LearningFromData-content/Setup/installing_anaconda.md", "LearningFromData-content/Setup/more_python_and_jupyter.md", "LearningFromData-content/Setup/setting_up.md", "LearningFromData-content/Setup/using_github.md", "LearningFromData-content/StochasticProcesses/Advanced_MCMC.md", "LearningFromData-content/StochasticProcesses/BUQ/Assignment_extending_radioactive_lighthouse.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-diagnostics.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-random-walk-and-sampling.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/Metropolis_Poisson_example.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/intuition_sampling.md", "LearningFromData-content/StochasticProcesses/BUQ/parameter_estimation_Gaussian_noise-2.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/HMC_intro_BUQ.md", "LearningFromData-content/StochasticProcesses/BUQ2/Liouville_theorem_visualization.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/Orbital_eqs_with_different_algorithms.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/PyMC_intro_updated.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/parameter_estimation_Gaussian_noise_compare_samplers.ipynb", "LearningFromData-content/StochasticProcesses/MCMC.md", "LearningFromData-content/StochasticProcesses/MCMC_intro_BUQ.md", "LearningFromData-content/StochasticProcesses/MCMC_overview.md", "LearningFromData-content/StochasticProcesses/MarkovChains.md", "LearningFromData-content/StochasticProcesses/Other_samplers.md", "LearningFromData-content/StochasticProcesses/OverviewIntroPyMC.md", "LearningFromData-content/StochasticProcesses/Recap_BUQ.md", "LearningFromData-content/StochasticProcesses/RootMCMC.md", "LearningFromData-content/StochasticProcesses/StochasticProcesses.md", "LearningFromData-content/StochasticProcesses/demo-MCMC.ipynb", "LearningFromData-content/StochasticProcesses/zeus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 3, 4, 8, 9, 11, 12, 15, 16, 18, 21, 22, 24, 26, 27, 28, 30, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 61, 62, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 97, 99, 100, 101, 102, 103, 105, 106, 107, 115, 119, 120, 122, 124, 125, 126, 128, 130, 131, 132, 133, 134, 135, 138, 139, 140, 142, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 164, 166, 167], "0": [0, 1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 24, 26, 27, 29, 30, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 97, 99, 100, 101, 102, 104, 105, 107, 109, 112, 119, 125, 126, 128, 130, 131, 132, 134, 135, 137, 138, 139, 140, 141, 142, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 166, 167, 168], "00": [1, 44, 55, 71, 74, 82, 83, 88, 98, 128, 132, 135, 150, 152, 155, 156, 157, 166, 167], "000": [36, 37, 48, 49, 80, 81, 138, 150, 156, 161, 164, 166, 167], "0000": 76, "000000": 138, "00000000e": [83, 132], "00001": 1, "000054": 138, "00008": 1, "00009": 138, "0001": [36, 75], "00011": 138, "00012": 138, "00046": 138, "00049": 138, "0005": 83, "0005735": 44, "00088142": 44, "000e": [128, 132], "001": [1, 82, 87, 88, 112, 135, 155, 156], "00107510802066753": 1, "0015": 54, "001mb": 82, "002": [138, 157], "00297317": 44, "0029802": 44, "0029e": 76, "003": 157, "0031": 76, "003100": 138, "003620": 138, "0038": 81, "00398911": 44, "004": [5, 135, 156, 166], "00400084": 44, "00414463": 135, "00429143": [152, 157], "0043": 36, "004752": 83, "005": [49, 83, 87, 148, 151, 156, 167], "00560623": [152, 157], "00568668": 44, "006": 156, "006078": 156, "006078arrai": 156, "0062": 134, "00727646693": 138, "007315": 138, "007825": 138, "00788": 77, "00796648": 44, "008": 132, "00806543": 44, "00807068": 132, "0084806e": 81, "00854895": 44, "008664": 138, "0086649156": 138, "008706": 156, "008706arrai": 156, "0089233": 132, "009": 1, "0094": 81, "00941": 97, "00978733": 44, "009e": 128, "00arviz_vers": 156, "00it": 157, "00j": 83, "01": [3, 20, 22, 38, 39, 42, 43, 47, 54, 70, 71, 72, 74, 75, 76, 78, 81, 82, 83, 86, 88, 97, 98, 100, 128, 132, 135, 156, 157, 166, 167], "01012718": 44, "01028139": 156, "0104": 76, "010902": 138, "01120706": 44, "01125": 1, "012": [132, 167], "013": [37, 166], "0130812": 132, "01335268": 44, "01382247": 44, "01399536": 132, "013e": 128, "014": 36, "014004": 1, "014101": 138, "01410649": 132, "01419539": 156, "015": 166, "0165": 134, "01652757": 44, "017": [1, 166], "0170907": 156, "01715": 1, "01716473": 44, "01740941": 44, "01795589": 44, "018": 132, "01818182": 132, "018232": 138, "01855247": 44, "01860414": 132, "01977117": 83, "01e": 86, "01it": 157, "02": [1, 42, 46, 47, 49, 81, 82, 83, 85, 87, 100, 128, 131, 132, 156, 157, 166, 167], "020": [1, 167], "02010975": 44, "021": 166, "02124813": 44, "021407347281695": 47, "02186284": 44, "022": [1, 132], "022227": 44, "02227172": [152, 157], "023": [36, 132], "02315780e": 156, "02381439": 156, "024": [132, 167], "025": 138, "02507": 1, "02599999": 44, "026218253x": 1, "02673241": 44, "02691404e": 83, "027": 43, "027034515190072987": 88, "02827408": [152, 157], "029": 132, "02941762": 44, "029733": 138, "02it": 157, "03": [1, 4, 46, 76, 81, 82, 83, 100, 128, 156, 157, 167], "030002": 138, "030003": [1, 138], "0303": 87, "03085711": 44, "03224": 138, "0323e": 76, "032501": 1, "03261455": 44, "03298378": 44, "033": 148, "0334508": 44, "03368687": 44, "034047": 138, "03431": 1, "0343265": 75, "034328": [83, 87], "03490736": 132, "03493433": [152, 157], "03494359": 44, "035002": 1, "0353601": 44, "035909": 138, "03616585e": 156, "03685498e": 132, "037": [132, 135], "0370": 1, "03703898": 44, "0387364": 44, "0388246": 44, "038847": 132, "03960056e": 132, "03998411": 135, "039e": 132, "03it": 157, "04": [38, 44, 55, 76, 81, 83, 100, 128, 135, 148, 156, 157, 167], "04008915": 44, "04011": 1, "04037143": 44, "0407972": 156, "041": 43, "04183091": 44, "042": 132, "04221375": 44, "04278640498515118": 5, "04279159257882259": 5, "043": 166, "04359686": 44, "04366899": 44, "04392": 156, "044": 156, "044001": 91, "0441": 131, "044334": 138, "04444209": 44, "04457474": 44, "04499441": 44, "045": 34, "04527": 1, "0453": 76, "04548788": [152, 157], "04618286": [152, 157], "0462994": 44, "0465673": 44, "047": 166, "04789471": 44, "0479379": 44, "0484": 1, "04845149": 132, "048920": 138, "049": 43, "04906169": 44, "0490804": 44, "04909075": 44, "04912": 1, "04914084": 156, "04921829": 44, "04938272": 158, "049462": 138, "04t16": 156, "05": [9, 22, 24, 47, 51, 54, 55, 70, 76, 81, 82, 83, 86, 87, 88, 99, 100, 101, 128, 131, 132, 135, 156, 157, 167], "05031709": 44, "05080775": 44, "05111262": 132, "05117344": 44, "05132077": 44, "05156034": 44, "052e": 128, "053": [4, 132, 148], "05340954": 44, "05367155": 132, "054": 138, "05418781": 138, "05424": 1, "0546241": 44, "05495304": 44, "05528": 1, "055676": 138, "056": [9, 132], "05635552": 44, "05667659": 44, "057": 132, "057121": 44, "05741082": 44, "058": [24, 132], "0587121": 54, "05917603": 132, "05930431": 132, "05931904": 44, "06": [74, 76, 78, 86, 87, 88, 98, 100, 156, 157, 167], "06032751": 44, "060349": 138, "06056664": [152, 157], "0607502": 44, "061679": 138, "0617284": 158, "06206018e": 83, "063443": 138, "063724": 138, "064": 132, "06423057": 44, "065026": 138, "06578332": 44, "06581816": 44, "065e": 128, "066": 4, "06608534": 44, "067": 86, "0672e": 76, "06798079e": 70, "068": 138, "06802716": 138, "0684": 54, "0687176": 132, "06897162": 44, "06898597": 44, "069584": 138, "06996554": 44, "07": [4, 43, 74, 76, 83, 87, 100, 135, 156, 157, 167], "070": 4, "0700": 76, "070043": 138, "07034132": 156, "07090": 1, "071": 156, "07125243": 44, "0713": 138, "0719842": 132, "0722519": 44, "07272727": 132, "07312806": 44, "074": 157, "074001": 54, "07432055": 44, "07454457e": 132, "0761167e": 81, "07638048": 44, "0771e": 76, "07734007": 44, "07782113": 44, "07782731e": 156, "078": [9, 39], "07941624": 157, "07it": 157, "08": [74, 82, 98, 100, 152, 156, 157, 167], "08008": 156, "08012115": 132, "0803": 1, "08075099": 44, "0809271": 44, "081": 157, "08114713": 107, "08155996": 44, "08176782": 44, "082875": 138, "083527": 138, "08352721390288316": 138, "08401706": 132, "08420815": 44, "08457563": 44, "086": 132, "08601": 1, "08646441": 44, "087887": 138, "087e": 128, "0883": 81, "08958761": [152, 157], "08968641": 44, "08972912": 44, "09": [34, 36, 43, 74, 83, 87, 156], "09169": 1, "092": 132, "093": 132, "093903": 156, "094": 156, "09499611": 44, "095": 132, "09542509": 44, "09574677": 44, "0975e": 76, "09811225": 44, "09836551": 44, "0986": 76, "09899633": 44, "099": 156, "09914922": [152, 157], "0_": 156, "0_1": 1, "0arrai": 156, "0e": [71, 154, 155], "0f": [6, 46, 74, 81, 139], "0inference_librari": 156, "0l": 72, "0m": [82, 88], "0px": 137, "0th": 81, "1": [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 22, 24, 26, 27, 28, 29, 30, 32, 34, 35, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 64, 66, 68, 69, 73, 74, 75, 76, 77, 78, 80, 81, 83, 85, 86, 87, 93, 95, 99, 100, 101, 102, 104, 105, 106, 107, 110, 111, 112, 115, 117, 118, 119, 122, 125, 126, 128, 130, 131, 132, 138, 139, 140, 141, 142, 147, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 163, 164, 167, 168], "10": [0, 1, 3, 4, 6, 9, 18, 20, 21, 22, 30, 34, 35, 36, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 54, 55, 56, 58, 70, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 98, 100, 101, 107, 112, 128, 130, 131, 132, 134, 135, 137, 138, 139, 141, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 164, 166, 167], "100": [0, 3, 4, 6, 9, 16, 18, 20, 21, 22, 34, 38, 39, 41, 42, 43, 45, 46, 47, 50, 55, 56, 70, 71, 72, 74, 75, 76, 78, 81, 83, 84, 86, 87, 91, 101, 128, 130, 131, 132, 135, 138, 141, 142, 148, 149, 150, 152, 154, 155, 156, 157, 158, 159, 163, 164, 166, 167], "1000": [6, 9, 22, 30, 34, 35, 38, 39, 43, 44, 45, 46, 47, 55, 70, 76, 78, 83, 87, 100, 101, 107, 132, 135, 138, 139, 142, 148, 149, 150, 151, 152, 156, 157, 164, 167], "10000": [6, 9, 22, 36, 38, 43, 46, 47, 75, 87, 135, 149, 156, 166], "100000": [6, 22, 38, 46, 87, 135, 156, 167], "1000000": 22, "1000010": 156, "10000coordin": 156, "1000xarrai": 156, "10025514": 44, "100480": 74, "1007": 1, "100_000": 156, "100coordin": 156, "100j": [78, 98], "101": [134, 140, 166], "1010002": 44, "10100181": 132, "10118794": 44, "10131681": 44, "1016": 1, "10165": 1, "1017": 1, "101770": 74, "102001": 1, "1022": 131, "10223673": 44, "1023": 131, "1024": [55, 81, 101, 131], "1026": 131, "1027": 131, "1028": 131, "1029": 131, "1030": 131, "1031": 131, "1032": 131, "1033": 131, "1034": 131, "1035": 131, "1036": 131, "10363908": 44, "1037": 131, "1038": 1, "104": 1, "10405339": 44, "10417433": 44, "104411": 138, "10473305": 44, "105": [1, 9], "1050e": 76, "10581": 91, "1058809": [1, 49], "1060285": 132, "10622272": 44, "106431": 138, "1066": 132, "107": 148, "10717545": 44, "10734329": 44, "10735333": 44, "10770823": [152, 157], "108": 138, "1080": 1, "10803082": 44, "10854853": [152, 157], "1086": 1, "10861676": 44, "1088": 1, "109": 148, "1092931": 1, "1093": 131, "1094027": 44, "10944442": 44, "1095": 131, "1096": 131, "1097": 131, "10972845": 44, "1098": 131, "1099": 131, "10_000": 156, "11": [30, 35, 39, 42, 43, 44, 45, 47, 51, 55, 72, 78, 82, 84, 86, 91, 98, 100, 101, 105, 107, 110, 125, 126, 128, 131, 138, 139, 141, 149, 151, 152, 153, 156, 157, 158, 159, 166, 167], "110": 138, "1100": [76, 131], "1101": 131, "1102": 131, "1103": 1, "11060505": 44, "111": [75, 157], "1110567": 44, "1111": 1, "1112": 138, "11133727": 44, "112": [148, 157, 166], "11236849": 44, "11237104": 44, "11248774": 44, "1132": 76, "1137": 1, "1139": 68, "11438298": 44, "11468225": 132, "11476995": 135, "1149e": 76, "115": [24, 100, 161], "11554413": 132, "1157018": 44, "11584111": 44, "116": [9, 157], "117": 46, "117430": 138, "1176": [55, 157], "11793957": 132, "1181334": 44, "118318": 138, "11858913": 44, "1186": 1, "11864245": 156, "11889123e": 156, "11900865": 44, "1194224": 44, "1196": 1, "11981094": 44, "11it": 157, "12": [0, 1, 5, 6, 9, 16, 21, 22, 30, 35, 38, 39, 42, 43, 44, 46, 48, 49, 54, 55, 57, 70, 71, 72, 77, 78, 80, 81, 82, 83, 84, 87, 88, 91, 98, 99, 100, 101, 128, 131, 132, 135, 137, 138, 141, 148, 149, 150, 152, 155, 156, 157, 158, 167], "120": [80, 131, 134, 157], "1200": [1, 46, 76], "1201": 93, "12015895": 44, "12069698": 132, "12073004": 156, "121": [1, 132, 157], "1212": 1, "1214": 1, "12141771": 44, "12182127": 44, "122": 81, "12214158": 44, "122282": 138, "1223": 135, "12232832": 44, "12248776943531486": 88, "12271848": 44, "12275761": 132, "123": 149, "1234": 22, "12341216": 44, "12369125": [152, 157], "124": [1, 135, 138], "1249115293": 156, "125": [1, 157], "1253235": 44, "126": 135, "12652001": 156, "12683902": 44, "1272": 46, "1277": 157, "127812": 138, "128": [47, 74, 80], "1281": 46, "12837699": 44, "12844774e": 156, "12878515": [152, 157], "128e": 156, "1290": 74, "12910158": 44, "12911235": 44, "12948391": 44, "1299": 47, "12999178": 44, "12it": 157, "13": [0, 1, 5, 20, 37, 39, 44, 56, 58, 61, 71, 72, 81, 82, 86, 88, 100, 132, 134, 138, 151, 156, 157, 158, 166, 167], "130": 148, "1300": 76, "1304781454370705": 128, "1309": 76, "130k": 135, "131": 157, "13109421": 132, "13135": 138, "13162939": 44, "13178918": 83, "132": 156, "13219435": 5, "13221278": 44, "13223132": 44, "13224778": 44, "1327083": [152, 157], "133": [55, 157], "13376944": 44, "1340482": 44, "13437312": 44, "13444589": 128, "134e": 128, "135": 131, "13513688": [152, 157], "1358": 157, "136": [46, 131, 157], "1361": 1, "13622942": 5, "1365": 1, "1369": 68, "137": [131, 157], "1375": 76, "13754542": 132, "13770121": 44, "13782807": 44, "138": [131, 157], "13868364": 44, "139": [68, 131], "14": [1, 5, 9, 24, 30, 35, 42, 43, 47, 49, 51, 58, 74, 75, 77, 83, 87, 100, 131, 132, 138, 151, 155, 156, 157], "140": [0, 21, 157], "1400": 76, "14010988": 44, "14039544": 44, "14048406": 44, "140px": 137, "1411": 45, "1412": 1, "14164054": 44, "14189485": 75, "14201814": 44, "14225137": 44, "1423273": 156, "14250318": 44, "1426": 76, "14381452": [152, 157], "144": [9, 35, 157], "14472371": 44, "1449": 76, "144993": 138, "145": [156, 157, 161], "1454651347": 156, "14548": 1, "146": 157, "14606510500297276": 82, "14676526": 44, "14690038": 44, "147": [156, 157], "148": 157, "14854434": 44, "149": 157, "14908685": 132, "14it": 157, "15": [1, 5, 19, 22, 24, 30, 38, 39, 41, 42, 43, 45, 46, 47, 55, 57, 58, 70, 81, 83, 87, 98, 131, 132, 135, 138, 151, 154, 156, 157, 166], "150": [38, 43, 128], "1500": 76, "15000": [43, 149], "15001628": 44, "1505": 1, "1506": 1, "1509": 1, "150px": 9, "151": 157, "152": 157, "15216546e": 156, "15259914": 44, "153036": 138, "1533e": 76, "153e": 128, "154": 157, "15431": 1, "15479436": 44, "155": 157, "15528789": 44, "15595162": 132, "156": [138, 157], "15612778": 132, "15626385": 44, "1563": 81, "157": [138, 157], "1570": 81, "15720037": 156, "15752961": 156, "158": [100, 138, 157], "15850375": 132, "159": [138, 157], "1593": 1, "15965453": 132, "16": [5, 22, 30, 38, 42, 43, 45, 46, 47, 55, 80, 87, 99, 100, 101, 128, 132, 134, 135, 137, 138, 140, 148, 151, 152, 154, 156, 157, 161, 166, 167], "160": [138, 157], "1600": [76, 128, 132], "16000": [150, 167], "16001109": 44, "16003707": 44, "1601": 1, "1603": 77, "16033857": 44, "16056499": 44, "160kb": 156, "161": 157, "16128569": 44, "16135738": 135, "1614": 1, "16143998": 44, "162": 157, "16206018": 132, "1623": 1, "162999": 138, "16363636": 132, "16384": 80, "164": 157, "16466507": 44, "16510496": 156, "16628447": 132, "167": 35, "16707517": 44, "1674": 1, "16760465": 44, "16938243": 44, "1698281": 44, "16983114": 44, "16986926": 44, "16998901": 44, "16b": 156, "16it": [55, 157], "16j": 83, "17": [1, 37, 39, 55, 74, 87, 100, 102, 110, 132, 138, 141, 156, 161, 167], "1700": 76, "17086272": 156, "1711": 1, "17134293": 156, "17137202": 44, "17195713": 44, "17197345": 156, "172421": 132, "17390257": 44, "17516773": 44, "175300": 138, "17608015": 44, "17718772": 44, "17753281": 44, "17801963736677": 128, "179": 157, "17it": 157, "18": [1, 5, 9, 20, 37, 38, 42, 50, 51, 70, 76, 83, 86, 98, 100, 135, 137, 141, 142, 156, 157, 167], "180": [98, 157], "1800": 76, "18001285": 132, "1800880e": 81, "18016403": 132, "1805": 115, "1809": 115, "18102913": 132, "18103874": 44, "1810401e": 81, "18215616": 132, "18264126": 156, "183": [107, 157], "18393424": 135, "183e": 132, "1841262e": 74, "18425706": 156, "1845098": 132, "184519": 138, "18496": 81, "185": [86, 157], "1850492": 75, "18515642": 44, "1853": 51, "18553562": 44, "18557541": 44, "186": 157, "18614219": 132, "18656139": 44, "1867": 51, "18697965": 44, "186e": 132, "187": 157, "1870": 82, "188": [100, 157], "18843153": 157, "18845060e": 156, "189": [156, 157], "1892932": 44, "189367": 138, "189496": 138, "1896": 82, "189622": 138, "18986165": 44, "18it": 157, "18th": 8, "19": [0, 1, 5, 16, 43, 49, 70, 71, 76, 87, 100, 101, 122, 138, 151, 156, 166, 167], "190": 157, "1900": 76, "19009207": 132, "1902": 97, "1903": 156, "1904": 91, "19069973": 44, "19091548": 44, "191": [148, 157], "1911528": 44, "191963": 138, "192": [100, 157], "1926": 157, "19268607": 44, "19292455": 132, "193": 157, "19380091": 156, "19381518": 44, "19382179": 44, "1939": 58, "194": 157, "1943": 72, "1948": 4, "19485974": 54, "195": 1, "1950": [158, 159], "19501328": [152, 157], "1953": [131, 149], "1954": [1, 67, 131], "19540886": [152, 157], "1955": 131, "1956": 131, "1957": 131, "196": 157, "1960": 4, "1961": 1, "19614443": 135, "1963": 4, "19686978": 44, "1970": 149, "19783084": 44, "1979": [90, 113], "1980": [51, 158, 159], "19829972": 44, "1983": 51, "1984": [4, 5], "1986": 1, "1987": 1, "1988": [1, 4, 58, 68], "1989": 1, "19891788": 44, "1992": 1, "1994": [1, 51], "19969212": 132, "1997": 149, "19975956": 44, "19it": 157, "19th": [8, 115], "1_": 72, "1_000": [85, 86, 140, 156, 157], "1_1": 72, "1_2": 72, "1_3": 72, "1_j": 72, "1_l": 72, "1a": 84, "1arrai": 156, "1b": 84, "1cm": 138, "1d": [31, 81, 128], "1darrai": 128, "1e": [46, 55, 83, 85, 86, 87, 128, 148], "1e15": 86, "1e2": 85, "1e30": 128, "1e5": 128, "1f": [22, 38, 42, 43, 45, 46, 47, 87, 101, 131, 135, 137, 140, 148, 150, 154, 155, 167], "1mgaussian_nois": [82, 88], "1mgp_regress": [82, 88], "1mlengthscal": [82, 88], "1mmat52": [82, 88], "1mmul": [82, 88], "1mrbf": [82, 88], "1msum": [82, 88], "1mvarianc": [82, 88], "1n": [57, 138], "1sampling_tim": 156, "1st": [15, 78, 98, 139], "1x": 138, "1xarrai": 156, "2": [0, 1, 3, 4, 6, 9, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 35, 38, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 64, 68, 70, 71, 73, 74, 75, 76, 77, 78, 81, 83, 84, 85, 86, 87, 90, 91, 93, 95, 99, 100, 101, 102, 104, 105, 106, 107, 108, 112, 117, 118, 119, 122, 125, 126, 128, 130, 131, 132, 138, 139, 140, 141, 142, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 163, 164, 167, 168], "20": [0, 16, 20, 21, 22, 24, 34, 37, 38, 41, 43, 45, 46, 49, 55, 56, 58, 70, 75, 76, 79, 82, 83, 88, 100, 101, 128, 131, 137, 138, 148, 150, 155, 156, 157, 158, 161, 166, 167, 168], "200": [9, 12, 38, 39, 43, 45, 46, 75, 76, 80, 83, 87, 107, 128, 134, 137, 148, 149, 155, 157, 164], "2000": [46, 49, 55, 70, 76, 128, 148, 151, 164], "20000": [128, 134, 148, 166], "2003": [1, 61], "2004": 56, "20045251": 44, "2005": [1, 61], "2006": [1, 58, 61], "2007": 1, "2008": 1, "2009": 1, "200_000": 156, "2010": 1, "2011": 1, "2012": [1, 82, 133], "20129269": 156, "2013": [0, 1, 61, 133], "2014": 1, "2015": 1, "2016": [1, 77, 78, 83, 87, 98, 138], "2017": [1, 138, 153, 159], "2018": [1, 78, 83, 87, 98], "20183018": 44, "2019": [1, 5, 43, 44, 55, 58, 61, 78, 79, 81, 82, 83, 91, 96, 100, 148, 149, 152, 154, 157], "20199118": [152, 157], "2020": [6, 78], "20205486": 44, "2021": [1, 5, 68, 156], "2022": [1, 49, 70], "2023": 156, "20231797": 156, "2024": 83, "2025": [55, 72, 86, 101, 128, 131, 156, 157], "20273021": 44, "2030": 82, "20303737": [152, 157], "20316765e": 83, "2035808": [152, 157], "204": 138, "20433313": 138, "20437739": 44, "2048": 128, "2048px": 0, "205231": 138, "20575791": 135, "206": 46, "2060": 157, "2066079": 44, "206915": 44, "207888": 138, "208": 1, "20845633": 44, "2088896239": 43, "20900359": 44, "20909668": 44, "20920005": 44, "209789": 138, "20_000": 156, "20it": 157, "20px": 47, "20th": 8, "21": [1, 39, 43, 46, 48, 55, 72, 84, 87, 91, 100, 101, 142, 149, 156, 157, 161], "2104": [1, 131], "2106": 1, "2110": 1, "21112476": 44, "2112": 1, "212": 157, "21208711": 44, "2121": 1, "213": 9, "2130": 46, "2135339": 44, "21374278": 132, "21397852": 132, "214": 49, "2140": 1, "21440984": 70, "214466": 44, "2153": 1, "2159": 1, "216": [1, 131], "217": 131, "21726515": [152, 157], "21746553": 44, "2179409": 44, "218": 131, "21808832": 44, "21987438": 44, "21it": 157, "22": [1, 39, 43, 50, 51, 72, 76, 83, 84, 87, 90, 91, 123, 135, 156, 157], "220": [131, 157], "2203": 1, "22054424": 132, "221": 131, "2210": 1, "221180": 138, "2212": 1, "222": [1, 9, 131], "22214117": 44, "222400": 138, "22243362": 44, "2228": 46, "223": 131, "22372221": 44, "224": [46, 131], "2245077": 44, "2246093": 1, "22483838": 44, "22492971": 44, "22515585": 44, "226": 148, "22671356": 54, "227": 37, "22783797": 54, "228": 157, "2282902": 54, "22836381": 54, "22837258": 54, "22837347": 54, "22837356": 54, "22863013": [152, 157], "22895559": 44, "229": 156, "22it": 157, "23": [43, 68, 72, 83, 87, 100, 101, 132, 141, 150, 156, 157, 158, 161], "230": 36, "23009474": 44, "2305582": 44, "23066907": 5, "23153842": 135, "2320": 132, "23219625": 44, "23225307": 44, "232435": 138, "23249456": 44, "23269017": 44, "23289919": 44, "23333913": 44, "23348992": 132, "234": [55, 101, 148], "2344157": 44, "235": [55, 101], "23548129": 132, "23598527": 107, "23616403": 44, "23684825": 132, "237": [55, 101], "2373327": 44, "2387931": 44, "23931144": 44, "23it": 157, "24": [1, 5, 39, 45, 70, 83, 87, 132, 137, 138, 156, 157, 167], "240": [37, 157], "2404": 5, "24050555": 44, "24073709": 44, "240kb": 156, "24193267": 44, "24266944": 44, "243": 156, "24407436": 44, "24433723": 44, "24439999e": 132, "24454398": [152, 157], "245": [35, 157], "2453781259": 156, "24542285": 44, "2455": 76, "24560206": 44, "2458e": 76, "24610704": [152, 157], "24879916": 44, "24957254": 132, "25": [8, 16, 38, 41, 43, 45, 46, 51, 54, 74, 78, 81, 83, 97, 98, 99, 132, 138, 141, 149, 156, 157, 166, 167], "250": [9, 39, 78, 98, 107], "2500": [0, 21, 148], "25003038": 44, "250154": 138, "250636": 138, "251879": 138, "252436": 138, "25284171": 44, "25286816": 44, "253": [35, 43], "253775": 138, "254": 132, "25410215": 132, "255": [74, 81], "255001": 138, "25558087": 42, "256": 47, "2562": 46, "25647226": [152, 157], "2566277": [152, 157], "258": [55, 101, 138, 156], "25839": 5, "259": [55, 101], "25908926": 156, "2593743975": 42, "25it": 157, "26": [46, 51, 77, 82, 83, 100, 138, 142, 156, 157], "260": 157, "2607": 81, "26081609": 135, "261": [55, 101], "262": [55, 101], "26246745": 44, "26271037": 44, "263": 157, "2632": 1, "264": [55, 101, 138], "264421": 138, "265": 138, "2650": 76, "26515305": 156, "26551159": [152, 157], "2656424": 44, "266": [138, 157], "26607016": [152, 157], "26666667": 158, "2667284": 44, "2667e": 76, "267": 37, "2680305": [152, 157], "2684253": 1, "26846902": 44, "26858737": 156, "269": 138, "2693": 1, "26972154": 132, "26it": 157, "27": [4, 39, 70, 77, 87, 100, 140, 156, 166], "270": 138, "27146251": 44, "27179816": 156, "272": 156, "27221951": 132, "27244608": 132, "27375593": 44, "27440288": 44, "27478507": 44, "275": [55, 148], "275082": 54, "276": 35, "2764993": 44, "276e": 128, "277": 47, "2774875": 132, "27760809": 44, "27852808": 44, "279": 86, "27967063": 156, "27991444": [152, 157], "27it": 157, "28": [39, 55, 74, 80, 82, 83, 88, 100, 148, 149, 153, 156, 157, 158, 159], "280": 157, "280179": 138, "28060553": 44, "28066508": 44, "281930": 138, "282259": 138, "28267571": 44, "28299553": 44, "283": 138, "28325825": 156, "284": 151, "28474811": 44, "28558733": 44, "28646695": 132, "28807817": 44, "28883234": 44, "289": 38, "2890": 138, "2890942": [152, 157], "28it": 157, "28x28": 74, "29": [1, 39, 42, 43, 50, 52, 54, 71, 82, 90, 99, 100, 132, 156, 167], "29090909": 132, "2911889": 44, "2919282": 54, "29209002": 132, "29271997": 135, "293": 132, "29305": 156, "2931": 138, "29322588": 44, "29354962": 44, "29365322": 132, "29371761": 44, "294": 156, "29406783": 132, "29415949": 44, "2949430162": 156, "295": 138, "29564967": 44, "296247": 138, "2963521956035": 47, "296414": 138, "2966": 1, "2968": 138, "297": 157, "2970796": 44, "2979": 76, "2980": 138, "298273": 138, "298375": 138, "29865557": 44, "2990": 138, "2996015": 44, "299748": 138, "29it": 157, "2_": [41, 57, 71, 72, 101, 112], "2_000": [156, 157], "2_1": 72, "2_2": 72, "2_3": 72, "2_n": 112, "2b": 100, "2d": [31, 38, 42, 45, 80, 82, 83, 84, 87], "2draw": 156, "2e": [71, 100], "2e_i": 43, "2f": [43, 44, 46, 47, 54, 82, 88, 100, 101, 128, 135, 139, 149, 150, 152, 155, 157, 166, 167], "2k": 56, "2kb": 156, "2l": [24, 39, 41], "2m": [51, 95, 101], "2n": 49, "2nd": [1, 15, 28, 39, 42, 78, 84, 98, 107, 141, 153, 164], "2p": 24, "2px": 47, "2r": 155, "2sigma": 46, "2w": 41, "2x": [5, 39, 106], "2x2": 4, "2x3": 141, "2z": 21, "3": [0, 1, 3, 4, 6, 9, 15, 18, 20, 22, 24, 27, 28, 30, 35, 38, 39, 41, 42, 44, 45, 47, 48, 50, 51, 52, 54, 55, 56, 58, 70, 71, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 90, 99, 100, 101, 104, 105, 106, 107, 118, 125, 128, 131, 132, 134, 138, 139, 140, 141, 142, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 167], "30": [0, 9, 21, 35, 42, 43, 45, 55, 81, 87, 101, 131, 132, 135, 139, 148, 156, 157, 167], "300": [45, 76, 154, 157], "30000": 78, "30017032": 44, "3006664": 44, "301": [5, 9, 35], "30163826": 44, "30196005": 44, "30218997": [152, 157], "3025": 5, "30253554": 44, "303": 1, "30365503": 156, "30394707e": 156, "30471708": 135, "3049": 1, "3050791": 44, "30526704": 44, "3053064": 44, "306": 1, "30620607": 44, "3072": 80, "30775337": 156, "307e": 128, "30833925": 44, "30847308": [152, 157], "3088": 132, "309": [1, 131], "30970591": 44, "30979757": 128, "30981676": 44, "30it": 157, "31": [41, 42, 43, 72, 131, 135, 156, 157, 161], "310": 131, "31027229": 44, "310e": 128, "311": 131, "31162642": 132, "312": [1, 131], "31216994": [152, 157], "31220038": 132, "31223869": 44, "31251261": 44, "3128273": 44, "313": 81, "31354772": 44, "314": [1, 157], "31475378": [152, 157], "31515939": 44, "31563495": 44, "31594001": 44, "316": 86, "31627214": 44, "31663724": 44, "3166589": 44, "31694": 54, "31713": 138, "31730164": 131, "3180143": 44, "3181542": 44, "319": [1, 55, 101, 131], "3190391": 44, "31914843": 44, "31932186": 44, "31935642": [152, 157], "31965694": 44, "31it": 157, "32": [39, 55, 57, 72, 74, 80, 81, 84, 87, 88, 100, 101, 131, 156, 157, 158, 161], "320": [55, 81, 101, 131, 157], "3200": 131, "32061622": 44, "321": [55, 101, 131], "32107876": 44, "32126591": 44, "3217": 76, "322": 131, "323": [1, 55, 101, 131], "32352735": 44, "323533a0": 1, "324": [9, 55, 101, 131], "32427424": 44, "3243e": 76, "32580419": 44, "326": [1, 55, 101], "326238": 138, "327": [55, 101, 132], "3272": 138, "32755196": 44, "3278": 138, "3285": 138, "32875387": 44, "329": [9, 87], "32903477": 135, "32933771": 44, "329492": 138, "32981411": 135, "32e": 100, "32it": 157, "32m": 81, "33": [39, 43, 46, 72, 87, 88, 98, 100, 156, 157, 166], "3303e": 76, "3306": 138, "331": 157, "3312": 138, "33145711": 44, "3315865": [152, 157], "331939": 138, "33333333": 158, "33424548": 44, "33461517": 107, "335": 9, "33513223": 44, "33587406": 44, "33722094": 44, "33776818e": 70, "3380": 76, "3380117": 44, "33844": 54, "33865576": 44, "3389": 1, "34": [43, 83, 156, 157], "340": 157, "3405": 156, "340583": 138, "342680": 138, "342e": 128, "3436": 138, "3437": 138, "34539683": 44, "34587827": 131, "3465969": 132, "347": [138, 157], "34710546": 44, "349": [68, 138], "34900685": 156, "3490481": 138, "34927873": 44, "34it": 157, "35": [30, 39, 43, 45, 87, 98, 100, 156, 157, 161, 166], "35010682": 44, "35016716": 44, "35054598": 44, "3511169": 44, "35249436": 44, "352e": 128, "353": 156, "35308331": 44, "35323281": 128, "35356722": 44, "35379069": 128, "35387043": 44, "353e": 128, "354e": 128, "355": 128, "35528451": 44, "35571726": 44, "356": 9, "356399": 138, "357508": 138, "3578502": 156, "36": [46, 83, 100, 141, 156, 157, 158, 161, 166], "360": 157, "36126959": 44, "361556": 138, "36180164": 44, "36184732": 44, "36255041": 44, "363": 157, "36300435": 44, "36347669": 5, "3654668": 156, "36633201": 44, "36723181": 44, "36870420e": 83, "368e": 132, "369": 68, "36919047": 44, "36928": 81, "36949272": 44, "36997127": 156, "36it": 157, "37": [37, 39, 43, 83, 156], "370": 35, "37030940e": 156, "3705584": 44, "37167029": 44, "371e": 128, "372": 132, "37245685": 44, "37256166": 44, "373": 132, "3733791492": 138, "374658": 44, "37497": 156, "375694": 138, "37596386": 83, "37601754": 156, "37646927": 44, "376547": 138, "37756379": 44, "379": 157, "37947517": 135, "379717": 39, "37975819": 44, "37999916": 44, "37e": 100, "37it": 157, "38": [37, 43, 87, 100, 115, 141, 156, 157], "380": 157, "38025555": 132, "38049834": 5, "3813": 156, "38196315": 44, "38211337": 156, "382187": 138, "38263794": 44, "38271517": 44, "384": 87, "38422765": 44, "3845": 76, "38496733": [152, 157], "38499134": 44, "3850718": 156, "38560229": 44, "38631426": 44, "38653915": 44, "38671552": 156, "387": 1, "38755787": 44, "38759303": 44, "38777641e": 156, "388": 9, "38824359": 44, "3887794": 44, "38m": 81, "39": [68, 71, 82, 102, 105, 110, 117, 138, 156, 158], "39014596": 44, "39198995e": 156, "392": 132, "39206493": 70, "39217823": 156, "39233491": 44, "39286306": 5, "393": 46, "3930016": 44, "39310924": 44, "39334122": [152, 157], "393562": 156, "39378773": 44, "394": 86, "39401868": 44, "39442803": 44, "3947": 76, "39470366": [152, 157], "395": [1, 157], "39539703": 44, "39607937": 44, "397": 74, "39788042": 44, "39799638": [152, 157], "398": 1, "39859839": 44, "3988432": 44, "39977467": 44, "399836": 138, "39984394": 44, "3998612": 44, "3d": [28, 42, 70, 81, 135], "3e": 71, "3f": [6, 9, 35, 38, 39, 43, 55, 74, 86, 87, 100, 101, 107, 128, 134, 138, 148, 152, 157, 166, 167], "3gb": 142, "3m": 51, "3rd": [15, 39, 42, 83, 91, 98, 107, 164], "3x": 28, "3x3": 141, "3x4": 141, "4": [0, 1, 2, 3, 4, 6, 8, 9, 12, 18, 19, 20, 22, 24, 27, 28, 30, 35, 38, 39, 41, 42, 44, 47, 48, 51, 52, 54, 55, 58, 63, 64, 66, 68, 71, 74, 75, 78, 81, 86, 87, 93, 95, 99, 100, 101, 107, 123, 126, 128, 131, 132, 134, 138, 139, 140, 141, 142, 148, 149, 150, 152, 155, 156, 157, 158, 166, 167], "40": [5, 38, 39, 43, 45, 112, 118, 128, 131, 156, 157, 158], "400": [35, 76, 83, 87, 128, 157], "4000": [128, 150, 167], "40000": [78, 134, 161], "40019547": 44, "40020999": [152, 157], "40025987e": 156, "401": 38, "40186698": 132, "402": 1, "4027718": 132, "4028": 76, "40349164": 44, "40358137": 83, "40391367": 44, "404": 35, "40433212": 44, "40615693": 44, "40665625": 44, "40753871": 44, "40754": 44, "40759038": 156, "4089": 1, "40890054": 44, "40925339": 44, "4096": [30, 35], "40_000": 156, "40it": 157, "41": [1, 39, 43, 82, 100, 128, 141, 156, 157], "41000": 131, "41005165": 44, "41026575": 44, "411": 157, "4111": 156, "4113266": 132, "41323712": 156, "41347606": 44, "41391972": 132, "415201": 138, "41536733": 132, "41591369": 156, "417": 35, "417302": 44, "41767401": 44, "417e": 128, "41m": 81, "42": [22, 39, 43, 45, 78, 87, 98, 100, 101, 128, 135, 138, 156, 157], "420": 157, "4202822": 44, "4207296": 132, "42084371": 44, "42142": 54, "422": 100, "42283293": 132, "4230685e": 81, "42349435": 44, "42361443": 44, "42592018": 44, "426": 35, "427": 157, "42875901": 131, "42887697": 44, "429": 132, "42952614": 44, "42m": 81, "43": [36, 39, 43, 54, 76, 83, 85, 100, 156, 157], "43085135": 44, "43103028": 132, "43181": 135, "432567834854126": 156, "432567834854126tuning_step": 156, "43302619": [152, 157], "43374455": 132, "43426185": 44, "43499832": 44, "435163": 138, "4352351e": 74, "43549215": 44, "4357685": 156, "4359862": 44, "43621127": 44, "4367634": 44, "43769457": 44, "43769889": 156, "438136": 138, "43816635": 44, "439": 157, "43it": 157, "43rd": 138, "44": [39, 43, 46, 68, 82, 156, 157], "44031858": 44, "441": 6, "441264": 138, "44136444": 44, "4420816898345947": 156, "4420816898345947tuning_step": 156, "44250528": 44, "44287693": 44, "44305844": 44, "443217": 138, "44351518": 156, "444": [156, 157], "4441e": 76, "445": 132, "44509671": 44, "44513761": [152, 157], "446": 9, "446453": 138, "44703778": 132, "44730122": 44, "448": 43, "4482e": 76, "44838065": 44, "44875772": 156, "4489894": 44, "44936865": 44, "45": [16, 39, 83, 87, 88, 100, 156, 167], "450": 43, "45015551": 44, "45021774": 44, "4504": 81, "45069099": [152, 157], "4507e": 76, "45112294": 44, "45128402": 44, "45142926": 44, "45161595": 44, "45194604": 44, "452553": 138, "4529": 76, "45391758": 44, "45422583": 44, "45454545": 132, "45459971": [152, 157], "45561175": 39, "45576187": 5, "4558919": 132, "455947": 138, "45652739": 44, "457": 1, "45784265": 132, "45794708": 44, "4580": 76, "458027": 138, "45810824": 44, "459": 157, "45it": 157, "46": [1, 156, 157, 167], "460": 157, "46012093": [152, 157], "46031844": 44, "46037826": 156, "46089238": 44, "4609029": [152, 157], "461": [9, 68, 132], "4611641": 44, "46120675": 44, "462": 46, "46210794": 44, "46277698": 44, "46353432": 44, "463861": 138, "464": 132, "46476976": 55, "46480133": 135, "46664327": 44, "46697967": 44, "4674011": 54, "4675": 76, "46765106": [152, 157], "46776598": 44, "4696879e": 74, "469849": 138, "4698802": 44, "46it": 157, "46m": 81, "47": [39, 47, 83, 88, 156, 157], "47016034": 44, "47054044": 55, "47070392": [152, 157], "470714": 138, "4707257": 132, "47073986": 44, "470e": 128, "4711e": 76, "47135104": 156, "47182825": 44, "472": 1, "474": 45, "47431968": 44, "476": 157, "47761018": 44, "47764353": 44, "479": 157, "47985237": 44, "4799219461948791e": 82, "47x": [54, 99], "48": [1, 43, 82, 87, 88, 156, 157], "480": 138, "481": 9, "48106553": 132, "48185445": 44, "48290554": 44, "48365209": 44, "48369614": 44, "48376312": 132, "48386948": 156, "484": 86, "4840": 131, "484537": [152, 157], "48465545": 132, "4848595": 135, "4849e": 76, "48550": 1, "48571114": 83, "486": [35, 55], "48851815": 44, "48946635": 5, "48954362": 44, "48e": 100, "49": [1, 24, 43, 135, 150, 156, 157, 166], "49042732": 44, "49056104": 44, "49102772": 44, "49152": 80, "49154287": 44, "49167851": [152, 157], "492": 157, "49233656": 44, "493": 37, "49355935": 44, "493754387128709": 83, "494": 37, "4940954": 138, "49434165": 44, "49436497": 156, "49515861": 44, "49521132": 44, "49553414": 44, "49588477": 44, "49602605": 44, "49681303": 70, "497": 135, "4972691": 44, "497630": 138, "49810818": 44, "4982711": [152, 157], "499": [38, 157], "49it": 157, "4_000": 156, "4d": [80, 148], "4e": [76, 101, 156], "4f": [76, 87, 101, 134], "4th": 15, "4x": 5, "4x6": 141, "5": [0, 1, 2, 3, 4, 6, 9, 11, 12, 13, 18, 20, 22, 24, 30, 34, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 54, 55, 56, 58, 72, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 86, 87, 88, 95, 97, 99, 100, 101, 104, 107, 125, 126, 128, 131, 132, 134, 138, 139, 140, 141, 142, 148, 150, 151, 152, 154, 155, 156, 157, 158, 164, 166, 167], "50": [22, 41, 43, 45, 46, 52, 55, 76, 78, 79, 81, 82, 84, 87, 88, 99, 101, 111, 131, 134, 135, 137, 138, 141, 148, 149, 152, 156, 157, 158, 161], "500": [0, 21, 22, 38, 39, 42, 47, 76, 78, 82, 88, 98, 107, 128, 131, 137, 147, 148, 149, 150, 156], "5000": [0, 9, 21, 46, 76, 78, 101, 128, 149, 156, 166], "50000": [22, 152, 157], "500000": 131, "500px": [9, 137], "50142959": 44, "50172511": 44, "50178644": 44, "5018": 45, "50249434": 44, "50274088": 44, "503": [9, 135], "50315846": 132, "50318481": 44, "50381297": 156, "504": 55, "505": 68, "5053819": 44, "50580623": 44, "50598029": 44, "506": 37, "507": 46, "50807396": 156, "50887486": 44, "509": 157, "50978847": 132, "50it": 157, "51": [24, 43, 68, 156, 157, 167], "5103076": 44, "51066278": [152, 157], "51093777": 44, "512": [47, 55, 132], "5120": 76, "51238578": [78, 98], "51292982": 44, "5129e": 76, "5135": 81, "51350548": 44, "514219": 138, "51484355": 44, "51507361": 44, "5154138": 44, "51764428": 132, "51790686": [152, 157], "518895": 138, "519": 157, "51981682": 44, "52": [37, 46, 68, 100, 156, 157], "52008362": 156, "520319": 138, "52057634": 44, "52081508": 44, "5208429": 44, "52132764": 44, "52138593": 44, "521e": 132, "52241915": 44, "522836": 138, "52287579": 44, "52343734": 44, "52385799": [152, 157], "52462712": 44, "52475049": 44, "52508223": 83, "526": 157, "52667659": 132, "52705173": 156, "52800342": 44, "52832571": 44, "52884307": 44, "52887975": 44, "52946532": 44, "52947828": 132, "52976291": 44, "53": [43, 156, 157], "53035547": 44, "5304": 156, "53098164": 156, "53116379": 44, "531280": 138, "53132618": 44, "532": 68, "532e": 132, "533": 1, "53384514": 44, "534362": 138, "53499597": 5, "53522913": 128, "5356518": 132, "53594643": 44, "536": 1, "53653633": 44, "5369426855815758": 82, "5372931": 156, "5385964": 44, "539": 157, "53920701": 44, "53960309": 156, "53e": 100, "53it": 157, "54": [43, 74, 83, 87, 100, 141, 156, 157], "54005717": 44, "5400699": 44, "54026428": 132, "54028232": 44, "541605": 138, "54167554": 44, "542": 157, "5420e": 76, "54264529": 44, "54301214": 44, "54335911": 44, "54388244": 44, "544439": 138, "5447030e": 81, "545": 35, "546876298240301": 82, "54747503": 44, "54755159": 5, "5476": 81, "54812958": 44, "54it": 157, "55": [16, 43, 87, 100, 156], "550": 5, "5505375": 44, "55093967": 156, "55126197": 44, "55155435": 132, "551e": 132, "552": 132, "55201704": 156, "55210482": 44, "55287144": 44, "5533008": 44, "555": 35, "55501599": 44, "55588619": 44, "55607351": 44, "556378888999681": 128, "55663421": 156, "55682807": 44, "556e": 132, "557": 132, "55743945": 44, "55777072": 44, "558": [35, 157], "55880554": 44, "559": [9, 157], "55912035": 156, "55912398": 44, "5593865e": 74, "55966988": 156, "55e": 100, "55it": 157, "56": [43, 81, 156, 157], "560kb": 156, "56100234": 44, "5610259186833": 47, "56179973": 44, "56218": 54, "56249102": 44, "5627611": 44, "563167": 138, "56372833": 132, "56378085": 156, "56438286": 44, "5649427": 156, "56504332": 44, "5650e": 76, "56515267": [152, 157], "56516224": 44, "56536": 138, "56553789": 132, "56877654": 70, "56it": 157, "57": [37, 87, 101, 138, 156, 157, 167], "570": 81, "5701": 1, "57042816": 156, "5707963": 54, "57085772": 44, "57180488": 44, "572069": 138, "57296273": 44, "57344458": 44, "57357138": 44, "575": 157, "57546791": 44, "57550721": 44, "57582227": 5, "576": 81, "5765217": 44, "57709": 54, "57714304": 44, "57846442": 44, "579": 157, "57arrai": 156, "57e": 100, "57x": [54, 99], "58": [16, 46, 100, 132, 142, 156, 157], "580147499327772": 83, "58033011": 44, "58085122": 44, "5810621": 44, "58144397": [152, 157], "5824294": 132, "58281521": 44, "583": 128, "583595": 138, "58464661": 44, "5851531": 44, "585662": 44, "58591043": 44, "586497": 44, "58662319": 44, "58685095": 156, "58697069": 44, "58836084": 44, "5892963": 5, "5898": 81, "59": [56, 68, 83, 87, 101, 156, 157], "59003946": 44, "591": 157, "5910e": 76, "5924728": 44, "59274796": 44, "59275998": 44, "59357852": 44, "594": 86, "59713092": 132, "5976": 156, "59767085": 44, "598": 46, "599": 157, "59912181": 44, "59921324": 44, "5a": 97, "5d": 97, "5r": 84, "5th": [15, 141], "5x5": 141, "6": [0, 3, 4, 5, 8, 13, 15, 24, 28, 30, 35, 38, 39, 42, 43, 44, 45, 46, 49, 52, 54, 55, 56, 58, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 87, 88, 93, 98, 99, 100, 101, 105, 107, 123, 126, 128, 131, 132, 134, 138, 139, 141, 148, 149, 150, 153, 155, 156, 157, 159, 166, 167], "60": [16, 43, 46, 81, 101, 126, 128, 156, 157], "600": 76, "6000": [58, 131], "60000": 74, "600px": 0, "60118718": 44, "602": [35, 72], "60231928": 44, "6024509": 44, "60324647": 44, "60337958": 44, "60350366": 44, "603636": 138, "60471697": 44, "60531032": 44, "60640394": 44, "6065484": 44, "60818376": 44, "60830612": 44, "6085147": 44, "60878366": 44, "6088": 1, "609": [86, 157], "60964487": 132, "60it": 157, "61": [1, 43, 156, 157], "61223252": 44, "612939": 138, "61320418": [152, 157], "61336137": 44, "613579": 138, "6145": 81, "6147": 5, "61472628": 44, "61509127": 156, "61516775": 44, "6151e": 76, "61594565": 44, "6169": 156, "6169496": 44, "61720311": 44, "61751414": 132, "61798553": 44, "618": 156, "61838026": 44, "61853913": 44, "618982": 138, "619": [1, 157], "6196092": 156, "61e": 100, "61it": 157, "62": [83, 100, 156, 157], "62048248": 44, "62060066": [152, 157], "6207e": 76, "6209": 76, "62091229": 44, "6210827": 44, "621102": 138, "62133597": [152, 157], "6218035": 44, "6222546e": 81, "62284909": 44, "62336218": 44, "62434536": 44, "62471505": 44, "62519531": 44, "62556168": 44, "626": 157, "62688268": 44, "626e": 128, "62743708": 44, "62765075": 44, "62896866": 157, "62it": 157, "63": [4, 42, 43, 46, 51, 68, 83, 156, 157], "63019567": 44, "63043757": 44, "6307175": 54, "6307441": 44, "63169151": 44, "6321e": 76, "633949": 138, "63546195": 44, "63612831": 39, "63658341": 44, "63738791": 44, "63750082": [152, 157], "63781955": [152, 157], "63840469": 132, "639": 157, "63it": 157, "64": [47, 81, 83, 101, 138, 142, 156, 157, 166], "640": 131, "6407759": 44, "64098587": 44, "641": 132, "6418": 81, "643": 157, "64435367": 44, "64659002": 44, "6471": 1, "64775015": 44, "648": 37, "64864364": 44, "64912811": [152, 157], "6497": 81, "64it": 157, "65": [1, 46, 87, 100, 135, 141, 156, 166], "650": 81, "65032321": 44, "65065728": 44, "6507e": 76, "650e": 132, "65101581": 44, "65130355": 44, "65223506": 44, "65383306": 156, "65458015": 44, "65478051e": 156, "65498998": 44, "65501279": 44, "65600": 81, "65601428": 156, "65609929": 44, "65614632": 44, "65617943e": 156, "656e": 128, "657041": 138, "65712464": 44, "65732421": 44, "658": 157, "6590498": 44, "65980218": 44, "66": [43, 81, 87, 156, 157], "660": 157, "66004503": 156, "66023155": [152, 157], "6603e": 76, "66085975": [152, 157], "66102029": 44, "66168108": 44, "66236766": [152, 157], "663": 86, "66479728": 44, "666597": 138, "667239": 138, "66804833": 44, "668172": 138, "66871683": 44, "66878884": 132, "669": 1, "6699e": 76, "66it": 157, "67": [43, 156], "670067": 1, "67094845": 44, "671308": 135, "67149674": 132, "67244070e": 70, "67261975": 44, "67262221": [152, 157], "672721": 138, "6735005": 44, "67393869": 44, "674": 86, "6743961": 44, "67457071": 44, "67471153": 44, "67486677": 54, "67545381": 44, "6755": 76, "67579578": 44, "6760e": 76, "67614785": 132, "67627133": 156, "677": 157, "6775828": 44, "67780757": 44, "6780": 81, "6780e": 76, "67887983": 128, "678e": 128, "67917707": 132, "67e": 100, "68": [9, 14, 15, 22, 24, 35, 41, 42, 43, 45, 46, 49, 131, 135, 152, 156, 157], "68006984": 44, "680144": 138, "6801984": 44, "6810": 156, "68121871": 156, "6813": 76, "682": 45, "68218368": 135, "68255141": 44, "683": 46, "6830988": 44, "68400133": 44, "68515134": 156, "68543614": 44, "6858752e": 81, "687": 132, "6870999932289124": 81, "6871": 81, "6875": 81, "68771659": 44, "6879182": 156, "68851": 54, "689": 132, "68901502": 44, "689345": 138, "68988323": 44, "69": [43, 87, 100, 156, 157], "690617": 138, "69087868": 44, "6916e": 76, "692": 35, "6924546": 44, "69257435": 44, "69336623": 44, "69346593": 44, "69379599": 44, "69380911": 44, "694": 157, "69427308": 44, "69509206": 44, "696e": 128, "697": 157, "6980": 1, "69803203": 44, "6984613": 44, "699": 35, "69902385": 44, "69942478": 5, "69it": 157, "6f": 83, "6omndqaaqbaj": 1, "7": [0, 1, 4, 5, 13, 20, 22, 30, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 52, 54, 55, 56, 58, 74, 75, 76, 81, 82, 83, 86, 87, 97, 99, 100, 101, 112, 118, 126, 128, 131, 132, 134, 135, 138, 139, 140, 141, 148, 149, 152, 155, 156, 157, 166], "70": [0, 4, 18, 21, 39, 81, 100, 107, 132, 135, 156, 157], "700": [76, 148], "70018815": 44, "70098212": 44, "701": 148, "70179412": 44, "70190716": 44, "702": 148, "70263812": 44, "70320221": 132, "70335885": 44, "7040": 81, "70459417": 44, "70474211": 44, "70548352": 44, "70623332e": 156, "706e": 132, "707": 56, "7080e": 76, "70816002": [152, 157], "7084054": 44, "70923249e": 83, "709698": 138, "70it": 157, "70px": [9, 137], "71": [1, 16, 43, 101, 132, 141, 156, 157], "71066184": 44, "711": 157, "71100266": 44, "71146298": 132, "71159529": 54, "71195902": [152, 157], "71269214": 44, "713": 139, "71304905": 44, "713163": 138, "71361508": 44, "714": 128, "7141": 76, "7147896": 44, "7151525e": 74, "71527897": [152, 157], "71613633": 156, "717": [100, 157], "71713645": 44, "71826373": 44, "71829074": 44, "719": [152, 157], "71it": 157, "72": [43, 68, 87, 100, 101, 156, 157, 161], "72090228": 44, "72152759": 54, "72171129": 44, "72176": 138, "72251838": 54, "72260711": 54, "72261458": 54, "72261518": 54, "722702": 44, "724": 80, "72415394": 44, "725474": 44, "72552256": 44, "72555052": 44, "72591685": 44, "72699708": 135, "727": 157, "72744124": 44, "72754221": 156, "7278135": 44, "72875201": [152, 157], "7288": 138, "72953922": 44, "73": [77, 81, 87, 150, 156, 157, 167], "731000": 138, "73140252": 44, "7316287": 44, "73176818": 156, "73211192": 44, "73268281": [152, 157], "73302323": 44, "733096": 138, "7334831242552866": 83, "73367312": 44, "73378149": 44, "7338137": 131, "7361": 76, "73625": 54, "737": 157, "73925038": 54, "73925165": 54, "73926589": 54, "73941564": 54, "73953394": 44, "73it": 157, "74": [100, 156, 157, 161], "74055645": 44, "74085574": 54, "74096404": 135, "74101715": 44, "74204416": 44, "743": 157, "74335654": 44, "74481176": 44, "74481415": [152, 157], "74488454": 44, "74545455": 132, "74582013": 44, "74643509": 44, "74694624": 156, "74832579": 44, "749765": 138, "74it": 157, "75": [16, 37, 41, 46, 70, 85, 87, 135, 138, 156], "750": 46, "75041164": 44, "750445": 138, "7504512": 135, "75062962": 44, "75133724": 44, "75136522": 44, "75283247": 54, "75539203": 44, "756352": 138, "757": 157, "75880566": 44, "759": 157, "75it": 157, "76": [83, 128, 156, 157, 161, 167], "760": 37, "76024082e": 156, "76024923": 44, "76041518": 44, "76131906e": 156, "76201118": 44, "76205806": 44, "76212473": 44, "76291349": 44, "76314662": 44, "76356305": 44, "76427936e": 156, "7653351": 44, "76687926": 44, "76781774": [152, 157], "76795995": 44, "76916026": 44, "76994186": 44, "76it": 157, "77": [82, 100, 156], "77042575": 44, "77123417": 44, "77124583": 44, "7715": 76, "77185931": 44, "77288737": 44, "77323981": 44, "77368576": 44, "77447832": 54, "77447851": 54, "77448062": 54, "77450405": 54, "77474252": 54, "77576423": 44, "776": [6, 157], "77683973": 156, "7768509": 54, "776e": 132, "777": 157, "7772263": [152, 157], "77727675": 132, "77741921": 44, "77758597": 44, "77767186": 44, "777777": [74, 81], "77778822": 132, "777e": 128, "77811": 138, "77817418": 44, "7789711": 44, "77it": 157, "78": [42, 46, 156, 157, 167], "7800": 47, "78002714": 44, "7802556": 44, "78046993": 44, "78126654": 44, "782": 138, "783e": 132, "784": 74, "78421011": [152, 157], "78477065": 44, "785061": 138, "78522692": 44, "78534616": 44, "78666187": 44, "78693299": 138, "786e": 132, "787": 138, "78730236": [152, 157], "78766106": 132, "7888": 134, "78975468": 44, "7898": 5, "789e": 128, "78it": 157, "79": [156, 157, 167], "79008879": 156, "79024706": 44, "7903551e": 74, "79053353": 156, "7908587e": 74, "7909571": 54, "791": 86, "79110577": 44, "79203455": 132, "79215821": 44, "79280687": 44, "793": 157, "793167": 138, "79452824": 44, "7946e": 76, "79502609": 44, "7957695978": 86, "796": 157, "79660555": 44, "7980638": 44, "7985268": 156, "799": 86, "79924193": 44, "79it": 157, "8": [1, 2, 15, 18, 19, 20, 30, 35, 38, 39, 42, 43, 44, 45, 46, 47, 51, 52, 54, 55, 68, 70, 74, 75, 76, 78, 81, 82, 83, 84, 86, 87, 88, 98, 100, 101, 107, 112, 126, 128, 131, 132, 134, 138, 139, 140, 141, 142, 148, 149, 152, 155, 156, 157, 166], "80": [1, 45, 46, 47, 82, 131, 156, 157, 167], "800": [46, 76, 128], "80043928": 44, "80073197": 44, "800b": 156, "80100182": 44, "80106255": 44, "80116214": 44, "80186103": 44, "80194408": 156, "8027": 134, "80358898": 44, "80413849": 44, "804217": 156, "80494266": 44, "805": 68, "80539342": 44, "80667836": 44, "8071": 138, "80725468": 132, "80745592": 44, "8079963": 44, "80816445": 44, "80884436": 44, "809": 157, "8094517": 44, "80977897": 44, "80991126": 39, "80kb": 156, "80px": 9, "81": [1, 51, 156, 157, 166, 167], "810": 1, "810159": 156, "81053491": 44, "81095167": 44, "810e": 132, "812376": 156, "81252782": 44, "81260110e": 156, "81304498": 44, "81342101": 44, "81343023": 44, "81434313": 44, "81582367": 44, "816": 157, "81604368": 44, "816454": 138, "8165998": 44, "816847": 138, "81693801": 44, "81757959": 44, "81768187": 44, "818": 45, "81889683": 44, "8190797": 44, "81986065e": 132, "819e": 132, "82": [88, 156, 157, 167], "82026273": 156, "82033": 135, "82038771": 44, "82093086": 156, "821": 156, "821arrai": 156, "82215417": 156, "8223678": 44, "82394729e": 156, "82400562": 44, "82401733": 44, "82454103": 44, "82458463": 44, "825": 157, "82502982": 44, "82529684": 44, "82539979": [152, 157], "82581966": 44, "82699862": [152, 157], "827": 6, "82757179": 44, "82797464": 44, "82818662": 44, "82it": 157, "83": [83, 87, 88, 128, 156, 167], "83030472e": 156, "83180116": 44, "83189927": 132, "83298219": 54, "83351405": 44, "83357905": 156, "8337": 76, "83374923": 156, "83463285": 156, "83471763": 44, "83599203": 44, "835e": 132, "836": 157, "83600472": 44, "8383258e": 74, "83863475": 44, "83880168": 44, "83883671": 156, "83898341": 44, "839818": 138, "8398299": 44, "8399": 81, "84": [1, 5, 22, 43, 46, 55, 99, 101, 128, 135, 148, 152, 156, 157], "84040535": 132, "84086156": 44, "8415": 76, "842": 157, "84222474": [152, 157], "842436": 138, "843": 132, "84300633": 44, "8439e": 76, "84417417": 156, "84501737": 44, "84550881": 44, "845635": 156, "84589891": 5, "84616065": 44, "847e": 132, "84858": 1, "84949567": 44, "84958685": 44, "85": [9, 47, 78, 98, 156], "85129577": 44, "85143789": 44, "8515102": 44, "85257974": [152, 157], "85270406": 44, "852e": 128, "85300949": 44, "85319204": 83, "85328122": 44, "85328219": 44, "85372673": 44, "853835": 138, "854": 157, "85555595": 44, "85565861": 44, "85566828": 156, "856": 157, "85673335e": 132, "85678947e": 156, "85680425": 44, "857": 156, "8574818": 44, "85753327": 44, "858": 157, "858185": 138, "8585": 76, "85907038": 83, "85987097": 44, "85it": 157, "86": [82, 100, 156, 157, 167], "86007019": 132, "86028827": 44, "86064819": 44, "86089124": 44, "8616231": 44, "861676": 138, "86334532": 44, "86339779": [152, 157], "86355526": 44, "86402267": 44, "86520687": 44, "86540763": 44, "866": 156, "86620796": 44, "86647138": 44, "8679e": 76, "867e": 132, "86808609": 135, "86828789": [152, 157], "86832437": 44, "86888616": 44, "8694594e": 81, "86983845": 156, "86it": 157, "87": [1, 56, 86, 98, 156, 167], "8709698": 44, "8726145e": 74, "87270": 54, "875": 157, "87583893": 44, "87616892": 44, "87710977": 44, "87784598": 44, "87798127": 44, "878": 132, "87809431": [152, 157], "878123": 138, "87953543": 44, "87985002": 44, "87it": 157, "88": [1, 43, 77, 156, 157], "8805": 55, "8808846": 44, "88092528": 156, "88094581": 44, "88122883": 44, "88176277": 132, "8820": [55, 153], "88268965": 44, "88288931": 44, "8830e": 76, "88352998": 44, "88355585": 44, "88401481": 44, "88490881": 44, "88512895": 44, "88514116": 44, "8858258": 44, "88583608": 44, "8865639": 44, "88772753": [152, 157], "88888889": 158, "88955297": 44, "8895a785550b": 140, "88it": 157, "89": [82, 83, 87, 100, 141, 156, 157, 167], "890": 157, "89000851": 44, "89160793": 44, "892": 157, "8922875": 44, "89230474": 156, "89320601": 44, "89342693": 44, "89353988": 44, "894": 157, "89465529": 44, "896": 81, "89711278": 44, "89806796": 44, "89825413": 44, "89938082": 44, "89943198": 132, "89984477": 44, "89it": 157, "8x8": [83, 87], "9": [0, 12, 15, 18, 20, 21, 39, 42, 43, 44, 46, 47, 50, 51, 52, 54, 55, 58, 74, 76, 78, 81, 83, 84, 85, 87, 88, 97, 98, 99, 100, 107, 112, 126, 128, 131, 132, 135, 138, 140, 141, 142, 152, 156, 157, 158, 166], "90": [1, 49, 84, 132, 135, 156, 167], "900": 76, "90010873": 44, "90085595": 44, "90148689": 44, "90159072": 44, "902340": 1, "90284564": 44, "90399917": 44, "90465871": 44, "9050": 76, "90508815": 44, "90575218": 44, "906": 55, "9063": 81, "9066e": 76, "9069": 76, "907": 55, "90756768": 44, "908": 55, "90841011": 156, "909": 157, "90909091": 132, "90966167": 44, "9099": 81, "91": [1, 34, 83, 100, 132, 141, 156, 157, 167], "9104236": 44, "9116924877687354e": 83, "91182056": 132, "91197": 1, "912": 132, "913": 157, "91360943": 44, "9150833487510681": 74, "9154": 81, "91549197": 44, "91549927": 44, "91582": 138, "91597758": 156, "916": 156, "91615796": 156, "91640524": 107, "9169": 76, "91745894": [152, 157], "91823968e": 156, "91826915": [152, 157], "91887782": [152, 157], "918992": 138, "91928931": 44, "91979229": 44, "91it": 157, "92": [38, 100, 156, 167], "92001793": 44, "92019511": [152, 157], "92036188367625": 88, "92061512": 44, "92145007": 44, "92272158": 156, "922e": 132, "92319798": 44, "92332064": 44, "923602": 138, "92381543": 44, "92442829": 44, "925": 1, "92550121": 44, "925e": 132, "926": 157, "9268873": 44, "92703138": 44, "92703572": 44, "927732": 138, "928": 132, "93": [88, 156, 157, 167], "93037546": 44, "9306713": 44, "931": 138, "93110208": 44, "93122954": 44, "93125568": 44, "93167903": 132, "93212342": 44, "93258998": 44, "93272141": 44, "933": 157, "93415215": [152, 157], "93504836": 156, "93514778": 44, "93660465": 156, "937082": 138, "93752881": 44, "93808797": [152, 157], "93820324": 44, "939": 138, "93916874": 44, "93934751": 44, "93985929": 44, "93it": 157, "94": [1, 83, 156, 157, 167], "94056472": 135, "9406321": 44, "941770367290452": 88, "943": 157, "94317552": 44, "945": 5, "94583889": 156, "94623562": 44, "94645393": 44, "94651631": 44, "947": 86, "94750117": 44, "94881155": 44, "9489627336466293": 88, "94940459": 128, "94980882": 44, "949e": 128, "95": [9, 20, 22, 24, 34, 35, 41, 42, 45, 58, 82, 83, 85, 87, 88, 98, 101, 128, 131, 135, 137, 156, 157, 167], "95029742": 44, "9504e": 76, "95093225": 44, "95103519": 135, "95116949": [152, 157], "9518": 76, "952": 45, "95216155e": 83, "9522": 76, "953": 157, "95413331": 44, "95446575": 44, "95449567": 44, "95486746": [152, 157], "95487808": 44, "955": 46, "95541062": 44, "9560789": 44, "9561217": 44, "9578333497047424": 74, "9581e": 76, "95826527364846": 47, "9586027": 44, "95922281": 132, "95e": 100, "95it": 157, "96": [85, 87, 100, 128, 156, 157, 167], "960": 157, "9603313": 44, "96081768": 44, "96082174": 44, "96130449": 44, "962": 156, "96240828e": 156, "96279877": 44, "962990": 138, "96318234": 44, "96371871": 44, "96400982": 44, "96463208": 44, "965548": 138, "96602": 5, "96622086": 44, "96653925": 44, "966899": 138, "9670395": 157, "96710175": 44, "96788032": 135, "96818283": 44, "9685333371162415": 74, "96908858": 44, "96953954": 131, "96it": 157, "97": [82, 83, 87, 88, 100, 148, 152, 156, 157, 167], "97061": 138, "971": 46, "97178163": 156, "971e": 132, "9721e": 76, "97247061": 44, "973": 157, "9734333157539368": 74, "974": 37, "97409466": [152, 157], "97538304": 44, "976": 157, "97682437": 128, "9771833419799805": 74, "97779878": 44, "97794526": 128, "977e": 128, "978": 1, "9780470015629": 1, "9780470028735": 1, "9780521642989": 1, "9781009023405": 1, "9781108843607": 1, "97811406": 44, "9781420079425": 1, "9781491912133": 1, "9781491962299": 1, "97815628": 156, "9783319154305": 1, "978642673791918": 82, "978e": 128, "97938827": 132, "97it": 157, "98": [16, 44, 58, 83, 87, 98, 156, 157, 167], "980": 74, "9800500273704529": 74, "98047744": 44, "98048015": 44, "98076837": 44, "98099948": 44, "9811": 5, "981321": 138, "9814362": 132, "9817500114440918": 74, "98181818": 132, "98218245": 44, "98228168": 44, "98254505": 44, "983310": 138, "9834499955177307": 74, "98401224": 44, "98495167": 44, "9850666522979736": 74, "98508459": [152, 157], "98519631": 44, "9857833385467529": 74, "986": 36, "98633519": 44, "98635218": 44, "98666377": 156, "9873354": 44, "9888561e": 81, "989": 157, "98907246": [152, 157], "99": [16, 41, 42, 43, 84, 132, 135, 156, 157, 166, 167], "990": [68, 138, 167], "99084937": 131, "990e": 128, "99161615": [152, 157], "992": 39, "99262196": 156, "99262487": 156, "993": 157, "9930": 87, "99397747": 156, "994": 39, "994e": 132, "995": 132, "996": 156, "997": [42, 45, 46, 167], "9972": 45, "99736185": 156, "99810852": 44, "998527": 83, "99890334": 132, "999": [30, 35, 112, 135], "9990": 156, "9991": 156, "9992": 156, "9993": 156, "9994": 156, "9995": 156, "9996": 156, "99962499": 44, "9996e": 76, "9997": 156, "9998": 156, "99983081": 44, "9999": 156, "9999052e": 74, "9999arrai": 156, "9999xarrai": 156, "99arrai": 156, "9e": 55, "A": [0, 1, 4, 8, 16, 17, 18, 21, 23, 26, 27, 28, 29, 30, 31, 32, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 61, 66, 67, 68, 69, 70, 71, 72, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 91, 94, 98, 99, 100, 102, 104, 105, 107, 109, 110, 111, 115, 122, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 137, 139, 141, 150, 151, 152, 154, 155, 156, 157, 158, 159, 166, 167, 168], "AND": [30, 84], "AS": 81, "And": [24, 41, 42, 46, 49, 53, 64, 67, 69, 71, 74, 80, 82, 88, 91, 151, 152, 157, 158, 159, 166], "As": [4, 8, 10, 22, 28, 38, 39, 43, 46, 50, 52, 53, 56, 57, 58, 64, 68, 69, 70, 72, 73, 77, 78, 80, 81, 82, 83, 87, 88, 93, 97, 103, 107, 112, 115, 117, 131, 132, 135, 138, 139, 140, 147, 152, 156, 157, 158, 159, 161], "At": [0, 5, 8, 16, 30, 39, 42, 45, 51, 56, 58, 61, 71, 93, 99, 110, 112, 132, 148, 149, 153, 158], "BE": [39, 104, 138], "BY": [48, 61], "Be": [37, 72, 86, 95, 97, 111, 130, 138, 141, 142, 147, 161], "Being": 52, "But": [4, 8, 13, 20, 24, 26, 27, 28, 34, 36, 39, 43, 45, 46, 53, 56, 57, 63, 64, 65, 67, 68, 71, 78, 83, 87, 91, 100, 106, 120, 122, 126, 131, 141, 142, 148, 150, 151, 156, 158, 159, 164, 167], "By": [16, 30, 36, 38, 39, 43, 47, 53, 58, 69, 71, 76, 80, 82, 83, 87, 88, 107, 124, 128, 135, 139, 147, 150, 156, 161, 166, 167], "For": [0, 4, 7, 8, 9, 16, 18, 20, 21, 22, 23, 24, 26, 30, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 61, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 90, 91, 93, 97, 98, 100, 101, 105, 108, 110, 115, 116, 122, 124, 130, 131, 132, 135, 136, 137, 138, 139, 141, 142, 144, 148, 149, 152, 154, 156, 157, 158, 161, 166], "If": [0, 4, 9, 11, 13, 16, 18, 22, 23, 24, 27, 28, 30, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 61, 67, 68, 71, 72, 73, 74, 76, 77, 78, 80, 81, 82, 83, 86, 88, 90, 91, 93, 95, 100, 101, 105, 122, 125, 128, 130, 132, 135, 136, 138, 139, 141, 142, 148, 151, 152, 153, 156, 157, 158, 159, 161, 164, 166], "In": [0, 2, 3, 4, 5, 7, 8, 9, 13, 16, 17, 18, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 87, 88, 90, 91, 93, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 112, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 137, 138, 139, 140, 141, 142, 149, 150, 151, 152, 153, 157, 158, 159, 160, 161, 162, 163, 166, 167, 168], "Ising": [72, 122, 150, 167], "It": [0, 3, 4, 7, 8, 16, 18, 20, 24, 26, 27, 28, 30, 36, 39, 41, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54, 58, 61, 63, 64, 66, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 83, 84, 85, 88, 90, 93, 97, 98, 99, 100, 102, 105, 109, 110, 112, 115, 116, 118, 120, 122, 128, 132, 134, 135, 138, 139, 140, 141, 142, 147, 148, 149, 151, 152, 153, 155, 156, 157, 158, 159, 161, 164, 166], "Its": [51, 72, 83, 87, 90, 161], "No": [4, 16, 41, 49, 52, 53, 56, 64, 67, 70, 74, 75, 78, 84, 91, 98, 128, 131, 133, 156, 158, 159], "Not": [4, 41, 43, 44, 46, 47, 48, 49, 56, 69, 81, 131, 149, 152, 157, 164], "OF": 81, "OR": [30, 81, 84], "Of": [36, 39, 105], "On": [4, 26, 67, 68, 69, 71, 75, 78, 80, 128, 134, 139, 166], "One": [9, 11, 23, 24, 34, 38, 39, 43, 51, 52, 53, 57, 60, 64, 66, 67, 70, 71, 72, 74, 78, 93, 126, 138, 141, 142, 151, 153, 158, 159, 161, 166], "Or": [22, 30, 58, 63, 82, 88, 100, 135, 138, 151], "Such": [18, 39, 48, 51, 67, 69, 71, 116, 135, 158, 161], "TO": 138, "That": [15, 22, 27, 36, 38, 39, 43, 45, 46, 52, 53, 54, 58, 67, 71, 72, 73, 77, 78, 93, 100, 105, 120, 128, 135, 139, 148, 149, 150, 151, 152, 156, 157, 158, 161, 167], "The": [1, 3, 5, 7, 8, 9, 10, 11, 12, 13, 15, 18, 20, 22, 23, 25, 27, 28, 29, 31, 34, 35, 36, 37, 38, 41, 42, 44, 47, 50, 52, 53, 55, 56, 57, 60, 61, 63, 64, 65, 66, 67, 69, 72, 73, 74, 75, 76, 78, 81, 84, 85, 86, 89, 91, 92, 94, 95, 96, 97, 98, 99, 101, 102, 104, 107, 109, 110, 111, 112, 115, 116, 118, 120, 121, 122, 125, 127, 129, 130, 131, 132, 134, 137, 138, 140, 141, 142, 143, 144, 145, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 163, 164, 166, 167], "Their": [52, 72, 77], "Then": [3, 4, 9, 18, 19, 24, 27, 28, 35, 39, 42, 46, 48, 49, 56, 57, 58, 70, 75, 76, 82, 84, 90, 91, 97, 130, 132, 135, 139, 140, 142, 147, 148, 149, 151, 152, 155, 157, 158, 159, 161, 163, 164, 168], "There": [4, 8, 9, 11, 16, 24, 30, 35, 37, 42, 43, 45, 48, 49, 50, 51, 52, 56, 61, 65, 68, 71, 72, 78, 80, 87, 91, 95, 100, 102, 109, 120, 134, 135, 137, 138, 139, 142, 148, 149, 151, 153, 156, 158, 159, 161, 168], "These": [4, 8, 27, 39, 42, 44, 48, 49, 50, 52, 53, 56, 57, 64, 66, 69, 70, 71, 72, 73, 74, 76, 77, 80, 87, 90, 93, 99, 100, 101, 106, 112, 115, 131, 132, 134, 135, 139, 152, 153, 156, 157, 159, 161, 166, 167], "To": [0, 8, 15, 16, 23, 30, 35, 39, 41, 43, 44, 48, 49, 51, 52, 53, 55, 56, 57, 58, 64, 66, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 86, 91, 99, 101, 106, 107, 111, 122, 135, 139, 142, 148, 149, 151, 152, 155, 157, 158, 159, 161], "Will": [22, 28, 39, 87, 107], "With": [4, 9, 16, 21, 34, 35, 39, 41, 45, 46, 49, 51, 52, 56, 58, 67, 70, 71, 72, 73, 74, 77, 81, 84, 91, 100, 102, 109, 138, 140, 152, 156, 157, 161, 166], "_": [4, 6, 9, 10, 11, 12, 18, 21, 24, 28, 29, 35, 38, 39, 41, 44, 49, 50, 51, 53, 57, 58, 69, 70, 71, 72, 77, 78, 82, 83, 85, 86, 87, 88, 91, 97, 98, 100, 102, 105, 110, 111, 112, 118, 122, 128, 130, 132, 134, 135, 140, 142, 152, 155, 157, 158, 161, 166], "_0": [4, 44, 47, 58, 102, 152, 157, 158], "_1": [0, 7, 39, 53, 70, 72, 73], "_2": [39, 53, 71, 72, 105], "__": [78, 98], "_________________________________________________________________": [74, 81], "__enter__": 131, "__former_attrs__": [55, 101], "__future__": 81, "__getattr__": [55, 101], "__init__": [9, 55, 76, 101, 128, 131, 154, 155], "__version__": [43, 46, 55, 74, 101, 148, 156, 157], "_a": 58, "_adjust_frame_s": 131, "_alpha": 101, "_amp1": 55, "_amp2": 55, "_amplitud": 101, "_background": 101, "_base": 55, "_beta": [55, 101], "_check_optimize_result": 86, "_config": 0, "_d": [126, 128, 153], "_data": 9, "_execute_child": 131, "_fig": 131, "_g": [49, 126], "_generatorcontextmanag": 131, "_gpr": 86, "_h": [128, 131], "_i": [7, 18, 39, 49, 51, 70, 71, 72, 102, 155, 158, 161], "_imag": 132, "_is_sav": 131, "_j": 51, "_k": [53, 71, 97], "_log": 131, "_m": [71, 72, 90], "_n": [90, 97, 112, 151], "_p": [29, 135], "_pformat_subprocess": 131, "_posit": 101, "_proc": 131, "_run": 131, "_sample_proba": [78, 98], "_setattr_cm": 131, "_sig": 55, "_sort": 46, "_supports_transpar": 131, "_t": 128, "_true": [44, 152, 157], "_v": 128, "_w": [93, 131, 137], "a0": [20, 101], "a0boogfu": 138, "a1": [22, 131, 135, 138], "a2": [22, 135, 138], "a3": 138, "a4": 138, "a_": [20, 41, 101, 130, 132], "a_0": [20, 39, 41, 54, 57, 95, 101, 104, 117], "a_1": [39, 54, 57, 87, 95, 101, 104, 117, 135], "a_1a": [39, 104, 138], "a_2": [39, 57, 87, 104, 135], "a_2a": [39, 104, 138], "a_3": [39, 104, 138], "a_4": [39, 104, 138], "a_arr": 20, "a_bar": 54, "a_grid": 42, "a_hat": 54, "a_i": [54, 58, 73, 87, 99, 135, 138], "a_j": [73, 87, 101, 135], "a_k": [54, 57, 73, 87], "a_margin": 42, "a_mat": 54, "a_max": 42, "a_n": [39, 117, 135, 161], "a_posterior": 20, "a_pt": 42, "a_tru": 42, "a_w": 137, "a_x": 58, "aa": 141, "ab": [1, 3, 6, 43, 45, 83, 87, 97, 128, 130, 141, 148, 149, 155, 156, 158, 166], "abandon": 153, "abar": 54, "abar_": 54, "abbrevi": [124, 139], "abeca3": 1, "abil": [43, 51, 52, 69, 76, 78, 116, 139, 141, 158], "abl": [16, 30, 39, 43, 48, 49, 50, 52, 58, 61, 72, 76, 78, 83, 87, 93, 100, 136, 139, 147, 149, 166], "abnormal_termination_in_lnsrch": 86, "abolut": 43, "about": [0, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 22, 27, 28, 30, 35, 36, 38, 39, 41, 42, 43, 45, 46, 47, 48, 51, 52, 53, 54, 55, 58, 63, 64, 67, 68, 69, 71, 72, 74, 77, 78, 81, 82, 83, 84, 86, 87, 88, 90, 91, 93, 95, 98, 99, 100, 101, 102, 106, 115, 122, 124, 125, 126, 135, 136, 137, 138, 139, 141, 142, 148, 149, 150, 156, 158, 159, 163, 164, 167], "abov": [0, 4, 5, 9, 18, 19, 20, 22, 24, 27, 28, 35, 36, 38, 39, 41, 43, 44, 45, 46, 47, 49, 53, 54, 56, 58, 68, 70, 71, 72, 73, 75, 76, 77, 78, 80, 81, 82, 87, 88, 93, 97, 98, 106, 107, 112, 125, 126, 128, 132, 135, 138, 139, 141, 148, 149, 150, 151, 152, 156, 157, 158, 161, 166, 167, 168], "absenc": [8, 68, 122], "abserr": [154, 155], "absolut": [3, 4, 8, 16, 52, 70, 71, 72, 90, 115, 130, 138, 141, 158], "absolute_import": 81, "absorb": 30, "abspath": [135, 161, 166], "abstract": [8, 16, 58, 71, 78, 161, 166], "abstractmoviewrit": 131, "abund": 110, "abundantli": 43, "ac": [37, 82], "ac83dd": 1, "academ": [48, 61], "accelar": 128, "acceler": [67, 69, 126, 128], "accentu": 38, "accept": [6, 24, 34, 44, 49, 50, 51, 55, 56, 58, 66, 69, 76, 80, 128, 142, 149, 150, 151, 152, 153, 157, 158, 159, 161, 166, 167, 168], "acceptance_fract": [6, 55, 128, 148, 152, 157], "acceptance_r": 156, "access": [8, 16, 39, 48, 50, 53, 56, 58, 61, 69, 70, 76, 82, 88, 93, 105, 118, 135, 138, 139, 141, 142, 144, 158, 159], "accid": [41, 69], "accommod": [8, 93], "accompani": 69, "accomplish": [53, 55, 76, 141, 151, 159], "accor": 70, "accord": [9, 16, 18, 34, 38, 39, 46, 47, 48, 49, 51, 55, 58, 65, 72, 73, 76, 101, 122, 131, 135, 138, 149, 158, 161, 163], "accordingli": [28, 48], "account": [0, 4, 16, 28, 34, 39, 42, 43, 48, 53, 60, 64, 65, 66, 68, 77, 124, 128, 132, 138, 148, 150, 166, 167], "accumul": [18, 49, 72, 76, 112, 128, 164], "accur": [45, 50, 52, 53, 58, 68, 70, 71, 74, 85, 94, 122, 124, 127, 129, 131, 155], "accuraci": [43, 45, 46, 48, 52, 53, 54, 55, 56, 68, 70, 72, 75, 78, 81, 98, 130, 135, 148, 150, 155, 159, 167], "accus": 8, "aceept": 153, "acf": 149, "achiev": [8, 46, 49, 51, 52, 58, 69, 70, 71, 72, 81, 93, 116, 122, 126, 138, 148, 158, 161], "acknowledg": [53, 66, 68], "acor": [148, 149], "acquaint": [39, 106, 115], "acquir": [9, 10, 11, 32, 67, 72, 122], "acquisit": [63, 97], "across": [39, 45, 48, 51, 52, 53, 76, 80, 82, 88, 107, 124, 148, 153, 164], "act": [8, 18, 45, 46, 56, 58, 63, 67, 115, 122, 134, 139], "act_1": [78, 98], "act_2": [78, 98], "act_out": [78, 98], "action": [68, 69, 122, 133, 168], "activ": [8, 51, 52, 69, 70, 74, 75, 76, 77, 78, 79, 80, 81, 98, 122, 128, 134, 139, 142], "activaiton": 122, "activit": 72, "actual": [7, 8, 9, 13, 16, 24, 26, 27, 30, 35, 36, 39, 41, 43, 45, 46, 48, 51, 56, 58, 63, 68, 70, 71, 76, 77, 82, 88, 91, 93, 98, 100, 109, 116, 122, 124, 138, 147, 150, 158, 161, 164, 167], "ad": [24, 30, 42, 43, 45, 49, 55, 58, 61, 71, 74, 78, 79, 82, 84, 85, 88, 91, 97, 98, 99, 100, 101, 102, 112, 122, 126, 128, 132, 135, 139, 147, 148, 149, 152, 157, 161, 164, 166], "adadelta": [1, 112], "adagrad": [72, 76], "adam": [1, 61, 72, 74, 76, 81], "adapt": [1, 9, 39, 42, 43, 44, 45, 52, 55, 61, 66, 72, 76, 82, 83, 87, 88, 92, 95, 100, 121, 122, 126, 127, 132, 147, 148, 149, 150, 152, 153, 155, 156, 157, 159, 167], "adapt_diag": [156, 157], "adaptation_lag": [55, 101], "adaptation_tim": [55, 101], "add": [0, 9, 22, 24, 36, 38, 39, 45, 52, 57, 69, 71, 73, 75, 78, 79, 80, 84, 85, 87, 91, 95, 98, 99, 100, 120, 127, 128, 135, 138, 139, 140, 141, 142, 143, 147, 148, 149, 152, 153, 155, 157, 158, 164], "add_ax": 131, "add_subplot": [5, 9, 22, 42, 43, 45, 46, 47, 54, 70, 75, 100, 131, 132, 137, 139, 140, 150, 154, 155, 167], "addbackward0": 76, "addit": [0, 2, 16, 18, 29, 30, 32, 36, 39, 47, 49, 51, 53, 56, 57, 58, 63, 66, 67, 69, 71, 72, 73, 76, 77, 78, 80, 82, 83, 85, 87, 90, 93, 98, 112, 115, 126, 129, 139, 142, 156, 159, 161], "addition": 72, "address": [43, 58, 60, 61, 62, 68, 77, 95, 100, 115, 121, 127, 152, 153, 157, 158], "adequ": [7, 68], "adher": [48, 58, 68], "adjac": [56, 72], "adjust": [9, 22, 42, 43, 47, 49, 68, 72, 74, 76, 77, 78, 91, 93, 116, 122, 131, 135, 137, 147, 153, 154, 156, 159], "admin": 142, "admir": 138, "adopt": [39, 43, 56, 68, 80, 125], "ador": 68, "adress": 49, "advanc": [8, 9, 52, 55, 61, 68, 72, 76, 96, 100, 101, 136, 142, 158, 161, 165], "advantag": [16, 32, 33, 39, 43, 48, 52, 61, 76, 80, 112], "advertis": 91, "advi": [77, 98, 156], "advic": 164, "advoc": [45, 93, 100, 153], "af_fig": 20, "affect": [24, 30, 43, 45, 46, 48, 67, 68, 69, 76, 85, 105, 135, 154, 158], "affin": [1, 52, 128, 151, 152, 153, 157, 158], "afford": [49, 81], "after": [4, 8, 9, 10, 11, 12, 16, 18, 22, 26, 27, 28, 30, 35, 42, 43, 48, 49, 51, 52, 53, 57, 58, 64, 67, 69, 71, 72, 73, 74, 76, 82, 85, 86, 88, 90, 100, 128, 131, 138, 139, 141, 148, 149, 151, 153, 155, 156, 161, 164, 166], "afterward": 138, "ag": [68, 69], "again": [4, 9, 17, 20, 27, 28, 35, 36, 38, 42, 49, 54, 58, 68, 70, 73, 82, 95, 100, 102, 117, 119, 120, 122, 130, 132, 135, 138, 139, 142, 149, 151, 152, 154, 156, 157, 158, 159, 161, 166], "against": [8, 13, 14, 20, 51, 56, 58, 68, 76, 132, 150, 166, 167], "agenc": 68, "agenda": 4, "agent": [8, 133], "aggress": 112, "agre": [13, 24, 58, 66, 81, 132, 152, 157], "agreement": [39, 44, 58, 107, 142, 152, 157], "ahead": [25, 28, 78, 98, 139], "ai": [1, 69, 94, 122], "aic": 56, "aid": [48, 51], "aim": [4, 39, 49, 51, 52, 61, 66, 67, 68, 69, 70, 71, 72, 82, 88, 105, 110, 128, 138, 166], "aip": 56, "air": [126, 128], "airplan": 81, "aka": [9, 35, 52, 90, 127], "akaiko": 56, "al": [0, 48, 49, 61, 71, 128, 131, 149], "alea": 77, "alexandr": 1, "alfio": 1, "algebra": [1, 18, 39, 55, 69, 72, 100, 104, 105, 117, 130, 139, 143], "algorithm": [1, 24, 43, 49, 52, 58, 61, 67, 70, 71, 75, 76, 77, 78, 94, 98, 102, 109, 110, 111, 116, 121, 122, 132, 135, 138, 141, 151, 156, 165], "alia": [55, 101], "alias": [55, 101], "align": [0, 4, 13, 15, 18, 21, 24, 27, 29, 38, 39, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 56, 71, 72, 77, 82, 84, 87, 88, 90, 91, 93, 100, 105, 112, 130, 131, 132, 135, 150, 151, 153, 154, 155, 156, 161, 163, 164, 167], "align_test": 0, "all": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 21, 22, 26, 27, 28, 30, 32, 35, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 82, 83, 84, 87, 88, 90, 91, 93, 94, 97, 99, 100, 101, 105, 107, 109, 110, 111, 112, 113, 122, 124, 125, 128, 129, 131, 132, 134, 135, 138, 139, 141, 142, 147, 148, 149, 150, 151, 152, 153, 156, 158, 161, 163, 164, 166, 167], "all_orbit": 154, "allow": [3, 4, 8, 9, 11, 12, 16, 18, 30, 35, 39, 43, 44, 48, 49, 51, 54, 58, 69, 70, 76, 78, 80, 85, 86, 87, 90, 94, 98, 100, 107, 109, 115, 116, 122, 128, 135, 138, 139, 141, 142, 149, 152, 156, 157, 158, 166], "allud": [0, 27], "almost": [18, 24, 68, 69, 70, 72, 78, 83, 87, 131, 153, 156, 158, 159, 166], "alo": 41, "alon": [4, 8, 56], "along": [48, 52, 67, 77, 80, 87, 95, 141, 153, 156, 161], "alongsid": [82, 88], "alp": 1, "alpha": [3, 6, 9, 13, 22, 24, 34, 35, 38, 39, 42, 44, 45, 46, 47, 52, 54, 55, 56, 70, 72, 75, 77, 78, 79, 82, 83, 85, 86, 87, 90, 93, 97, 98, 99, 100, 101, 107, 122, 128, 131, 132, 134, 135, 138, 148, 149, 155, 157, 158, 161, 163], "alpha_1": [9, 35], "alpha_1_w": 9, "alpha_2": 9, "alpha_2_w": 9, "alpha_3": 9, "alpha_3_w": 9, "alpha_bound": 86, "alpha_v": 128, "alphabet": 61, "alphavec": [28, 95], "alreadi": [16, 18, 22, 24, 36, 39, 42, 44, 54, 57, 61, 65, 68, 70, 78, 82, 88, 91, 115, 122, 132, 138, 139, 142, 149, 150, 152, 157, 159, 161, 165, 167], "also": [0, 3, 4, 5, 7, 8, 9, 16, 18, 19, 20, 22, 24, 26, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 56, 57, 58, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 82, 83, 86, 87, 88, 90, 91, 93, 94, 97, 99, 100, 101, 102, 105, 106, 107, 109, 112, 115, 116, 118, 121, 122, 126, 129, 131, 132, 134, 135, 137, 138, 139, 140, 141, 142, 147, 148, 149, 152, 153, 156, 157, 158, 159, 161, 164, 166], "alter": [8, 9, 35], "altern": [3, 4, 6, 22, 39, 43, 44, 46, 49, 51, 52, 53, 58, 66, 69, 71, 93, 97, 99, 102, 120, 127, 131, 135, 143, 147, 157, 158, 161, 165], "although": [0, 8, 11, 18, 24, 27, 30, 38, 39, 48, 50, 52, 53, 58, 61, 65, 68, 87, 102, 103, 104, 109, 110, 117, 135, 138, 141, 158, 161, 164, 166], "altogeth": [49, 90], "alwai": [6, 7, 8, 16, 20, 22, 24, 27, 28, 34, 39, 45, 48, 53, 54, 58, 63, 68, 69, 70, 71, 72, 77, 90, 97, 103, 106, 108, 117, 134, 135, 138, 139, 140, 149, 150, 151, 156, 158, 159, 161, 163, 164, 166, 167], "am": 1, "amat": 132, "amatt": 132, "amax": [47, 101], "amaz": [69, 78], "amazon": 61, "ambigu": 72, "ambit": [50, 72], "ambiti": [63, 67], "ame2003": 138, "ame2012": 138, "ame2016": 138, "amelior": 71, "american": [1, 66, 133], "amin": [47, 101], "among": [8, 34, 43, 45, 48, 52, 53, 60, 61, 71, 80, 93, 161], "amount": [8, 9, 30, 44, 45, 56, 58, 67, 68, 71, 78, 80, 95, 102, 116, 151, 152, 157, 161], "amplifi": 68, "amplitud": [20, 39, 55, 56, 58, 85, 87, 95, 101, 137], "an": [0, 1, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 63, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 105, 109, 110, 111, 112, 115, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 165, 167, 168], "anaconda": [55, 61, 76, 136, 139, 144, 145], "anaconda3": [55, 142], "anal": 1, "analog": [56, 71, 99, 130, 149, 159], "analogi": [0, 1, 8, 27, 38, 56, 66, 72, 77, 149], "analys": [30, 35, 39, 48, 51, 52, 127, 131], "analysi": [0, 1, 7, 8, 16, 18, 20, 24, 30, 32, 34, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 61, 66, 68, 69, 70, 71, 78, 91, 93, 98, 99, 100, 104, 107, 117, 121, 122, 126, 128, 129, 130, 132, 138, 139, 150, 152, 157, 158, 164, 167], "analyt": [7, 16, 18, 21, 35, 39, 41, 44, 45, 49, 52, 54, 58, 68, 70, 71, 72, 87, 93, 102, 104, 149, 152, 157, 161, 164], "analyz": [8, 16, 24, 30, 34, 39, 43, 54, 64, 68, 69, 80, 95, 99, 101, 103, 107, 122, 147], "anayt": 158, "ancestor": 115, "andrea": [1, 50, 61, 83, 87], "andrei": 30, "andrew": [0, 1, 61], "ang_mom": 155, "angl": [41, 45, 47, 147], "angular": 47, "angwin": 68, "anharmon": 52, "ani": [0, 4, 5, 7, 8, 9, 11, 16, 19, 22, 24, 27, 30, 35, 36, 37, 38, 39, 43, 45, 46, 48, 49, 50, 53, 54, 55, 56, 57, 58, 61, 63, 64, 66, 68, 69, 70, 72, 76, 78, 81, 83, 85, 87, 90, 91, 93, 97, 100, 101, 106, 107, 122, 125, 128, 135, 139, 140, 141, 147, 148, 157, 158, 159, 161, 166, 168], "anim": [72, 131], "anindita": 1, "ankl": 81, "ann": 94, "ann_input": [78, 98], "ann_output": [78, 98], "anneal": 56, "annft": 122, "annot": [9, 22, 42, 47, 100, 131, 149], "anoth": [0, 4, 9, 13, 16, 18, 21, 24, 28, 30, 38, 39, 42, 48, 49, 56, 58, 60, 68, 69, 70, 71, 72, 73, 80, 81, 84, 93, 95, 99, 100, 102, 115, 132, 135, 138, 139, 140, 141, 149, 150, 153, 155, 157, 159, 161, 164, 167], "ansatz": 138, "answer": [7, 8, 31, 32, 38, 44, 47, 57, 58, 64, 68, 69, 71, 82, 84, 88, 90, 97, 98, 99, 103, 108, 128, 132, 135, 139, 149, 152, 156, 157, 159, 166], "anteced": 52, "anti": [9, 11, 12, 58, 83, 135], "antialias": [42, 135], "anticip": 68, "anymor": 90, "anyon": [64, 140], "anyth": [11, 16, 26, 47, 66, 72, 135, 139, 147, 156, 158, 159], "anywai": 149, "anywher": [0, 22, 28, 37, 48, 57, 161], "ap": 132, "apach": 81, "apart": [49, 58, 78, 84, 91], "aperiod": [149, 158, 161], "api": [78, 81, 98], "apologi": 67, "app": [1, 91], "appar": [30, 151, 164], "apparatu": 28, "appeal": [51, 135], "appear": [4, 7, 8, 20, 27, 37, 39, 43, 47, 48, 50, 52, 58, 61, 68, 69, 71, 72, 77, 82, 88, 90, 98, 120, 130, 138, 142, 154, 158, 159, 161, 163, 166], "append": [38, 41, 43, 55, 70, 75, 101, 128, 134, 137, 138, 140, 141, 142, 148, 149, 154, 158, 164, 166], "appendix": [28, 29, 32, 61, 97, 131, 136], "appl": 142, "appli": [0, 7, 8, 15, 18, 22, 24, 27, 30, 36, 37, 39, 40, 44, 48, 49, 52, 53, 56, 57, 58, 63, 68, 70, 72, 73, 75, 76, 77, 78, 80, 93, 99, 109, 115, 122, 128, 134, 138, 141, 150, 153, 154, 158, 159, 161, 167], "applic": [1, 7, 8, 16, 23, 28, 29, 30, 42, 44, 46, 48, 49, 50, 51, 52, 53, 57, 61, 64, 67, 68, 69, 70, 71, 72, 76, 78, 81, 91, 93, 94, 109, 117, 126, 152, 157, 161, 166], "approach": [1, 4, 8, 9, 11, 16, 17, 18, 22, 23, 24, 26, 30, 33, 35, 38, 39, 41, 45, 48, 49, 50, 51, 52, 53, 56, 58, 60, 64, 65, 66, 69, 70, 71, 76, 77, 78, 79, 83, 84, 88, 93, 100, 102, 106, 107, 115, 116, 118, 122, 124, 125, 126, 130, 132, 133, 134, 135, 140, 153, 156, 158, 159], "appropri": [0, 4, 16, 22, 30, 39, 48, 53, 58, 68, 82, 88, 90, 125, 131, 132, 135, 139, 151, 159], "approx": [3, 4, 12, 16, 19, 24, 34, 36, 37, 43, 46, 50, 51, 57, 58, 72, 77, 78, 84, 98, 100, 115, 120, 130, 132, 151, 158, 159, 161, 164, 166], "approxim": [1, 4, 17, 18, 23, 24, 34, 39, 44, 46, 49, 50, 52, 56, 57, 58, 60, 71, 72, 76, 77, 78, 95, 98, 100, 101, 105, 115, 116, 120, 124, 127, 132, 135, 149, 151, 152, 153, 157, 158, 159, 163], "ar": [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 87, 88, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 166, 167, 168], "aragorn": 138, "arang": [38, 42, 44, 47, 54, 55, 70, 75, 82, 83, 85, 87, 88, 100, 101, 135, 138, 139, 140, 141, 143, 148, 154, 155, 157], "arbitrari": [28, 48, 51, 52, 72, 85, 135, 158], "arbitrarili": [39, 87, 149], "archetyp": 72, "architectur": [74, 76, 78, 81, 122], "archiv": 8, "arcsin": 3, "area": [23, 24, 48, 53, 58, 61, 69, 77, 80, 109, 138, 153, 154, 168], "aren": 68, "arg": [0, 5, 6, 21, 39, 43, 45, 46, 75, 87, 97, 101, 105, 118, 128, 131, 135, 137, 148, 151, 152, 157], "argmax": [4, 9, 22, 35, 46, 47, 74, 81, 131], "argmin": [42, 71, 90, 109, 154, 155, 166], "argsort": [46, 101], "argu": [4, 8, 18, 24, 39, 48, 51, 63, 64, 65, 67, 68, 78, 122, 138, 148, 156], "argument": [0, 13, 18, 38, 39, 43, 48, 51, 55, 57, 72, 77, 81, 84, 97, 101, 107, 109, 122, 132, 138, 139, 141, 143, 149, 161, 164], "aris": [7, 39, 52, 53, 56, 58, 71, 82, 88, 129, 138, 166], "aristotelian": 67, "arithmet": [27, 141], "arlier": 140, "around": [13, 19, 20, 24, 28, 30, 34, 39, 41, 46, 48, 49, 58, 76, 78, 81, 82, 88, 94, 110, 115, 131, 132, 135, 148, 149, 153, 156, 164, 168], "arr": 141, "arr1": 141, "arr1_2d": 141, "arr2": 141, "arr_from_list": 141, "arr_int": 141, "arr_to_list": 141, "arrai": [3, 5, 9, 18, 20, 21, 22, 30, 34, 35, 38, 39, 42, 43, 44, 45, 46, 47, 49, 54, 55, 70, 72, 74, 75, 78, 81, 82, 83, 84, 87, 88, 98, 99, 100, 101, 108, 128, 131, 132, 135, 138, 143, 148, 149, 151, 152, 154, 155, 156, 157, 158, 161, 166, 167], "arrang": [80, 132], "array_equ": 141, "array_lik": 128, "array_split": 141, "arrest": 68, "arriv": [8, 71, 72, 105, 138, 139], "arrow": [22, 72, 122, 131, 139, 153, 159], "arrowprop": [22, 42, 131, 149], "arrowstyl": 149, "arsen": 27, "art": [49, 78], "articl": [32, 53, 71, 81, 94, 126, 128, 133, 141], "articul": [53, 58, 62, 66], "artifact": 7, "artifici": [39, 45, 50, 52, 68, 69, 75, 79, 93, 94, 106, 107, 109, 122], "artificialneuron": 72, "arviz": [78, 98, 156, 157], "arviz_vers": 156, "arxiv": [1, 45, 77, 91, 97, 99, 131, 156, 168], "as_cmap": [78, 98], "as_grai": 132, "asarrai": [6, 82, 88, 97, 101], "ascend": [42, 141], "ascertain": [48, 58, 158], "asid": [25, 26, 30, 44, 48, 152, 156, 157], "ask": [11, 16, 18, 27, 36, 38, 46, 47, 48, 54, 56, 58, 64, 65, 73, 105, 139, 142, 150, 151, 167], "aspect": [17, 30, 31, 42, 52, 54, 58, 61, 63, 65, 68, 82, 83, 87, 88, 93, 94, 135, 168], "aspir": 48, "ass": 78, "assembl": [80, 97], "assembli": 138, "assert": [38, 42, 55, 75, 87, 101, 149, 152, 157, 166], "assess": [7, 39, 48, 53, 56, 68], "assign": [8, 18, 21, 26, 27, 30, 35, 39, 43, 48, 49, 51, 58, 60, 63, 70, 77, 84, 90, 93, 106, 124, 125, 135, 141, 156, 159, 166], "assist": 139, "associ": [39, 44, 48, 50, 58, 72, 78, 82, 83, 88, 90, 102, 109, 115, 122, 138, 152, 155, 156, 157], "assum": [3, 4, 8, 16, 18, 19, 20, 24, 26, 27, 28, 30, 34, 36, 39, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 68, 70, 71, 72, 76, 77, 78, 83, 85, 87, 90, 91, 93, 95, 97, 100, 101, 104, 106, 107, 118, 120, 124, 125, 126, 128, 131, 135, 138, 141, 142, 147, 148, 149, 152, 156, 157, 158, 159, 161, 166], "assumpt": [7, 8, 12, 18, 39, 46, 47, 48, 51, 58, 66, 67, 68, 70, 80, 83, 87, 100, 102, 105, 124, 138, 161], "asterisk": [0, 39, 139], "astro": 85, "astronom": [1, 16, 18, 46, 63, 115, 164], "astrophysicist": 164, "astropi": 147, "astyp": [78, 98, 141], "asymmet": 24, "asymmetr": [23, 24, 149, 159, 164], "asymmetri": [68, 138], "asymptot": [28, 71], "atari": 78, "atleast_1d": 128, "atol": [154, 155], "atom": [1, 67, 138, 149], "atomic_mass": 138, "attack": 52, "attain": [8, 53], "attempt": [9, 16, 41, 49, 53, 58, 71, 77], "attend": 68, "attent": [16, 27, 68], "attitud": [66, 68, 69], "attr": [55, 101, 161], "attract": 138, "attractor": 56, "attribut": [7, 48, 55, 58, 101, 135, 141, 156], "attributeerror": [55, 101], "au": 39, "audi": [1, 138], "augment": [49, 97], "aurelien": 71, "author": [51, 61, 78, 81, 82, 85, 86, 96, 122, 124], "authorize_download": 82, "authour": 69, "auto": [83, 87, 148, 156], "autocorrel": [48, 149, 151, 168], "autoencod": 78, "automag": 69, "automat": [1, 7, 43, 69, 76, 77, 78, 94, 102, 110, 138, 141, 163], "automobil": 81, "autonomi": 68, "autoscal": [9, 47, 134], "autoscale_on": [83, 87], "autotun": 151, "auxiliari": [161, 168], "avail": [4, 9, 22, 28, 30, 44, 45, 48, 49, 51, 53, 61, 69, 78, 82, 86, 87, 88, 90, 99, 109, 124, 126, 128, 135, 138, 139, 142, 143, 144, 149, 152, 155, 157, 158, 159], "availa": 128, "available_cor": 128, "avec": [54, 57], "avec_1": 57, "avec_2": 57, "avenu": 78, "averag": [4, 16, 23, 24, 26, 38, 41, 48, 49, 56, 57, 58, 64, 70, 71, 72, 76, 77, 80, 98, 101, 112, 115, 135, 138, 148, 149, 150, 151, 157, 158, 159, 164, 166, 167], "avg": 156, "avg_lnl": 101, "avoid": [16, 27, 36, 48, 49, 51, 55, 71, 72, 76, 77, 78, 91, 97, 101, 112, 138, 139, 142, 153], "awai": [12, 18, 39, 43, 44, 51, 58, 132, 139, 151, 152, 153, 157, 159, 164], "awar": [52, 66, 68, 86, 93, 111, 161], "award": 72, "awesom": 39, "awkward": 140, "ax": [0, 3, 5, 6, 9, 20, 21, 22, 30, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 54, 55, 58, 70, 75, 78, 82, 83, 86, 87, 88, 93, 98, 100, 101, 107, 130, 131, 132, 134, 135, 137, 138, 139, 140, 141, 148, 149, 151, 152, 154, 157, 158, 161, 166, 167], "ax1": [22, 42, 44, 83, 87, 131, 132, 139, 149, 157], "ax2": [5, 22, 42, 44, 83, 87, 131, 132, 139, 149, 157], "ax2_1": 42, "ax2_2": 42, "ax2_3": 42, "ax2_4": 42, "ax3": [22, 42, 131, 132, 149], "ax3d": 135, "ax4": 42, "ax_1": [22, 47], "ax_2": [22, 47, 155], "ax_3": [22, 47], "ax_4a": 155, "ax_4b": 155, "ax_4c": 155, "ax_4d": 155, "ax_5a": 155, "ax_c": 154, "ax_pass": 140, "ax_plot": [150, 167], "ax_run": [161, 166], "ax_trac": [150, 167], "ax_tru": 42, "axes3d": [55, 70], "axhlin": [42, 131, 152, 155, 156, 157], "axi": [9, 22, 38, 41, 42, 43, 44, 45, 47, 55, 70, 71, 78, 82, 83, 86, 87, 93, 98, 99, 101, 128, 131, 132, 135, 139, 140, 141, 143, 147, 151, 154, 157, 161, 166], "axiom": [8, 16, 29], "axiomat": [30, 67], "axis_label": 154, "axs_vec": [30, 35], "axvlin": [9, 42, 47, 131, 132, 135, 149, 152, 157], "az": [156, 157], "azim": 70, "b": [0, 1, 4, 9, 13, 22, 26, 27, 28, 30, 36, 39, 41, 42, 43, 45, 46, 47, 49, 51, 52, 54, 67, 69, 70, 72, 73, 75, 76, 77, 78, 80, 81, 82, 83, 87, 88, 95, 97, 98, 100, 101, 119, 120, 122, 128, 130, 131, 132, 135, 138, 139, 140, 148, 149, 151, 156, 159], "b1": [22, 131], "b2": 22, "b_": [41, 100], "b_0": 41, "b_1": [117, 135], "b_2": 135, "b_grid": 42, "b_i": [72, 135], "b_j": [72, 73, 135], "b_k": 132, "b_m": 72, "b_margin": [41, 42], "b_max": 42, "b_n": [39, 117, 135], "b_pt": 42, "b_std": 134, "b_true": 42, "b_true_fix": [41, 42], "b_true_index": 42, "b_x": 58, "b_y": 58, "ba": 1, "ba524": 1, "baath": 131, "bacciagaluppi": 133, "back": [1, 8, 9, 10, 11, 16, 22, 30, 35, 41, 45, 56, 58, 68, 70, 71, 72, 75, 76, 80, 83, 84, 87, 93, 98, 132, 139, 140, 148, 151, 156, 158, 159, 164], "backend": [78, 139], "background": [4, 8, 16, 29, 30, 43, 48, 58, 61, 67, 68, 95, 100, 101, 127, 159, 163, 165], "backpropag": 77, "backtick": 0, "backward": [15, 72, 73, 76, 77, 132, 151, 153], "bacteri": 166, "bacteria": 166, "bad": [24, 46, 71, 78, 81], "badli": [53, 156], "bag": 16, "baggin": 138, "bailei": 131, "baishan": 1, "balanc": [56, 58, 68, 71, 153, 158], "ball": [4, 16, 125, 152, 157], "balldrop": 126, "balzac": 50, "banana": [4, 158, 159], "band": [22, 52, 53, 84, 87, 91, 99, 161], "bandwidth_factor": 87, "bar": [4, 16, 20, 22, 27, 34, 36, 38, 42, 43, 45, 46, 49, 54, 57, 58, 70, 71, 74, 81, 82, 88, 112, 125, 128, 131, 132, 135, 138, 139, 148, 149, 151, 152, 156, 157], "bare": [41, 56, 68], "barnett": 90, "bartlett": 71, "base": [1, 4, 8, 9, 26, 27, 30, 36, 37, 38, 39, 42, 43, 44, 48, 50, 51, 52, 53, 55, 56, 58, 63, 67, 68, 69, 71, 72, 74, 76, 77, 82, 83, 87, 88, 93, 94, 97, 98, 100, 101, 105, 106, 112, 118, 122, 124, 128, 129, 135, 138, 139, 140, 142, 143, 145, 148, 149, 152, 153, 156, 157, 158, 159], "baselin": [38, 42, 155], "basi": [1, 4, 18, 27, 50, 52, 58, 67, 68, 70, 81, 84, 85, 90, 91, 93, 105, 106, 107, 115, 126, 127, 130, 132], "basic": [8, 19, 25, 27, 32, 41, 49, 52, 54, 55, 61, 67, 69, 71, 73, 74, 78, 84, 90, 92, 95, 96, 98, 110, 135, 138, 139, 143, 147, 151, 153, 154, 158, 161, 163, 164, 167, 168], "basic_model": [156, 163], "basic_model_alt": 156, "batch": [71, 72, 73, 81, 93, 102], "batch_siz": [74, 78, 111], "bay": [1, 7, 8, 9, 13, 15, 16, 18, 24, 25, 29, 32, 35, 37, 39, 40, 41, 42, 44, 46, 47, 48, 49, 54, 57, 58, 60, 61, 63, 64, 67, 90, 93, 100, 149, 152, 156, 157, 163], "bayes_text": 9, "bayesian": [1, 2, 11, 12, 13, 14, 17, 18, 20, 23, 25, 26, 28, 29, 30, 33, 34, 40, 41, 42, 45, 47, 49, 50, 51, 52, 54, 55, 57, 61, 62, 63, 65, 67, 69, 84, 90, 91, 93, 94, 95, 96, 99, 101, 102, 105, 106, 108, 115, 118, 121, 122, 124, 125, 126, 127, 128, 129, 131, 135, 147, 148, 149, 150, 156, 159, 166, 167, 168], "bayesian_7": 156, "bayesian_cr_slope_max": 46, "bayesian_cr_slope_min": 46, "bayesian_neural_network_advi": [78, 98], "bayesian_neural_networks_tif285": 98, "bayesian_research_cycl": 0, "bayesian_slope_maxprob": 46, "bayesian_slope_mean": 46, "bayesianastronomi": [42, 45], "bayesianoptim": 97, "bayesianworkflow": 0, "baysian": 77, "bbox": [100, 131], "bbox_inch": [154, 155], "bbox_to_anchor": 86, "bckw15": [1, 77], "bda": [56, 151], "bda3": [0, 1, 39, 56, 58], "beach": [152, 157], "beam": 56, "bearer": 8, "beat": 78, "beaten": 67, "becaus": [5, 13, 20, 24, 28, 30, 36, 38, 39, 41, 43, 44, 45, 47, 48, 52, 53, 54, 56, 57, 58, 63, 67, 68, 71, 76, 77, 80, 81, 82, 83, 85, 87, 88, 100, 102, 130, 132, 140, 141, 148, 149, 151, 152, 153, 157, 159, 164], "bechmark": 78, "becom": [0, 4, 7, 18, 21, 22, 24, 30, 38, 39, 41, 44, 49, 50, 51, 53, 57, 58, 67, 69, 70, 71, 72, 77, 78, 82, 83, 87, 88, 90, 91, 94, 100, 102, 104, 105, 110, 112, 118, 125, 126, 127, 138, 139, 141, 152, 157, 158, 159, 161, 166], "been": [4, 8, 20, 24, 30, 32, 36, 48, 49, 51, 52, 53, 54, 58, 61, 64, 66, 68, 69, 71, 72, 77, 78, 85, 105, 112, 124, 128, 131, 142, 151, 156, 159, 163], "befor": [0, 8, 9, 10, 16, 18, 28, 29, 30, 36, 39, 44, 45, 47, 48, 49, 53, 57, 58, 64, 68, 70, 71, 72, 73, 74, 76, 80, 81, 82, 83, 85, 86, 87, 88, 93, 102, 110, 132, 135, 138, 141, 147, 148, 152, 153, 155, 157, 164], "beforehand": [58, 149, 158], "begin": [0, 3, 4, 7, 8, 9, 13, 15, 16, 18, 19, 20, 21, 24, 27, 29, 30, 39, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 54, 56, 58, 68, 70, 71, 72, 73, 76, 77, 80, 82, 83, 84, 87, 88, 90, 91, 93, 100, 102, 104, 105, 107, 108, 109, 111, 112, 118, 125, 128, 130, 132, 135, 137, 138, 139, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 166, 167], "beginn": 74, "behav": [18, 128, 159], "behavior": [11, 42, 49, 55, 58, 69, 76, 84, 95, 101, 126, 134, 138, 149], "behaviour": [58, 72, 73, 90], "behind": [16, 58, 68, 100, 138, 153], "being": [4, 16, 18, 24, 26, 27, 28, 30, 36, 37, 38, 39, 44, 45, 48, 49, 51, 52, 53, 58, 61, 63, 68, 69, 71, 72, 73, 76, 78, 82, 88, 90, 93, 94, 98, 122, 127, 131, 135, 142, 148, 149, 151, 152, 157, 159, 161, 163, 164], "belatedli": 28, "belief": [8, 10, 11, 15, 16, 22, 24, 27, 30, 39, 46, 48, 51, 66, 68, 135, 149], "believ": [10, 11, 30, 39, 47, 53, 62, 66, 68, 78, 115, 132], "bell": [131, 139], "belong": [67, 68, 70, 74, 77, 87, 91, 93, 130, 166], "below": [0, 4, 7, 20, 21, 22, 24, 26, 27, 38, 39, 43, 44, 48, 49, 51, 52, 55, 56, 58, 65, 68, 70, 71, 72, 74, 75, 77, 78, 81, 82, 83, 87, 88, 90, 97, 98, 100, 101, 105, 107, 125, 126, 131, 132, 135, 138, 139, 141, 147, 149, 150, 151, 155, 156, 158, 161, 164, 166, 167], "benchmark": 78, "benefici": 158, "benefit": [52, 61, 68, 71, 76], "benign": 71, "berg": 138, "bernardo": 1, "bernardo94": 53, "bernoulli": [8, 9, 78, 98], "besid": [16, 47, 91, 156], "best": [0, 4, 5, 8, 9, 11, 18, 20, 21, 22, 23, 24, 30, 34, 35, 39, 41, 43, 52, 55, 56, 58, 60, 64, 67, 70, 71, 72, 75, 76, 79, 84, 91, 93, 96, 97, 100, 102, 109, 111, 126, 128, 135, 139, 142, 147, 158, 159, 166, 167], "bet": [8, 30, 139], "beta": [9, 23, 24, 35, 39, 43, 46, 50, 52, 55, 56, 101, 128, 131, 132, 135, 138, 149, 161], "beta0": 39, "beta1": 39, "beta1_label": 22, "beta2_dist": 22, "beta2_label": 22, "beta_": 56, "beta_0": 39, "beta_1": [9, 35, 39, 163], "beta_1_w": 9, "beta_2": [9, 56, 163], "beta_2_w": 9, "beta_3": 9, "beta_3_w": 9, "beta_dist": 22, "beta_grid": 39, "beta_i": [39, 50, 52, 56, 163], "beta_n": 56, "beta_sampl": 22, "beta_v": 128, "betai": 39, "betas0": 101, "betavec": 52, "better": [0, 4, 5, 7, 8, 28, 30, 34, 36, 38, 39, 41, 44, 45, 47, 51, 52, 58, 68, 70, 71, 72, 74, 75, 76, 78, 80, 82, 84, 88, 90, 97, 98, 101, 102, 115, 122, 128, 130, 135, 138, 140, 152, 153, 155, 156, 157, 158, 159], "betti": [26, 67], "between": [0, 4, 9, 11, 15, 16, 18, 19, 20, 24, 26, 27, 28, 30, 31, 35, 39, 41, 42, 43, 45, 47, 48, 49, 51, 53, 56, 57, 58, 61, 64, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 81, 82, 83, 88, 90, 91, 93, 97, 98, 100, 101, 102, 109, 110, 115, 119, 121, 122, 124, 125, 128, 131, 135, 138, 139, 141, 143, 148, 151, 153, 156, 158], "beutler": 168, "bewar": 27, "beyond": [8, 24, 31, 52, 53, 58, 67, 83, 124, 150, 167], "bf": [54, 126, 128], "bf02551274": 1, "bfg": 97, "bgd": 111, "bgjm11": [1, 49], "bi": [39, 56, 87], "bia": [1, 24, 30, 39, 69, 70, 72, 73, 76, 77, 79, 82, 88, 93, 98, 100, 102, 104, 112, 122, 134], "bianca": 1, "bias": [9, 16, 28, 30, 35, 44, 64, 66, 69, 72, 73, 76, 77, 80, 98, 122, 124, 152, 157, 166], "bias_std": 134, "bib": 0, "bibtex": 0, "bic": 56, "bicyclist": 69, "bienaym\u00e9": 51, "big": [39, 65, 69, 105, 122, 159, 161], "bigg": [39, 50, 105], "bigger": [47, 61, 73], "biggest": 68, "biggl": [84, 91], "biggr": [84, 91], "bigl": [4, 24, 29, 34, 39, 41, 52, 56, 84, 91, 122, 153, 164], "bigr": [4, 24, 29, 34, 39, 41, 52, 56, 84, 91, 122, 153, 164], "bilbo": 138, "billiard": 43, "billion": 72, "bimod": [22, 72, 135], "bin": [4, 22, 24, 34, 38, 41, 42, 46, 47, 55, 87, 101, 131, 134, 135, 148, 149, 150, 151, 156, 161, 167], "bin_arrai": 38, "bin_bound": 47, "bin_edg": 131, "bin_num": [150, 167], "bin_width": [38, 47], "binari": [9, 35, 68, 69, 71, 74, 76, 77, 78, 79, 81, 98, 138], "binary_classification_data_fig": 70, "binarygibbsmetropoli": 156, "binarymetropoli": 156, "bind": 159, "binder": 142, "binomi": [13, 24, 30, 38], "biolog": [53, 72, 93, 115], "biologi": [1, 51], "bipoc": 68, "bird": 81, "birth": 138, "bit": [9, 11, 24, 43, 56, 142, 152, 157], "bitrat": 131, "bivari": [18, 49, 58, 77, 87, 91, 125, 158, 161, 166], "bivariate_fig": 135, "bla": 141, "black": [7, 22, 28, 39, 42, 43, 45, 47, 52, 65, 68, 70, 86, 93, 107, 122, 128, 131, 140, 150, 155, 167, 168], "blank": 37, "blei": [1, 77], "blind": [20, 135], "blindli": 156, "block": [21, 69, 71, 74, 90, 135, 138], "blockedstep": 156, "blog": [43, 77, 78, 98, 112, 131, 132, 139, 149, 153, 158, 159], "blond": 4, "bloodi": 67, "blow": 122, "blown": 96, "blr": [16, 33, 105, 108, 118], "blue": [5, 9, 22, 28, 35, 36, 37, 38, 39, 42, 43, 45, 47, 49, 52, 54, 70, 71, 74, 77, 80, 81, 84, 85, 93, 98, 100, 107, 126, 131, 132, 137, 139, 148, 149, 150, 152, 155, 157, 159, 167, 168], "blundel": 1, "bmatrix": [39, 93, 105], "bmax": 101, "bmc": 1, "bn": 100, "bnn": 94, "bnn_binary_classifier_mean": 77, "bnn_binary_classifier_stddev": 77, "bo": 158, "bob": 141, "bodi": [16, 50, 67, 69, 115, 119, 131], "boh": 126, "bohr": 30, "boil": 8, "bold": [39, 104, 115, 139], "boldfac": [98, 122, 132], "boldsymbol": [0, 7, 9, 18, 35, 39, 49, 70, 71, 72, 73, 77, 79, 83, 87, 93, 101, 102, 105, 109, 110, 111, 125, 128, 132, 135, 138, 158, 161, 166], "boltzman": 56, "boltzmann": [4, 5, 49, 56, 72], "bon": 39, "bonu": [43, 95, 101], "book": [1, 9, 28, 44, 45, 47, 55, 63, 64, 67, 68, 77, 80, 86, 100, 101, 131, 136, 145, 157], "boolean": [30, 35, 128, 132, 141, 158], "boost": [72, 78], "boot": 81, "bootstrap": [15, 49, 78], "border": [47, 137, 139, 164], "bore": 56, "bori": [1, 61], "born": 28, "borrow": 138, "boson": [24, 135], "both": [4, 7, 11, 20, 24, 27, 30, 36, 38, 39, 42, 43, 45, 48, 49, 52, 53, 55, 58, 61, 64, 68, 70, 71, 72, 76, 77, 79, 82, 85, 86, 90, 98, 102, 111, 112, 115, 118, 124, 125, 126, 130, 131, 135, 137, 138, 139, 141, 147, 148, 149, 150, 153, 155, 156, 164, 165, 166, 167], "bother": [8, 53], "bottleneck": 110, "bottom": [10, 11, 22, 38, 42, 58, 99, 131, 159, 164], "bought": 8, "bound": [24, 39, 43, 47, 51, 52, 58, 72, 87, 97, 105, 128, 149], "boundari": [39, 52, 75, 77, 78, 79, 149, 158, 164], "bovin": 67, "bower": 1, "bowl": 153, "box": [0, 4, 9, 16, 22, 24, 37, 48, 52, 55, 61, 65, 70, 113, 122, 137, 139, 142, 164, 168], "br": 9, "bra": 52, "bracket": [82, 88], "bragg": 20, "brain": [1, 67, 72, 93], "braket": 52, "branch": [8, 48], "brand": 78, "break": [0, 3, 27, 53, 76, 138, 139], "breakdown": 76, "bremen": [85, 86], "breviti": 135, "brewer": [0, 28], "bridg": 1, "brief": [53, 58, 127, 130, 139, 163], "briefli": [16, 28, 53, 69, 102, 138], "bring": [67, 68], "british": 68, "broad": [39, 44, 46, 52, 58, 69, 152, 157], "broaden": [64, 116], "broader": [109, 117], "broadli": [50, 53, 61, 66, 94, 130], "broken": 64, "brook": 1, "brown": [27, 37], "brownian": [82, 88, 166], "browser": 139, "bruno": 51, "brynjarsd\u00f3ttir": 124, "bs06": [1, 49], "bsd": [85, 86], "bubnov": 52, "bufsiz": 131, "bug": [67, 97, 138, 139], "build": [1, 4, 7, 28, 39, 47, 50, 52, 53, 66, 67, 68, 69, 70, 71, 75, 78, 79, 82, 88, 90, 94, 98, 100, 134, 139, 142, 153, 159], "build_model": 134, "built": [22, 24, 28, 38, 52, 53, 56, 71, 76, 135, 138, 139, 140, 158], "builtin": [55, 101], "bukov": 1, "bulk": 51, "bullet": [16, 128, 139], "buqey": [0, 1, 127, 132], "burden": 51, "burn": [6, 43, 55, 94, 101, 128, 150, 151, 152, 156, 157, 159, 164, 167], "burnin": [55, 157], "busi": 68, "bution": 48, "button": [5, 9, 137, 139, 142, 143], "button_styl": 9, "bv": 119, "bvec": 57, "bx": 132, "byte": [74, 138], "b\u00e5\u00e5th": 131, "c": [0, 1, 3, 11, 16, 26, 39, 41, 43, 49, 54, 55, 56, 58, 61, 69, 70, 71, 72, 73, 75, 76, 77, 78, 82, 83, 84, 87, 88, 91, 93, 97, 98, 102, 105, 109, 110, 111, 112, 118, 125, 128, 131, 132, 135, 136, 138, 139, 142, 147, 151, 155, 156, 161, 166], "c0": 128, "c2pread": 131, "c2pwrite": 131, "c41": 138, "c_": [71, 75, 87, 90, 105, 111], "c_0": 84, "c_1": 16, "c_2": 16, "c_i": 51, "c_k": 16, "c_n": [110, 111], "c_w": 77, "cal": [53, 73], "calcul": [0, 7, 9, 13, 16, 20, 24, 27, 36, 38, 39, 42, 44, 47, 48, 49, 51, 52, 55, 57, 70, 72, 73, 76, 77, 91, 96, 100, 101, 106, 127, 128, 130, 131, 135, 137, 138, 139, 141, 148, 150, 151, 152, 153, 155, 156, 157, 159, 161, 163, 164, 167], "calculu": [0, 8, 16, 24, 63, 64, 159, 166], "calibr": [48, 49, 50, 52, 71, 82, 84, 91, 115, 124, 126, 127, 149, 156], "call": [0, 3, 8, 9, 11, 12, 15, 16, 19, 22, 23, 24, 28, 30, 34, 36, 39, 42, 43, 45, 49, 51, 52, 55, 57, 58, 60, 64, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 83, 84, 91, 93, 98, 99, 100, 101, 102, 105, 107, 109, 115, 130, 131, 132, 135, 137, 138, 139, 140, 141, 142, 148, 149, 150, 152, 153, 155, 156, 157, 158, 159, 161, 166, 167, 168], "callabl": [128, 149], "callback": [9, 131], "cambridg": [1, 61], "camco": 1, "camp": 58, "can": [0, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 90, 91, 93, 94, 95, 97, 98, 99, 100, 101, 102, 105, 106, 107, 109, 110, 111, 112, 115, 116, 117, 118, 120, 122, 124, 127, 128, 129, 130, 131, 132, 133, 135, 136, 138, 139, 140, 141, 142, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 166], "canada": 1, "cancel": [4, 49, 56, 57, 58, 71, 149], "candid": [4, 30, 60, 68, 109, 158, 159, 164], "cannot": [20, 24, 26, 30, 39, 48, 51, 52, 58, 68, 70, 78, 98, 105, 108, 135, 139], "canon": [49, 53, 153], "canva": 131, "cap": [27, 71, 135], "capabl": [22, 69, 109], "caprici": 27, "capsiz": 128, "caption": [0, 161], "captur": [48, 49, 51, 52, 68, 71, 72, 76, 124, 126, 148], "car": [16, 69, 78], "card": 37, "care": [5, 8, 16, 22, 28, 36, 37, 41, 42, 48, 52, 56, 63, 77, 78, 95, 132, 135, 138, 140, 141], "carefulli": [48, 51, 61], "carl": [1, 90], "carlin": 1, "carlo": [1, 16, 18, 48, 69, 77, 101, 128, 150, 152, 156, 157, 162, 164, 165, 166, 167, 168], "carlsson": 61, "carmak": 69, "carmen": [147, 153], "carri": [13, 39, 42, 48, 49, 54, 58, 64, 65, 66, 67, 71, 91, 93, 122, 126, 149, 150, 159, 167], "carrol": 63, "cartesian": 155, "cartoon": 56, "case": [0, 8, 9, 10, 16, 18, 21, 23, 26, 27, 28, 30, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 48, 49, 52, 53, 54, 57, 58, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 84, 85, 91, 93, 97, 98, 100, 101, 102, 105, 106, 107, 108, 110, 115, 120, 122, 125, 128, 132, 135, 138, 139, 141, 142, 147, 149, 151, 152, 153, 156, 157, 158, 159, 161, 164, 168], "casino": 166, "cast": [52, 65, 72], "cat": [81, 122], "categor": [26, 48, 50, 69, 77, 115], "categori": [8, 52, 68, 69, 70, 72, 80, 93, 109, 129], "categoricalgibbsmetropoli": 156, "cauchi": [47, 131, 149], "cauchy_dist": 47, "cauchypropos": 156, "caus": [15, 36, 43, 53, 58, 67, 71, 76, 110, 111, 131, 156, 159], "causal": 67, "caution": [7, 46, 140], "caveat": 142, "cbar": [55, 78, 98, 128], "cbarbieri": 50, "cbo9780511790423": 1, "cbo9780511791277": 1, "cbook": 131, "cc": [39, 48, 72, 83, 108, 138, 161], "ccc": [72, 161], "cccc": 132, "cd": [142, 145], "cdf": 97, "cdot": [13, 16, 24, 28, 36, 37, 38, 39, 47, 49, 50, 52, 53, 54, 57, 70, 72, 76, 93, 99, 125, 128, 132, 141, 147, 148, 151, 161, 164], "ceil": 141, "celebr": 51, "cell": [20, 42, 47, 55, 70, 74, 75, 78, 98, 101, 131, 138, 140, 143, 147, 149, 156, 158], "cent": 8, "center": [8, 11, 24, 38, 39, 41, 42, 47, 55, 58, 77, 78, 79, 93, 130, 131, 132, 135, 148, 149, 155], "central": [29, 31, 47, 48, 69, 99, 125, 133, 134, 155, 159], "centrifug": 155, "centuri": [8, 58, 67, 115], "certain": [7, 11, 15, 39, 48, 50, 51, 53, 63, 68, 77, 78, 80, 93, 100, 109, 124, 138, 141, 149, 158, 161], "certainli": [49, 69, 72, 110, 139, 140, 152, 157, 166], "certainti": [8, 16, 48, 77], "cf": [24, 36, 37, 41, 56, 57, 78, 84, 90, 91, 98, 127, 153, 159, 164], "cft": 38, "cft_n": 38, "cft_n_pt": 38, "ch": [43, 44, 58, 157], "chain": [1, 6, 16, 18, 43, 46, 48, 56, 64, 72, 74, 76, 101, 128, 149, 150, 151, 152, 153, 156, 157, 164, 165, 166, 167, 168], "chain1": [55, 148], "chain1d": [148, 149], "chain2": [55, 148], "chain_data": 128, "chain_length": 156, "chainpandasindexpandasindex": 156, "challeng": [8, 16, 39, 49, 53, 56, 58, 78, 93, 97, 112, 115, 118, 124, 127, 159], "chalmer": [1, 61, 83], "champion": 78, "chanc": [16, 24, 30, 77, 149, 164], "chang": [3, 4, 9, 11, 13, 16, 17, 22, 27, 29, 30, 35, 38, 39, 41, 42, 44, 45, 48, 50, 52, 54, 56, 58, 61, 63, 66, 69, 72, 73, 76, 78, 82, 84, 88, 91, 97, 98, 99, 100, 101, 127, 128, 131, 132, 136, 137, 138, 139, 140, 147, 148, 149, 151, 153, 154, 155, 156, 157, 158, 161, 163, 164], "channel": [70, 78, 80, 81, 93, 142], "chapman": [0, 1, 61], "chapter": [2, 7, 16, 17, 25, 31, 32, 33, 35, 39, 40, 41, 42, 48, 49, 51, 58, 60, 62, 66, 68, 69, 71, 77, 80, 91, 93, 94, 103, 104, 110, 115, 123, 124, 129, 158, 159, 161, 165], "charact": [9, 138], "character": [8, 16, 17, 22, 24, 41, 48, 52, 71, 72, 84, 99, 111, 116, 127, 130, 131, 148, 152, 157, 159], "characteris": 68, "characterist": [68, 76, 91], "charg": [26, 138], "charl": 1, "chart": 100, "chase": 7, "chatterji": 71, "cheat": 141, "cheatsheet": 139, "chebyshev": 51, "check": [0, 3, 4, 13, 21, 23, 27, 39, 40, 41, 42, 43, 47, 49, 54, 56, 64, 71, 74, 78, 82, 88, 90, 91, 97, 98, 99, 101, 128, 131, 132, 139, 141, 142, 148, 150, 151, 153, 156, 158, 161, 164, 167], "checkabl": 54, "checkbox": [5, 9, 137], "checklist": 33, "checklist_b": 0, "checkmark": 29, "checkpoint": 139, "chess": 84, "chi": [18, 23, 24, 31, 43, 50, 54, 56, 57, 100, 101, 102, 130, 132, 153, 158, 159], "chi2": 34, "chi_": 128, "chi_sqs_dof": 100, "chi_squar": 100, "chief": 64, "child": [50, 131], "child_exception_typ": 131, "children": [9, 68, 137], "chines": [1, 138], "ching": 1, "chiral": [1, 52, 131], "chisq_min": 54, "choic": [4, 8, 9, 15, 16, 22, 24, 28, 30, 35, 43, 44, 45, 46, 48, 49, 51, 58, 68, 69, 70, 71, 72, 76, 79, 82, 85, 88, 97, 99, 100, 105, 111, 112, 118, 122, 125, 135, 139, 143, 149, 152, 157, 158, 161, 164, 166, 168], "choleski": [83, 91], "choos": [5, 7, 13, 24, 41, 43, 45, 46, 47, 48, 49, 51, 52, 53, 58, 63, 67, 68, 71, 72, 74, 76, 77, 82, 88, 109, 110, 139, 148, 149, 150, 151, 158, 167], "chose": [52, 101, 161], "chosen": [0, 7, 30, 41, 51, 52, 55, 56, 58, 82, 88, 90, 110, 149, 150, 156, 158, 159, 167], "chri": [90, 133], "christian": [1, 43, 44, 49, 55, 61, 78, 82, 83, 98, 100, 148, 149, 152, 157], "christoph": [1, 133], "chromosom": 135, "ci": [9, 35, 128], "cifar": 81, "circ": [73, 83], "circl": [4, 39, 41, 43, 72, 77, 83, 158], "circular": 158, "circumst": [8, 24, 48, 68], "circumstanti": 67, "circumv": 58, "citat": [0, 68], "cite": [0, 48, 53, 77], "citizen": 69, "clabel": 135, "claim": [26, 47, 49, 56, 68, 69, 84, 91, 116, 120, 122, 132, 156, 159], "clang": [78, 98], "clariti": [83, 122], "class": [9, 33, 39, 51, 52, 58, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 86, 98, 101, 102, 110, 130, 135, 138, 142, 150, 155, 161, 164, 166, 167], "class_i": 70, "class_mean": 70, "class_mean_list": 70, "class_nam": 81, "class_weight": 75, "classic": [8, 30, 44, 47, 56, 138, 152, 153, 157, 158], "classif": [48, 52, 67, 71, 72, 74, 76, 77, 78, 80, 81, 96, 98], "classifi": [68, 69, 71, 72, 77, 79, 81], "classifier_elbo": [77, 78], "classmat": 39, "claus": [85, 86], "clean": [76, 131], "cleaner": 78, "cleans": 97, "cleanup": 131, "clear": [10, 18, 24, 28, 39, 43, 45, 49, 56, 58, 64, 66, 76, 77, 78, 83, 95, 100, 101, 102, 108, 135, 139, 161], "clearer": [36, 48], "clearli": [7, 12, 39, 43, 48, 66, 68, 71, 78, 80, 84, 106, 161, 164], "clever": [39, 161], "clf": [75, 131, 138], "click": [22, 61, 139, 142, 166], "clickabl": 61, "climat": 51, "climb": 149, "clint": 1, "clip": 43, "clockwis": 132, "clone": [142, 144, 145], "close": [0, 12, 16, 34, 36, 38, 39, 42, 43, 45, 48, 49, 54, 58, 61, 69, 72, 73, 77, 78, 82, 85, 88, 91, 94, 100, 101, 102, 109, 112, 124, 130, 132, 138, 148, 149, 156, 158, 159], "close_fd": 131, "closer": [22, 43, 91, 156], "closest": [9, 18, 35, 42, 58, 70, 132], "cloth": 81, "cloud": [0, 27, 61, 136, 142], "clt": [38, 134], "clt_pdf": 38, "cluster": [52, 67, 71, 153], "cluster_std": 79, "clutter": [24, 91], "cm": [39, 42, 54, 55, 70, 74, 75, 81, 131, 135], "cmap": [39, 42, 45, 55, 70, 74, 75, 78, 81, 98, 132, 135], "cnn": [72, 94], "cntl": 159, "co": [38, 39, 51, 56, 76, 82, 87, 88, 97, 117, 139, 154, 155], "code": [13, 20, 21, 22, 35, 38, 39, 41, 43, 45, 47, 48, 52, 55, 56, 61, 69, 75, 78, 81, 82, 88, 92, 97, 98, 99, 100, 101, 107, 111, 128, 138, 143, 147, 149, 150, 151, 156, 158, 163, 166, 167], "codebas": 48, "codec": 131, "codeloc": [128, 161, 166], "coef": 138, "coef_": [75, 138], "coeffici": [4, 21, 29, 52, 54, 70, 71, 72, 78, 91, 93, 99, 128, 135, 138, 141], "coerc": 138, "coher": [8, 133], "coin": [8, 13, 16, 28, 115, 166], "coin_data": 9, "coin_ppd": 0, "coinflipping_fig_1": 30, "col": [30, 35, 138, 139, 140], "colab": 81, "collabor": [16, 61], "collaps": 57, "collat": 82, "colleagu": [61, 68], "collect": [8, 12, 16, 30, 39, 40, 42, 44, 48, 49, 51, 52, 53, 67, 68, 69, 70, 71, 73, 74, 83, 84, 87, 90, 91, 105, 106, 107, 115, 122, 128, 129, 133, 135, 149, 152, 157, 158, 161, 166], "collid": 26, "collis": 166, "colon": [0, 139], "color": [3, 4, 5, 9, 22, 28, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 54, 68, 70, 71, 74, 76, 78, 80, 81, 82, 83, 85, 86, 87, 88, 93, 98, 100, 107, 125, 128, 131, 132, 135, 137, 139, 140, 148, 149, 150, 152, 154, 155, 157, 161, 166, 167], "color_channel": 81, "colorbar": [39, 55, 74, 78, 83, 87, 98, 157], "colour": 4, "columbia": 1, "column": [18, 36, 37, 39, 43, 50, 70, 100, 105, 107, 130, 133, 138, 139, 141, 148, 149, 151, 158, 161, 164], "com": [1, 78, 85, 86, 98, 132, 135, 140, 142, 145, 166], "combin": [0, 8, 16, 24, 36, 38, 39, 42, 44, 48, 49, 51, 52, 53, 55, 58, 60, 64, 67, 71, 72, 76, 78, 83, 84, 87, 90, 91, 93, 98, 111, 122, 125, 128, 130, 132, 147, 151, 152, 157, 158, 161, 163], "come": [0, 4, 8, 9, 10, 11, 16, 22, 24, 26, 34, 35, 39, 41, 43, 45, 48, 54, 56, 58, 67, 68, 71, 72, 77, 78, 84, 91, 97, 98, 106, 108, 131, 138, 142, 148, 149, 151, 152, 157, 159, 163, 164, 168], "comet": 115, "comfort": [24, 51], "comm": 1, "command": [0, 69, 74, 76, 82, 88, 99, 131, 138, 139, 140, 142, 147, 156], "comment": [22, 24, 41, 42, 45, 48, 54, 55, 56, 58, 70, 78, 101, 132, 139, 155, 159, 163], "commiss": 68, "commit": 68, "common": [0, 7, 11, 21, 24, 31, 39, 43, 45, 46, 48, 49, 51, 52, 53, 58, 61, 63, 65, 67, 70, 71, 72, 73, 75, 78, 81, 83, 87, 90, 91, 93, 100, 102, 104, 110, 115, 118, 122, 131, 135, 137, 138, 140, 141, 153, 154, 155, 156, 158, 159, 166], "common_num": 140, "commonli": [4, 45, 71, 93, 112, 122, 156, 158], "commun": [24, 61, 66, 69, 72, 102, 161], "comp": 1, "compact": [28, 70, 72, 73, 128], "compani": 68, "compar": [1, 6, 7, 9, 11, 14, 20, 22, 24, 34, 35, 39, 42, 43, 47, 48, 49, 52, 55, 56, 58, 68, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 83, 87, 88, 91, 97, 98, 99, 100, 125, 126, 130, 132, 134, 135, 138, 149, 155, 156, 161, 163, 164, 166, 168], "comparison": [16, 18, 22, 38, 39, 43, 48, 52, 56, 57, 67, 78, 98, 100, 107, 112, 121, 124, 131, 149, 151, 155, 161], "compat": [48, 93, 97, 132, 151], "compel": 66, "compet": [7, 53, 58, 66, 67, 69], "competit": 52, "compil": [39, 69, 74, 78, 98, 138], "compl": 71, "complaint": 156, "complementari": 58, "complet": [0, 3, 16, 18, 27, 30, 33, 36, 37, 39, 42, 43, 48, 51, 53, 54, 56, 57, 70, 72, 76, 81, 87, 90, 91, 121, 128, 135, 138, 139, 156, 158, 161, 166], "completemodel": 53, "completenn": 72, "complex": [1, 20, 49, 51, 52, 53, 67, 69, 72, 75, 79, 100, 122, 124, 141, 156, 159], "complianc": 81, "complic": [16, 39, 43, 56, 58, 69, 72, 75, 100, 102, 104, 110, 111, 112, 117, 149, 152, 156, 157, 158, 159], "compon": [46, 52, 58, 69, 76, 90, 129, 130, 151, 154, 155, 159], "compos": [52, 72, 101, 161], "compoundstep": 156, "comprehens": [42, 48], "compress": [52, 130, 138, 139, 141], "compromis": [68, 76], "comput": [1, 5, 9, 11, 16, 24, 30, 35, 39, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 58, 61, 63, 64, 65, 67, 69, 70, 71, 72, 73, 75, 77, 78, 80, 81, 83, 84, 85, 87, 90, 91, 93, 94, 97, 100, 101, 102, 107, 109, 110, 112, 124, 127, 128, 129, 132, 135, 136, 138, 139, 141, 142, 145, 148, 149, 150, 151, 152, 156, 157, 158, 161, 164, 167], "computation": [7, 43, 49, 56, 76, 81, 84, 90, 110, 117, 127], "compute_sigma_level": 46, "compute_test_valu": [78, 98], "concat": 138, "concaten": [55, 101, 128, 139, 143, 167], "concentr": [9, 48, 77, 158], "concept": [1, 28, 29, 43, 48, 53, 66, 71, 78, 82, 88, 122], "conceptu": [24, 53, 71, 72], "concern": [7, 8, 18, 39, 50, 51, 58, 69, 70, 78, 93, 109, 133, 135, 138, 161], "concic": 138, "concis": 71, "conclud": [24, 36, 39, 44, 45, 55, 56, 68, 71, 107, 132, 157], "conclus": [12, 22, 39, 41, 42, 45, 56, 63, 66, 67, 72, 100, 101, 115, 135, 155], "concret": [16, 29, 122, 148, 158, 159], "conda": [75, 76, 78, 98, 139, 147], "condemn": 51, "condens": 48, "condit": [4, 8, 16, 24, 26, 27, 28, 29, 30, 34, 35, 36, 37, 39, 40, 42, 48, 49, 52, 58, 63, 66, 81, 82, 88, 90, 91, 125, 128, 130, 132, 134, 153, 154, 155, 158], "condition": 16, "conduct": [8, 26, 48, 53], "conf": 56, "confid": [9, 11, 16, 22, 30, 31, 34, 35, 46, 48, 51, 58, 60, 81, 82, 85, 88, 93, 126, 152, 157], "config": [78, 98, 134, 142], "configur": [48, 56, 81, 134, 142, 161], "confin": 164, "confirm": [51, 68, 72], "confiur": 151, "conflict": [48, 139], "conform": 67, "confront": [30, 35, 51, 67, 69], "confus": [37, 46, 68, 70, 101], "conisd": 120, "conjectur": 66, "conjug": [9, 39, 45, 49, 57, 100, 131, 141], "conjugaci": 57, "conjunct": 52, "connect": [4, 8, 28, 31, 38, 49, 51, 53, 56, 65, 66, 68, 71, 72, 73, 74, 78, 80, 95, 101, 112, 122, 132, 140], "consecut": 141, "consensu": [48, 66], "consequ": [8, 29, 38, 39, 40, 50, 51, 52, 63, 66, 68, 70, 71, 72, 73, 134, 149, 151, 154, 158], "conserv": [19, 49, 84, 126, 153, 156], "consid": [3, 4, 5, 6, 7, 8, 9, 10, 16, 18, 19, 20, 24, 27, 30, 31, 34, 38, 39, 42, 43, 44, 48, 49, 50, 51, 52, 53, 54, 57, 58, 62, 67, 68, 69, 70, 71, 72, 73, 77, 78, 79, 80, 82, 87, 90, 91, 93, 98, 101, 104, 105, 109, 110, 115, 116, 119, 120, 122, 128, 129, 130, 135, 149, 152, 153, 154, 155, 157, 159, 161, 163, 164, 165, 166], "consider": [10, 53, 56, 66, 67, 76, 105], "considerd": 128, "consist": [4, 8, 22, 27, 37, 39, 48, 52, 53, 54, 56, 58, 63, 64, 67, 70, 71, 72, 74, 76, 77, 79, 80, 84, 98, 126, 128, 131, 139, 141, 147, 150, 161, 167], "consolid": 134, "consruct": 78, "constant": [3, 4, 5, 13, 18, 20, 30, 38, 39, 41, 42, 43, 45, 46, 47, 48, 50, 54, 56, 58, 72, 78, 83, 85, 90, 93, 95, 98, 99, 100, 101, 104, 107, 120, 125, 126, 127, 128, 135, 138, 139, 148, 149, 153, 158, 159, 164, 166], "constant_": 76, "constant_valu": 87, "constantkernel": [86, 87], "constantli": 159, "constitu": 138, "constitut": [12, 71, 77, 90], "constrain": [44, 45, 51, 52, 57, 58, 65, 71, 78, 80, 82, 88, 90, 116, 124, 126, 152, 157, 161], "constrain_posit": [82, 88], "constrained_layout": [128, 131], "constraint": [4, 8, 34, 43, 48, 51, 52, 71, 82, 88, 109, 131, 161, 166], "construct": [0, 8, 18, 23, 26, 27, 30, 43, 44, 48, 49, 50, 51, 52, 53, 54, 55, 58, 69, 70, 72, 75, 77, 78, 82, 87, 88, 90, 101, 115, 124, 134, 135, 139, 140, 151, 152, 154, 156, 157, 158, 161], "construct_nn": [78, 98], "constructor": 76, "consum": [65, 68], "contact": 138, "contain": [8, 9, 15, 18, 22, 24, 30, 35, 46, 49, 51, 53, 67, 72, 74, 77, 78, 80, 81, 93, 98, 116, 128, 132, 135, 138, 141, 147, 152, 156, 157, 158, 161], "contemp": 1, "contemporari": 153, "content": [9, 48, 61, 96, 124, 127, 130, 137, 138, 141, 142], "context": [2, 4, 16, 18, 27, 28, 34, 39, 48, 49, 52, 53, 55, 58, 62, 63, 64, 65, 66, 68, 70, 71, 76, 77, 82, 88, 90, 101, 109, 115, 116, 129, 130, 135, 151, 155, 156, 163], "contextlib": 131, "contextmanag": 131, "contigu": 141, "contin": 91, "conting": [4, 10, 26, 27, 28, 63, 129], "continu": [1, 9, 11, 16, 22, 25, 27, 28, 29, 30, 31, 49, 51, 52, 53, 54, 58, 68, 69, 70, 71, 72, 76, 77, 87, 91, 93, 102, 106, 110, 127, 156, 158, 159, 161, 164, 166], "continuo": 70, "continuosli": 69, "continuous_upd": [9, 137], "continuum": [4, 28, 35, 48], "contour": [41, 42, 45, 46, 49, 55, 58, 70, 75, 78, 83, 87, 98, 135, 156, 157], "contour_func": [55, 157], "contour_level": [42, 45, 46], "contourf": [39, 42, 45, 55, 70, 75, 78, 98], "contract": 132, "contradict": [27, 66], "contrari": [44, 64, 152, 157], "contrast": [8, 17, 31, 34, 41, 54, 67, 72, 77, 126, 166], "contribut": [43, 56, 57, 58, 61, 66, 69, 90, 138, 158], "contributor": 69, "control": [1, 9, 11, 52, 69, 75, 76, 79, 81, 85, 99, 125, 138, 147], "controversi": [44, 152, 157], "conv": 80, "conv2d": [76, 81], "conv2d_1": 81, "conv2d_2": 81, "convei": 52, "conveni": [39, 41, 42, 43, 44, 45, 46, 52, 54, 72, 73, 78, 122, 137, 139, 148, 152, 157], "convent": [0, 39, 52, 58, 72, 106, 121, 132, 137, 139, 159], "convention": [28, 139], "converg": [5, 12, 30, 46, 48, 51, 54, 73, 76, 78, 86, 97, 98, 110, 111, 112, 156, 157, 158, 164, 165, 168], "convergencewarn": [55, 86], "convers": [24, 133, 135, 161], "convert": [24, 47, 53, 74, 138, 139, 141, 156], "convex": [93, 102, 109], "convexhul": 154, "convinc": [4, 16], "convolut": [18, 20, 76, 78, 94], "cookbook": 91, "coolwarm": [70, 135], "coordin": [8, 45, 52, 58, 70, 101, 132, 148, 153, 155, 156], "copi": [9, 49, 81, 83, 98, 101, 138, 140, 147, 148, 149, 156, 159, 164], "copyright": 81, "core": [8, 128, 138, 156], "cornebis": 1, "corner": [7, 8, 22, 30, 41, 43, 46, 55, 56, 77, 79, 87, 99, 101, 128, 135, 142, 147, 148, 151, 152, 157, 161, 166], "cornerplot": [55, 157], "corollari": 15, "corrcoef": 141, "correct": [12, 16, 18, 20, 27, 28, 48, 53, 56, 57, 58, 70, 71, 74, 81, 90, 91, 112, 120, 122, 138, 139, 147, 153, 158, 159, 164], "correctli": [16, 23, 39, 74, 106, 140, 141, 152, 155, 157, 164], "correl": [0, 4, 20, 29, 48, 49, 51, 52, 55, 69, 72, 78, 83, 87, 90, 91, 98, 99, 115, 122, 125, 132, 141, 149, 158, 159, 164, 166, 168], "corrent": 110, "correspond": [4, 18, 20, 21, 29, 30, 39, 42, 43, 46, 48, 49, 51, 52, 53, 55, 58, 65, 66, 70, 71, 72, 73, 75, 77, 79, 80, 81, 82, 83, 86, 87, 88, 91, 93, 101, 102, 104, 105, 106, 107, 110, 111, 112, 117, 118, 120, 122, 125, 126, 132, 135, 138, 139, 141, 149, 151, 154, 158, 161, 166], "correspondingli": 72, "cortex": 72, "cosh": 76, "cosin": [38, 39, 139], "cosineft": 38, "cosineft2": 38, "cosmo": 56, "cosmolog": 56, "cosmologi": [1, 26, 45, 100], "cosmologist": 164, "cost": [39, 49, 50, 51, 56, 58, 68, 69, 71, 72, 74, 75, 77, 90, 102, 105, 109, 110, 111, 112, 118, 128, 159], "cost_funct": 111, "costli": [49, 78, 110], "couch": [63, 67], "could": [3, 5, 8, 9, 11, 24, 26, 27, 30, 39, 48, 49, 51, 52, 53, 56, 57, 58, 63, 66, 70, 71, 72, 75, 77, 78, 80, 82, 88, 93, 101, 102, 106, 109, 110, 115, 116, 120, 124, 129, 131, 135, 137, 138, 140, 149, 151, 156, 158, 159, 161, 163], "coulomb": [39, 104, 138], "count": [4, 8, 9, 22, 38, 41, 42, 44, 47, 65, 72, 122, 128, 131, 138, 148, 157], "countabl": [91, 109, 135, 161], "counter": [16, 44, 47, 68, 132, 152, 157], "counterexampl": 161, "counterpart": [36, 93], "coupl": [28, 31, 45, 52, 57, 58, 122, 127, 139], "courag": 66, "cours": [1, 4, 24, 30, 35, 36, 39, 43, 44, 45, 55, 61, 68, 77, 82, 84, 93, 96, 99, 100, 102, 105, 139, 143, 148, 149, 152, 157], "cov": [29, 39, 51, 55, 70, 83, 87, 100, 132, 135, 148, 151, 166], "cov_exp": 128, "cov_mat": 54, "cov_matrix": 128, "cov_new": 87, "cov_opt": 87, "cov_rbf": [83, 87], "cov_tot": 128, "covari": [4, 18, 29, 39, 46, 51, 52, 54, 58, 77, 84, 85, 91, 97, 100, 124, 125, 126, 128, 130, 151, 153, 158, 166], "covariancematrix": 87, "cover": [24, 49, 68, 77, 121, 126, 128, 139, 159], "coverag": [94, 158], "covparslr": 39, "covr": 39, "cow": 26, "cox": [1, 27, 36, 37], "cox61": [1, 27], "cprob": [16, 26, 27, 51, 135, 161], "cpu": [43, 46, 55, 78, 98, 128, 141, 148, 168], "cpu_affin": 128, "cpu_count": 128, "cr": [43, 46], "crank": 156, "crash": [69, 143], "crc": [0, 1, 61], "creat": [6, 18, 39, 41, 42, 43, 45, 46, 52, 69, 70, 71, 72, 76, 78, 79, 80, 82, 85, 86, 87, 88, 93, 97, 98, 99, 100, 107, 116, 128, 131, 132, 134, 135, 139, 145, 148, 149, 153, 154, 156, 158, 159, 161, 166], "create_multiple_process": [161, 166], "created_at": 156, "creation": [78, 140, 141], "creationflag": 131, "creativ": 61, "cred68": [9, 22, 35, 131], "cred95": [9, 22, 35, 131], "credibl": [9, 22, 23, 31, 35, 46, 48, 49, 67, 87, 91, 99, 131], "credible_range_dist": 87, "credibleregions_fig": 135, "credit": 148, "creep": 68, "cri": 67, "cricl": 75, "crime": 68, "crimin": 68, "crit": 24, "criterion": [58, 76, 153, 158, 159], "critic": [8, 43, 48, 58, 66, 68, 69, 71, 72, 76, 78, 122, 133, 135, 141, 153], "cross": [4, 52, 56, 69, 70, 72, 75, 77, 133], "crossval_err": 100, "croupier": 166, "crowd": 71, "crucial": [16, 27, 48, 53, 58, 68, 76], "crudest": 155, "cs231": 80, "cset": [55, 157], "csr": 141, "csr_matrix": 141, "cstride": [42, 70], "csv": 82, "cubehelix_palett": [78, 98], "cubehelix_r": 55, "cubic": 58, "cubism": 133, "cuda": 76, "cultur": [68, 166], "cumsum": [42, 45, 46, 132, 138, 141], "cumul": [49, 132, 141], "cup": [27, 135], "cup_": 135, "current": [9, 26, 30, 39, 49, 51, 54, 55, 56, 58, 72, 74, 76, 81, 82, 88, 100, 112, 139, 142, 148, 149, 153, 156, 158, 159, 161], "current_posit": [149, 164], "curs": 158, "cursor": 139, "curv": [22, 24, 43, 52, 76, 83, 87, 125, 131, 132, 134, 135, 149, 166], "curvatur": [39, 46], "cusp": 78, "custom": [78, 128, 158], "cut": [20, 22, 54, 57, 58, 100, 138, 140], "cutoff": [42, 43, 45, 46, 51], "cv": [69, 71, 75, 100], "cwd": 131, "cxxflag": [78, 98], "cyb89": [1, 72], "cybenko": 1, "cycl": [48, 72], "cycle_b": 0, "cycler": 54, "d": [0, 1, 3, 8, 9, 10, 11, 15, 16, 18, 20, 21, 22, 24, 28, 30, 35, 36, 39, 41, 42, 43, 44, 45, 46, 47, 49, 53, 54, 56, 57, 58, 61, 71, 72, 76, 77, 82, 83, 84, 87, 88, 90, 91, 93, 97, 98, 100, 101, 105, 107, 119, 120, 122, 126, 128, 130, 131, 135, 138, 148, 149, 150, 151, 152, 153, 155, 157, 158, 159, 163, 167], "d0": [0, 21, 46], "d1": 42, "d1_": 54, "d1_c_5": 99, "d2": 42, "d_": [30, 35, 41, 77], "d_1": [15, 39], "d_2": [15, 39], "d_3": 15, "d_i": [43, 44, 56, 152, 157], "d_k": [4, 15, 41, 42, 101], "d_list": 38, "d_max": 42, "da": [20, 41, 57], "daan": 1, "dagger": [50, 53], "dai": [1, 16, 58, 161], "daili": 68, "damian": [83, 87], "damp": 154, "dan": [122, 152, 157], "danc": 148, "danger": [48, 50, 68], "daniel": [1, 5, 61, 138, 156, 164], "dare": 51, "dark": [22, 43, 61, 135], "darkgreen": [9, 28, 35], "darkgrid": [83, 97], "dash": [9, 20, 42, 43, 49, 99, 135, 152, 155, 157], "dat": [99, 138], "dat_id": 138, "data": [0, 1, 3, 4, 7, 8, 9, 10, 11, 12, 15, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30, 34, 35, 41, 44, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66, 67, 71, 72, 73, 75, 76, 77, 83, 84, 85, 86, 87, 90, 91, 93, 94, 95, 96, 97, 99, 100, 102, 103, 105, 106, 107, 108, 110, 111, 114, 115, 116, 118, 120, 122, 123, 124, 126, 128, 130, 131, 134, 135, 136, 139, 143, 149, 150, 151, 152, 156, 158, 159, 163, 164, 167], "data1": 22, "data2": 22, "data_": [7, 39, 69, 71], "data_batch": 111, "data_fram": [39, 107], "data_generating_process": 71, "data_generating_process_measur": [39, 107], "data_generating_process_r": [39, 107], "data_i": [39, 71, 111], "data_id": 138, "data_in": 156, "data_inst": 111, "data_panda": 138, "data_path": 138, "dataarrai": 156, "databin": 42, "datacamp": 143, "datafil": 138, "datafram": [39, 107, 138, 148], "dataframegroupbi": 138, "datapoint": [39, 85, 93, 106, 107], "dataset": [42, 43, 44, 45, 57, 68, 71, 72, 74, 75, 76, 77, 78, 79, 82, 93, 98, 114, 122, 128, 147, 152, 156, 157], "dataset_mirror": 82, "datasetdimens": 156, "datat": 70, "date": [8, 50, 56, 68, 69, 131, 138, 142, 158, 159], "date_format": 131, "datetim": 131, "datum": [39, 43, 71, 77, 105], "daughter": 50, "dave": 126, "david": [1, 51, 61, 68, 77, 131, 133, 164], "db": 41, "dbeta": 101, "dc": 82, "ddot": [39, 57, 105, 155], "de": [1, 39, 48, 50, 51, 85, 86], "deactiv": 142, "deal": [8, 18, 22, 30, 39, 46, 53, 56, 57, 58, 60, 64, 67, 69, 70, 72, 80, 115, 117, 122, 130, 135, 138, 161], "dealt": 4, "dean": 1, "death": [152, 157], "debat": [152, 157], "debug": [76, 131, 143], "dec": 156, "decad": 69, "decai": [42, 52, 76, 77, 79, 93, 112, 138, 158, 161], "decemb": 1, "decid": [4, 15, 24, 28, 30, 39, 43, 53, 54, 69, 70, 76, 80, 97, 107, 137, 149, 151, 153, 158, 159, 164], "decim": [37, 128, 132, 138, 139, 159], "decis": [8, 16, 56, 66, 68, 75, 77, 78, 79, 93, 116, 158, 159, 161], "deck": 37, "declar": [9, 58, 67, 137, 139, 141], "decompos": [52, 53, 58, 132], "decomposit": [52, 72, 83, 91, 129, 132], "decreas": [30, 38, 51, 54, 57, 69, 71, 76, 100, 110, 111, 112, 126, 149, 156, 158, 159, 164], "decreasing_learning_r": 111, "decri": 158, "deduc": [16, 42, 67, 69], "deduct": 67, "deem": 51, "deep": [1, 73, 74, 76, 80, 98, 122, 166], "deeper": [48, 50, 67, 68, 69, 78, 81], "deeplearn": [78, 98], "deepli": 67, "deer": 81, "def": [0, 5, 6, 9, 20, 21, 22, 30, 34, 35, 38, 39, 42, 43, 45, 46, 47, 54, 55, 70, 74, 75, 76, 78, 81, 82, 83, 86, 87, 93, 97, 98, 100, 101, 107, 128, 131, 132, 134, 135, 137, 138, 139, 140, 143, 148, 149, 150, 152, 154, 155, 156, 157, 161, 166, 167], "defalt": 9, "default": [9, 28, 35, 38, 39, 54, 55, 71, 74, 82, 84, 87, 88, 97, 100, 101, 107, 112, 128, 131, 134, 138, 139, 141, 142, 143, 151, 154, 155, 156], "default_rng": [35, 39, 107, 135], "defect": [28, 58, 64], "defend": 68, "defer": 18, "defici": 46, "defin": [0, 6, 7, 8, 11, 13, 16, 18, 21, 22, 23, 24, 28, 39, 41, 42, 43, 45, 46, 48, 49, 51, 52, 54, 55, 56, 58, 61, 64, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 90, 91, 93, 94, 97, 98, 99, 100, 101, 105, 107, 112, 115, 118, 122, 125, 126, 130, 131, 135, 138, 139, 142, 143, 148, 149, 150, 152, 155, 156, 157, 161, 164, 166, 167], "definit": [0, 8, 9, 11, 16, 22, 24, 26, 28, 29, 30, 35, 45, 46, 47, 49, 51, 54, 66, 67, 70, 71, 75, 76, 82, 83, 87, 88, 90, 91, 93, 100, 101, 115, 125, 132, 139, 143, 149, 161, 164], "deform": 84, "deg": [26, 100], "degener": 55, "degeneraci": 52, "degre": [4, 8, 15, 22, 24, 27, 30, 34, 39, 43, 44, 48, 49, 51, 58, 60, 71, 91, 100, 101, 104, 105, 107, 122, 131, 132, 135, 152, 157], "degree_max": 100, "degreef": 135, "del": 131, "del_x": 42, "delet": [39, 100, 107, 139, 141], "deliber": 149, "delimit": [0, 139], "deliv": 102, "delta": [4, 15, 16, 19, 20, 21, 22, 24, 28, 34, 39, 41, 42, 43, 45, 46, 50, 51, 54, 56, 57, 58, 73, 90, 93, 109, 123, 125, 128, 135, 138, 148, 151, 153, 155, 158, 161, 163, 166], "delta_": [34, 70, 71, 90, 130, 132], "delta_bin": 131, "delta_h": 138, "delta_i": 43, "delta_j": 73, "delta_k": 73, "delta_n": 138, "delta_t": [154, 155], "delta_x": 42, "deltah": [0, 21], "delv": 166, "demand": [61, 90, 117], "demetropoli": 156, "demetropolisz": 156, "demo": [18, 75, 91, 98, 153, 158, 159], "democraci": 68, "demograph": 68, "demonst": 132, "demonstr": [11, 18, 24, 31, 39, 44, 49, 52, 64, 67, 71, 76, 77, 91, 92, 94, 102, 107, 141, 152, 157, 158, 165], "den": 149, "denisti": 161, "denomin": [10, 13, 16, 18, 20, 30, 39, 47, 51, 54, 57, 58, 112, 147, 148, 158], "denot": [4, 16, 24, 28, 30, 34, 39, 47, 49, 50, 51, 68, 71, 72, 73, 77, 83, 87, 90, 91, 93, 100, 101, 102, 104, 111, 115, 125, 128, 135, 148, 151, 156, 158, 159, 161], "dens": [39, 74, 91, 107], "dense_1": [74, 81], "denser": [39, 107], "densest": 87, "densiti": [8, 9, 11, 24, 25, 27, 30, 32, 34, 35, 38, 39, 41, 42, 47, 48, 49, 51, 53, 56, 58, 84, 87, 90, 128, 131, 134, 149, 153, 156, 158, 159, 161, 166], "depaoli": 1, "departur": 56, "depend": [4, 12, 13, 16, 23, 24, 30, 39, 41, 42, 43, 45, 48, 50, 51, 52, 53, 56, 57, 66, 68, 69, 70, 71, 72, 73, 76, 77, 81, 84, 90, 91, 93, 99, 101, 102, 104, 105, 109, 110, 111, 114, 115, 117, 122, 125, 134, 139, 140, 142, 145, 151, 152, 155, 156, 157, 158, 159, 161, 166], "depict": 161, "deploi": 68, "deploy": 68, "deprec": [42, 55, 75, 101, 138], "deprecationwarn": 42, "depth": [51, 58, 72, 76, 80, 122, 134, 139, 165], "deriv": [0, 8, 16, 18, 19, 20, 24, 30, 36, 38, 39, 42, 43, 44, 47, 48, 49, 50, 51, 52, 57, 58, 71, 76, 77, 93, 95, 101, 102, 105, 110, 112, 119, 122, 124, 128, 152, 153, 156, 157, 163], "derivati": 153, "desai": 56, "descend": [115, 132, 141], "descent": [70, 71, 72, 73, 75, 76, 78, 80, 93, 118, 121, 159], "describ": [4, 16, 18, 20, 24, 39, 42, 43, 44, 46, 48, 49, 51, 52, 53, 54, 60, 61, 68, 69, 70, 71, 72, 76, 77, 78, 90, 93, 98, 100, 102, 105, 110, 112, 115, 116, 120, 121, 122, 123, 125, 135, 138, 142, 147, 148, 149, 152, 153, 155, 157, 158, 161, 165, 166], "descript": [9, 28, 39, 47, 48, 70, 104, 105, 115, 137, 139, 141, 156, 161], "deserv": [71, 102], "desiderata": 67, "design": [0, 8, 16, 28, 41, 42, 48, 49, 51, 52, 56, 58, 61, 65, 70, 72, 76, 77, 82, 88, 90, 93, 106, 107, 108, 127, 135, 138, 155, 158, 166], "desir": [18, 24, 30, 43, 46, 48, 52, 56, 58, 69, 71, 76, 91, 105, 122, 135, 148, 153, 161], "despin": [78, 98], "despis": 68, "despit": [20, 44, 48, 52, 68, 70, 71, 72, 115, 152, 157, 158], "desrib": 24, "destroi": [152, 157], "det": [54, 55, 57, 58, 83, 91, 100, 101, 128, 141, 161], "deta": 71, "detail": [9, 11, 16, 24, 25, 27, 28, 29, 32, 33, 39, 41, 43, 45, 48, 49, 50, 52, 55, 56, 57, 64, 65, 74, 77, 82, 91, 100, 101, 116, 121, 130, 131, 139, 142, 144, 147, 151, 152, 153, 156, 157, 158, 163, 165], "detect": [7, 43, 47, 48, 67, 71, 72, 147], "detector": 56, "determin": [3, 4, 9, 11, 17, 18, 19, 24, 28, 39, 41, 42, 46, 54, 57, 58, 67, 68, 70, 71, 72, 73, 83, 87, 90, 91, 95, 101, 108, 115, 122, 126, 135, 138, 149, 152, 155, 157, 158, 159, 161, 166], "determinist": [53, 71, 77, 93, 115, 122, 128, 135, 150, 153, 166, 167], "determmin": 70, "detour": 49, "dev": [22, 86, 131], "devalu": 68, "devdoc": [55, 101], "develop": [8, 16, 38, 51, 52, 61, 66, 68, 69, 70, 72, 78, 126, 139], "devianc": 56, "deviat": [3, 4, 12, 18, 20, 22, 24, 29, 34, 38, 39, 41, 42, 43, 44, 45, 46, 48, 51, 55, 58, 70, 76, 77, 78, 79, 83, 85, 86, 98, 99, 100, 125, 126, 128, 131, 134, 135, 138, 140, 148, 149, 150, 151, 152, 156, 157, 163, 164, 167], "devic": [30, 56, 78], "devinderjit": 7, "devis": [49, 72], "df": [20, 131, 135, 138], "df1": 138, "df_chain": 148, "dfm": 164, "dft": 84, "dgrid": [0, 21], "dh": [18, 21, 126, 128], "dh_0": 46, "dhdt": 128, "dhs11": [1, 112], "di": [0, 21], "diag": [39, 52, 54, 55, 87, 128, 132], "diagnos": [48, 68], "diagnost": [48, 78, 98, 99, 146, 151, 157, 158, 164, 165], "diagon": [39, 46, 50, 52, 55, 58, 71, 77, 83, 87, 90, 91, 99, 112, 132, 135, 141, 151, 152, 153, 157, 161, 166], "dialect": 69, "dic": 56, "dice": [3, 77], "dick": [0, 5, 43, 55, 61, 82, 83, 137, 142, 148, 154, 156], "dick_in_tailcoat": 132, "dict": [9, 22, 42, 100, 131, 137, 149], "dict_kei": 74, "dictat": [8, 39, 42, 72, 83, 158], "dictionari": 138, "did": [7, 30, 39, 45, 55, 68, 78, 101, 135, 149, 150, 152, 155, 157, 167], "didn": [36, 54, 55, 131, 158, 159], "die": [4, 8, 28], "diederik": 1, "diff": [101, 131], "diffeq": 155, "differ": [3, 4, 6, 7, 8, 9, 11, 12, 15, 16, 18, 20, 22, 23, 24, 27, 28, 30, 31, 32, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 61, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 104, 105, 109, 110, 112, 116, 122, 128, 131, 134, 135, 138, 139, 140, 141, 142, 147, 148, 149, 150, 151, 152, 153, 156, 157, 158, 159, 161, 164, 166, 167], "different": [77, 78], "different_num": 140, "differenti": [1, 20, 41, 56, 69, 72, 76, 77, 78, 80, 83, 87, 90, 98, 102, 110, 135, 153, 154, 155, 163, 166, 168], "differentialmov": 55, "difficult": [30, 48, 49, 52, 57, 68, 72, 100, 102, 109, 110, 124, 151, 153, 159, 161, 164], "difficulti": [58, 110, 112], "diffus": [48, 153, 159], "digit": [68, 130, 138, 167], "dillon": 1, "dim": [46, 55, 72, 97, 101], "dimenion": 23, "dimens": [8, 28, 39, 49, 50, 52, 55, 65, 72, 80, 81, 82, 83, 84, 87, 88, 90, 91, 101, 102, 105, 110, 118, 128, 131, 132, 138, 141, 148, 149, 151, 152, 153, 156, 157, 158], "dimensin": 141, "dimension": [16, 22, 24, 28, 31, 38, 39, 45, 48, 49, 50, 51, 52, 54, 56, 58, 72, 74, 77, 78, 82, 85, 88, 90, 91, 97, 98, 118, 129, 130, 132, 134, 135, 138, 149, 151, 152, 153, 157, 158, 159, 161, 166, 168], "dimensionalisti": 56, "dimensionless": [28, 49, 118, 135], "diminish": 124, "dip": 48, "dir": 156, "dirac": [28, 128], "direc": 128, "direct": [4, 8, 13, 24, 39, 53, 58, 71, 72, 74, 93, 102, 110, 128, 132, 139, 149, 151, 152, 153, 155, 157, 158, 159, 164], "directli": [24, 28, 37, 38, 47, 49, 51, 52, 77, 78, 90, 98, 99, 126, 129, 132, 135, 166], "directori": [0, 128, 131, 135, 142, 145], "disabl": [9, 68, 131, 137], "disadvantag": [43, 68], "disappear": [58, 158, 161], "discard": [6, 49, 53, 55, 148, 152, 156, 157], "disciplin": [69, 72], "disclaim": 69, "discov": [16, 24, 133], "discoveri": [66, 67, 72], "discrep": [16, 34, 39, 53, 60, 64, 115, 116, 125, 126, 163], "discret": [4, 9, 11, 16, 22, 27, 28, 29, 30, 42, 49, 69, 70, 72, 77, 93, 115, 126, 128, 150, 151, 166, 167], "discrimin": [58, 68, 93], "discuss": [7, 16, 18, 20, 24, 26, 28, 30, 34, 42, 44, 45, 46, 49, 51, 53, 61, 63, 64, 65, 68, 69, 71, 73, 77, 78, 93, 99, 100, 101, 103, 110, 115, 118, 119, 122, 125, 126, 132, 148, 156, 159, 161, 164], "diseas": [27, 36, 68, 93], "dishonest": 66, "disjoint": 135, "disk": [56, 139], "dismiss": 161, "disord": 93, "disp": 43, "dispers": 49, "displai": [3, 5, 9, 20, 53, 70, 71, 72, 74, 81, 83, 93, 131, 135, 138, 139, 149, 156, 157, 158, 161, 166], "display_nam": 0, "displaystyl": [39, 105, 164], "dispos": 151, "disproportion": 43, "disregard": 68, "disrupt": 69, "dist": [9, 22, 35, 47, 87, 131], "dist_hist_plot": 47, "dist_label": [22, 131], "dist_mod": [9, 22, 35, 131], "dist_plot": [22, 131], "dist_pt": 47, "dist_pts_alt": 47, "dist_stuff": [9, 22, 35, 131], "distanc": [39, 46, 52, 56, 70, 75, 83, 87, 119, 120, 128, 153, 166], "distant": 58, "distinct": [4, 7, 48, 51, 53, 63, 80, 94, 109, 126, 140], "distinguish": [27, 53, 56, 62, 63, 102, 158], "distract": 48, "distrbut": 166, "distri": 48, "distribut": [1, 5, 6, 7, 8, 9, 11, 13, 17, 18, 21, 23, 24, 25, 28, 29, 30, 31, 32, 34, 35, 41, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 56, 58, 65, 68, 72, 77, 78, 79, 81, 82, 86, 88, 93, 94, 97, 98, 99, 100, 101, 107, 115, 122, 125, 126, 128, 129, 142, 147, 148, 149, 152, 153, 156, 157, 159, 163, 165, 166, 168], "distrubt": 161, "div": 0, "dive": [43, 138], "diverg": [24, 73], "diverging_palett": [78, 98], "divers": [28, 68], "divid": [4, 32, 34, 38, 43, 48, 58, 71, 72, 74, 81, 97, 98, 100, 109, 141, 148, 149, 151, 164], "divis": [71, 76, 81, 112, 141], "divorc": 28, "dj\u00e4rv": 61, "dk": [42, 101], "dk_pt": 42, "dkpr87": [1, 49], "dl": [24, 41], "dlnz": 101, "dmat": [39, 105, 106, 107, 108], "dmf": [1, 50], "dna": 93, "dnn": 72, "do": [0, 1, 3, 4, 5, 7, 8, 9, 11, 13, 15, 16, 18, 20, 22, 23, 28, 29, 30, 34, 35, 36, 37, 39, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 64, 66, 67, 69, 70, 71, 72, 73, 76, 78, 79, 80, 81, 82, 84, 88, 90, 94, 95, 99, 101, 102, 105, 106, 107, 109, 122, 130, 134, 135, 137, 138, 139, 140, 141, 142, 147, 149, 152, 153, 155, 156, 157, 158, 159, 161, 167, 168], "dob": [9, 22, 24, 30, 35, 46], "dobrow": 166, "doc": [22, 78, 98, 135, 156], "docstr": [84, 139, 141, 156], "doctor": 68, "document": [9, 11, 13, 42, 44, 47, 48, 75, 76, 82, 88, 92, 99, 132, 139, 140, 141, 142, 150, 151, 152, 153, 156, 157, 163, 167, 168], "documentari": 67, "doe": [1, 5, 8, 9, 12, 16, 18, 20, 23, 24, 27, 30, 34, 35, 36, 37, 39, 42, 43, 44, 45, 47, 49, 52, 53, 54, 55, 56, 58, 67, 68, 69, 70, 71, 72, 75, 76, 80, 82, 88, 90, 91, 95, 98, 99, 100, 101, 105, 112, 126, 129, 134, 135, 138, 139, 140, 141, 147, 148, 149, 151, 152, 153, 155, 156, 157, 159, 161, 164, 166], "doesn": [5, 13, 27, 34, 38, 43, 44, 56, 68, 73, 80, 152, 153, 154, 157, 159, 164], "dof": [100, 122], "dog": [81, 139], "doi": [1, 48], "dollar": 8, "domain": [0, 8, 22, 28, 48, 51, 52, 53, 58, 65, 69, 71, 87, 115, 124, 126, 128, 135, 151], "domin": [12, 24, 34, 53, 57, 58, 70, 78, 90, 115, 130], "don": [9, 11, 15, 22, 28, 30, 34, 35, 36, 38, 39, 41, 45, 47, 54, 63, 66, 68, 69, 70, 71, 77, 82, 83, 87, 88, 90, 99, 100, 101, 122, 138, 139, 150, 151, 156, 158, 159, 164, 167], "donald": [1, 158], "done": [0, 39, 41, 43, 46, 48, 53, 54, 55, 58, 63, 67, 71, 76, 77, 78, 102, 130, 131, 132, 140, 142, 148, 153, 159], "donut": [153, 158], "door": 16, "dordrecht": 1, "dot": [4, 39, 49, 53, 70, 71, 72, 73, 75, 78, 80, 83, 85, 87, 93, 98, 105, 107, 128, 132, 147, 148, 149, 154, 155], "dot_product_term": 128, "dotproduct": [86, 128], "doubl": [30, 48, 52, 68, 77, 130, 139, 140, 142, 166], "doubt": [24, 61], "dougla": 61, "down": [0, 8, 18, 20, 22, 27, 57, 64, 72, 73, 76, 78, 83, 87, 98, 115, 122, 135, 139, 141, 161], "downhil": [102, 110], "download": [61, 75, 82, 138, 139, 142, 144, 145], "downsampl": 80, "downward": 128, "dozen": 132, "dp": [3, 24, 154], "dp_h": [11, 13, 30, 35], "dp_i": 153, "dp_phi": 154, "dphi": [154, 155], "dpi": [128, 131, 154, 155], "dq": 154, "dq_i": 153, "dr": [100, 128, 155], "draft": [1, 82, 88], "drag": [119, 120, 126, 128], "drastic": [122, 149], "draw": [16, 22, 23, 24, 28, 34, 37, 41, 43, 47, 49, 52, 56, 63, 71, 72, 77, 78, 79, 82, 84, 86, 88, 94, 101, 115, 125, 131, 135, 149, 151, 152, 156, 157, 158, 159, 161, 164], "draw_ev": 131, "drawback": [48, 71, 78, 100, 139], "drawn": [24, 34, 42, 46, 49, 76, 77, 86, 93, 100, 122, 128, 152, 153, 157, 164, 168], "drawpandasindexpandasindex": 156, "drawstyl": 42, "dream": 69, "dress": [70, 139, 143], "drink": 7, "drischler": 1, "drive": [55, 56, 63, 69, 101, 154, 161], "driven": [50, 52], "driver": 69, "drop": [16, 56, 78, 107, 125, 135, 138, 156, 164, 168], "drop_const": [39, 107], "dropbox": 55, "dropdown": [0, 5, 9, 137], "dropna": 138, "dropout": [72, 74], "drug": 68, "dry": [16, 69], "dsdt": 21, "dstack": [39, 70, 83, 87], "dt": [13, 21, 43, 126, 128, 153, 154, 155, 166], "dtp2023": 50, "dtype": [6, 38, 42, 55, 74, 76, 78, 81, 98, 100, 101, 134, 138, 141, 150, 156, 167], "du": [58, 155], "du_": 155, "du_1": 135, "du_cf": 155, "du_eff": 155, "du_i": 58, "du_n": 135, "dual": 75, "dualiti": 49, "duan": [1, 49], "dubourg": 85, "duchi": 1, "duchi11a": 1, "duco": 1, "due": [4, 18, 39, 43, 45, 51, 56, 58, 72, 76, 77, 78, 101, 102, 105, 109, 126, 128, 138, 148, 158, 161, 166], "dumb": 149, "dummi": [75, 140, 149], "dummy_out": [78, 98], "dumpti": 63, "dunson": 1, "duplic": 132, "durat": 120, "dure": [8, 49, 51, 72, 74, 76, 77, 78, 82, 88, 111, 119, 128, 141, 152, 156, 157, 166], "durham": 61, "durrand": [82, 88], "dustin": [1, 78], "duvenaud": 91, "dvdt": 128, "dwell": 8, "dx": [3, 4, 18, 19, 21, 22, 24, 28, 29, 30, 41, 57, 87, 135, 151, 158], "dx1": 55, "dx2": 55, "dx_1": [24, 38, 135], "dx_2": [0, 22, 28, 38, 135], "dx_j": 24, "dx_k": 47, "dx_n": [24, 38], "dxdy": [18, 21], "dxp": 55, "dy": [19, 41, 43, 45, 46, 72, 100, 135, 148, 151, 158, 166], "dy2": 45, "dy_data": 54, "dy_dt": [154, 155], "dy_pt": 54, "dynam": [49, 52, 72, 76, 78, 98, 128, 153, 166], "dz": [21, 135], "e": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 15, 16, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 64, 65, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 81, 82, 83, 84, 87, 88, 90, 91, 93, 95, 97, 98, 99, 100, 101, 102, 105, 106, 107, 110, 119, 122, 124, 125, 127, 128, 129, 130, 132, 135, 136, 138, 139, 141, 142, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 165, 167, 168], "e1": 132, "e2": 132, "e_": [39, 50, 71, 132, 138, 164], "e_1": 132, "e_2": 132, "e_i": [39, 43, 107], "e_tot_0": 155, "e_tot_0_eul": 155, "e_tot_0_lf": 155, "e_tot_pt": 155, "e_tot_pts_eul": 155, "e_tot_pts_lf": 155, "e_tot_rel_pt": 155, "e_tot_rel_pts_eul": 155, "e_tot_rel_pts_lf": 155, "e_w": [77, 93], "each": [4, 6, 7, 8, 9, 11, 15, 22, 29, 30, 34, 35, 36, 37, 39, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 61, 68, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 81, 83, 84, 86, 87, 88, 91, 93, 95, 98, 101, 105, 111, 112, 115, 122, 125, 128, 130, 131, 132, 134, 135, 138, 139, 140, 141, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 159, 161, 164, 166, 167], "eapprox": 138, "earli": [8, 12, 51, 53, 78, 112, 126], "earlier": [39, 54, 58, 73, 76, 93, 126, 132, 142, 161], "earliest": 115, "earn": 158, "earth": 120, "easi": [0, 11, 13, 24, 26, 38, 47, 48, 49, 56, 71, 73, 78, 82, 88, 93, 135, 138, 139, 140, 148, 158, 161, 164], "easier": [6, 20, 45, 47, 56, 58, 69, 71, 72, 99, 124, 138, 156], "easiest": [51, 57], "easili": [0, 4, 39, 42, 48, 52, 58, 69, 73, 78, 82, 88, 93, 100, 106, 138, 139, 140, 141, 153, 158], "eat": [26, 67], "ebegin": 71, "ebind": 138, "ec": [52, 100, 131], "eccentr": [41, 58, 83, 155], "ecolor": 101, "econometr": 138, "economist": 67, "ed": 94, "edg": [52, 100, 109, 131, 164], "edgecolor": [42, 43, 70], "edit": [0, 1, 61, 91, 134, 139, 142], "edu": [0, 1, 56, 83, 85, 137, 142, 154, 156], "educ": [68, 69], "edward": [1, 69, 77, 78, 90], "eff": [49, 155], "effect": [1, 7, 16, 24, 30, 39, 43, 45, 48, 49, 51, 52, 53, 54, 55, 56, 58, 62, 67, 68, 71, 76, 77, 82, 85, 88, 99, 101, 119, 122, 128, 131, 132, 138, 151, 155, 156, 159, 168], "effectivepotenti": 5, "effici": [1, 38, 43, 49, 51, 52, 56, 72, 76, 78, 80, 98, 99, 111, 112, 132, 138, 141, 153, 156, 158, 159, 165, 168], "effort": [53, 61, 65, 68, 152, 157, 168], "eft": [50, 52, 57, 96], "ei": [37, 97], "eig": [82, 88, 132, 141], "eigen": 52, "eigen_galerkin": 52, "eigenenergi": 50, "eigensolut": 143, "eigenst": 50, "eigenvalu": [50, 52, 58, 82, 83, 84, 87, 88, 130, 132, 158, 161], "eigenvector": [1, 41, 52, 58, 127, 130, 132, 158, 161], "eigh": [132, 141], "eigval": [82, 83, 87, 88, 132], "eigvec": 132, "einstein": [8, 16, 132, 139], "einstein_equ": 0, "either": [0, 8, 9, 11, 19, 24, 43, 45, 48, 56, 58, 61, 68, 70, 71, 72, 77, 81, 91, 93, 135, 138, 139, 140, 142, 149, 166], "ek": 101, "ekstr\u00f6m": [1, 50, 61], "el": 138, "elabor": [11, 30, 32, 48], "elad": 1, "elast": 71, "elbo": [77, 78, 98], "eleanor": [1, 61], "elect": 30, "electr": [72, 138], "electromagnet": 95, "electron": [26, 135, 161], "elegantli": 7, "element": [1, 3, 9, 39, 42, 46, 48, 49, 50, 52, 58, 68, 69, 71, 72, 76, 77, 82, 83, 87, 88, 90, 93, 101, 105, 109, 112, 130, 132, 138, 139, 140, 143, 153, 155, 158, 161, 166], "elementwis": 80, "eleph": [109, 132], "elessar": 138, "elev": 70, "elevanth": [153, 159], "elif": [39, 83, 87, 101, 107, 128, 134, 139, 154], "elimin": [7, 12, 22, 68, 131, 132], "ell": [83, 84, 87, 91, 122, 125, 128], "ell_rbf": 83, "ellips": [42, 58, 83, 91, 151], "ellipsoid": 51, "ellipt": 41, "els": [3, 6, 8, 39, 42, 43, 45, 47, 53, 55, 74, 75, 81, 83, 87, 101, 107, 128, 131, 134, 147, 148, 149, 150, 152, 154, 157, 158, 159, 161, 164, 166, 167], "elsewher": [19, 21, 39, 45, 47, 100, 135, 148, 163], "elu": [72, 75, 134], "em": [9, 50], "email": 142, "emce": [1, 6, 41, 43, 46, 55, 56, 95, 99, 147, 148, 151, 152, 153, 159, 164, 168], "emcee_lnprob": 46, "emcee_sampl": 128, "emcee_trac": 46, "emerg": [24, 56, 61], "emilia": 139, "emiss": 58, "emit": [47, 147], "emph": [53, 127], "emphas": [26, 36, 39, 52, 62, 70, 124, 135, 159], "emphasi": [36, 39, 138, 151], "empir": [4, 45, 48, 50, 58, 93, 94, 100, 115, 122, 134, 138, 149], "emploi": [9, 16, 20, 35, 39, 51, 56, 58, 67, 71, 72, 77, 101, 111, 112, 124, 149, 161], "employ": [68, 69], "employe": 69, "empti": [98, 101, 131, 134, 135, 139, 148, 149], "empty_lik": [78, 98], "emptyset": [71, 135], "emul": [1, 51, 67, 72, 129, 130], "en": [46, 109, 157, 168], "enabl": [8, 30, 39, 43, 48, 50, 52, 56, 58, 63, 67, 76, 84, 139, 151, 158, 159], "encapsul": 30, "enclos": 24, "encod": [24, 43, 44, 45, 54, 58, 63, 80, 83, 87, 126, 131, 152, 157, 163], "encompass": [8, 11, 51, 55, 56, 58], "encount": [8, 16, 30, 31, 43, 58, 62, 65, 69, 70, 71, 73, 93, 102, 109, 116, 139, 149, 158, 166], "encourag": [32, 48, 51, 64, 77, 138, 139, 142], "end": [0, 3, 4, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 24, 27, 28, 29, 30, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 58, 68, 69, 70, 71, 72, 73, 77, 80, 82, 83, 84, 87, 88, 90, 91, 93, 97, 100, 102, 104, 105, 108, 109, 111, 112, 118, 128, 130, 131, 132, 135, 137, 139, 141, 142, 151, 152, 153, 154, 155, 156, 157, 158, 161, 163, 164, 166], "end_tim": 128, "endeavor": 52, "endeavour": 115, "endow": 53, "endpoint": [9, 22, 135, 140, 153], "energi": [26, 49, 50, 52, 56, 77, 83, 84, 87, 96, 109, 135, 153, 156, 159, 161], "energy_0": 155, "enforc": [7, 38, 52, 72, 78], "engin": [1, 52, 68, 69, 72, 76], "english": [40, 58, 166], "enlighten": 4, "enorm": 50, "enough": [5, 9, 12, 24, 34, 35, 39, 42, 45, 48, 49, 50, 52, 58, 61, 68, 72, 82, 88, 91, 132, 136, 150, 151, 159, 161, 167], "ensambl": [77, 152, 157], "ensembl": [1, 55, 72, 77, 78, 101, 152, 157, 158], "ensemblesampl": [6, 43, 46, 55, 101, 128, 148, 151, 152, 157], "ensur": [4, 5, 48, 51, 52, 68, 76, 77, 82, 83, 87, 88, 128, 161, 163], "entail": [8, 39, 58, 107], "enter": [0, 30, 39, 48, 51, 69, 82, 88, 101, 104, 110, 117, 139, 145, 158, 159], "entir": [24, 39, 48, 53, 55, 56, 57, 68, 71, 80, 93, 137, 139], "entireti": 53, "entiti": 28, "entitl": [66, 69, 122], "entri": [0, 37, 43, 44, 47, 57, 68, 73, 77, 91, 131, 132, 138, 156, 157, 158, 159, 161], "entropi": [8, 18, 43, 45, 47, 48, 60, 67, 70, 72, 75, 77], "enumer": [0, 3, 6, 20, 21, 38, 43, 46, 47, 51, 70, 82, 83, 86, 87, 88, 100, 101, 128, 135, 140], "env": [55, 75, 86, 101, 131, 157], "envelop": 84, "envi": 50, "environ": [41, 61, 74, 75, 98, 136, 139, 144, 147], "environment": 68, "environment_jb": [142, 145], "environment_window": 98, "envis": 49, "eotwash": 56, "epidemiologi": [51, 53], "epistemologi": [25, 26, 30], "eplac": 38, "epoch": [71, 72, 73, 74, 75, 76, 81, 93, 111], "epsilon": [3, 4, 39, 71, 77, 82, 84, 88, 105, 110, 128, 153, 155], "epsilon_i": [3, 39, 71, 100, 105, 125], "epsrel": 5, "eq": [0, 16, 18, 19, 20, 30, 39, 49, 50, 51, 52, 53, 58, 70, 71, 102, 105, 110, 112, 115, 125, 128, 135, 151, 154, 158, 161, 166], "eq_ppd": 0, "eqn": [53, 58], "equal": [3, 4, 8, 11, 24, 27, 28, 30, 36, 37, 38, 39, 41, 42, 43, 45, 49, 51, 55, 58, 68, 70, 71, 73, 76, 77, 82, 83, 87, 88, 105, 128, 130, 132, 135, 140, 141, 149, 150, 151, 155, 158, 161, 164, 167], "equat": [1, 3, 4, 7, 8, 16, 18, 19, 20, 27, 28, 30, 44, 49, 50, 51, 52, 53, 54, 56, 58, 61, 69, 70, 71, 72, 77, 80, 84, 90, 93, 102, 104, 106, 109, 111, 112, 118, 119, 120, 125, 126, 128, 130, 135, 139, 147, 152, 153, 154, 157, 158, 161, 164, 166], "equilibr": [150, 159, 161, 164, 167], "equilibrium": [149, 158, 161, 166], "equip": 16, "equiv": [3, 4, 7, 13, 18, 20, 22, 24, 26, 29, 34, 39, 41, 44, 50, 51, 54, 56, 58, 70, 71, 73, 77, 84, 87, 90, 91, 93, 99, 100, 101, 105, 110, 111, 112, 130, 135, 148, 152, 154, 157, 158, 159, 161], "equival": [3, 4, 7, 24, 30, 39, 43, 44, 52, 53, 54, 58, 77, 83, 99, 101, 139, 151, 152, 157, 161], "ergod": 153, "eriador": 138, "ermal": 1, "ernest": 135, "err": 99, "err_filenam": 131, "err_msg": 131, "err_slop": 46, "err_slope_max": 46, "err_slope_min": 46, "err_theta_ml": 46, "err_v0": 46, "errno": 131, "errno_num": 131, "erron": [60, 68, 109], "error": [0, 1, 3, 4, 7, 16, 22, 33, 34, 38, 43, 45, 48, 49, 51, 52, 53, 54, 55, 58, 60, 61, 64, 65, 69, 72, 73, 76, 77, 78, 82, 84, 90, 93, 98, 99, 100, 101, 102, 105, 106, 107, 115, 120, 125, 126, 128, 130, 131, 132, 138, 139, 140, 141, 151, 152, 156, 157, 158], "errorbar": [39, 43, 45, 46, 54, 85, 100, 101, 107, 128, 148], "errread": 131, "errstat": 97, "errwrit": 131, "esc": 139, "especi": [30, 72, 76, 78, 115], "ess": 49, "ess_bulk": [156, 157], "ess_tail": [156, 157], "essai": 122, "essenc": 76, "essenti": [1, 5, 8, 52, 53, 56, 62, 63, 66, 69, 72, 73, 126, 149, 153], "est": 39, "establish": [8, 52, 53, 67], "estim": [1, 5, 9, 11, 14, 20, 22, 24, 25, 26, 27, 29, 30, 32, 35, 39, 41, 42, 43, 47, 48, 49, 51, 54, 56, 64, 65, 69, 70, 71, 76, 77, 78, 84, 85, 93, 95, 96, 98, 100, 105, 107, 112, 115, 124, 126, 128, 129, 131, 132, 138, 147, 148, 150, 151, 156, 159, 161, 167], "et": [0, 48, 49, 61, 71, 128, 131, 149], "eta": [7, 54, 73, 75, 84, 93, 102, 110, 111, 112, 125, 128], "eta0": 75, "eta_n": [110, 112], "etc": [4, 8, 9, 11, 18, 22, 63, 65, 69, 72, 80, 82, 88, 93, 101, 115, 142, 161], "ethic": 1, "eti": 135, "euclidean": [39, 70, 83, 105, 109], "euclidean_dist": 70, "euler": [153, 155], "euro": 166, "european": 68, "evalu": [0, 1, 7, 13, 16, 18, 21, 30, 34, 39, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 56, 58, 68, 70, 71, 72, 76, 77, 78, 87, 90, 97, 98, 100, 105, 106, 107, 110, 111, 125, 128, 132, 138, 139, 140, 143, 148, 149, 150, 152, 155, 157, 158, 159, 161, 167], "evaluate_gradi": 111, "evd": 130, "even": [0, 5, 7, 8, 12, 16, 22, 26, 30, 39, 44, 48, 49, 50, 52, 53, 54, 58, 61, 63, 68, 69, 70, 71, 72, 77, 78, 80, 81, 83, 84, 87, 90, 91, 106, 108, 126, 138, 139, 147, 152, 153, 156, 157, 158, 161, 164], "evenli": [42, 45, 82, 88, 141], "event": [4, 8, 16, 22, 27, 28, 30, 42, 68, 161], "eventu": [12, 24, 30, 45, 54, 57, 61, 71, 72, 102, 112, 136, 139, 148, 149, 161, 164], "ever": [8, 16, 58, 67, 68], "everi": [6, 9, 11, 12, 24, 28, 30, 49, 54, 55, 56, 68, 72, 76, 80, 81, 83, 84, 87, 90, 101, 110, 111, 112, 128, 131, 157, 164], "everybodi": 58, "everydai": [58, 61], "everyon": 8, "everyth": [16, 28, 73, 78, 130, 139, 159], "everywher": [9, 53, 68, 72, 140], "evid": [3, 7, 8, 9, 10, 16, 28, 30, 34, 35, 39, 44, 55, 64, 67, 68, 95, 96, 101, 128], "evluat": 70, "evolut": [30, 77, 153, 158, 161], "evolv": [30, 35, 61, 69, 122, 154, 161, 166], "exac": 167, "exact": [42, 49, 50, 52, 53, 54, 56, 73, 77, 99, 111, 115, 138, 150, 153, 164, 167], "exact_data": 42, "exact_fev": 97, "exactli": [16, 34, 35, 39, 45, 53, 71, 73, 80, 107, 130], "examin": [43, 48, 49, 56, 74, 81, 126, 148, 156], "exampl": [0, 4, 6, 7, 8, 9, 11, 16, 18, 20, 21, 22, 24, 26, 27, 32, 35, 37, 40, 42, 48, 49, 50, 51, 52, 53, 55, 57, 58, 60, 69, 71, 72, 73, 74, 77, 78, 79, 81, 84, 86, 88, 90, 92, 93, 98, 99, 100, 101, 102, 106, 107, 110, 112, 115, 117, 122, 124, 125, 126, 127, 130, 132, 134, 137, 138, 139, 140, 142, 149, 150, 153, 157, 158, 161, 163, 165, 167, 168], "example_revers": 161, "exce": [58, 72, 128, 166], "exceed": 128, "excel": [61, 69, 77, 149, 152, 153, 157, 158, 159, 168], "except": [36, 39, 42, 48, 70, 71, 76, 81, 101, 128, 131, 152, 157, 158, 164], "excercis": 156, "excerpt": 53, "excess": [102, 138], "exchang": [24, 56, 66], "excit": [11, 52, 69, 161], "exclud": [30, 51, 68, 71, 100, 138, 166], "exclus": [27, 28, 30, 36, 37, 53, 68, 71, 73, 81, 138], "execut": [76, 131, 140, 142], "exemplifi": [39, 135], "exercis": [9, 13, 17, 18, 19, 27, 35, 43, 54, 61, 74, 96, 97, 107, 136, 148], "exercisesp": 166, "exert": 43, "exhaust": [27, 28, 30, 36, 37, 51, 71, 135], "exhibit": 151, "exist": [4, 8, 24, 30, 39, 44, 53, 55, 65, 66, 67, 68, 69, 81, 97, 101, 105, 122, 135, 138, 139, 147, 152, 154, 157, 161], "exit": 139, "exp": [0, 4, 5, 18, 19, 20, 21, 29, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 53, 54, 55, 58, 70, 72, 73, 75, 76, 77, 83, 87, 90, 93, 95, 97, 100, 101, 117, 125, 128, 134, 135, 139, 143, 148, 149, 150, 152, 157, 163, 166, 167], "expand": [8, 24, 27, 28, 36, 37, 39, 41, 43, 48, 52, 53, 58, 93, 94, 122, 168], "expans": [7, 16, 24, 39, 52, 58, 63, 72, 99, 122], "expect": [4, 8, 9, 10, 12, 13, 18, 20, 21, 24, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 70, 71, 73, 77, 78, 84, 91, 97, 98, 107, 115, 119, 131, 138, 141, 147, 148, 150, 151, 156, 157, 158, 159, 161, 163, 164, 166, 167], "expected_improv": 97, "expens": [36, 52, 84, 100, 127, 129], "experi": [4, 8, 9, 11, 16, 24, 26, 30, 35, 41, 42, 45, 47, 48, 56, 64, 65, 66, 67, 68, 69, 76, 85, 91, 94, 97, 101, 115, 119, 125, 126, 132, 133, 135, 138, 158], "experienc": 164, "experiment": [0, 9, 20, 22, 28, 30, 34, 35, 42, 44, 46, 52, 53, 56, 58, 63, 65, 67, 71, 101, 115, 124, 126, 127, 129, 135, 138, 152, 157], "expert": [0, 16, 48, 52, 67, 68, 72, 132], "expertis": 52, "explain": [7, 12, 24, 39, 48, 53, 64, 68, 70, 71, 76, 84, 95, 99, 101, 105, 131, 132, 138, 139, 147, 150, 158, 166, 167], "explan": [7, 24, 58, 67, 71, 112, 161, 163], "explanatori": 115, "explcitli": 90, "explic": 68, "explicit": [7, 9, 22, 39, 44, 48, 49, 52, 58, 64, 72, 80, 90, 122, 132, 139, 152, 157, 161], "explicitli": [4, 16, 27, 28, 30, 38, 47, 53, 58, 69, 76, 78, 85, 90, 91, 94, 128, 137, 138, 141, 166], "explod": [73, 76, 122], "exploit": [9, 11, 43, 49, 52, 72, 97], "explor": [9, 28, 31, 32, 35, 39, 42, 43, 46, 47, 49, 50, 52, 54, 56, 58, 60, 64, 68, 70, 71, 78, 91, 96, 97, 99, 102, 107, 110, 115, 122, 124, 125, 128, 131, 140, 141, 151, 153, 158, 159, 161, 164, 166], "exploratori": [78, 98], "expon": [18, 39, 49, 57], "exponenti": [24, 39, 41, 49, 55, 72, 76, 82, 83, 87, 88, 90, 112, 120, 139, 143, 149, 158], "expos": [64, 71], "exposit": 48, "express": [4, 9, 15, 16, 18, 19, 24, 27, 35, 36, 39, 43, 44, 45, 46, 49, 50, 51, 53, 54, 56, 58, 63, 64, 70, 71, 72, 73, 78, 80, 81, 82, 88, 90, 98, 101, 102, 104, 105, 106, 109, 119, 122, 125, 130, 132, 135, 138, 148, 149, 152, 157, 158, 161], "expsinesquar": 86, "expt": [34, 163], "extend": [4, 28, 32, 44, 52, 60, 61, 64, 67, 68, 70, 78, 83, 99, 139, 157, 166], "extens": [0, 25, 28, 48, 52, 68, 69, 72, 76, 90, 100, 112, 126, 132, 138, 139], "extent": [8, 22, 39, 42, 51, 69], "extern": [9, 137, 166], "extra": [41, 48, 57, 58, 72, 81, 91, 161, 168], "extra_anim": 131, "extra_arg": 131, "extra_group": 131, "extra_rbm_emul": 127, "extract": [18, 19, 22, 28, 39, 43, 46, 49, 55, 74, 78, 79, 82, 87, 88, 93, 99, 100, 101, 107, 116, 124, 126, 128, 135, 142, 149, 152, 156, 157, 167], "extrapol": [50, 52, 53, 76, 84, 127, 138], "extrem": [8, 16, 24, 30, 43, 48, 53, 58, 68, 69, 71, 72, 78, 138, 139, 164], "extremum": [16, 39, 105], "ey": [27, 37, 43, 48, 54, 55, 69, 83, 87, 141, 148, 151], "e\u00f6t": 56, "f": [0, 1, 3, 4, 5, 6, 9, 13, 16, 18, 19, 20, 21, 22, 34, 35, 38, 39, 42, 43, 44, 45, 46, 47, 49, 54, 55, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 83, 85, 86, 87, 88, 91, 93, 97, 98, 100, 101, 107, 122, 126, 128, 131, 132, 134, 135, 137, 138, 139, 140, 141, 142, 148, 150, 151, 155, 156, 157, 158, 164, 166, 167, 168], "f11": 138, "f12": 138, "f13": 138, "f9": 138, "f_": [39, 52, 53, 72, 105], "f_0": [20, 39, 104, 105], "f_1": [53, 91], "f_2": [53, 72, 91], "f_arr": 20, "f_j": [39, 104, 105], "f_k": [53, 101], "f_likelihood": 20, "f_posterior": 20, "f_r": 140, "fab": [42, 154, 155], "face": [4, 16, 57, 158], "facecolor": [22, 42, 101, 131], "facet": 60, "facilit": [39, 48, 52, 78], "fact": [3, 4, 15, 16, 18, 20, 21, 28, 30, 39, 41, 43, 46, 49, 58, 67, 68, 69, 70, 71, 72, 77, 80, 87, 90, 104, 115, 116, 135, 138, 148, 158, 159, 161, 166], "factor": [5, 10, 16, 18, 20, 24, 30, 38, 39, 41, 43, 47, 48, 49, 52, 53, 54, 55, 57, 58, 66, 68, 95, 100, 101, 105, 128, 132, 135, 147, 148, 149, 155, 156, 158, 159, 164], "factori": [4, 38, 42, 150, 167], "fail": [5, 20, 24, 27, 43, 47, 48, 49, 56, 58, 60, 64, 68, 86, 131, 138, 139, 142, 151], "failur": [34, 49, 53, 93], "fair": [3, 8, 9, 11, 13, 16, 24, 35, 48, 58], "fairli": [44, 67, 152, 157], "faith": 39, "fake": 153, "fall": [24, 39, 48, 51, 58, 68, 85, 107, 119, 120, 128], "fallaci": 36, "fallen": 119, "fals": [3, 9, 20, 26, 34, 36, 38, 39, 42, 43, 45, 46, 55, 68, 69, 70, 75, 78, 81, 83, 85, 87, 93, 97, 100, 107, 128, 131, 132, 135, 137, 138, 148, 149, 154, 158, 161, 166], "falsif": 66, "falsifi": [58, 67], "famili": [52, 61, 68, 71, 72, 91, 93, 117, 138, 161, 166], "familiar": [4, 7, 27, 28, 34, 36, 39, 42, 52, 58, 67, 70, 122, 138, 140, 150, 166, 167], "famou": [16, 51, 72, 73], "fan_out": 76, "fantast": 69, "far": [8, 16, 18, 19, 30, 38, 39, 49, 52, 58, 68, 72, 76, 78, 81, 84, 85, 91, 131, 149, 151, 153, 158], "farther": 56, "fashion": 66, "fast": [22, 24, 51, 52, 73, 111, 129, 131, 135, 139, 140, 156, 164, 168], "faster": [50, 51, 52, 76, 78, 98, 140, 156], "fastest": 12, "fat": 158, "favor": [24, 43, 56, 57, 68, 70, 93, 102, 153, 158], "favour": [4, 42, 58], "fc": [80, 100], "feasibl": [109, 158, 159], "featur": [9, 11, 39, 42, 43, 44, 46, 51, 52, 58, 65, 67, 68, 69, 70, 71, 72, 73, 76, 78, 83, 91, 98, 99, 102, 104, 105, 110, 122, 130, 132, 134, 135, 138, 141, 152, 153, 157, 163], "fed": 74, "federico": 1, "feed": [46, 73, 74, 75, 77, 81, 83, 122, 138], "feedforward": 72, "feel": [16, 30, 35, 42, 68, 149], "femal": 135, "feng": [18, 153, 158, 159], "feroz": 1, "few": [4, 9, 11, 20, 22, 28, 42, 43, 45, 47, 52, 58, 68, 69, 72, 74, 76, 80, 81, 85, 97, 131, 132, 135, 138, 153, 156, 158, 161, 166], "fewer": [34, 52, 58, 70, 71, 130, 138, 153], "ffmpeg": 131, "ffmpegwrit": 131, "ffnn": 72, "fhb09": [1, 158], "fhi": [1, 50], "fiber": 56, "fictiti": 153, "fiddl": 78, "fidel": [50, 51, 52, 127], "field": [1, 8, 16, 48, 52, 54, 67, 68, 69, 72, 78, 94, 96, 98, 99, 109, 122, 131, 159], "fieri": 58, "fifth": [58, 138, 148, 149], "fig": [0, 3, 4, 5, 6, 9, 20, 21, 22, 30, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 58, 70, 71, 72, 75, 77, 78, 80, 82, 83, 84, 86, 87, 88, 93, 98, 100, 101, 102, 107, 125, 126, 128, 131, 132, 134, 135, 137, 138, 139, 140, 149, 150, 152, 154, 157, 158, 161, 166, 167, 168], "fig1": [44, 157], "fig2": [42, 44, 157], "fig3": 38, "fig3d": 135, "fig_2": 155, "fig_4": 155, "fig_5": 155, "fig_af": 20, "fig_corn": [161, 166], "fig_cprob_revers": 161, "fig_cr": 135, "fig_id": 138, "fig_knn_classifi": 70, "fig_linear_classifi": 70, "fig_linear_classifier_plan": 70, "fig_pdfi": 135, "fig_point": 135, "fig_run": [161, 166], "fig_runs_revers": 161, "fig_slopesampl": 3, "fig_train_data": 70, "fig_tru": 42, "fig_x1x2": 135, "fig_x2givenx0": 161, "fig_xmgivenx0": 161, "figsiz": [5, 6, 9, 20, 22, 30, 34, 35, 38, 39, 42, 43, 44, 45, 46, 47, 54, 55, 70, 74, 75, 78, 81, 82, 83, 86, 87, 88, 93, 98, 100, 107, 128, 131, 132, 134, 135, 138, 139, 140, 148, 149, 150, 154, 155, 156, 157, 158, 166, 167], "figur": [5, 9, 18, 22, 30, 38, 41, 43, 44, 45, 46, 47, 54, 55, 56, 58, 70, 71, 73, 74, 75, 77, 81, 82, 83, 84, 85, 87, 88, 91, 93, 97, 98, 99, 100, 101, 125, 126, 128, 131, 132, 138, 140, 142, 143, 150, 153, 154, 155, 157, 161, 164, 167, 168], "figure1": 22, "figure2": 22, "figure_id": 138, "figure_titl": 47, "figurefil": 138, "file": [9, 48, 55, 75, 81, 98, 101, 128, 131, 137, 138, 139, 142, 144, 145], "filenam": [74, 131], "filenotfounderror": 131, "fill": [9, 35, 37, 39, 47, 51, 52, 57, 82, 84, 99, 101, 130, 131, 138, 147, 159], "fill_between": [9, 22, 46, 85, 86, 87, 99, 101, 131, 135], "filter": [80, 131, 132, 156], "filterwarn": [78, 98, 148], "final": [4, 6, 17, 18, 20, 21, 28, 30, 36, 39, 43, 45, 46, 47, 48, 49, 51, 55, 58, 62, 67, 69, 70, 71, 72, 74, 76, 77, 79, 80, 81, 90, 97, 102, 105, 111, 120, 125, 130, 138, 148, 152, 157, 161, 163, 168], "financi": 69, "find": [0, 3, 4, 5, 9, 16, 18, 19, 20, 21, 22, 24, 27, 28, 30, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 56, 57, 58, 61, 68, 69, 70, 71, 72, 73, 75, 76, 77, 82, 88, 90, 91, 93, 94, 97, 98, 99, 100, 101, 102, 104, 105, 106, 109, 110, 111, 115, 118, 122, 126, 128, 130, 131, 135, 136, 137, 138, 139, 140, 143, 147, 148, 149, 150, 152, 153, 154, 156, 157, 158, 159, 161, 163, 164, 166, 167], "find_contour_level": 42, "find_index": 42, "find_map": [156, 157], "findabl": 48, "fine": [52, 71, 76], "finer": [55, 56, 101], "finetti": 51, "finish": [45, 98, 142], "finit": [16, 24, 38, 39, 48, 49, 52, 71, 72, 83, 87, 90, 91, 96, 122, 130, 149, 161, 166], "firmli": 8, "first": [1, 3, 5, 8, 9, 11, 15, 16, 18, 20, 22, 23, 24, 27, 28, 30, 31, 32, 36, 37, 39, 41, 43, 44, 47, 48, 49, 52, 53, 54, 55, 56, 58, 62, 64, 68, 69, 71, 72, 74, 76, 77, 78, 80, 81, 82, 83, 85, 87, 88, 90, 91, 93, 97, 98, 99, 100, 101, 112, 115, 120, 122, 126, 130, 131, 132, 135, 139, 140, 141, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 161, 163, 164, 165, 166, 167], "first_nam": 139, "fisher": [1, 100], "fission": 52, "fist": 161, "fit": [20, 22, 28, 34, 39, 41, 43, 48, 52, 54, 56, 57, 58, 68, 70, 71, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 91, 93, 97, 98, 99, 101, 102, 106, 107, 108, 109, 116, 124, 126, 129, 132, 143, 151, 158], "fit_degree_n": 100, "fit_intercept": [75, 138], "fit_transform": 128, "fiti": 138, "five": [30, 39, 42, 104, 109, 125, 135, 138], "fix": [3, 9, 18, 21, 24, 27, 28, 39, 42, 48, 54, 55, 56, 58, 71, 76, 77, 80, 82, 87, 88, 90, 101, 110, 111, 122, 125, 126, 128, 133, 134, 135, 137, 138, 139, 148, 149, 150, 153, 155, 158, 159, 161, 163, 166, 167], "fk": 101, "flag": [42, 43], "flash": 41, "flat": [6, 8, 26, 30, 39, 41, 42, 43, 44, 45, 55, 57, 73, 91, 101, 128, 152, 157], "flatchain": [43, 46, 55, 148], "flatlnprob": 46, "flatten": [6, 38, 41, 46, 54, 55, 74, 80, 81, 82, 87, 88, 131, 141, 148, 151, 152, 156, 157], "flavor": 8, "flavour": 110, "flaw": 64, "flexibl": [42, 43, 52, 58, 71, 72, 76, 78, 90, 116, 138], "flexibli": 78, "flick": 153, "flip": [11, 13, 16, 30, 35, 153, 166], "flipper": 9, "float": [47, 55, 74, 75, 87, 101, 128, 134, 138, 139, 141, 154, 155], "float32": [74, 76, 78, 81, 134], "float64": [55, 101, 138, 156], "float640": 156, "float641": 156, "float6410": 156, "float6412": 156, "float642": 156, "float_widget": 137, "floatslid": [5, 9, 137, 139], "floatx": [78, 98], "floor": 141, "florian": 168, "flow": [49, 72, 122, 128, 158], "flowchart": 143, "fluctuat": [11, 28, 34, 41, 42, 45, 47, 95, 99, 101, 110, 111, 156, 159, 164], "fluid": 166, "flux": 58, "fly": [78, 98], "fm": 52, "fmhlg13": [1, 158], "fmin": 43, "fmt": [39, 43, 45, 46, 54, 100, 101, 107, 128, 148], "fn": [68, 69], "fnois": 97, "focu": [28, 48, 49, 69, 71, 77, 82, 88, 90, 109, 138, 147, 158, 161], "focus": [39, 48, 54, 67, 69, 78, 93, 94, 158], "fold": 100, "folder": 138, "follow": [4, 8, 9, 11, 12, 16, 18, 22, 24, 27, 30, 31, 39, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 58, 62, 66, 67, 69, 70, 71, 72, 74, 76, 77, 78, 80, 88, 90, 93, 97, 98, 99, 100, 101, 107, 108, 109, 110, 111, 115, 122, 124, 125, 128, 130, 131, 132, 135, 138, 139, 140, 141, 142, 143, 144, 147, 149, 150, 152, 153, 156, 157, 158, 159, 161, 164, 165, 166, 167], "font": [5, 9, 39, 42, 47, 115, 131, 132, 137, 138, 154, 155], "font_siz": [5, 9, 137, 154, 155], "font_size_w": 137, "fontsiz": [20, 22, 38, 43, 47, 55, 86, 101, 128, 135, 148, 152, 157], "food": 166, "fool": 36, "foolish": 71, "foral": [52, 70, 109, 161], "forc": [1, 56, 58, 64, 70, 119, 120, 126, 128, 131, 155, 159], "forcefulli": 153, "forecast": [16, 72], "forefront": 7, "foreman": [1, 152, 157, 164], "forest": [72, 78], "forestgreen": 125, "forev": 148, "forg": [78, 142], "forget": [26, 35, 70, 78, 98, 139], "forgotten": 138, "fork": 55, "form": [0, 4, 8, 13, 21, 24, 28, 30, 38, 42, 43, 45, 48, 52, 53, 54, 57, 58, 63, 68, 69, 70, 72, 73, 75, 76, 78, 80, 82, 83, 85, 87, 88, 91, 93, 96, 98, 100, 102, 105, 109, 111, 115, 122, 125, 130, 135, 139, 147, 149, 153, 155, 156, 158, 159, 161], "formal": [8, 30, 39, 52, 53, 58, 87, 105, 106, 115, 132, 161], "format": [0, 1, 30, 35, 43, 44, 45, 46, 47, 54, 55, 61, 74, 76, 78, 81, 97, 100, 101, 137, 138, 139, 140, 141, 148, 150, 152, 157], "format_nam": 0, "former": [8, 39, 48, 58, 71, 90, 105, 109, 115, 130], "formul": [0, 4, 5, 8, 9, 12, 30, 44, 48, 52, 64, 65, 70, 86, 95, 101, 118, 152, 157, 161, 166], "formula": [24, 42, 47, 52, 53, 54, 56, 58, 84, 90, 91, 95, 132, 138, 139, 149, 151], "forssen": [43, 44, 55, 82, 83, 100, 148, 149, 152, 157], "forss\u00e9n": [1, 49, 61, 78, 83, 98], "forth": [56, 72, 139], "fortran": [69, 138], "fortun": [48, 78, 142, 166], "forward": [8, 13, 46, 73, 75, 77, 80, 93, 102, 110, 119, 122, 153, 158], "fou": 56, "found": [4, 5, 8, 15, 22, 24, 26, 32, 34, 41, 43, 45, 49, 51, 52, 56, 58, 61, 68, 70, 72, 76, 77, 97, 109, 135, 141, 142, 149, 150, 155, 156, 158, 159, 164, 167, 168], "foundat": [30, 67], "four": [4, 42, 52, 55, 56, 68, 72, 73, 90, 91, 109, 125, 139, 161, 166], "fourier": [24, 39, 132], "fourth": [15, 73, 138], "fp": [68, 69, 131], "fphy": 1, "fr": [34, 38, 42, 135, 148, 161, 166], "frac": [3, 4, 8, 9, 10, 13, 16, 18, 19, 20, 21, 24, 27, 28, 29, 30, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 51, 53, 54, 56, 57, 58, 70, 71, 72, 73, 77, 83, 84, 87, 90, 91, 93, 99, 100, 101, 102, 105, 112, 118, 119, 125, 126, 128, 130, 131, 132, 135, 138, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 164, 166, 167], "frac12": [54, 83, 99, 154], "fraction": [4, 6, 9, 37, 47, 55, 58, 68, 70, 71, 74, 102, 110, 112, 115, 128, 132, 135, 148, 149, 152, 157, 158, 159], "fraction_100_after_10min": 166, "fraction_kept": 132, "fragoso2018": 53, "frame": [1, 53, 131, 138, 161], "frame_skip": 131, "frame_switch": 131, "frameon": 34, "framework": [8, 16, 30, 32, 33, 35, 48, 51, 53, 65, 66, 76, 78, 83, 90, 122, 124, 126, 128], "franci": [1, 115], "franciscan": 58, "frederi": 61, "free": [35, 43, 46, 54, 56, 72, 77, 100, 119, 120, 122, 128, 130, 168], "freedom": [24, 34, 44, 49, 58, 100, 122, 131, 135, 152, 157, 164], "freeli": [69, 78], "freq": 139, "frequenc": [4, 8, 37, 38, 39, 43, 95, 135, 137, 139, 154], "frequent": [4, 7, 28, 43, 44, 69, 93, 111, 152, 157, 158, 159], "frequentist": [9, 17, 26, 27, 28, 30, 31, 35, 37, 39, 40, 41, 44, 46, 48, 56, 100, 106, 135], "fresh": 152, "frictionless": 153, "friedman": 1, "friedrich": 1, "friend": 139, "friendli": 32, "frivol": 26, "frobeniu": 132, "frodo": 138, "frog": 81, "from": [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 16, 18, 20, 22, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 81, 83, 85, 86, 87, 90, 93, 94, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 109, 110, 115, 116, 119, 120, 122, 124, 125, 126, 127, 128, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 147, 148, 149, 150, 152, 153, 154, 155, 157, 161, 163, 166, 167, 168], "front": [1, 44, 49, 139, 140, 157], "fruition": 8, "frustra": 58, "fstring": [44, 139, 143, 157], "ft": 38, "ft_pt": 38, "ft_uniform": 38, "ft_uniform_pt": 38, "ft_valu": 38, "fuch": 133, "fuction": 134, "fulfil": [4, 48, 109, 135, 158, 161, 166], "full": [17, 20, 22, 23, 24, 39, 43, 45, 48, 49, 51, 52, 54, 56, 58, 61, 66, 72, 77, 81, 83, 84, 85, 87, 96, 98, 100, 101, 105, 111, 130, 132, 135, 141, 142, 148, 151, 153, 154, 156, 159, 164, 168], "full_cov": [82, 88], "full_matric": 132, "full_nam": 139, "fulli": [10, 48, 51, 56, 71, 72, 74, 78, 80, 124, 161, 164, 166], "fun": [38, 78, 97, 128], "func": [100, 131], "funcanim": 131, "function": [1, 3, 4, 7, 8, 9, 11, 15, 16, 19, 20, 21, 24, 25, 29, 30, 31, 32, 35, 38, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 69, 71, 72, 74, 77, 78, 79, 80, 84, 85, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 109, 110, 111, 112, 115, 118, 120, 121, 122, 125, 126, 128, 131, 132, 134, 138, 140, 141, 143, 148, 149, 151, 152, 153, 155, 156, 157, 158, 161, 164, 166], "fundament": [8, 16, 30, 39, 44, 61, 65, 71, 106, 152, 157], "fundtion": 105, "fungibl": [9, 11], "furnstah": 55, "furnstahl": [0, 1, 5, 43, 55, 61, 82, 83, 137, 142, 148, 154, 156], "further": [4, 7, 18, 20, 25, 26, 28, 29, 39, 41, 51, 53, 57, 58, 77, 78, 80, 83, 87, 91, 139, 140, 151, 153, 156, 158, 159, 161], "furthermor": [18, 30, 39, 43, 44, 46, 49, 51, 52, 54, 65, 71, 72, 77, 80, 82, 87, 88, 90, 93, 135, 138, 152, 157, 158, 166], "futur": [16, 29, 30, 39, 48, 55, 68, 70, 71, 78, 101, 115, 138, 156, 161, 166], "futuredata": 16, "futurewarn": [55, 101, 138, 156], "fvec": 91, "fvec_1": [84, 91], "fvec_2": [84, 91], "fwhm": 149, "g": [0, 1, 3, 4, 7, 8, 16, 18, 22, 23, 24, 26, 28, 30, 38, 39, 41, 43, 49, 50, 51, 52, 53, 54, 56, 57, 58, 61, 65, 66, 68, 70, 71, 72, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 91, 97, 98, 99, 100, 101, 110, 120, 122, 125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 138, 139, 142, 147, 149, 151, 153, 154, 158, 159, 165, 166, 168], "g1": 43, "g2": 43, "g_": [54, 99], "g_1": 43, "g_2": 43, "g_fun": 54, "g_i": 43, "gabri": 56, "gain": [48, 52, 57, 58, 61, 69, 78, 132], "galact": 46, "galaxi": [1, 18, 46, 58, 61, 67], "galerkin": 52, "galerkin_ortho": 52, "galleri": [18, 69, 139, 158], "galton": 115, "gambl": 8, "gambler": 166, "game": [16, 52, 77, 78, 130, 166], "gamge": 138, "gamma": [13, 22, 43, 47, 49, 112, 131, 147], "gamma2_dist": 131, "gamma_1": 112, "gamma_2": 112, "gamma_a": 131, "gamma_dist": 131, "gamma_label": 131, "gamma_scal": 131, "gap": [71, 102], "garcia": 1, "gate": 72, "gather": [24, 58, 72, 91, 161, 166], "gaug": [72, 76], "gauss": 115, "gaussian": [0, 1, 3, 16, 23, 28, 29, 31, 34, 42, 43, 45, 46, 47, 49, 50, 52, 55, 56, 57, 65, 75, 76, 77, 78, 79, 84, 92, 94, 95, 97, 99, 100, 101, 122, 123, 124, 125, 126, 128, 129, 134, 147, 148, 151, 153, 158, 159, 163], "gaussian_model": 157, "gaussian_nois": [82, 83, 88], "gaussian_norm": 54, "gaussian_process": [85, 86, 87, 127, 128], "gaussianmov": [55, 148, 151], "gaussianprocessregressor": [85, 86, 87, 97], "gave": [9, 68], "gc": [0, 1, 39, 56, 58, 61], "gca": [55, 83, 87, 100, 101, 132, 154], "gcc": [78, 98], "gcf": [101, 131], "gd": 73, "ge": [20, 72, 77, 93], "gedankenmodel": 53, "gelfand": 1, "gelman": [0, 1, 56, 61, 66, 77, 91, 149, 151], "gelman2013bayesian": 0, "gelman_rubin_diagnostic_calc": 148, "gelmen": 156, "gen": 131, "gen_gaussian_sampl": 83, "gen_plot_gaussian_sampl": 83, "gene": [1, 135], "gener": [0, 3, 4, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 24, 27, 28, 31, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 61, 62, 64, 66, 67, 70, 71, 72, 73, 75, 76, 77, 79, 82, 83, 84, 87, 88, 90, 91, 94, 95, 97, 99, 100, 102, 105, 106, 107, 109, 110, 111, 112, 114, 115, 116, 117, 120, 121, 122, 125, 126, 127, 129, 130, 131, 132, 138, 139, 142, 144, 148, 149, 150, 151, 152, 154, 155, 156, 159, 161, 163, 165, 166, 167], "generaliz": 94, "generallay": 72, "generate_binaryclass_data": 70, "generate_data": 9, "genesi": 61, "gentli": 149, "geoff": 112, "geoffrei": 1, "geometr": 8, "geometri": 16, "georg": [1, 16, 51, 66, 67, 68, 113], "geq": [4, 34, 41, 42, 43, 51, 87, 97, 109, 135, 150, 158, 159, 161, 164, 166, 167], "geron": 71, "geron17": [1, 71], "get": [0, 4, 8, 9, 10, 11, 12, 15, 16, 18, 20, 21, 22, 23, 24, 28, 30, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 47, 49, 51, 53, 54, 55, 56, 58, 70, 72, 73, 77, 78, 84, 91, 93, 95, 97, 98, 99, 100, 101, 106, 128, 130, 131, 132, 134, 135, 137, 141, 142, 143, 144, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 161, 164, 166, 167], "get_ax": 22, "get_batch": 111, "get_chain": [55, 128, 157], "get_cmap": 54, "get_fram": 9, "get_param": 87, "get_subplotspec": 3, "gev": 135, "gewek": 156, "gg": [4, 34, 42, 49, 53, 57, 58, 72], "gibb": 156, "gid": [75, 131], "gif": 131, "gif_filenam": 131, "gilk": 149, "git": [49, 69, 142, 145], "github": [45, 48, 61, 69, 75, 78, 81, 89, 98, 127, 135, 136, 141, 144, 153, 158, 159, 166], "githubusercont": 132, "gitlab": 69, "give": [0, 3, 4, 9, 12, 13, 16, 18, 20, 21, 22, 27, 28, 29, 30, 33, 35, 36, 37, 39, 41, 43, 45, 49, 50, 51, 53, 56, 58, 60, 68, 69, 70, 71, 72, 75, 76, 77, 78, 81, 82, 83, 84, 86, 87, 88, 90, 93, 99, 121, 129, 130, 132, 134, 135, 137, 138, 139, 141, 149, 151, 158, 160, 161, 164, 165, 166], "given": [0, 4, 5, 7, 8, 9, 10, 11, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 67, 69, 70, 71, 72, 73, 75, 76, 77, 83, 84, 85, 87, 90, 91, 93, 95, 96, 98, 100, 105, 109, 110, 112, 115, 122, 125, 126, 127, 128, 131, 132, 134, 135, 138, 139, 141, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 166, 167, 168], "glanc": 8, "glass": 63, "glean": 67, "glib": 142, "global": [1, 43, 55, 56, 58, 93, 102, 110, 131, 164, 168], "globalmov": 55, "glorot": 76, "gloss": [44, 152, 157], "glue": [3, 20, 70, 93, 135, 158, 161, 166], "gm": 120, "gmail": [85, 86], "go": [4, 9, 11, 13, 15, 16, 24, 27, 30, 34, 35, 38, 49, 57, 58, 61, 64, 68, 73, 78, 81, 91, 98, 102, 122, 132, 137, 138, 139, 141, 142, 145, 149, 150, 151, 152, 153, 157, 161, 164, 167], "goal": [9, 18, 22, 27, 35, 36, 37, 39, 41, 42, 47, 48, 49, 51, 53, 60, 63, 66, 69, 77, 84, 93, 94, 96, 102, 105, 109, 118, 122, 132, 152, 156, 157, 166], "goat": 16, "god": 24, "goe": [4, 18, 37, 57, 60, 71, 151, 161], "goggan": 56, "gold": [16, 82], "goldstein": [1, 51], "goldstein2009reifi": 53, "gone": 164, "good": [1, 2, 24, 27, 32, 34, 38, 39, 41, 44, 45, 47, 48, 49, 51, 52, 56, 58, 66, 68, 69, 71, 72, 73, 76, 78, 80, 82, 88, 90, 91, 97, 102, 105, 112, 126, 130, 131, 139, 141, 148, 149, 152, 153, 156, 157, 164], "goodman": [1, 158], "googl": [1, 22, 28, 47, 81, 84, 135, 137, 139, 143], "googlenet": 78, "gossett": [0, 28], "got": 34, "gothenburg": 16, "gotten": 24, "govern": [16, 68, 81, 126], "gp": [52, 82, 88, 92, 94, 97, 122, 124, 125, 126, 127, 128], "gp_kernel": 86, "gp_regress": [82, 83, 88], "gp_sklearn": 87, "gpkernel": 97, "gpplot": 87, "gpr": [86, 97], "gpr_model": 86, "gpr_sklearn": 87, "gpregress": [82, 83, 84, 88], "gpu": [78, 98], "gpy": [83, 84, 90, 91, 97], "gr92": [1, 49], "grab_fram": 131, "grad": 76, "grad_fn": 76, "grade": 8, "gradient": [39, 49, 70, 71, 72, 73, 75, 77, 78, 80, 93, 105, 118, 121, 122, 156, 159, 163, 168], "gradienttap": 81, "gradual": 52, "graduat": 61, "grai": [42, 43, 45, 101, 131, 132, 153], "grand": 37, "graph": [1, 9, 22, 41, 47, 69, 76, 78, 81, 82, 98, 109, 137, 140, 150, 159, 167], "graphic": [131, 142], "graphs_rjf": 131, "grass": [26, 67], "grate": 61, "gratefulli": 9, "gravit": [7, 56, 120, 126], "gravitation_orbit_1": 155, "graviti": [56, 126, 128], "grayscal": 80, "gre05": [1, 2, 32, 58, 61, 159, 167], "great": [7, 16, 52, 61, 78, 92, 142, 164], "greater": [24, 38, 42, 43, 49, 56, 58, 82, 88, 125, 126, 128, 148, 156], "greatest": [16, 98], "greatli": 70, "greedi": 52, "greek": 135, "green": [9, 38, 49, 74, 80, 101, 126, 131, 135, 139, 149, 153, 155, 159, 164, 168], "greenfield": 103, "gregori": [1, 2, 32, 42, 58, 61, 150, 167], "gregory_7_2": 58, "grei": [52, 70], "grid": [0, 21, 39, 42, 45, 46, 55, 56, 70, 75, 77, 78, 79, 81, 91, 98, 101, 107, 139, 161], "grid_2d": [78, 98], "griffith": 133, "grist": 63, "ground": [8, 52, 53, 126, 128, 138, 161], "groundwork": 39, "group": [4, 42, 69, 78, 82, 88, 90, 122, 131, 138, 141], "groupbi": 138, "grow": [34, 73, 91, 120, 122, 152, 157, 158, 159, 166], "growth_fig": 166, "growth_quest": 166, "gsl": 39, "gt": [120, 156, 159, 164], "guarante": [8, 16, 39, 52, 83, 87, 105, 149, 155, 161], "guess": [20, 22, 43, 87, 91, 97, 128, 152, 157, 161], "guesswork": 161, "gui": 131, "guid": [1, 11, 32, 46, 58, 67, 69, 74, 76, 86, 99, 122, 124, 136, 137, 142, 144], "guidanc": [55, 101, 131], "guidelin": [48, 99], "guido": 133, "guillaum": [85, 86], "guilti": 68, "guin": 28, "guiness": 0, "gull": [4, 47, 58], "gw07": [1, 51], "gw10": [1, 158], "h": [0, 1, 8, 16, 18, 20, 21, 29, 30, 36, 39, 49, 50, 51, 52, 58, 75, 90, 100, 120, 126, 128, 130, 135, 138, 149, 153, 154, 164, 166], "h0": [0, 21, 46, 128], "h2mc": 159, "h_": [18, 39, 46, 52, 58], "h_0": [18, 21, 126, 128], "h_1": 30, "h_3": 16, "h_i": 30, "h_j": 16, "ha": [0, 4, 8, 9, 10, 16, 18, 22, 24, 27, 28, 30, 33, 34, 35, 36, 39, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 64, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 80, 81, 82, 83, 84, 85, 87, 90, 91, 93, 94, 95, 97, 99, 100, 101, 102, 109, 110, 111, 112, 116, 119, 120, 122, 126, 128, 130, 132, 135, 136, 138, 139, 140, 141, 142, 149, 150, 151, 152, 153, 156, 157, 158, 159, 161, 165, 166, 167], "habit": 48, "hackernoon": 140, "had": [4, 13, 16, 22, 24, 30, 46, 58, 61, 77, 135, 138, 149, 151, 159, 164], "hadamard": [73, 141], "hagan": 124, "hair": 4, "hal21": [1, 122], "half": [8, 22, 41, 42, 43, 45, 46, 49, 58, 75, 148, 153, 161], "halfnorm": 156, "halfwai": [56, 155], "hall": [0, 1, 16, 61], "halt": 112, "halv": [51, 148], "halverson": 1, "hamilton": [49, 153, 154], "hamiltonian": [1, 50, 52, 127, 154, 158, 159, 162, 165], "hamiltonianmc": 156, "hamiltonianpendulum": 154, "hammer": 1, "hand": [0, 1, 4, 9, 16, 20, 26, 27, 30, 31, 39, 43, 58, 67, 69, 71, 72, 74, 77, 78, 80, 82, 88, 102, 132, 142, 154, 155, 158, 161, 166, 168], "handbook": [1, 49, 71], "handed": 4, "handl": [49, 72, 75, 76, 87, 100, 115, 118, 138], "handle_color": 9, "handsid": 73, "hang": 56, "hanin": 1, "hao": 1, "happen": [5, 8, 11, 12, 20, 34, 39, 41, 42, 45, 46, 54, 63, 71, 73, 81, 82, 91, 95, 101, 132, 135, 149, 151, 156], "happend": 39, "happi": 137, "hard": [1, 36, 49, 54, 70, 72, 78, 93, 122, 149, 156, 159], "harder": [39, 72, 156], "hardest": 77, "hardli": 72, "hardwar": [69, 142], "hare": 72, "harm": [68, 71], "harmon": 52, "harsher": 58, "hashtag": 139, "hast": [55, 56, 148, 151, 153, 156, 164, 165], "hasti": [1, 71], "hat": [34, 43, 48, 49, 54, 56, 57, 68, 90, 112, 126, 128, 148, 156], "have": [0, 3, 4, 5, 7, 8, 9, 10, 11, 13, 16, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 58, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 83, 84, 85, 87, 88, 90, 91, 92, 93, 95, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 112, 116, 117, 118, 120, 122, 124, 125, 128, 129, 130, 131, 132, 134, 135, 136, 138, 139, 140, 141, 142, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 161, 163, 164, 165, 166, 167], "haven": 58, "hazan": 1, "hbox": [5, 9, 137], "hbox0": [9, 137], "hbox1a": [9, 137], "hbox1b": [9, 137], "hbox2": [9, 137], "hbox3": [9, 137], "hbox_1": 137, "hbox_2": 137, "hd": 18, "hdi_3": [156, 157], "hdi_97": [156, 157], "hdr": 135, "he": [1, 8, 16, 30, 42, 51, 52, 58, 66, 67, 76, 93, 122, 131], "head": [0, 8, 9, 11, 13, 16, 24, 28, 30, 35, 57, 138, 139, 166], "header": [138, 139], "headlin": 78, "heads_in_data_to_n": 9, "headstart": 132, "health": 78, "healthcar": 68, "hear": 69, "heart": [63, 124], "heavi": [12, 22, 23, 52, 69, 131], "heavili": [56, 69, 70, 111, 159], "heavisid": 49, "hei": 78, "height": [0, 9, 22, 41, 58, 80, 81, 115, 120, 126, 131, 137, 151, 168], "heisenberg": 16, "held": [27, 55, 153], "hello": [139, 140], "hello_funct": 139, "help": [9, 43, 47, 48, 49, 63, 68, 69, 71, 72, 74, 76, 78, 90, 98, 112, 116, 128, 137, 143, 144, 148], "help_bayes_w": 9, "help_max_height": [9, 137], "help_overview_w": [9, 137], "help_parameters_w": 137, "help_priors_w": 9, "help_setup_w": [9, 137], "help_tab": [9, 137], "help_times_w": 137, "help_toss_coin_w": 9, "helper": [39, 74, 75, 81, 107], "henc": [0, 27, 28, 39, 58, 71, 83, 87, 90, 96, 104, 138, 161], "henceforth": 161, "hendrik": [85, 86], "hennig": 66, "hensman": [82, 88], "her": [58, 68], "here": [0, 4, 5, 9, 13, 16, 18, 21, 22, 24, 28, 29, 30, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 61, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 86, 88, 90, 91, 92, 93, 94, 97, 98, 100, 105, 107, 108, 117, 120, 121, 122, 125, 126, 127, 128, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 161, 163, 164, 165, 166, 167], "hereaft": 24, "hermitian": [52, 141], "heroic": 67, "hesian": 159, "hesit": 27, "hess_inv": 46, "hessian": [39, 41, 46, 58, 100], "heurist": [78, 164], "hexp_err": 128, "hexp_err_sc": 128, "hexp_mean": 128, "hexp_mean_sc": 128, "hexp_std": 128, "hg": [1, 49, 135], "hi": [0, 28, 30, 42, 58, 67, 109, 126, 156, 159], "hi95": [82, 88], "hick": 148, "hidden": [20, 21, 48, 56, 68, 70, 72, 73, 75, 76, 78, 80, 98, 122, 134, 135], "hidden1": 76, "hidden2": 76, "hidden3": 76, "hide": 0, "hierarch": 78, "hierarchi": [45, 78], "higdon": [126, 128], "higdon2004combin": 53, "higg": [24, 135, 159], "high": [1, 5, 9, 26, 36, 39, 43, 48, 49, 50, 51, 52, 54, 56, 61, 68, 69, 71, 72, 77, 78, 80, 101, 102, 107, 111, 118, 127, 132, 138, 149, 151, 153, 154, 158], "higher": [9, 16, 24, 28, 39, 45, 52, 68, 69, 71, 78, 82, 85, 100, 128, 138, 149, 153, 154, 161], "highest": [24, 51, 55, 56, 78, 81, 84, 101, 130, 135, 156, 168], "highli": [32, 46, 49, 52, 57, 69, 71, 78, 83, 87, 91, 111, 138, 139, 157, 164], "highlight": [0, 38, 48, 61, 68, 100, 130, 139], "hilbert": 52, "hill": 149, "him": [109, 122, 133], "himself": 58, "hinder": 110, "hint": [0, 16, 18, 36, 42, 44, 56, 82, 88, 93, 101, 147, 157, 161, 166], "hinton": [1, 112], "hist": [22, 34, 38, 44, 47, 55, 78, 87, 98, 131, 134, 135, 148, 149, 150, 156, 157, 167], "hist_kwarg": 128, "hist_norm": 131, "hist_pt": 131, "hist_pts_al": 131, "histogram": [22, 23, 24, 34, 38, 41, 44, 47, 48, 49, 55, 84, 87, 134, 135, 148, 149, 150, 151, 152, 156, 157, 158, 159, 161, 164, 166, 167], "histogram2d": 46, "histogram_ax": 38, "histor": [51, 53, 68, 93, 94, 109], "historam": 38, "historgram": 164, "histori": [1, 60, 72, 74, 81, 112, 115, 161, 166], "historian": [8, 67], "histplot": 149, "histtyp": [135, 149], "hit": [11, 22, 41, 135, 139], "hitchhik": 61, "hjorth": 61, "hmc": [49, 156, 159, 163, 164, 165], "hmodel_sc": 128, "hms21": [1, 122], "hmv": 153, "ho": 52, "hobson": 1, "hoc": 43, "hoffman": 1, "hogg": [1, 100, 164], "hold": [9, 11, 36, 39, 52, 53, 68, 71, 78, 80, 98, 128, 141, 153, 158, 161], "holdout": 71, "hole": [7, 56], "home": [0, 82], "homemad": 155, "homogen": [72, 141], "honest": [4, 66], "honesti": 66, "honor": 50, "hood": 76, "hope": [53, 63, 64, 66, 93], "hopefulli": [50, 74, 78, 132], "hopfield": 72, "hopkin": 1, "horizont": [22, 24, 55, 83, 87, 137, 141, 148], "horizontalalign": [9, 20, 47], "hors": [81, 93], "hospit": 68, "host": 16, "hour": 42, "hous": 16, "how": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 16, 17, 22, 23, 24, 27, 28, 29, 30, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 52, 54, 55, 56, 58, 61, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 82, 83, 84, 85, 87, 90, 93, 96, 97, 98, 100, 105, 107, 118, 119, 120, 122, 126, 128, 129, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 147, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 161, 166, 167, 168], "howard": 135, "howev": [4, 8, 11, 16, 20, 30, 39, 43, 44, 48, 49, 50, 51, 52, 53, 56, 58, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 82, 88, 90, 93, 97, 98, 102, 104, 105, 106, 109, 110, 111, 112, 115, 122, 124, 127, 135, 138, 139, 140, 141, 142, 149, 151, 152, 156, 157, 158, 161, 166], "hp_bound": 128, "hpd": [24, 156], "hspace": 138, "hsplit": 141, "htf09": [1, 71], "html": [0, 1, 9, 22, 46, 47, 55, 75, 78, 86, 98, 101, 127, 135, 137, 139, 156, 157, 168], "htmlmath": [5, 9, 137], "http": [0, 1, 22, 45, 46, 55, 56, 74, 78, 81, 82, 86, 98, 101, 109, 127, 132, 135, 140, 142, 145, 153, 156, 157, 159, 166, 168], "hu": 1, "huang": [1, 138], "hubbl": [18, 46], "huber_loss": 43, "huge": [4, 18, 65, 67, 78, 80], "hugh": 135, "human": [67, 68, 69, 72], "hump": 24, "humpti": 63, "hundr": [72, 132], "hungarian": 66, "hungri": 72, "hunt": 58, "hw": [83, 87], "hybrid": [1, 49, 52, 78], "hydrogen": [138, 149], "hyper": [53, 78, 156], "hyperbol": [72, 76], "hypercub": [52, 84, 158], "hyperlink": [0, 61], "hyperparamet": [9, 22, 48, 49, 52, 71, 72, 74, 76, 77, 80, 83, 85, 87, 88, 91, 93, 102, 111, 122, 124, 125, 126, 128, 163], "hyperparmet": 128, "hyperrectangl": 51, "hyperreduct": 52, "hypothes": [7, 30, 58, 68, 72, 116, 124], "hypothesi": [8, 11, 24, 30, 44, 57, 68, 152, 157], "hypothet": [24, 58], "i": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 21, 23, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 163, 165, 166, 167, 168], "i1": 72, "i10": 166, "i3": 138, "i5": 138, "i6qkdaeacaaj": 1, "i_": [51, 91, 132, 161], "i_0": 161, "i_1": 161, "i_2": 161, "i_d": [0, 21, 91], "i_i": 51, "i_m": 51, "i_n": [158, 161], "i_num": 158, "i_rel_error": 158, "i_sort": 46, "i_unsort": 46, "ia": 20, "ian": [1, 61], "iax": 3, "ib": 101, "ichain": [55, 148], "iclass": 70, "iclass_mean": 70, "icol": [55, 148], "id": [1, 139], "idata": 70, "idea": [9, 24, 29, 35, 38, 43, 48, 49, 52, 56, 61, 68, 69, 71, 72, 78, 82, 84, 88, 90, 97, 99, 102, 122, 131, 132, 147, 149, 151, 153, 156, 164, 168], "ideal": [4, 39, 49, 67, 69, 101], "ideg": 100, "idenitfi": 161, "ident": [39, 52, 56, 58, 63, 67, 71, 77, 78, 101, 107, 126, 128, 138, 141, 153, 161], "identif": [51, 109, 135], "identifi": [4, 8, 24, 31, 39, 43, 46, 48, 49, 51, 53, 68, 69, 70, 72, 74, 91, 93, 99, 119, 130, 135, 139, 141, 151, 159, 161, 168], "idx": 86, "iexp": 158, "iexp_i_num": 158, "ignor": [3, 4, 8, 9, 13, 18, 21, 22, 30, 34, 43, 46, 47, 49, 51, 53, 54, 58, 66, 78, 81, 98, 131, 135, 148, 149, 151, 158], "ii": [1, 17, 39, 42, 43, 48, 57, 58, 64, 68, 87, 99, 100, 112, 126, 130, 132, 135, 138, 153, 161], "iia": 96, "iib": 96, "iib_how_many_lines_ptemce": 95, "iid": [58, 88, 101, 128, 148], "iii": [17, 48, 58, 64, 99, 126, 161], "iiia": 96, "iiib": 96, "iint": 49, "ij": [34, 39, 52, 58, 72, 73, 87, 91, 100, 130, 132, 148, 161, 166], "ik": [70, 87, 130, 132], "il": 72, "ill": [130, 132], "illustr": [18, 36, 37, 46, 52, 53, 54, 56, 58, 71, 72, 82, 85, 87, 88, 92, 123, 125, 126, 135, 168], "ilogp": 43, "ils": 1, "im": [39, 70, 101], "imag": [68, 72, 74, 122, 130, 131, 139], "image_height": 81, "image_path": 138, "image_width": 81, "imagemagick": 131, "imagenet": 78, "imagin": [4, 16, 30, 36, 42, 45, 53, 70, 71, 78, 101, 131, 151, 158, 159, 164], "img": [74, 81, 132], "img2": 132, "img99": 132, "img995": 132, "img_orig": 132, "immedi": [4, 16, 24, 58, 63, 65], "imp": 97, "impact": [28, 48, 68, 69, 76, 95, 99], "imparti": 66, "imper": 48, "imperfect": [28, 53], "impi": 161, "implaus": [51, 77], "implement": [27, 32, 39, 41, 43, 47, 48, 49, 52, 53, 56, 63, 68, 75, 76, 77, 78, 79, 80, 82, 87, 88, 95, 97, 101, 111, 112, 138, 140, 141, 150, 151, 154, 155, 161, 164, 166, 167, 168], "impli": [3, 4, 7, 18, 20, 21, 24, 27, 28, 34, 36, 37, 39, 43, 44, 45, 46, 49, 50, 52, 53, 54, 58, 67, 69, 70, 71, 72, 77, 80, 81, 83, 87, 90, 100, 102, 104, 105, 112, 117, 124, 132, 135, 139, 140, 148, 149, 152, 157, 161, 166], "implic": [10, 64], "implicit": [9, 28, 35, 39, 44, 54, 83, 87, 90, 152, 157], "implicitli": [24, 34, 45, 47, 148], "import": [0, 1, 3, 6, 7, 8, 9, 12, 20, 21, 22, 24, 29, 30, 33, 34, 35, 38, 39, 42, 44, 45, 46, 47, 48, 51, 52, 54, 58, 60, 61, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 83, 84, 85, 86, 87, 90, 93, 98, 102, 105, 107, 109, 110, 111, 124, 128, 130, 131, 134, 139, 140, 141, 143, 148, 150, 152, 154, 155, 157, 158, 159, 161, 164, 166, 167], "importantli": [30, 42, 48, 83, 87, 120], "impos": [51, 65, 71, 84, 166], "imposs": [20, 39, 52], "impract": 158, "impress": [152, 157], "imprint": [69, 161], "improv": [5, 7, 15, 16, 23, 48, 53, 55, 56, 58, 69, 71, 76, 78, 94, 97, 98, 101, 111, 112, 122, 140, 151, 153, 155, 156, 167], "imput": 67, "imread": 132, "imshow": [74, 81, 83, 87, 132], "in_featur": [76, 134], "inaccur": [68, 70, 126], "inaccuraci": 51, "inact": [51, 72], "inadequ": 159, "inadvert": 61, "inappropri": 131, "inch": 154, "includ": [0, 4, 8, 12, 15, 16, 18, 27, 29, 30, 31, 32, 33, 34, 38, 39, 41, 44, 46, 48, 51, 52, 53, 55, 56, 60, 61, 64, 69, 70, 71, 72, 75, 76, 77, 78, 79, 82, 87, 88, 90, 91, 93, 94, 97, 98, 101, 105, 107, 115, 120, 121, 122, 126, 127, 128, 130, 131, 135, 137, 138, 139, 142, 146, 149, 152, 156, 157, 158, 161, 166, 168], "include_group": 138, "inclus": [44, 48, 57, 68, 152, 157], "incom": 72, "incomplet": [8, 51, 58, 68, 158], "inconsist": 68, "incorpor": [0, 4, 7, 16, 20, 30, 48, 66, 71, 72, 124, 125, 126, 155], "incorrect": [74, 81, 126, 128, 141], "increas": [16, 22, 28, 30, 38, 39, 46, 51, 52, 54, 55, 69, 70, 71, 72, 76, 77, 87, 100, 101, 102, 107, 112, 125, 128, 147, 148, 149, 151, 156, 158, 159, 164, 166], "increasingli": [30, 38, 45, 52, 53, 56, 58, 68, 83, 125, 126, 139, 151, 152, 157], "incredibli": 69, "increment": [9, 11, 76, 164], "inde": [8, 9, 16, 24, 27, 30, 35, 39, 58, 63, 65, 69, 105, 106, 138, 158, 161, 166], "indent": [139, 143], "independ": [3, 4, 9, 12, 15, 16, 18, 20, 24, 27, 28, 30, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 68, 70, 71, 72, 77, 83, 85, 90, 91, 93, 100, 101, 104, 105, 107, 114, 115, 117, 118, 125, 126, 128, 132, 148, 153, 158, 159, 161, 166], "index": [5, 38, 39, 42, 49, 70, 81, 87, 90, 91, 93, 107, 122, 125, 130, 131, 135, 138, 140, 154, 155, 156, 157, 161, 166, 168], "index_col": 138, "index_cv": 100, "index_max": 131, "indiana": 61, "indic": [0, 4, 9, 22, 30, 34, 39, 43, 45, 46, 49, 51, 54, 56, 58, 68, 70, 74, 76, 77, 87, 109, 115, 130, 131, 132, 135, 138, 141, 142, 148, 151, 152, 153, 156, 157, 159, 161, 166], "indiffer": [8, 18, 48, 67], "indigen": 68, "indirect": 58, "indirectli": [48, 49], "individu": [27, 37, 38, 39, 43, 45, 46, 48, 49, 51, 53, 54, 68, 72, 78, 84, 86, 93, 100, 142, 148, 154, 166], "induc": [51, 56, 122], "induct": [1, 7, 47, 66, 118], "industri": 72, "ineffici": [49, 72, 111], "inequ": 51, "inevit": 135, "inexpens": [36, 52], "inf": [6, 38, 42, 43, 45, 47, 101, 128, 135, 148, 152, 157], "infeas": [48, 49, 52], "infer": [1, 8, 16, 23, 29, 30, 32, 33, 35, 39, 47, 52, 58, 60, 61, 62, 63, 64, 69, 70, 76, 94, 96, 100, 101, 107, 120, 124, 126, 129, 135, 148, 151, 156, 166, 168], "inference_librari": 156, "inference_library_vers": 156, "inferenti": [16, 53], "infil": 138, "infin": [18, 24, 43, 122, 131, 148], "infinit": [18, 43, 58, 69, 82, 87, 88, 90, 91, 115, 122, 158, 161], "infinitesim": [19, 30, 35, 58, 112], "influenc": [4, 16, 17, 30, 43, 48, 51, 68, 71, 82, 88, 90, 126], "influenti": [48, 67], "info": [41, 78, 98, 128, 131, 138, 141, 144, 156], "inform": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 16, 18, 20, 21, 23, 24, 27, 28, 29, 30, 34, 35, 36, 37, 39, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 57, 58, 60, 61, 63, 64, 66, 67, 68, 70, 71, 72, 77, 78, 84, 90, 93, 99, 100, 106, 112, 116, 118, 122, 124, 126, 128, 132, 135, 137, 138, 140, 142, 148, 152, 156, 157, 159, 164], "informatik": [85, 86], "infrastructur": 68, "infti": [0, 4, 15, 18, 21, 22, 24, 28, 29, 38, 39, 41, 42, 43, 46, 49, 53, 54, 58, 77, 107, 135, 148, 151, 158, 161, 166], "ingredi": [19, 25, 29, 32, 51, 52, 56, 64, 72, 147], "inher": [48, 49, 58, 71, 76, 77, 78, 124, 166], "inherit": [76, 105], "inhibit": 71, "init": [55, 76, 134, 164], "init_1": [78, 98], "init_2": [78, 98], "init_out": [78, 98], "init_weight": 76, "initi": [9, 11, 16, 28, 35, 42, 46, 47, 51, 52, 55, 56, 57, 58, 61, 71, 72, 78, 82, 84, 87, 88, 97, 98, 101, 102, 110, 112, 122, 126, 128, 132, 135, 140, 142, 148, 150, 151, 154, 155, 156, 157, 158, 159, 161, 163, 164, 166, 167, 168], "initial_text": [9, 137], "initial_text_w": [9, 137], "initialis": [55, 157], "initialize_model": 134, "initio": [1, 97], "initv": 156, "inlin": [5, 38, 42, 43, 44, 45, 46, 47, 54, 75, 78, 82, 83, 88, 97, 98, 100, 101, 132, 135, 138, 139, 148, 149, 150, 152, 154, 157, 167], "inner": [8, 73, 82, 88], "innov": 78, "innovi": 78, "input": [0, 5, 9, 17, 39, 45, 48, 51, 53, 61, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 87, 90, 91, 93, 94, 97, 98, 101, 106, 109, 114, 115, 122, 124, 125, 126, 128, 136, 139, 141, 163, 164, 166], "input_dim": [82, 83, 88, 97], "input_shap": [74, 81], "input_v": 134, "inputs_i": [39, 69, 70, 71, 111], "inputs_j": 71, "inputt": [39, 104, 106, 107, 115, 117, 118, 119], "inputt_": 118, "inputt_1": [70, 72, 118], "inputt_2": [70, 72, 118], "inputt_i": 118, "inputt_p": 72, "inquiri": 124, "insensit": 70, "insert": [16, 27, 36, 37, 52, 73, 75, 82, 88, 97, 135, 139, 141, 161, 166], "insid": [76, 100, 138, 139, 140, 154, 158, 168], "insight": [7, 25, 29, 31, 39, 50, 51, 53, 58, 69, 76, 78, 82, 88, 105, 116, 124], "inspect": [8, 39, 43, 107], "inspir": [69, 71, 72, 77, 78, 141, 149], "instal": [75, 78, 139, 147], "instanc": [16, 20, 67, 68, 70, 72, 76, 90, 93, 111, 118, 135, 156, 161, 166], "instanti": [84, 128, 154, 156], "instead": [8, 16, 18, 20, 24, 39, 43, 44, 48, 49, 51, 53, 54, 56, 57, 58, 63, 67, 70, 76, 77, 78, 79, 80, 82, 83, 84, 87, 88, 90, 102, 110, 111, 112, 135, 139, 140, 141, 142, 149, 151, 152, 156, 157, 161, 164, 166], "institut": [68, 69, 135], "instruct": [22, 30, 35, 48, 58, 69, 142, 147], "insuffici": 58, "insur": 61, "int": [4, 9, 18, 21, 22, 24, 28, 30, 38, 39, 42, 46, 47, 49, 54, 56, 57, 58, 75, 77, 78, 86, 87, 90, 98, 100, 128, 131, 141, 148, 150, 154, 158, 159, 164, 167], "int64": 156, "int640": 156, "int8": [78, 98], "int_": [0, 3, 4, 16, 18, 21, 24, 28, 29, 38, 43, 46, 53, 58, 135, 151, 158], "int_0": [4, 11, 13, 21, 30, 41, 43, 56, 135], "int_1": 135, "int_a": [22, 28, 135, 159], "int_v": 159, "integ": [9, 13, 38, 41, 42, 44, 49, 74, 109, 115, 128, 134, 139, 140, 148, 150, 159, 161, 167], "integr": [0, 4, 5, 16, 18, 19, 20, 21, 22, 23, 24, 28, 29, 36, 37, 39, 41, 42, 43, 48, 49, 52, 55, 56, 57, 58, 65, 76, 77, 78, 98, 100, 128, 131, 135, 139, 152, 153, 154, 155, 157, 159, 164], "integrand": [29, 38, 39, 43, 54, 57, 135, 158, 159], "integrand_pt": 38, "integration_fig": 158, "intel": 142, "intellectu": 66, "intellig": [1, 68, 69, 94, 109], "intend": [56, 66, 76], "intens": [43, 61, 84, 95], "intent": 48, "interact": [0, 16, 18, 30, 32, 48, 50, 61, 72, 122, 137, 138, 139, 153, 158, 159, 164], "interactive_output": 9, "interc": [57, 84, 91, 130, 151, 153], "intercept": [3, 6, 28, 39, 41, 43, 45, 46, 58, 104, 105, 138, 148], "intercept_": 75, "intercept_limit": 45, "intercept_rang": 45, "intercept_sc": 75, "interchang": 161, "interdepend": 51, "interest": [4, 8, 16, 18, 20, 22, 24, 28, 30, 36, 39, 45, 46, 48, 49, 50, 51, 52, 53, 58, 63, 65, 69, 71, 72, 73, 78, 82, 88, 93, 101, 110, 116, 121, 132, 135, 138, 140, 151, 153, 158, 166], "interestingli": 78, "interfac": [11, 139, 158], "interior": [109, 138], "interlaboratori": 131, "intermedi": [30, 84, 95, 149, 153], "intern": [0, 1, 72, 151], "internet": 158, "interoper": 48, "interplai": 72, "interplo": 50, "interpol": [42, 46, 50, 52, 53, 83, 84, 85, 91], "interpret": [4, 5, 7, 8, 11, 16, 24, 25, 26, 27, 28, 30, 31, 37, 39, 42, 44, 48, 51, 56, 58, 65, 66, 67, 73, 77, 82, 85, 88, 94, 99, 100, 122, 124, 129, 133, 135, 152, 157, 158, 161], "intersect": [26, 27, 168], "interv": [4, 11, 15, 19, 22, 30, 31, 41, 42, 46, 48, 56, 84, 85, 87, 91, 93, 97, 101, 131, 135, 152, 156, 157, 166, 168], "interview": [68, 133], "intial": [128, 161], "intimid": 138, "intp": [78, 98], "intract": [52, 77, 152, 157], "intric": 16, "intrins": [30, 65], "introduc": [4, 7, 16, 18, 23, 26, 27, 29, 30, 32, 39, 43, 45, 47, 48, 49, 50, 51, 53, 56, 58, 63, 64, 68, 69, 70, 71, 72, 76, 93, 100, 102, 105, 112, 118, 121, 123, 124, 125, 135, 139, 149, 151, 161, 168], "introduct": [1, 25, 32, 44, 52, 58, 60, 77, 94, 127, 130, 152, 157, 158, 159, 163, 165], "introductori": [92, 129, 138], "intrus": [50, 52], "intslid": [5, 9, 137], "intuit": [8, 11, 16, 20, 27, 36, 41, 43, 44, 47, 49, 56, 67, 71, 72, 77, 78, 98, 122, 132, 138, 139, 152, 157], "inv": [39, 54, 55, 70, 100, 107, 128, 141], "invalid": [139, 164], "invalu": 151, "invari": [1, 4, 8, 45, 46, 48, 49, 60, 90, 100, 122, 148, 151, 152, 153, 155, 157, 158, 161], "invcft": 38, "invent": [42, 99], "inventor": 112, "invers": [8, 18, 19, 21, 28, 38, 46, 54, 56, 58, 71, 90, 105, 106, 128, 130, 131, 132, 143, 158, 161], "invert": [39, 53, 70, 90, 93, 102, 105, 109, 130, 151, 153, 154], "invest": 71, "investig": [63, 66, 69, 82, 87, 88, 97, 147, 148, 163, 166], "invft": 38, "invft_uniform_pt": 38, "invgamma": 135, "invit": [26, 53], "invok": [0, 155, 156], "involv": [18, 19, 27, 30, 39, 43, 44, 48, 51, 53, 58, 67, 68, 69, 71, 72, 76, 77, 78, 87, 93, 98, 109, 115, 116, 150, 152, 157, 158, 159, 166, 167], "io": [46, 78, 98, 127, 131, 132, 153, 156, 157, 159, 168], "ipad": 139, "ipr": 6, "ipsen": 1, "ipykernel_2829": 42, "ipykernel_2861": 43, "ipykernel_3757": 138, "ipykernel_3968": 156, "ipynb": [41, 43, 46, 56, 75, 95, 98, 99, 132, 139, 147, 148, 151, 153, 155, 159, 163, 164, 168], "ipython": [5, 9, 131, 138, 139], "ipywidget": [5, 9, 131, 139], "ironclad": 67, "irow": [55, 148], "irreduc": [71, 102, 149, 158, 161], "irregular": 48, "irrelev": [39, 42, 49], "irrespect": [30, 149], "irun": 166, "is_avail": 76, "is_first_col": 3, "isak": [1, 49, 61], "isbn": 1, "iscalar": [78, 98], "isinst": [38, 42, 76, 128, 134], "isn": [68, 78, 153], "isnet": 61, "iso": [58, 87], "isol": [61, 130, 132], "isotrop": 151, "issu": [43, 68, 76, 100, 102, 110, 118, 148, 156, 158, 161], "isupp": 156, "ital": [44, 47, 139], "item": [3, 76, 134, 141], "iter": [1, 15, 43, 48, 49, 55, 56, 71, 72, 75, 76, 77, 78, 84, 86, 97, 101, 102, 110, 111, 112, 138, 139, 143, 148, 149, 151, 153, 156, 157, 158, 161], "itila": 1, "its": [0, 4, 7, 8, 9, 11, 12, 20, 22, 24, 27, 29, 30, 39, 42, 43, 45, 46, 48, 51, 52, 54, 57, 58, 65, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 80, 82, 83, 85, 87, 88, 90, 93, 101, 105, 109, 110, 112, 124, 126, 130, 132, 135, 137, 138, 139, 140, 141, 143, 148, 149, 152, 154, 156, 157, 158, 161, 166], "itself": [4, 7, 9, 24, 36, 38, 44, 45, 48, 49, 52, 55, 58, 63, 64, 68, 69, 72, 91, 101, 102, 122, 132, 137, 152, 155, 157], "iv": [65, 161], "ix": [46, 82, 88], "ix1": 70, "ix2": 70, "j": [1, 4, 5, 16, 24, 34, 39, 42, 49, 51, 53, 54, 61, 71, 72, 73, 83, 84, 87, 101, 104, 105, 112, 122, 130, 132, 135, 138, 148, 151, 154, 156, 158, 161, 166], "j_": [77, 112], "jacob": 8, "jacobian": [3, 19, 21], "jaiswal": [126, 128], "jake": [71, 85], "jame": [1, 82, 88], "jan": [85, 86], "januari": 26, "javascript": [158, 159], "jax": 110, "jay03": [1, 61], "jay2020": 53, "jay88": [1, 67], "jayn": [1, 4, 45, 61], "jb": [0, 61, 136], "jb_test": 0, "jefferi": 58, "jeffrei": [3, 8, 43, 45, 56, 58], "jen": 1, "jensen": 61, "jeopard": 66, "jet": 42, "jforssen22": [1, 49, 51], "jhm": [85, 86], "ji": [72, 73, 130, 161], "jiang": [1, 49, 61], "jimmi": 1, "jitter": [83, 156, 157], "jk": [73, 130, 132], "jmlr": 1, "joanna": 68, "job": [68, 95, 156, 157], "john": [1, 8, 109, 168], "johnson": 4, "join": [138, 141], "joint": [4, 7, 18, 22, 27, 36, 37, 39, 41, 46, 47, 49, 58, 83, 87, 90, 91, 125, 147, 151, 152, 153, 157, 158, 161, 166, 168], "jointli": [90, 153], "jonathan": 1, "jone": 1, "jordan": 61, "joukj": 1, "journal": [1, 15, 48, 68], "jpeg": 80, "jpg": 132, "jstor": 1, "judg": [34, 65, 71, 151], "judgement": [48, 51, 58], "judgment": [52, 115], "jul": 142, "juli": 128, "julia": 68, "julien": 1, "jump": [9, 11, 28, 41, 56, 131, 149, 159], "jump_w": 9, "june": [5, 43, 55, 82, 100, 148, 149], "junli": 1, "jupyt": [28, 31, 32, 75, 126, 128, 130, 134, 136, 137, 141], "jupytext": 0, "juri": 67, "just": [0, 6, 9, 11, 13, 18, 22, 24, 27, 28, 29, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 81, 82, 87, 88, 90, 91, 93, 95, 98, 100, 101, 102, 105, 107, 110, 116, 132, 135, 136, 137, 138, 139, 142, 149, 151, 152, 157, 158, 159, 161, 164, 168], "justic": 68, "justif": [15, 69], "justifi": [29, 47, 49, 124], "k": [1, 3, 4, 6, 9, 15, 16, 24, 34, 41, 42, 43, 45, 46, 47, 49, 53, 54, 56, 57, 58, 72, 73, 76, 77, 82, 84, 88, 90, 91, 93, 97, 99, 100, 101, 112, 122, 125, 128, 130, 132, 135, 138, 147, 150, 151, 153, 155, 158, 159, 161, 164, 166, 167], "k0": [150, 167], "k1": 87, "k1__constant_valu": 87, "k1__constant_value_bound": 87, "k2": 87, "k2__length_scal": 87, "k2__length_scale_bound": 87, "k99": 132, "k995": 132, "k_": [54, 83, 84, 91, 150, 167], "k_0": [72, 150, 167], "k_1": [72, 82, 88, 150, 167], "k_2": [57, 72, 82, 88, 150, 167], "k_3": [150, 167], "k_arrai": [150, 167], "k_b": [4, 56], "k_i": [72, 150, 167], "k_l": 72, "k_list": 70, "k_max": 54, "k_now": [150, 167], "k_order": 54, "k_rbf": [83, 87], "kaim": 76, "kaiming_normal_": 76, "kalman": 130, "kami\u0144ska": 68, "kangaroo": 4, "kappa": [84, 90, 91, 128, 130], "kappa_": 84, "karamani": 168, "karl": 67, "kaspar": 1, "kati": 141, "kavukcuoglu": 1, "kazantzidi": 56, "kb": [74, 142], "kb1": [82, 88], "kb2": [82, 88], "kbf": 91, "kde": [149, 157], "keegan": 1, "keep": [6, 15, 24, 27, 30, 38, 39, 42, 44, 45, 46, 48, 49, 50, 69, 74, 76, 78, 101, 107, 111, 112, 120, 130, 132, 139, 149, 150, 151, 152, 156, 157, 158, 164, 167], "kei": [9, 11, 26, 27, 28, 29, 39, 48, 49, 50, 53, 63, 67, 68, 70, 72, 74, 76, 82, 84, 87, 88, 90, 93, 122, 129, 130, 132, 139, 149, 151, 158, 159, 161, 164], "keith": 1, "kejzlar2019bayesian": 53, "kejzlar2020": 53, "kennedi": [1, 124], "kept": [9, 28, 35, 49, 61, 130, 132, 167], "kera": [69, 74, 75, 77, 81, 141], "kern": [82, 83, 84, 88, 97], "kern1": [82, 88], "kern2": [82, 88], "kernel": [52, 82, 84, 85, 88, 91, 92, 97, 122, 124, 125, 126, 128, 139, 149, 159], "kernel_": [85, 86, 87], "kernel_func": 128, "kernel_rbf": 87, "kernelspec": 0, "ket": 52, "kev": 138, "keyboard": 139, "keyword": [99, 139, 143, 155], "kg": [126, 128], "ki": [70, 130], "kick": 78, "kill": 38, "kilomet": 82, "kind": [8, 24, 39, 63, 69, 71, 72, 78, 81, 83, 87, 93, 102, 106, 115, 116, 157, 166], "kinet": [49, 50, 153, 156], "king": 1, "kingma": 1, "kingmaba14": [1, 112], "kj": [72, 73, 132], "kk": 130, "kl": 77, "km": [18, 46, 82], "kmax": 54, "knew": [44, 152, 157], "knn_classifi": 70, "know": [3, 4, 8, 9, 11, 13, 16, 18, 19, 20, 22, 23, 24, 26, 27, 28, 30, 35, 36, 39, 45, 46, 47, 52, 53, 61, 64, 68, 69, 70, 77, 78, 84, 86, 130, 136, 138, 139, 141, 150, 151, 158, 159, 161, 164, 167], "knowledg": [4, 7, 8, 9, 11, 13, 16, 18, 26, 30, 32, 39, 42, 44, 45, 46, 48, 49, 51, 52, 58, 61, 63, 64, 65, 66, 69, 72, 78, 95, 116, 124, 125, 126, 129, 135, 152, 156, 157], "known": [4, 7, 8, 16, 18, 21, 22, 30, 34, 39, 42, 43, 45, 46, 48, 49, 50, 51, 52, 53, 54, 58, 65, 67, 68, 70, 71, 72, 73, 76, 77, 78, 80, 82, 83, 84, 85, 87, 88, 90, 93, 95, 100, 102, 104, 105, 109, 115, 116, 122, 132, 135, 147, 148, 149, 156, 158, 161, 166], "knuth": 158, "ko": 101, "kochurov": [78, 98], "koh": [53, 125, 126], "kohn": 52, "kolmogorov": [8, 30], "kondev": [1, 138], "korai": 1, "kp": [150, 167], "kr": 155, "kramer": 1, "krasser": 77, "krgb15": [1, 77], "krishak": 56, "kroneck": [18, 21], "kucukelbir": [1, 77], "kullback": 4, "kutta": [153, 155], "kwarg": [39, 46, 55, 107, 131, 156, 157], "kwd": 131, "kx": [82, 88], "l": [1, 4, 7, 13, 18, 21, 24, 39, 41, 43, 44, 46, 49, 58, 72, 78, 87, 90, 91, 93, 97, 98, 122, 128, 135, 152, 153, 154, 155, 157, 166, 168], "l1": [72, 78], "l1_ratio": 75, "l2": [75, 78, 79], "l_": 72, "l_1": 93, "l_2": 93, "l_cumsum": 46, "l_h": 128, "l_i": 90, "l_j": [72, 73], "l_opt": 87, "l_pt": 47, "l_v": 128, "l_x": 58, "l_y": 58, "la": [39, 132], "la_i": 73, "la_k": 73, "lab": [46, 56, 69, 128], "label": [3, 5, 9, 15, 18, 20, 21, 22, 24, 34, 35, 38, 39, 41, 42, 43, 45, 46, 47, 48, 51, 52, 53, 54, 55, 58, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 85, 86, 87, 93, 98, 100, 101, 102, 107, 112, 116, 122, 128, 131, 132, 134, 135, 137, 138, 139, 140, 148, 149, 152, 154, 155, 157, 158, 161, 166, 167], "labels": 38, "labels_corn": 101, "labor": 69, "laboratori": 16, "lack": [4, 8, 45, 71, 115, 122, 135], "ladder": [55, 56, 101], "lag": [49, 148, 149, 164], "lagrang": [4, 5], "lagrangian": [22, 154], "lai": [30, 39], "lam": 166, "lambda": [3, 5, 38, 41, 43, 58, 71, 75, 82, 128, 132, 138, 156, 161, 166], "lambda_": 58, "lambda_0": [4, 58, 161], "lambda_1": [4, 41], "lambda_2": 41, "lambda_i": 58, "lambda_mat": 54, "lambda_mat_inv": 54, "lambdas0": 5, "lambdas_min": 5, "land": 8, "landmark": 84, "landscap": 49, "lang": 1, "langermann": 97, "langevin": 159, "langl": [4, 24, 42, 47, 50, 56, 90, 151, 158, 164], "languag": [0, 39, 48, 63, 67, 68, 69, 70, 76, 81, 95, 101, 110, 139, 141, 157, 158], "lapack": 141, "laplac": [8, 39, 56, 67, 77, 100], "laplacepropos": 156, "laps": 61, "larg": [3, 4, 18, 22, 24, 30, 34, 38, 39, 42, 43, 45, 46, 49, 50, 51, 52, 53, 56, 58, 60, 63, 65, 67, 69, 72, 73, 76, 77, 78, 94, 102, 109, 110, 112, 115, 116, 118, 119, 129, 132, 134, 135, 149, 151, 154, 158, 159, 161, 166], "larger": [4, 28, 30, 34, 38, 41, 42, 43, 45, 46, 50, 51, 56, 58, 71, 80, 82, 83, 85, 87, 91, 126, 130, 131, 149, 156, 159], "largest": [4, 46, 49, 68, 71, 74, 83, 87, 130, 132, 158, 168], "lasagn": 78, "laser": [56, 161], "last": [15, 16, 37, 39, 41, 42, 49, 53, 55, 56, 61, 69, 71, 73, 74, 75, 77, 78, 80, 81, 83, 97, 98, 100, 101, 105, 107, 128, 131, 132, 135, 138, 139, 142, 149, 154, 156, 159, 161, 163], "last_nam": 139, "lastli": 61, "later": [9, 10, 11, 24, 30, 38, 39, 41, 43, 45, 46, 51, 68, 69, 72, 78, 83, 87, 93, 98, 100, 102, 107, 118, 126, 138, 139, 140, 142, 147, 148, 149, 151, 159, 161, 164], "latest": [1, 46, 75, 76, 156, 157, 168], "latex": [0, 45, 46, 47, 54, 100, 131, 139, 140, 147], "latex_macro": 0, "latin": [52, 58, 77, 84], "latter": [29, 39, 47, 48, 53, 54, 56, 58, 67, 71, 90, 91, 112, 115, 125, 129, 130, 138, 149, 161], "lattic": [49, 72], "launch": 67, "laundri": 151, "law": [44, 56, 67, 68, 69, 81, 122, 135, 152, 157], "lawrenc": [82, 88], "lawyer": 67, "lay": 0, "layer": [72, 73, 74, 75, 76, 77, 78, 98, 122, 134], "layout": [5, 9, 141], "lbfg": [75, 86], "lbrace": 53, "lcb": 97, "ldot": [7, 15, 19, 22, 23, 24, 28, 34, 38, 39, 41, 42, 44, 51, 52, 53, 56, 57, 58, 71, 72, 87, 91, 93, 95, 97, 101, 105, 117, 118, 130, 135, 143, 150, 151, 152, 153, 157, 158, 159, 161, 164, 166, 167], "le": [4, 19, 20, 30, 39, 101], "lead": [7, 15, 27, 28, 30, 42, 43, 45, 48, 51, 52, 53, 54, 58, 60, 61, 62, 64, 67, 68, 69, 71, 72, 73, 76, 77, 78, 80, 93, 99, 110, 111, 122, 124, 126, 128, 130, 135, 138, 139, 141, 148, 151], "leaki": [72, 75, 134], "leaky_relu": 134, "leakyrelu": [76, 134], "leap": 39, "leapfrog": [49, 153, 155], "leapfrog_energy_test_1": 155, "leapfrog_orbit_1": 155, "learn": [1, 8, 22, 28, 30, 34, 39, 41, 44, 46, 52, 55, 61, 62, 63, 64, 66, 67, 74, 77, 80, 86, 90, 91, 100, 104, 109, 110, 111, 112, 115, 116, 122, 124, 126, 129, 132, 136, 138, 139, 141, 148, 149, 152, 157, 158], "learnabl": 80, "learner": 78, "learning_curv": 102, "learning_r": 111, "learningfromdata": [127, 132, 142], "least": [4, 8, 9, 16, 18, 20, 24, 28, 35, 42, 44, 48, 49, 51, 64, 67, 70, 71, 74, 93, 99, 100, 107, 115, 128, 132, 135, 137, 152, 156, 157, 166], "leav": [28, 30, 43, 49, 56, 57, 71, 73, 80, 100, 152, 153, 156, 157], "lebesgu": 4, "lec": [50, 52, 57], "lectur": [1, 3, 48, 50, 51, 58, 61, 68, 69, 71, 72, 73, 75, 77, 93, 97, 100, 102, 116, 132, 138, 139, 148, 164], "lecturenot": 132, "lee": [1, 78], "left": [0, 3, 4, 9, 10, 13, 16, 18, 19, 20, 21, 22, 24, 27, 29, 30, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 56, 57, 58, 61, 69, 70, 71, 72, 73, 77, 83, 86, 87, 90, 93, 97, 99, 100, 101, 102, 105, 108, 110, 111, 112, 119, 122, 125, 126, 130, 131, 132, 135, 148, 149, 150, 151, 152, 155, 156, 157, 158, 161, 164, 166, 167], "leftarrow": [73, 161], "leftmost": 130, "leftrightarrow": [20, 41, 109, 130, 161], "leg": 9, "legal": 8, "legend": [0, 5, 9, 20, 21, 22, 34, 38, 39, 42, 43, 54, 75, 76, 78, 81, 82, 85, 86, 87, 88, 93, 98, 100, 107, 128, 131, 132, 134, 135, 138, 139, 140, 148, 149, 154, 155, 158, 166, 167], "legendr": [115, 154], "lemaitr": [85, 86], "lemaitre58": [85, 86], "len": [5, 30, 35, 39, 42, 43, 46, 47, 54, 55, 70, 75, 82, 83, 84, 87, 88, 100, 101, 107, 128, 132, 138, 141, 148, 149, 152, 155, 156, 157, 166], "lend": 48, "length": [1, 7, 8, 28, 39, 43, 47, 49, 52, 56, 70, 82, 83, 84, 87, 88, 90, 91, 93, 100, 101, 111, 125, 128, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 166], "length_scal": [85, 86, 87, 128], "length_scale_bound": [85, 86], "lengthscal": [82, 83, 84, 87, 88, 97], "lenp": 52, "leprechaun": 7, "leq": [9, 11, 13, 18, 19, 21, 22, 28, 34, 41, 43, 49, 51, 54, 56, 58, 70, 71, 87, 100, 101, 109, 126, 135, 150, 158, 159, 161, 164, 166, 167], "less": [4, 11, 26, 42, 43, 49, 57, 58, 63, 65, 67, 68, 71, 72, 85, 100, 105, 132, 135, 138, 141, 148, 149, 159, 164], "lesson": [12, 68], "lesssim": 50, "let": [4, 6, 8, 9, 11, 15, 16, 18, 19, 20, 24, 30, 35, 36, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 58, 64, 68, 69, 70, 71, 72, 73, 74, 76, 77, 81, 82, 83, 85, 87, 88, 90, 91, 93, 100, 101, 102, 106, 107, 112, 118, 125, 128, 132, 135, 138, 139, 140, 141, 148, 149, 151, 152, 153, 156, 157, 158, 159, 161, 164, 166], "lett": 1, "letter": [28, 93, 135], "level": [8, 9, 16, 24, 34, 41, 42, 45, 46, 48, 52, 58, 61, 64, 68, 70, 77, 78, 79, 85, 87, 135, 137, 141, 148, 151, 161], "level_1sigma": 46, "leverag": [53, 76, 124], "lewi": 63, "lfd": 127, "lfd_develop": 145, "lfd_for_physicist": 142, "li": [8, 9, 19, 30, 35, 51, 52, 58, 67, 68, 83, 87, 137, 141], "li6e_nnloopt_nmax10": [83, 87], "lib": [55, 86, 101, 131, 157], "libcxx": 142, "librari": [22, 31, 39, 61, 69, 77, 78, 81, 98, 110, 138, 139, 141, 142, 158], "licat": 48, "licens": [61, 81, 85, 86, 142, 158], "lie": [30, 56, 58, 71], "life": [42, 61, 69, 72, 103, 138], "light": [7, 22, 30, 35, 39, 52, 58, 61, 63, 78, 84, 98, 135], "lightest": 138, "lightgrai": 46, "lighthous": 159, "lighthouse_stat": 47, "like": [0, 4, 9, 11, 12, 16, 22, 23, 24, 26, 27, 28, 35, 36, 38, 39, 41, 42, 44, 46, 47, 48, 49, 52, 53, 55, 56, 57, 61, 63, 67, 68, 69, 70, 71, 72, 76, 78, 82, 83, 84, 87, 88, 91, 93, 97, 98, 110, 111, 112, 119, 122, 130, 132, 135, 136, 138, 139, 141, 142, 148, 149, 150, 151, 152, 153, 156, 157, 158, 161, 164, 167], "likelihoo": [55, 56], "likelihood": [4, 7, 8, 9, 10, 16, 18, 20, 28, 30, 34, 35, 42, 44, 45, 47, 49, 51, 52, 54, 56, 57, 58, 71, 77, 78, 79, 82, 85, 86, 88, 90, 98, 99, 101, 128, 132, 135, 147, 148, 149, 152, 156, 157, 159, 163], "likewis": 131, "lim_": [18, 49, 161], "limit": [1, 4, 8, 9, 18, 19, 20, 22, 28, 31, 35, 39, 42, 45, 47, 48, 56, 58, 63, 66, 70, 71, 81, 83, 87, 94, 99, 107, 115, 118, 124, 131, 134, 135, 137, 158, 159, 166], "limits_": 49, "lin": [83, 87], "linalg": [39, 54, 55, 70, 82, 83, 87, 88, 100, 107, 128, 132, 141], "lindholm": 1, "lindsei": 1, "lindsten": 1, "line": [0, 4, 9, 10, 15, 20, 24, 26, 28, 39, 41, 42, 43, 49, 55, 58, 69, 70, 71, 74, 75, 77, 78, 81, 82, 83, 84, 87, 88, 91, 93, 96, 98, 99, 107, 108, 122, 131, 135, 137, 138, 139, 142, 143, 147, 149, 150, 151, 152, 154, 155, 156, 157, 159, 163, 164, 167], "line1": 9, "line2": 9, "line3": 9, "linear": [1, 3, 16, 18, 20, 32, 33, 43, 45, 46, 50, 52, 53, 55, 58, 60, 69, 71, 75, 76, 77, 78, 80, 82, 83, 87, 88, 91, 93, 100, 102, 108, 109, 110, 118, 121, 122, 128, 130, 131, 134, 138, 139, 143, 151, 163], "linear_model": [75, 79, 138], "linearli": [34, 39, 51, 58, 78, 90, 98, 101, 104, 117], "linearregress": 138, "liner": [70, 140], "lineshap": 58, "linestyl": [9, 39, 42, 45, 47, 54, 76, 82, 85, 86, 88, 107, 139, 149, 154, 155], "linewidth": [22, 42, 43, 45, 47, 54, 55, 135, 157], "link": [0, 1, 8, 22, 48, 49, 61, 72, 135, 136, 137, 139, 153], "linspac": [0, 5, 9, 20, 21, 22, 30, 34, 35, 38, 39, 43, 45, 46, 47, 54, 76, 82, 83, 84, 85, 86, 87, 88, 93, 100, 101, 107, 128, 131, 134, 135, 137, 139, 140, 141, 149, 155, 158, 166], "linux": [98, 128, 139, 142], "liouvil": [49, 153], "liouville_test": 154, "liouville_theorem_visu": 153, "liquid": 138, "list": [1, 7, 9, 18, 22, 30, 35, 42, 46, 47, 48, 49, 51, 61, 66, 67, 68, 70, 72, 80, 87, 98, 101, 125, 128, 131, 134, 135, 137, 138, 139, 142, 143, 145, 149, 151, 156, 158, 161, 163], "list_a": 140, "list_b": 140, "list_lik": 87, "liter": 43, "literatur": [10, 22, 28, 43, 48, 52, 53, 56, 61, 72, 73, 90, 93, 99, 127], "littl": [8, 45, 58, 73, 76, 77, 132, 148, 153], "liu": 1, "live": [45, 53, 68, 153, 158, 159], "liz": 141, "ll": [3, 6, 9, 10, 11, 15, 18, 20, 22, 24, 26, 28, 30, 35, 36, 38, 39, 43, 44, 45, 46, 47, 50, 54, 57, 64, 70, 72, 76, 82, 83, 84, 87, 88, 90, 98, 99, 100, 124, 130, 131, 132, 135, 137, 139, 142, 148, 149, 150, 151, 152, 153, 157, 158, 159, 161, 164, 167], "ln": [4, 42, 49, 56, 72, 100, 101, 135], "lnlike": [55, 101], "lnpost": [43, 55, 148], "lnprob": [55, 101], "lnprobabl": [43, 46, 55, 148], "lnz": 101, "lnzl": 101, "lo95": [82, 88], "load": [74, 75, 82], "load_data": [74, 81], "load_model": 74, "loadtxt": [83, 87], "loc": [0, 9, 20, 21, 22, 34, 38, 39, 43, 47, 55, 75, 81, 82, 85, 86, 87, 88, 93, 100, 101, 131, 135, 138, 155, 158, 166, 167], "local": [4, 22, 53, 56, 72, 78, 80, 93, 97, 102, 110, 122, 128, 135, 138, 142, 158], "locat": [6, 16, 39, 45, 47, 48, 58, 82, 87, 88, 97, 99, 100, 101, 135, 141, 142, 145, 151, 152, 157, 158], "log": [3, 5, 6, 22, 39, 41, 42, 43, 44, 45, 46, 47, 49, 54, 55, 56, 58, 71, 76, 77, 79, 82, 84, 86, 88, 93, 99, 100, 101, 128, 141, 148, 152, 153, 156, 157], "log10": 82, "log_evidence_estim": 101, "log_flat_prior": [6, 45], "log_jeffreys_prior": 6, "log_l_pt": 47, "log_likelihood": [42, 43, 45, 46, 47, 55, 82, 100, 101, 128, 147, 148, 152, 157], "log_likelihood_singl": 46, "log_likelihood_v": 128, "log_likelihood_valu": 128, "log_marginal_likelihood": 86, "log_p1": [45, 46], "log_p1_1": 46, "log_p2": 45, "log_posterior": [42, 43, 46, 55, 101, 128, 147, 148, 151, 152, 157], "log_posterior_cauchi": 43, "log_posterior_conserv": 43, "log_posterior_gaussian": 43, "log_prior": [6, 42, 43, 46, 47, 55, 101, 128, 147, 148, 152, 157], "log_prior_": 128, "log_prior_cbar": 128, "log_prior_l": 128, "log_prior_param": 128, "log_prior_phi": 128, "log_prior_pt": 47, "log_prior_r": 128, "log_prior_theta": 128, "log_prior_v": 128, "log_priors_mdgp": 128, "log_priors_model": 128, "log_priors_thetaphi": 128, "log_prob_cutoff": 46, "log_prob_max": 46, "log_symmetric_prior": [6, 45], "logaddexp": [43, 55], "logarithm": [3, 4, 24, 42, 43, 45, 46, 58, 76, 77, 93, 100, 101, 147], "logic": [1, 4, 8, 9, 11, 16, 25, 58, 61, 67, 69, 150, 167], "logical_and": [42, 135, 152, 157], "logist": [68, 70, 72, 73, 78, 94, 98], "logisticregressioncv": 75, "logisticregressioncvifit": 75, "logit": [70, 72, 93], "logl": [46, 55, 101, 128], "logl1": 43, "logl2": 43, "loglarg": [55, 101], "loglikelihood": 101, "loglkwarg": [55, 101], "loglog": [154, 158], "logp": [6, 43, 55, 101, 128, 156], "logparg": [55, 101], "logpkwarg": [55, 101], "logpr": 6, "logz": 128, "logz_err": 128, "long": [15, 16, 22, 26, 39, 42, 43, 48, 51, 52, 56, 57, 58, 61, 71, 72, 99, 135, 138, 141, 142, 149, 151, 157, 161], "longer": [8, 12, 52, 56, 71, 72, 93, 125, 148, 151, 156], "longleftarrow": [143, 153], "longrightarrow": [0, 3, 11, 12, 13, 15, 16, 22, 24, 29, 36, 37, 38, 39, 41, 42, 56, 57, 143, 151, 164], "loocv": 71, "look": [0, 2, 9, 11, 13, 16, 17, 22, 23, 24, 25, 31, 32, 36, 38, 39, 41, 42, 43, 44, 47, 49, 54, 55, 56, 57, 58, 60, 63, 68, 72, 74, 81, 82, 83, 87, 88, 91, 95, 97, 101, 107, 111, 119, 130, 132, 135, 138, 139, 142, 146, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 161, 162, 164, 165, 167], "loop": [39, 73, 76, 111, 140, 150, 152, 157, 167], "loos": 72, "lorentzian": 58, "lose": [53, 58, 166], "loss": [8, 74, 76, 77, 80, 81, 87, 93, 98, 109, 121, 122, 132], "lost": [43, 130, 132], "lot": [7, 24, 27, 34, 38, 68, 78, 98, 140, 149, 159, 164], "love": 67, "low": [1, 11, 36, 39, 48, 49, 50, 51, 52, 55, 56, 68, 71, 77, 84, 96, 101, 107, 132, 141, 151, 154, 156, 158, 159], "lower": [24, 30, 39, 43, 47, 55, 56, 58, 68, 73, 76, 78, 81, 124, 126, 128, 134, 135, 140, 152, 156, 157, 161, 164], "lowest": [52, 99, 161], "lp": 128, "lr": 76, "lra": [0, 3, 4, 56, 57, 84, 91, 95, 130, 151, 153, 159, 164], "lstsq": 132, "lt": [83, 156, 164], "luck": 16, "lvert": [77, 109, 125], "lw": [9, 34, 39, 43, 47, 70, 93, 107, 132, 134, 135, 137, 138, 139, 149, 166], "lwahlstromlschon21": [1, 68], "m": [1, 4, 16, 19, 39, 41, 42, 43, 44, 45, 46, 49, 50, 51, 54, 55, 56, 57, 58, 71, 72, 75, 76, 77, 82, 83, 84, 87, 88, 90, 91, 95, 97, 100, 101, 104, 105, 106, 107, 109, 112, 119, 120, 123, 126, 128, 130, 132, 134, 135, 138, 139, 148, 152, 153, 154, 156, 157, 159, 161], "m_": [57, 73, 153], "m_0": 100, "m_1": [0, 7, 57, 84, 91, 100], "m_2": [7, 57, 84, 91], "m_h": 138, "m_i": [4, 7, 39, 51, 105, 153], "m_j": [4, 7], "m_k": [57, 70], "m_l": 73, "m_n": 138, "m_p": 138, "ma_theta0": 148, "ma_theta1": 148, "mac": [98, 139, 142], "mac03": [1, 61, 77], "mach": 1, "machin": [1, 39, 52, 55, 61, 62, 67, 71, 72, 76, 77, 90, 91, 92, 93, 98, 100, 104, 109, 112, 115, 116, 122, 129, 130, 132, 136, 138, 148, 149, 158, 163], "machineri": [46, 135], "mackai": [1, 61, 77], "mackei": [1, 152, 157, 164], "maco": [128, 142], "macosx": [78, 98], "macroscop": 4, "made": [9, 11, 18, 20, 38, 39, 46, 48, 49, 56, 57, 58, 61, 66, 68, 69, 76, 77, 80, 85, 90, 93, 120, 121, 125, 132, 137, 138, 139, 140, 149, 158, 166], "mae": [70, 71, 72], "magazin": 133, "magic": [139, 140, 149], "magnifi": 130, "magnitu": 84, "magnitud": [7, 42, 51, 52, 54, 56, 58, 68, 76, 101, 102, 128, 132], "mahalanobi": 128, "mahlet": 1, "mai": [1, 7, 23, 24, 26, 27, 28, 39, 42, 48, 51, 52, 53, 54, 56, 58, 61, 63, 64, 66, 67, 68, 69, 71, 72, 73, 80, 81, 82, 88, 93, 99, 101, 109, 129, 131, 132, 136, 138, 139, 142, 150, 154, 159, 167], "main": [8, 48, 51, 52, 58, 77, 80, 84, 93, 95, 112, 132, 156, 158], "mainli": [48, 50, 68, 69, 78, 109, 115, 138, 149], "maintain": [41, 49, 53, 72, 76, 128, 141, 161], "maiti": 1, "major": [41, 43, 68, 70, 78, 109, 110, 138], "make": [0, 4, 6, 7, 8, 9, 11, 16, 18, 22, 23, 24, 28, 29, 34, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 67, 68, 69, 70, 71, 72, 75, 77, 78, 79, 80, 82, 83, 84, 87, 88, 90, 93, 94, 97, 98, 99, 100, 101, 102, 104, 106, 107, 109, 111, 115, 116, 132, 134, 135, 138, 139, 140, 143, 147, 148, 149, 150, 152, 153, 156, 157, 158, 159, 163, 166, 167], "make_blob": 79, "make_circl": 98, "make_data": [45, 148], "make_dataset": 42, "make_fig": 42, "make_matric": 54, "make_moon": [75, 78, 98], "make_plot": 134, "makedir": 138, "mala": 159, "male": [68, 135], "manag": [9, 49, 53, 68, 80, 131, 142, 163], "mandat": 64, "mani": [4, 7, 8, 9, 11, 12, 22, 24, 26, 28, 30, 32, 34, 35, 37, 38, 39, 41, 44, 45, 48, 49, 50, 52, 53, 54, 56, 58, 61, 62, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 82, 83, 84, 87, 88, 93, 96, 98, 102, 107, 109, 110, 112, 116, 122, 124, 125, 126, 127, 131, 134, 135, 138, 139, 140, 141, 142, 149, 150, 151, 152, 153, 156, 157, 158, 159, 161, 164, 166, 167], "manifest": 68, "manifestli": 52, "manifesto": 53, "manifold": 50, "manipul": [8, 25, 30, 39, 84, 91], "mankind": 8, "manner": 80, "manual": [22, 28, 48, 69, 135, 139, 143, 151, 152, 157], "manufactur": 78, "manzoni": 1, "map": [8, 19, 39, 43, 51, 53, 69, 70, 72, 77, 93, 101, 106, 115, 128, 140, 151, 153, 156, 164], "map_estim": 157, "mapsto": [53, 111], "mar": [1, 83, 138, 154], "marathon": 82, "march": [58, 138], "margin": [0, 7, 10, 15, 16, 17, 22, 24, 27, 36, 37, 40, 41, 42, 43, 45, 48, 49, 54, 57, 58, 77, 82, 87, 88, 90, 99, 101, 128, 129, 131, 152, 153, 157, 158, 159, 161, 164, 166, 168], "margina": 42, "marin": 1, "marina": 1, "mark": [22, 70, 131, 132, 139, 150, 167], "markdown": [143, 147], "marker": [39, 43, 54, 77, 83, 85, 87, 107, 138, 149, 150, 156, 167], "markers": [54, 85, 128], "markov": [1, 16, 18, 43, 48, 56, 148, 149, 150, 151, 152, 153, 156, 157, 164, 165, 166, 167, 168], "markovprocessexampl": 161, "markovprocessexample_corner_fig": 161, "markovprocessexample_runs_fig": 161, "martin": 77, "masquerad": 7, "mass": [1, 7, 8, 24, 28, 38, 39, 42, 48, 49, 51, 53, 56, 77, 84, 87, 104, 109, 119, 120, 126, 128, 153, 154, 158, 159, 166], "mass16": 138, "mass16round": 138, "massag": 138, "masses2016": 138, "masseval2016": 138, "massiv": [49, 78], "master": [1, 16, 61], "match": [1, 43, 48, 60, 72, 82, 88, 126], "materi": [32, 71, 80, 129], "matern": [82, 84, 86, 88, 91], "matern32": [82, 88, 97], "matern52": [82, 84, 88], "math": [1, 5, 38, 42, 48, 78, 98, 137, 141, 150, 167], "mathbb": [0, 22, 29, 30, 39, 49, 71, 72, 77, 87, 90, 91, 93, 105, 109, 112, 118, 132, 135, 151, 153, 166], "mathbf": [28, 39, 70, 83, 87, 90, 97, 105, 126, 132, 155], "mathcal": [0, 3, 4, 7, 13, 16, 20, 21, 24, 29, 34, 39, 43, 44, 45, 46, 49, 51, 52, 54, 58, 72, 77, 82, 84, 87, 88, 90, 93, 97, 100, 105, 107, 109, 122, 125, 135, 148, 149, 152, 154, 157, 158, 159, 161, 163, 164, 166], "mathemat": [1, 8, 9, 11, 22, 24, 28, 30, 45, 61, 63, 66, 67, 69, 70, 78, 83, 87, 93, 98, 118, 121, 122, 135, 138, 149, 158], "mathematica": [1, 42, 139], "mathematician": [0, 48, 66, 67], "mathop": [39, 105, 118], "mathrm": [3, 4, 7, 9, 18, 20, 22, 30, 35, 38, 39, 42, 46, 49, 50, 51, 52, 53, 58, 69, 70, 71, 72, 77, 80, 83, 87, 90, 93, 100, 101, 105, 111, 118, 128, 132, 135, 138, 149, 161], "matlab": 139, "matmul": [39, 70, 76, 107, 158], "matplotlib": [0, 3, 5, 6, 9, 20, 21, 30, 34, 35, 38, 39, 42, 43, 44, 45, 46, 47, 54, 55, 70, 74, 75, 76, 78, 81, 82, 83, 85, 86, 87, 88, 93, 97, 98, 99, 100, 101, 107, 128, 131, 132, 134, 135, 137, 138, 140, 142, 143, 148, 149, 150, 152, 154, 155, 156, 157, 158, 161, 166, 167], "matric": [39, 50, 52, 54, 57, 72, 80, 82, 84, 87, 88, 90, 91, 93, 105, 130, 138, 158, 161], "matrix": [19, 41, 43, 46, 49, 50, 52, 54, 57, 58, 68, 70, 71, 73, 76, 77, 78, 80, 82, 83, 84, 85, 87, 88, 91, 93, 98, 100, 102, 106, 107, 108, 109, 111, 112, 122, 127, 128, 135, 138, 143, 151, 153, 158, 166], "matrix_larg": 141, "matrix_large_spars": 141, "matrix_rank": 141, "matshow": [82, 88], "matt": 61, "matter": [24, 41, 42, 49, 52, 58, 67, 159, 161], "matthew": 1, "matur": 52, "max": [4, 9, 19, 20, 21, 28, 34, 38, 41, 42, 45, 46, 47, 49, 54, 55, 58, 72, 74, 75, 80, 81, 83, 87, 97, 99, 100, 101, 131, 137, 138, 139, 141, 143, 150, 158, 166, 167], "max68": 135, "max90": 135, "max_": 51, "max_arg": 46, "max_height": [9, 137], "max_i_num": 158, "max_it": [55, 75], "max_lag": [148, 149], "max_lik": 128, "max_mode_theta": 46, "max_n": [38, 42], "max_n1": 42, "max_n2": 42, "max_norm_pt": 131, "max_of_mod": 46, "max_param": 128, "max_pooling2d": 81, "max_pooling2d_1": 81, "max_posterior": 47, "max_sigma_v": 131, "max_theta": [152, 157], "maxa": 20, "maxent": 5, "maxim": [8, 13, 41, 43, 44, 45, 46, 54, 56, 77, 78, 82, 88, 90, 93, 98, 100, 109, 152, 157], "maxima": [58, 138], "maximimum": 77, "maximum": [8, 9, 13, 16, 18, 20, 22, 24, 30, 35, 38, 39, 41, 42, 43, 44, 45, 47, 48, 51, 52, 54, 56, 58, 60, 67, 77, 78, 80, 83, 84, 85, 95, 97, 101, 128, 131, 132, 134, 138, 147, 152, 156, 157], "maxlik": 41, "maxlike_result": [152, 157], "maxpooling2": 81, "maxpooling2d": 81, "may22": [1, 51], "mayb": [10, 36, 95, 135, 156, 159], "mb": [111, 142], "mb_k": 70, "mbgd": 111, "mbox": [9, 11, 13, 15, 22, 24, 35, 41, 42, 43, 47, 52, 83, 91, 130, 148, 150, 167], "mbpt": 52, "mbw": [1, 71, 122], "mc": [0, 139, 147, 151, 158], "mcculloch": 72, "mcelreath": [49, 153, 158, 159], "mchain": 148, "mcmc": [1, 6, 18, 43, 46, 47, 48, 50, 51, 55, 56, 77, 78, 98, 128, 146, 152, 153, 156, 157, 160, 165, 168], "mcmc_data0": 55, "mcmc_data_nt": 55, "mcmc_random_walk_and_sampl": 159, "mcmc_sampling_i": 164, "mcmc_sampling_ii": [153, 163], "mcmcsampl": [152, 157], "mcse_mean": [156, 157], "mcse_sd": [156, 157], "md": [0, 126, 128], "md2": 128, "md_kernel": 128, "mdc": 128, "mdf": [1, 50], "mdn": 78, "me": [26, 27, 83, 87, 134], "mead": 5, "mean": [0, 6, 9, 11, 12, 13, 16, 18, 20, 21, 22, 23, 24, 26, 28, 29, 30, 34, 35, 36, 39, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 55, 56, 57, 58, 63, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 88, 91, 93, 98, 99, 100, 101, 102, 105, 106, 107, 115, 118, 122, 125, 126, 128, 130, 131, 132, 134, 138, 140, 141, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 161, 163, 164, 166, 167, 168], "mean1000": 167, "mean100000": 167, "mean100000b": 167, "mean100000c": 167, "mean1000b": 167, "mean1000c": 167, "mean16000": 167, "mean16000b": 167, "mean16000c": 167, "mean4000": 167, "mean4000b": 167, "mean4000c": 167, "mean_": 128, "mean_68cr": 43, "mean_absolute_error": 138, "mean_dist": 47, "mean_k": 70, "mean_posterior": 47, "mean_predict": 85, "mean_squared_error": 138, "meaning": [48, 51, 74, 116, 124], "means_arrai": 38, "meant": 69, "meanwhil": 9, "measur": [4, 7, 8, 16, 18, 20, 28, 30, 39, 42, 43, 44, 45, 46, 48, 51, 54, 56, 58, 65, 68, 69, 70, 71, 72, 73, 74, 76, 77, 84, 101, 102, 107, 115, 118, 124, 125, 126, 128, 129, 131, 138, 140, 148, 152, 157, 161, 166], "mechan": [4, 16, 27, 28, 39, 48, 52, 67, 69, 72, 76, 106, 129, 133, 142, 150, 161, 164, 167], "medal": 82, "media": 1, "median": [9, 22, 23, 30, 35, 48, 131], "medic": [40, 68, 135], "medicin": [53, 69, 72, 131], "mediev": 7, "mediocr": 53, "medium": 137, "meet": [61, 68, 141], "mehta": [1, 71], "mel": 52, "melendez": [1, 61, 83], "member": [27, 56, 68, 148], "memor": 122, "memori": [72, 76, 138, 141], "men": [82, 135], "meng": 1, "mention": [8, 44, 48, 53, 56, 71, 72, 78, 102, 152, 157], "menu": 142, "mere": [52, 124], "merg": 7, "merger": 61, "merit": [8, 58], "mermim": 133, "mermin": 133, "merriam": 115, "mesh": [5, 9, 35, 52, 135], "meshgrid": [42, 55, 75, 83, 87, 135], "messag": [83, 128, 139, 142], "messeng": 67, "met": 48, "meta": 24, "metadata": [48, 131], "meterologist": 161, "method": [1, 4, 5, 8, 16, 17, 20, 22, 24, 30, 39, 43, 44, 48, 52, 53, 55, 56, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 82, 88, 93, 94, 97, 98, 100, 102, 105, 110, 112, 115, 117, 118, 121, 122, 127, 128, 129, 130, 132, 135, 138, 139, 141, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 165, 166, 167, 168], "methodologi": 51, "metr": 8, "metric": [51, 68, 70, 71, 74, 81, 102, 105, 115, 135, 138, 140], "metropoli": [49, 55, 56, 148, 151, 153, 156, 165], "metropolis_poisson_exampl": [159, 164], "metropolis_r": [150, 167], "metzen": [85, 86], "mev": [52, 83, 87, 138], "mew": [82, 88], "mg": [120, 126], "mgl": 154, "mgrid": [39, 70, 78, 98], "mh": [56, 151, 153, 156], "mi": [48, 51], "michael": [1, 51, 80], "michigan": 61, "micro": [4, 138], "micron": 56, "microst": 4, "mid": [9, 35, 36, 37, 38, 42, 43, 45, 46, 54, 67, 83, 100, 125, 148], "middl": [12, 61, 135], "might": [3, 4, 7, 8, 18, 20, 24, 26, 28, 30, 34, 36, 39, 43, 44, 45, 46, 48, 49, 50, 51, 53, 56, 57, 58, 61, 65, 67, 68, 69, 70, 71, 72, 76, 78, 86, 90, 97, 99, 100, 101, 105, 110, 115, 116, 130, 132, 135, 137, 139, 140, 141, 142, 148, 149, 152, 156, 157, 158, 159, 161, 166], "mild": 70, "mill": [63, 132], "millimet": 56, "million": [18, 68, 138], "mimic": [72, 93], "min": [4, 9, 19, 21, 39, 46, 47, 49, 54, 56, 58, 75, 82, 83, 87, 100, 101, 105, 118, 137, 138, 139, 141, 143, 153, 158, 161, 166], "min68": 135, "min90": 135, "min_": 132, "min_height": [9, 137], "min_obj": 97, "min_param": 128, "min_theta": [152, 157], "min_val": 97, "min_x": 97, "mina": 168, "mind": [9, 30, 35, 45, 48, 49, 68, 69, 122, 152, 157], "mine": 1, "minfunc": [45, 46], "mini": [54, 71, 73, 102, 168], "minibatch": [78, 98], "minibatch_i": 78, "minibatch_x": 78, "miniconda": 142, "miniconda3": [55, 86, 101, 131, 157], "minim": [8, 11, 27, 34, 39, 43, 45, 46, 52, 54, 56, 67, 70, 71, 72, 73, 74, 76, 77, 96, 97, 102, 105, 106, 110, 121, 122, 128, 132, 159, 164], "minima": [78, 93, 102, 109, 110], "minimum": [4, 5, 7, 9, 39, 44, 47, 56, 70, 74, 83, 97, 102, 105, 109, 110, 111, 128, 134, 137, 152, 157, 159, 161], "minka": 100, "minor": [5, 41, 140], "minu": [24, 34, 45, 46, 49, 77, 153], "minut": [43, 58, 82, 84, 128, 149, 166], "mirror": [56, 161], "misclassif": [68, 71], "misclassifi": [70, 71], "misconcept": 61, "miser": 20, "misfit": 48, "misinterpret": 58, "mislead": [48, 53], "mismatch": [16, 39, 58, 123], "miss": [30, 48, 49, 51, 68, 115, 124, 158], "misspel": 139, "mistak": 20, "misus": 48, "mit": [1, 158], "mith": 141, "mitig": [50, 68], "mix": [49, 56, 59, 60, 71, 72, 148, 151, 156], "mixtur": [43, 55, 77], "mkdir": 138, "mkl": 39, "ml": [65, 68, 78, 82, 88, 93, 94, 102, 132], "mle": [43, 46, 56, 57, 77, 93, 130, 132], "mlmodel": [69, 70], "mloutput": [69, 70, 71], "mloutput_": 70, "mloutput_i": 70, "mltestoutput": [70, 71], "mm": 161, "mnemon": [0, 27], "mnist": 74, "mock": 126, "mod": [0, 141], "modal": [56, 168], "mode": [0, 9, 22, 23, 30, 34, 35, 39, 45, 46, 47, 51, 52, 55, 56, 58, 61, 72, 76, 101, 131, 139, 148, 158, 164], "model": [0, 1, 4, 8, 17, 18, 24, 25, 28, 29, 33, 41, 44, 49, 51, 52, 55, 56, 57, 60, 63, 64, 65, 66, 67, 68, 70, 75, 76, 84, 85, 86, 93, 95, 96, 97, 101, 102, 106, 107, 109, 110, 111, 114, 118, 122, 125, 127, 129, 130, 132, 134, 135, 138, 149, 150, 151, 152, 157, 158, 159, 161, 163, 167], "model_func": 101, "model_height": 128, "model_i": 101, "model_param_bound": 128, "model_select": [78, 79, 98, 138], "model_typ": [39, 97, 107], "modeldiscrep": 128, "modeloutput": [39, 103, 104], "modeloutput_i": 39, "moder": 53, "modern": [1, 18, 56, 69, 93, 141, 148], "modif": [48, 56, 58, 77, 100, 149], "modifi": [10, 30, 35, 39, 42, 43, 45, 46, 47, 55, 56, 61, 68, 71, 72, 73, 75, 76, 77, 82, 88, 98, 100, 101, 105, 112, 128, 136, 139, 140, 149, 156], "modul": [6, 8, 55, 74, 75, 76, 78, 86, 98, 101, 128, 134, 135, 139, 141, 142, 145, 152, 157, 161, 166], "modulenotfounderror": [74, 75, 78, 98, 139], "modulu": 20, "molecular": 49, "mom": [49, 109], "mom_": 49, "mom_i": 49, "moment": [72, 76, 112, 166], "momenta": 153, "momentum": [49, 72, 112, 153, 154], "monetari": 48, "monitor": [48, 49, 67, 71, 72, 74, 76, 102, 151, 164], "monk": 58, "monoton": [4, 72, 112, 164], "mont": [1, 16, 18, 48, 69, 77, 101, 128, 150, 152, 156, 157, 162, 164, 165, 166, 167, 168], "montepython": 49, "monthli": 1, "monti": 16, "moo": 67, "mor": 52, "moral": 164, "more": [0, 3, 4, 7, 8, 9, 11, 13, 15, 16, 18, 20, 22, 23, 24, 28, 30, 33, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 76, 77, 78, 79, 80, 81, 83, 84, 86, 87, 88, 90, 94, 96, 98, 99, 100, 101, 102, 104, 107, 108, 109, 111, 115, 117, 121, 122, 124, 126, 128, 132, 133, 135, 136, 138, 139, 140, 141, 142, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 161, 163, 164, 165, 166], "more_replac": [78, 98], "moreov": [16, 48, 53, 68, 78, 80, 116, 124], "morn": 8, "morten": 61, "most": [4, 8, 11, 12, 16, 23, 24, 30, 38, 39, 42, 45, 46, 48, 49, 51, 53, 54, 55, 58, 61, 62, 63, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 81, 90, 91, 93, 98, 100, 101, 102, 110, 116, 118, 122, 130, 131, 132, 133, 135, 138, 139, 141, 148, 152, 153, 156, 157, 158, 166], "mostli": [39, 43, 73, 78, 104, 115, 161], "mot": 49, "motion": [16, 120, 126, 128, 153, 155, 166], "motiv": [16, 18, 24, 43, 49, 53, 65, 70, 78, 93, 122, 153, 158, 163], "mount": 56, "move": [4, 9, 15, 30, 47, 49, 53, 55, 72, 73, 76, 93, 110, 137, 139, 148, 149, 151, 156, 161, 168], "movement": 149, "moviewrit": 131, "mp4": 131, "mpc": [0, 18, 21, 46], "mpl": [131, 138], "mpl_toolkit": [42, 55, 70], "mplot3d": [42, 55, 70], "mr": 58, "mr_k": 70, "mrg_randomstream": 78, "mse": [70, 71, 72, 76, 105], "mseloss": 76, "msg": 139, "mu": [4, 5, 19, 21, 22, 24, 29, 38, 39, 41, 42, 44, 46, 49, 51, 57, 58, 77, 82, 83, 84, 87, 88, 90, 91, 97, 131, 132, 134, 135, 149, 150, 152, 155, 156, 157, 159, 163, 166, 167, 168], "mu0": 55, "mu1": [39, 55], "mu2": [22, 55, 131], "mu_": [58, 135, 163], "mu_0": [5, 44, 57, 58, 152, 157], "mu_est": [44, 152, 157], "mu_i": [4, 83, 87, 91, 166], "mu_interval__": 157, "mu_j": 4, "mu_k": 4, "mu_mean_prior": 156, "mu_new": 87, "mu_opt": 87, "mu_prior": 156, "mu_sampl": 97, "mu_sample_opt": 97, "mu_sd_prior": 156, "mu_tru": [41, 44, 152, 157], "mu_x": [83, 91], "mu_z": [72, 87], "much": [8, 12, 22, 30, 34, 36, 39, 41, 43, 48, 49, 50, 51, 52, 56, 57, 58, 61, 65, 67, 68, 69, 70, 71, 72, 73, 78, 98, 99, 100, 102, 107, 111, 117, 132, 135, 138, 139, 140, 147, 149, 152, 157, 158, 159, 166], "multi": [16, 31, 51, 55, 60, 64, 76, 78, 93, 96, 98, 100, 101, 141, 158, 166, 168], "multi_class": 75, "multiclass": [68, 93], "multidimension": [22, 39, 56, 72, 84, 100, 127, 138, 141, 153, 159], "multilay": [72, 76], "multimod": [23, 24, 56, 78, 101, 135, 153, 158, 159, 168], "multinest": [1, 56, 158], "multinomi": 93, "multipl": [1, 11, 16, 38, 39, 42, 44, 47, 48, 49, 51, 52, 56, 57, 60, 66, 69, 71, 72, 73, 76, 77, 84, 93, 100, 129, 130, 131, 132, 148, 151, 152, 156, 157, 158, 159, 166, 168], "multipli": [4, 5, 37, 38, 39, 43, 45, 46, 52, 54, 58, 72, 77, 82, 84, 88, 90, 132, 141, 143, 148, 151], "multiprocess": [128, 156, 157], "multivari": [4, 19, 48, 49, 54, 69, 84, 90, 156, 158, 159, 166], "multivariate_norm": [39, 70, 74, 82, 83, 87, 88, 97, 132, 135], "multivariatenormalpropos": 156, "multivers": 135, "mumv": 87, "mup": 55, "mus2": 5, "mus3": 5, "mus4": 5, "mus5": 5, "must": [4, 5, 8, 16, 19, 24, 30, 38, 39, 42, 43, 48, 49, 50, 53, 58, 63, 67, 68, 69, 70, 72, 83, 90, 97, 101, 109, 111, 126, 128, 132, 135, 140, 141, 152, 157, 158, 159, 161, 164, 166], "mutat": 93, "mutual": [27, 28, 36, 37, 71, 81], "muvec": [83, 91], "muz": 87, "mvec": 91, "mvec_1": [84, 91], "mvec_2": 91, "mvn": 87, "mx": [45, 46, 148], "my": [0, 9, 35, 78, 142, 149], "my_ax": [134, 139], "my_bin": 38, "my_fig": [134, 139], "my_funct": [137, 139, 143], "my_metropolis_model": 156, "my_model": 156, "my_mu": 134, "my_multinorm_rv": 135, "my_norm_rv": 135, "my_normal_rv": 135, "my_nuts_model": 156, "my_output": 134, "my_rv": 135, "my_sigma": 134, "my_student_t_rv": 135, "my_suptitl": 22, "my_titl": [82, 156], "mymodel": 76, "myst": 0, "myst_nb": [3, 20, 70, 93, 135, 158, 161, 166], "mysteri": 133, "m\u00e4rten": 1, "n": [1, 3, 4, 7, 8, 9, 11, 13, 15, 18, 22, 24, 29, 30, 34, 35, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 56, 58, 68, 70, 71, 72, 73, 77, 78, 82, 83, 84, 86, 87, 88, 93, 97, 100, 101, 102, 104, 107, 110, 112, 117, 122, 125, 128, 130, 131, 132, 135, 138, 140, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 161, 163, 166, 167], "n_": [34, 47, 49, 50, 52, 56, 69, 71, 72, 76, 80, 83, 87, 111, 122, 164], "n_0": [41, 42, 72], "n_1": [84, 91], "n_2": [84, 91], "n_a": 8, "n_activ": 128, "n_active_mltpl": 128, "n_b": 52, "n_col": 87, "n_color": 131, "n_d": [39, 105, 107, 111, 118], "n_dim": [54, 128], "n_eff": 128, "n_effect": 128, "n_effective_mltpl": 128, "n_epoch": 111, "n_evid": 128, "n_featur": 79, "n_gamma": 131, "n_h": 52, "n_hidden": [78, 98], "n_i": [4, 140], "n_in": 76, "n_job": 75, "n_k": [41, 42, 70], "n_l": 72, "n_max": 47, "n_max_step": 128, "n_max_valu": 47, "n_mean": 38, "n_means_arrai": 38, "n_new": 87, "n_p": [39, 104, 105, 107, 112], "n_prior": 128, "n_pt": [38, 42, 148, 150, 167], "n_restart": 97, "n_restarts_optim": [85, 87], "n_row": 87, "n_sampl": [78, 79, 86, 134], "n_step": 128, "n_steps_mltpl": 128, "n_total": 128, "n_trials_max": 9, "n_trials_max_w": 9, "n_uncertainty_digit": 135, "n_val": 38, "n_w": 9, "nabla": [39, 84, 101, 102, 105, 110, 111], "nabla_": 39, "naimi": [1, 138], "naiv": [20, 48, 58, 93], "name": [0, 4, 10, 18, 22, 28, 30, 39, 44, 46, 47, 49, 54, 56, 58, 68, 69, 72, 73, 74, 75, 78, 80, 81, 82, 84, 88, 96, 98, 99, 100, 101, 107, 109, 128, 130, 132, 135, 138, 139, 141, 142, 143, 149, 151, 152, 156, 157, 159], "namespac": 139, "nan": [43, 141], "narrow": [9, 11, 12, 15, 18, 30, 34, 35, 43, 46, 58, 78, 98, 126, 158], "nasti": [9, 35], "nat": 1, "nation": 68, "nativ": 68, "natur": [1, 7, 8, 16, 30, 39, 42, 43, 47, 48, 49, 52, 54, 57, 58, 65, 67, 69, 72, 74, 76, 77, 78, 85, 91, 101, 115, 122, 125, 135, 141, 154], "navier": 72, "navig": [110, 112], "nb": 52, "nbin": 46, "nbsp": 75, "nburn": [6, 43, 101, 128, 152, 157], "nburnin": [55, 101], "nbviewer": 75, "nc": 61, "nchain": 148, "ncol": [3, 30, 35, 38, 44, 83, 87, 93, 98, 100, 135, 139, 149, 157, 158, 166], "ncore": 128, "ncorr": 6, "ncross": 100, "ncsm": [83, 87], "nd": [39, 107], "ndarrai": [47, 87, 128], "ndata": [39, 101, 107], "ndiffer": 156, "ndim": [6, 22, 43, 46, 55, 101, 128, 148, 151, 152, 157], "ndimens": 99, "ndoubl": [30, 35], "neal": [49, 153], "nearbi": [24, 49], "nearest": 141, "nearli": [39, 126, 132], "neat": 138, "necess": [8, 44, 152, 157, 159], "necessari": [4, 16, 47, 58, 74, 76, 98, 135, 138, 142, 147], "necessarili": [0, 8, 26, 28, 30, 39, 44, 48, 51, 69, 71, 105, 135, 142, 149, 152, 157], "necessit": [153, 159], "need": [6, 7, 18, 22, 24, 27, 30, 36, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 61, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 79, 81, 82, 84, 90, 91, 93, 95, 97, 98, 99, 100, 101, 102, 105, 109, 115, 120, 124, 127, 128, 131, 132, 135, 136, 137, 138, 139, 141, 142, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 161, 163, 164, 166, 167], "needless": 61, "neg": [4, 24, 26, 36, 38, 39, 42, 45, 46, 49, 55, 68, 69, 70, 76, 77, 82, 88, 93, 97, 101, 110, 138, 161, 164], "negat": 49, "neglect": [16, 24, 34, 50, 58, 119, 120, 126], "neglig": [39, 46, 56, 57, 90, 120], "negri": 1, "neighbor": [11, 24, 47], "neighborhood": [52, 70], "neighbourhood": 58, "neil": [82, 88], "neither": [63, 72, 76, 151], "neq": [0, 4, 18, 27, 36, 37, 39, 58, 71, 77, 130, 135, 161, 164, 166], "nest": [0, 56, 57, 58, 72, 158, 159], "net": [71, 72, 76, 78, 98, 134], "netherland": 1, "network": [1, 50, 52, 65, 93, 94, 96, 110, 111, 121, 122, 134, 141], "neumann": 109, "neural": [1, 50, 52, 65, 93, 94, 96, 110, 111, 121, 122, 141], "neural_network": [78, 98], "neural_network_minibatch": 78, "neuralnet": 75, "neuron": [1, 73, 74, 75, 76, 77, 78, 79, 93, 98, 122, 134], "neutral": 138, "neutron": [1, 39, 84, 104, 138, 159], "never": [16, 39, 58, 71, 73, 82, 88, 106, 139], "nevertheless": [16, 44, 105, 152, 157], "new": [0, 7, 9, 10, 11, 13, 15, 16, 18, 30, 39, 42, 43, 45, 48, 49, 51, 53, 54, 55, 56, 58, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 81, 82, 84, 87, 91, 93, 94, 98, 100, 122, 131, 132, 136, 138, 139, 140, 141, 142, 147, 148, 149, 150, 153, 155, 156, 158, 159, 161, 167, 168], "new_arr": 141, "new_data": 78, "new_data_button_w": 9, "new_hobbit": 138, "newarr": 141, "newaxi": [83, 87], "newcommand": [0, 9, 35, 45, 46, 47, 49, 54, 83, 100, 109, 132, 156], "newer": 56, "newli": [49, 139], "newton": [56, 119, 120], "newtonian": [16, 56], "next": [8, 9, 11, 16, 30, 35, 36, 39, 42, 44, 45, 46, 48, 52, 53, 56, 68, 69, 74, 80, 85, 97, 105, 107, 112, 122, 131, 138, 139, 141, 142, 148, 149, 150, 152, 156, 157, 161, 164, 167], "next_button_w": 9, "nfev": 128, "nframe": 131, "nh": 90, "ni": 51, "nice": [43, 53, 74, 100, 126, 149, 152, 157], "nicer": [22, 38, 43, 44, 138, 149, 150, 152, 157], "nicola": [82, 88], "niel": 30, "nielsen": 80, "nifti": 20, "nine": [82, 88, 158], "nist": 68, "nit": 128, "niter": [55, 101], "nk_pt": 42, "nll": 128, "nlp": 128, "nm": [72, 84], "nm_n": 138, "nmap": 128, "nmax": [47, 83, 87], "nmaximum": 128, "nn": [70, 76, 90, 134], "nnloopt": [83, 87], "no_grad": [76, 134], "no_of_chain": [55, 148], "no_of_head": [30, 35], "no_of_sampl": 149, "no_of_tail": [30, 35], "nobel": 72, "node": [72, 73, 74, 78, 98], "nois": [3, 7, 24, 34, 43, 45, 46, 54, 68, 71, 75, 77, 78, 82, 83, 84, 87, 88, 90, 91, 95, 97, 99, 100, 101, 128, 132, 147, 148, 157, 163], "noise_std": 85, "noise_var": 84, "noisi": [70, 71, 76, 93, 95, 96, 97, 100, 101, 102, 128], "nomin": [4, 149], "non": [6, 11, 28, 29, 34, 36, 38, 39, 42, 43, 45, 48, 50, 51, 52, 53, 68, 70, 71, 72, 74, 75, 76, 77, 78, 80, 81, 87, 93, 94, 98, 101, 105, 106, 107, 118, 121, 122, 132, 135, 138, 141, 151, 161], "nonconvex": 109, "none": [4, 6, 22, 34, 38, 39, 42, 46, 47, 54, 55, 70, 74, 75, 81, 82, 83, 85, 87, 88, 97, 101, 107, 128, 131, 132, 134, 138, 148, 149, 152, 154, 157], "nonetheless": 68, "noninform": [44, 152, 157], "nonlinear": [39, 58, 72, 76, 107, 158], "nonlinearli": 52, "nonloc": 56, "nonneg": 71, "nonparametr": [83, 87, 91], "nonsens": [130, 135], "nonsequenti": 141, "nonstandard": 158, "nonstationari": 126, "nontreiv": 153, "nonumb": [53, 93], "nonzero": [24, 72, 141, 164], "nor": [8, 63, 69, 72, 76, 95], "norm": [5, 6, 9, 22, 30, 34, 35, 38, 39, 42, 44, 50, 54, 55, 70, 71, 78, 87, 97, 100, 105, 106, 131, 132, 135, 148, 149, 152, 156, 157], "norm1": 55, "norm1_dist": 22, "norm2": 55, "norm2_dist": [22, 131], "norm_dist": [22, 131], "norm_label": [22, 131], "norm_loc": 131, "norm_pt": 131, "norm_sampl": 22, "norm_scaled_v": 131, "norm_x_pt": 38, "norm_y_pt": 38, "normal": [0, 10, 13, 15, 16, 18, 19, 21, 23, 24, 28, 29, 31, 35, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 54, 55, 56, 57, 71, 72, 74, 75, 77, 78, 81, 82, 84, 85, 88, 93, 97, 98, 100, 101, 102, 106, 107, 109, 115, 120, 128, 131, 132, 134, 135, 148, 149, 150, 152, 153, 156, 157, 158, 159, 161, 163, 164, 166, 167], "normal_": [76, 134], "normal_distribut": 39, "normaliz": 24, "normalize_i": 87, "normalized_posterior_funct": 149, "normalpropos": 156, "normp": 55, "northpoint": 68, "northwestern": 61, "notabl": 126, "notag": 52, "notat": [13, 16, 22, 25, 26, 28, 29, 36, 37, 39, 40, 41, 42, 43, 47, 52, 53, 54, 70, 71, 73, 77, 94, 106, 107, 109, 112, 122, 128, 149, 150, 158, 161, 163, 167], "note": [1, 3, 4, 5, 8, 9, 11, 13, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 61, 68, 69, 70, 71, 72, 73, 77, 78, 80, 81, 82, 84, 85, 87, 88, 90, 91, 93, 95, 97, 98, 99, 100, 101, 102, 104, 105, 107, 110, 111, 115, 116, 117, 118, 128, 130, 131, 132, 135, 137, 138, 139, 140, 141, 142, 147, 148, 149, 150, 151, 152, 153, 156, 157, 158, 161, 163, 164, 166, 167], "notebook": [5, 9, 11, 14, 16, 22, 28, 31, 32, 36, 38, 39, 41, 42, 44, 46, 54, 55, 57, 61, 75, 76, 77, 78, 81, 91, 94, 95, 97, 98, 99, 100, 101, 107, 126, 128, 129, 130, 134, 136, 137, 140, 141, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 164, 167, 168], "noth": [3, 8, 24, 39, 41, 48, 52, 71, 72, 78, 98], "notic": [1, 4, 28, 44, 58, 73, 77, 83, 84, 87, 90, 93, 152, 157, 159, 164], "notin": [51, 135], "notion": [8, 9, 30, 35, 48], "notori": [49, 69, 140], "novel": 71, "novemb": [5, 82], "now": [0, 3, 4, 5, 9, 15, 16, 18, 19, 20, 22, 24, 26, 28, 30, 34, 35, 36, 38, 39, 41, 42, 43, 45, 46, 47, 51, 53, 54, 57, 58, 64, 68, 69, 70, 71, 72, 73, 78, 82, 83, 85, 87, 88, 90, 91, 93, 97, 98, 99, 101, 106, 107, 132, 134, 137, 138, 139, 140, 141, 142, 148, 149, 151, 152, 153, 154, 155, 156, 158, 159, 161], "nowadai": [8, 69, 158], "np": [0, 3, 5, 6, 9, 20, 21, 22, 30, 34, 35, 38, 39, 42, 43, 44, 45, 46, 47, 53, 54, 55, 70, 74, 75, 76, 78, 81, 82, 83, 84, 85, 86, 87, 88, 93, 97, 98, 99, 100, 101, 107, 111, 128, 131, 132, 134, 135, 137, 138, 139, 140, 141, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 161, 164, 166, 167], "np_random_numb": 135, "npl": 56, "nprop": [55, 101], "npropos": 149, "npy": [78, 98], "nrow": [3, 30, 35, 38, 44, 83, 86, 87, 93, 98, 100, 135, 139, 157, 158, 166], "nsampl": [22, 82, 84, 88, 99, 167], "nstep": [6, 43, 46, 55, 101, 128, 148, 152, 157], "nswap": [55, 101], "nswap_accept": [55, 101], "nt": 55, "ntemp": [55, 101], "ntemper": 55, "ntemps_hi": [55, 101], "ntemps_lo": [55, 101], "ntest": 74, "nthin": [55, 101], "nthread": [55, 101], "ntk": 122, "nu": [22, 34, 49, 86, 90, 131, 135], "nu1": 22, "nu2": 22, "nu3": 22, "nuclear": [1, 49, 51, 52, 53, 84, 96, 97, 131, 159], "nucleartal": [142, 145], "nuclei": [52, 84, 138], "nucleon": [1, 50, 131, 138], "nucleu": [52, 84, 138, 159], "nugget": [83, 84, 87, 91], "nuisanc": [7, 17, 22, 28, 30, 41, 101, 151, 164], "null": [11, 24, 58, 138], "num": [34, 46, 85, 86, 93, 137, 140, 158, 166], "num_bin": [22, 131, 156], "num_burn": 128, "num_coin_toss": 35, "num_col": [74, 81], "num_cor": 128, "num_data": 100, "num_data_per_class": 70, "num_draw": 38, "num_imag": [74, 81], "num_it": 148, "num_mean": 70, "num_model_param": 128, "num_param": 128, "num_plot": 100, "num_pt": [22, 47], "num_row": [38, 74, 81], "num_run": 166, "num_sampl": [22, 47, 83, 87, 154, 156, 158], "num_step": [128, 150, 167], "num_t": [137, 154], "num_t_pt": 155, "num_t_w": 137, "num_walker_per_dim": 128, "num_x_pt": 54, "number": [4, 6, 7, 8, 9, 11, 16, 23, 24, 28, 30, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 86, 87, 88, 91, 93, 95, 96, 98, 99, 100, 101, 102, 104, 105, 107, 110, 111, 112, 115, 122, 128, 129, 130, 131, 132, 134, 137, 138, 139, 140, 141, 142, 147, 148, 149, 150, 152, 153, 156, 157, 158, 161, 164, 166, 167], "numer": [0, 8, 16, 18, 21, 34, 39, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 70, 72, 77, 82, 84, 88, 90, 91, 95, 99, 100, 101, 106, 110, 111, 130, 132, 135, 138, 148, 149, 161], "numpeak": [95, 101], "numpi": [0, 3, 5, 6, 9, 20, 21, 22, 30, 34, 35, 38, 39, 42, 43, 44, 45, 46, 47, 54, 55, 70, 74, 75, 76, 78, 81, 82, 83, 85, 86, 87, 88, 93, 97, 98, 100, 101, 107, 128, 131, 132, 134, 135, 137, 138, 142, 143, 148, 149, 150, 152, 154, 155, 156, 157, 158, 161, 166, 167], "numpt": 135, "numref": 0, "nut": [49, 78, 153, 156, 157, 159], "nwalker": [6, 43, 46, 55, 101, 128, 148, 151, 152, 157], "nwarmup": [43, 46, 55, 148], "nwe": 101, "nx": 54, "nx_iy_i": 132, "nz": 138, "o": [1, 3, 24, 39, 43, 45, 46, 54, 72, 74, 82, 83, 87, 100, 107, 122, 124, 128, 131, 135, 138, 148, 149, 150, 156, 161, 166, 167], "o1": 155, "ob": [7, 30, 35, 39, 156], "obei": [8, 13], "object": [6, 8, 9, 16, 22, 28, 35, 43, 48, 53, 55, 58, 76, 77, 78, 82, 83, 88, 97, 98, 101, 109, 110, 125, 131, 135, 137, 138, 139, 140, 141, 143, 154], "oblig": 58, "observ": [0, 1, 3, 4, 7, 9, 10, 11, 12, 16, 18, 24, 28, 30, 35, 36, 39, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 58, 63, 65, 66, 67, 68, 69, 70, 71, 72, 76, 78, 80, 82, 85, 86, 88, 90, 91, 97, 98, 101, 105, 110, 115, 116, 120, 122, 124, 125, 126, 129, 131, 132, 135, 147, 149, 150, 151, 152, 156, 157, 159, 161, 163, 166, 167], "observed_data": 156, "obtain": [4, 7, 8, 9, 14, 16, 18, 19, 20, 28, 30, 35, 39, 41, 46, 48, 49, 50, 52, 53, 63, 64, 68, 70, 71, 72, 73, 76, 77, 81, 82, 87, 88, 91, 93, 97, 102, 105, 125, 126, 130, 135, 149, 150, 151, 155, 156, 158, 159, 166, 167, 168], "obviou": [16, 24, 39, 70, 161], "obvious": [4, 8, 16, 20, 30, 38, 39, 50, 71, 77, 78, 90, 93, 99], "occam": [56, 57, 58], "occasion": [61, 142, 161], "occupi": [4, 153], "occur": [8, 27, 30, 61, 68, 70, 93, 135, 138, 161], "occurr": 8, "ockham": [7, 58, 95], "oct": [83, 156], "octob": 1, "od": [153, 154, 155], "odd": [29, 30, 39, 58, 93, 138], "odds_ratio": 100, "odeint": 128, "odot": [50, 71, 77], "ofeffect": 96, "off": [7, 9, 22, 38, 41, 47, 53, 54, 56, 57, 58, 78, 97, 98, 132, 135, 138, 153, 156, 166], "offenc": 68, "offend": 68, "offer": [7, 18, 19, 46, 49, 51, 76, 118, 122, 139, 141, 156], "offici": 156, "offlin": [50, 52], "offset": [43, 46, 56, 58, 128, 138, 148], "often": [3, 4, 7, 13, 15, 16, 20, 23, 24, 28, 34, 39, 43, 44, 45, 46, 48, 49, 50, 51, 52, 58, 60, 63, 65, 67, 68, 69, 70, 71, 72, 73, 76, 78, 90, 91, 93, 100, 102, 105, 107, 109, 110, 111, 115, 116, 124, 127, 129, 131, 135, 139, 140, 141, 148, 149, 151, 152, 157, 158, 159, 164, 166], "ohio": [26, 61], "oin": 9, "ok": [0, 27, 42, 47, 101, 132, 139, 156, 159, 164], "okai": 24, "ol": [39, 70, 71, 107, 164], "old": 158, "older": [43, 139], "oliv": 61, "ols_cov": [39, 70, 107], "ols_d": [39, 107], "ols_ep": [39, 107], "ols_s2": [39, 107], "ols_theta": [39, 70, 107], "ols_xtd": [39, 70, 107], "olymp": 82, "olympic_marathon_men": 82, "olympicmarathontim": 82, "omega": [16, 24, 38, 39, 137, 158], "omega_0": 154, "omega_i": 49, "omega_j": 49, "omega_pt": 38, "omega_w": 137, "omit": [16, 27, 29, 54, 58, 61, 78, 90, 122, 149], "on_click": 9, "onc": [4, 8, 9, 12, 15, 16, 27, 30, 35, 41, 42, 43, 45, 47, 48, 52, 53, 58, 64, 71, 72, 78, 90, 102, 139, 142, 158, 159, 166], "one": [0, 4, 5, 7, 8, 9, 11, 16, 18, 21, 22, 23, 24, 27, 28, 29, 30, 31, 34, 36, 37, 39, 41, 42, 43, 44, 46, 48, 49, 51, 52, 53, 54, 56, 57, 58, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 91, 93, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 109, 111, 112, 115, 116, 120, 122, 124, 125, 126, 130, 131, 132, 134, 135, 138, 139, 140, 141, 142, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 161, 163, 164, 166, 167, 168], "oned_arr": 141, "ones": [5, 24, 39, 42, 43, 48, 55, 58, 67, 70, 71, 72, 75, 78, 98, 100, 101, 107, 110, 122, 135, 138, 141, 158, 166], "ones_lik": [6, 43, 45, 101, 138, 141, 148], "onevariablenet": 76, "ongo": 8, "onli": [0, 4, 7, 8, 11, 15, 16, 18, 22, 23, 24, 28, 29, 30, 34, 36, 39, 41, 42, 43, 45, 46, 48, 49, 52, 53, 54, 55, 56, 57, 58, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 77, 78, 80, 81, 84, 85, 86, 87, 90, 91, 93, 101, 102, 105, 107, 109, 110, 112, 120, 124, 126, 128, 132, 134, 135, 138, 140, 141, 148, 149, 151, 153, 156, 158, 161], "onlin": [1, 52, 69, 75, 76, 82, 88, 90, 139, 140, 156], "onto": [19, 50, 132, 158, 164], "onu": 58, "op": 131, "opac": 49, "open": [8, 16, 30, 48, 66, 69, 78, 127, 138, 139], "openli": 69, "oper": [7, 8, 30, 39, 49, 52, 67, 68, 69, 71, 72, 78, 80, 82, 84, 88, 104, 106, 138, 139, 143, 149], "operation": 71, "operatornam": [71, 90, 109], "opinion": [68, 164], "opportun": [49, 52, 58, 63, 69], "oppos": [24, 56, 121, 139], "opposit": [4, 8, 24, 42, 73, 102, 110], "opt_r": 86, "optic": 51, "optim": [1, 4, 5, 16, 39, 41, 43, 45, 46, 52, 56, 58, 70, 71, 72, 74, 75, 76, 77, 78, 81, 82, 83, 84, 85, 87, 88, 90, 96, 98, 100, 104, 105, 111, 115, 121, 122, 124, 128, 132, 164, 168], "optima": 97, "optimis": [82, 88], "optimum": [20, 39, 46, 72, 82, 87, 97, 105, 114], "option": [9, 11, 30, 39, 43, 45, 52, 55, 57, 61, 72, 75, 76, 95, 99, 100, 101, 128, 136, 141, 142, 155, 156, 161, 163], "optpar": [49, 109, 114], "optpara": 49, "optpars_i": 49, "optparslr": 39, "opvi": 78, "oracl": 53, "orang": 85, "orbit": 115, "orbit_gam": 155, "order": [5, 7, 24, 39, 46, 48, 49, 51, 52, 54, 57, 58, 61, 63, 67, 71, 72, 73, 76, 77, 78, 84, 93, 99, 101, 102, 105, 106, 107, 120, 138, 139, 142, 153, 155, 161, 166], "ordinari": [52, 56, 58, 70, 71, 80, 93, 101, 153, 155], "ordinarili": 132, "org": [1, 22, 45, 55, 74, 75, 81, 86, 98, 101, 109, 135, 153, 156, 159], "organ": [9, 68, 72, 137, 141, 166], "orient": [41, 55, 58, 68, 137, 148], "origin": [4, 16, 31, 38, 43, 47, 48, 49, 51, 52, 53, 55, 56, 58, 61, 68, 70, 71, 77, 78, 80, 82, 84, 93, 96, 98, 101, 132, 141, 148, 149, 156, 158, 168], "orthogon": [27, 50, 52, 58, 130, 132, 151], "orthonorm": [27, 36, 37, 52, 130], "oscil": [52, 56], "oslo": 61, "osu": [0, 83, 137, 142, 154, 156], "osx": 142, "other": [1, 4, 7, 8, 9, 10, 12, 13, 16, 18, 22, 23, 24, 26, 28, 30, 32, 35, 36, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 61, 68, 69, 70, 71, 72, 73, 74, 76, 78, 80, 82, 83, 84, 87, 88, 91, 93, 97, 98, 99, 102, 105, 107, 110, 111, 115, 118, 122, 130, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142, 148, 149, 150, 152, 153, 155, 156, 157, 158, 159, 161, 163, 165, 166, 167], "otherwis": [7, 8, 18, 20, 30, 35, 43, 46, 47, 49, 52, 58, 76, 86, 91, 93, 97, 100, 124, 135, 139, 150, 158, 161, 167], "ouput": 73, "our": [0, 4, 7, 8, 9, 10, 11, 13, 16, 18, 20, 22, 24, 26, 27, 28, 30, 32, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 78, 81, 82, 83, 84, 85, 87, 88, 90, 91, 93, 94, 98, 99, 100, 101, 102, 104, 105, 106, 107, 115, 118, 124, 126, 128, 132, 135, 141, 143, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 161, 164, 166, 167], "ourselv": [51, 71, 72, 87, 109, 115, 135, 138, 158], "out": [1, 4, 5, 9, 13, 16, 18, 19, 22, 24, 28, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 64, 65, 66, 67, 68, 71, 73, 76, 77, 78, 81, 82, 88, 91, 93, 98, 99, 100, 105, 106, 120, 126, 128, 132, 137, 138, 139, 141, 142, 147, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 166, 167], "out_featur": 76, "outcom": [8, 9, 11, 27, 28, 30, 35, 36, 48, 51, 58, 68, 93, 94, 115, 128, 135, 141, 158, 161, 163, 166], "outer": [0, 73], "outfil": 131, "outlier": [46, 60, 159], "outlin": [43, 46, 53, 112, 149, 158], "outperform": 52, "output": [0, 5, 9, 17, 39, 46, 48, 50, 51, 52, 53, 63, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 90, 93, 94, 98, 101, 104, 106, 107, 114, 115, 122, 125, 135, 138, 139, 140, 141, 166], "output_": [70, 118], "output_1": 118, "output_2": 118, "output_i": [70, 71, 118], "outputlayer1": 72, "outputs_i": [69, 111], "outsid": [3, 24, 51, 58, 87, 100, 140, 149, 168], "outward": 24, "over": [0, 4, 16, 20, 21, 22, 23, 24, 27, 28, 36, 39, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 56, 57, 58, 60, 61, 68, 69, 70, 73, 76, 77, 78, 81, 82, 83, 87, 88, 90, 91, 93, 94, 98, 100, 101, 111, 122, 125, 129, 130, 131, 132, 135, 138, 140, 142, 147, 148, 149, 151, 152, 157, 158, 159, 166, 168], "overal": [9, 13, 36, 38, 42, 52, 53, 68, 78, 99, 101, 125, 137], "overall_titl": [42, 154, 155], "overarch": [69, 77], "overbrac": [9, 10, 28, 35], "overcom": 72, "overconfid": 126, "overestim": [71, 148], "overfit": [16, 34, 69, 70, 71, 72, 74, 76, 77, 78, 80, 99, 100, 102, 118], "overflow": 139, "overhead": 73, "overlai": 22, "overlaid": 134, "overlap": [20, 27, 49, 68, 71, 75, 81, 149, 164], "overli": [16, 43, 65], "overlin": [36, 47, 99, 148, 151, 159], "overlook": 68, "overrepres": 68, "overset": [13, 15, 24, 37, 91, 147], "overshoot": 111, "oversight": 68, "overview": [9, 16, 32, 33, 50, 61, 80, 94, 137, 142], "overview_text": [9, 137], "overweight": 68, "overwhelm": 58, "ow": 69, "own": [0, 4, 11, 27, 38, 42, 48, 61, 68, 69, 71, 74, 99, 132, 136, 138, 139, 144, 148, 166, 167], "oxford": [1, 61], "o\u02bchagan": 124, "p": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 13, 15, 16, 18, 19, 20, 21, 22, 28, 29, 30, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 68, 70, 71, 72, 75, 77, 78, 82, 83, 84, 87, 88, 90, 91, 93, 98, 100, 101, 104, 105, 107, 109, 118, 122, 130, 131, 132, 135, 137, 138, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 161, 163, 166, 167, 168], "p0": [55, 101, 148, 151], "p1": [45, 46, 154], "p2": 45, "p2cread": 131, "p2cwrite": 131, "p_": [15, 18, 24, 53, 56, 77, 93, 135, 154, 161, 166], "p_0": 154, "p_1": [4, 15, 16], "p_2": [4, 15], "p_3": 4, "p_4": 4, "p_accept": 149, "p_current": 149, "p_h": [9, 11, 12, 13, 15, 24, 30, 35], "p_i": [3, 4, 16, 49, 153], "p_j": 4, "p_n": 15, "p_phi": 154, "p_phi_0": 154, "p_phi_now": 154, "p_phi_vs_time_label": 154, "p_propos": 149, "p_star": 100, "p_x": [30, 58, 135], "p_y": [58, 72], "p_z": [18, 72], "pa": 20, "pace": [82, 164], "pacif": 1, "pack": 138, "packag": [22, 28, 43, 46, 48, 55, 69, 78, 82, 86, 88, 98, 101, 128, 131, 135, 138, 139, 142, 151, 152, 157, 158], "pad": [75, 83, 100, 155], "page": [0, 1, 22, 28, 46, 61, 75, 82, 88, 89, 92, 99, 135, 138, 139, 142, 147, 151, 153, 158, 159], "pai": [27, 68, 72, 77], "painfulli": [110, 140], "painstak": 69, "pair": [39, 45, 48, 52, 53, 56, 83, 87, 100, 104, 132, 138, 140, 148, 151], "pairplot": 166, "palett": 139, "panda": [39, 107, 139, 148], "panel": [20, 30, 42, 46, 48, 61, 70, 77, 100, 102, 126, 135, 138, 149, 152, 157, 161, 166], "pankaj": 1, "papanicola": 5, "paper": [1, 39, 48, 49, 51, 54, 56, 66, 77, 91, 99, 100, 106, 131, 148], "par": [7, 16, 39, 41, 49, 50, 51, 52, 58, 69, 71, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 117, 118, 119, 122, 123, 125, 158], "para": [39, 48, 49, 135, 158], "para_": [71, 105, 112], "para_0": [104, 105, 106, 117, 119, 120], "para_1": [49, 52, 105, 106, 117, 119, 120, 158], "para_1f_1": [39, 105], "para_2": [49, 52, 105, 117, 119, 120, 158], "para_2f_2": 105, "para_3": 52, "para_i": [49, 50, 52, 112, 158], "para_j": [104, 105], "para_n": 52, "paradigm": [8, 16, 43, 48, 52, 69, 100, 124], "paradox": 133, "parallel": [26, 41, 55, 58, 61, 78, 95, 98, 122, 128, 153, 168], "paralr": 39, "paralr_": 39, "paralr_0": 39, "paralr_1": 39, "paralr_1f_1": 39, "paralr_2": 39, "paralr_2f_2": 39, "paralr_i": 39, "paralr_j": 39, "param": [39, 55, 74, 81, 87, 101, 107, 111, 128, 148], "param_bound": 128, "param_max": 128, "param_min": 128, "param_resc": 128, "paramet": [1, 3, 4, 6, 8, 9, 10, 11, 13, 17, 20, 22, 23, 24, 25, 28, 29, 30, 32, 34, 35, 39, 41, 42, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 61, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 90, 91, 95, 96, 97, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 139, 141, 148, 149, 150, 151, 153, 154, 155, 156, 158, 159, 163, 164, 166, 167, 168], "parameter": [51, 77, 83, 87, 90, 122, 151], "parameter_estim": 168, "parameter_estimation_fitting_straight_line_i": [43, 46, 148], "parameter_estimation_fitting_straight_line_ii": 148, "parameter_estimation_gaussian_nois": 147, "parameter_estimation_gaussian_noise_compare_sampl": 168, "parameters_text": 137, "parametr": [8, 33, 49, 50, 52, 77, 78, 82, 83, 84, 87, 91, 121, 127, 138], "params_gradi": 111, "params_mod": 55, "params_rbf": 87, "paranmet": 111, "paraphras": 122, "parenthes": 130, "pars_": [50, 110, 112], "pars_0": 110, "pars_1": 52, "pars_2": 52, "pars_i": [7, 49, 50, 52, 158], "pars_j": [49, 52], "pars_n": [52, 110, 111, 112], "parsec": [18, 22], "parslr": 39, "parslr_1": 39, "parslr_2": 39, "part": [0, 16, 28, 32, 36, 37, 38, 39, 41, 46, 48, 50, 56, 61, 63, 64, 65, 67, 68, 69, 70, 76, 77, 78, 80, 82, 91, 95, 96, 99, 100, 105, 115, 116, 118, 129, 132, 138, 141, 147, 148, 153, 159, 161, 164], "parti": 26, "partial": [1, 3, 4, 19, 34, 39, 41, 44, 49, 58, 73, 93, 100, 102, 105, 110, 112, 130, 132, 152, 153, 154, 157], "particl": [0, 1, 22, 24, 26, 28, 122, 128, 131, 138, 153, 161, 166], "particulali": 61, "particular": [0, 3, 4, 7, 8, 9, 16, 27, 29, 30, 34, 35, 36, 39, 43, 44, 46, 47, 49, 51, 52, 53, 55, 56, 57, 58, 61, 64, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 82, 88, 90, 91, 93, 97, 99, 100, 102, 105, 109, 110, 115, 118, 121, 122, 125, 126, 127, 131, 135, 137, 138, 143, 150, 152, 157, 158, 159, 167], "particularli": [28, 29, 32, 43, 48, 56, 61, 67, 71, 76, 80, 124, 135, 139, 158, 159, 166], "partit": [5, 39, 90, 91, 135, 164], "partli": [48, 52, 58, 83, 87], "pass": [22, 28, 55, 72, 73, 76, 77, 80, 81, 83, 93, 101, 115, 122, 128, 131, 132, 134, 138, 139, 141, 151, 154, 156, 158, 161, 166], "pass_fd": 131, "passeng": 69, "past": [8, 9, 16, 22, 26, 29, 51, 58, 112, 140, 147, 161], "patent": 158, "path": [1, 53, 67, 75, 82, 88, 91, 128, 135, 138, 153, 161, 166], "patient": [61, 68, 93, 142], "pattern": [1, 16, 54, 56, 67, 69, 72, 76, 81, 94, 161], "pauciora": 58, "pauli": 138, "paus": 24, "pb": 1, "pc": 139, "pca": [84, 129], "pcg64": 135, "pcolor": 45, "pct": [42, 45, 46], "pd": [39, 107, 138, 148], "pd_d": [39, 107], "pd_design_matrix": [39, 107], "pd_m": [39, 107], "pd_m_ol": [39, 107], "pd_r": [39, 107], "pd_x": [39, 107], "pd_xmeasur": [39, 107], "pd_xrealiti": [39, 107], "pdf": [0, 1, 3, 7, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 24, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 51, 54, 58, 60, 77, 79, 83, 87, 90, 91, 97, 101, 128, 131, 152, 153, 156, 157, 159, 161, 163, 164, 165, 166], "pdf_1": [0, 21], "pdf_2": [0, 21], "pdf_2_grid": [0, 21], "pdf_3": [0, 21], "pdf_3_grid": [0, 21], "pdf_4": [0, 21], "pdfy": 135, "peacock": 168, "peak": [9, 12, 20, 24, 38, 39, 41, 42, 44, 46, 54, 55, 56, 57, 58, 72, 95, 96, 100, 101, 135, 151, 152, 153, 157], "pen": [0, 28, 39, 106], "penal": 58, "penalti": [56, 57, 58, 71, 75], "pendleton": 1, "pendulum": 56, "peopl": [0, 4, 24, 27, 36, 58, 61, 67, 68, 69, 82, 103, 148, 156, 158], "per": [34, 46, 52, 58, 63, 72, 76, 82, 85, 100, 128, 131, 134, 138, 147, 154, 166], "perceiv": [68, 69], "percent": [22, 30, 54, 135], "percentag": [23, 24, 81, 131, 132, 153, 156], "percentil": [43, 99, 101], "perceptron": [72, 76, 78, 98], "peregrin": 138, "perfect": [39, 45, 46, 49, 53, 64, 70, 84, 91, 138, 148], "perfectli": [44, 49, 148, 152, 156, 157], "perfom": [70, 72], "perform": [4, 7, 8, 16, 21, 30, 35, 36, 39, 43, 46, 48, 49, 50, 51, 52, 53, 55, 56, 58, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 93, 97, 100, 102, 105, 107, 110, 111, 115, 116, 117, 124, 126, 130, 132, 135, 138, 139, 140, 141, 147, 148, 149, 151, 152, 157, 158, 161, 168], "perhap": [45, 67, 69], "perimet": 133, "period": [6, 39, 43, 49, 58, 82, 86, 88, 128, 150, 152, 157, 161, 167], "periodic_matern32": 82, "periodicexponenti": [82, 88], "periodicity_bound": 86, "perivolaropoulo": 56, "perm": [83, 87], "permeat": 77, "permiss": [49, 81, 126], "permit": [7, 48, 52, 58, 71], "permut": [83, 87, 93, 109], "persist": [48, 124], "person": [8, 9, 27, 35, 48, 68, 135], "perspect": [1, 8, 39, 52, 62, 64, 65, 66, 67, 82, 88, 91, 93, 94, 104, 115, 118], "persuad": 5, "pertain": [30, 35], "pertin": 73, "perturb": [63, 122], "pervers": 24, "pessimist": 43, "peter": 132, "petrov": 52, "petunin": 51, "pf": [20, 161], "ph": [30, 35], "phase": [48, 50, 52, 55, 56, 57, 72, 76, 101, 137, 153, 154], "phase_space_label": 154, "phd": 61, "phenomena": [7, 56, 127], "phenomenolog": [39, 53, 104], "phenomenon": [7, 45, 67, 115], "phi": [18, 56, 125, 128, 137, 154, 155, 158, 164], "phi_": [90, 155], "phi_0": [154, 155], "phi_and_p_high": 154, "phi_and_p_low": 154, "phi_i": 155, "phi_now": 154, "phi_pt": 155, "phi_pts_eul": 155, "phi_pts_lf": 155, "phi_vs_time_label": 154, "phi_w": 137, "phil": [1, 61], "phillip": [5, 61, 156], "philosoph": [7, 24, 25, 30, 44, 152, 157], "philosophi": [8, 44, 133, 152, 157], "phivec": [159, 164], "photon": 65, "phrase": 50, "phtrue": 35, "phy": [1, 5, 49, 54, 83, 87, 91], "physic": [0, 1, 4, 16, 18, 22, 24, 28, 39, 48, 51, 52, 53, 55, 56, 58, 61, 62, 64, 69, 70, 72, 77, 84, 93, 97, 99, 105, 107, 116, 122, 124, 126, 127, 131, 132, 133, 135, 138, 150, 158, 159, 164, 166, 167], "physicist": [1, 8, 22, 28, 32, 34, 58, 61, 62, 64, 65, 67, 72, 122, 131], "physrep": 1, "physrevc": 1, "physrevlett": 1, "pi": [4, 18, 19, 21, 24, 29, 38, 39, 42, 43, 44, 45, 46, 47, 49, 54, 55, 57, 58, 72, 75, 77, 82, 83, 88, 91, 97, 99, 100, 101, 107, 119, 128, 134, 135, 137, 139, 140, 148, 149, 151, 152, 155, 157, 161], "pi_": 161, "pi_1": 161, "pi_2": 161, "pi_3": 161, "pi_i": [158, 161], "pi_j": 161, "pi_jt_": 161, "pi_n": 161, "pick": [13, 16, 24, 34, 56, 58, 70, 98, 131, 139, 154], "pictur": [43, 45, 46, 78, 122, 132, 148], "piec": [9, 24, 34, 44, 52, 115, 152, 153, 157], "pierr": [8, 39], "pillar": 78, "pioneer": [0, 8, 28], "pipe": 131, "pipelin": 69, "pipenv": 142, "pipes": 131, "pippin": 138, "pitt": 72, "pivot": 8, "pixel": [74, 80, 81, 122], "place": [8, 16, 24, 27, 37, 44, 47, 48, 53, 56, 65, 67, 72, 76, 78, 80, 84, 101, 138, 139, 147, 148, 149, 152, 156, 157, 158, 166], "plai": [5, 9, 11, 22, 28, 32, 35, 39, 41, 57, 58, 69, 71, 72, 78, 91, 107, 132, 137], "plain": [73, 77], "plan": [24, 66, 101, 159], "plane": [24, 70, 79], "planetari": 16, "plate": 56, "plateau": [71, 102, 128], "platform": [49, 68], "plato": 161, "platon": 67, "plausibl": [1, 47, 66, 77, 128], "player": [16, 166], "pleas": [35, 54, 75, 100, 156], "plenti": [72, 151], "plethora": 72, "plot": [0, 3, 6, 7, 9, 11, 18, 20, 21, 24, 30, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 48, 54, 55, 56, 58, 70, 71, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 88, 91, 93, 97, 98, 99, 100, 101, 102, 107, 122, 132, 134, 135, 137, 138, 143, 147, 149, 150, 151, 152, 154, 157, 158, 161, 164, 166, 167, 168], "plot_autocorr": 156, "plot_conditional_distribut": 161, "plot_contour": 87, "plot_data": [39, 107], "plot_decision_boundari": 75, "plot_dens": 83, "plot_estim": 135, "plot_forest": 156, "plot_gaussian_contour": [83, 87], "plot_gpr_sampl": 86, "plot_hist": 22, "plot_imag": [74, 81], "plot_it": 139, "plot_limit": [82, 88], "plot_lin": 5, "plot_mcmc_model": 46, "plot_mcmc_trac": 46, "plot_num": 154, "plot_out": [9, 137], "plot_pair": 157, "plot_posterior": 156, "plot_process": [161, 166], "plot_propos": 149, "plot_result": 45, "plot_sample_dimens": [83, 87], "plot_sample_result": 38, "plot_sine_map": 140, "plot_start": [154, 155], "plot_stop": [154, 155], "plot_surfac": [42, 70, 135], "plot_titl": [45, 83, 148, 150, 167], "plot_trac": [156, 157], "plot_value_arrai": [74, 81], "plot_y_vs_x": 154, "plt": [0, 3, 5, 6, 9, 20, 21, 22, 30, 34, 35, 38, 39, 42, 43, 44, 45, 46, 47, 54, 55, 70, 74, 75, 76, 78, 81, 82, 83, 85, 86, 87, 88, 93, 97, 98, 100, 101, 107, 128, 131, 132, 134, 135, 137, 138, 139, 140, 148, 149, 150, 152, 154, 155, 156, 157, 158, 161, 166, 167], "plu": [17, 24, 31, 39, 42, 57, 61, 71, 72, 77, 95, 98, 99, 101, 132, 135, 142, 153, 161, 162, 165], "plug": [36, 45, 149], "plumle": 61, "plura": 58, "pm": [4, 18, 20, 24, 34, 39, 41, 45, 46, 58, 78, 86, 98, 156, 157, 159, 161, 163], "pm1": [77, 79], "pm2": [77, 79], "pm3": 156, "pmatrix": [39, 41, 50, 57, 58, 72, 84, 90, 91, 158, 161], "pmc": 128, "pmf": [22, 28, 29, 38], "pmm": 127, "pn": 49, "png": [0, 3, 4, 6, 30, 58, 77, 78, 102, 138, 139, 154, 155], "po": [43, 49, 55, 109, 128, 148, 157], "pocomc_sampl": 128, "pod": [52, 130], "pofm": 53, "pofm1": 53, "point": [0, 4, 6, 7, 8, 9, 11, 16, 19, 22, 24, 28, 30, 34, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 58, 66, 68, 70, 71, 74, 75, 76, 77, 78, 82, 83, 84, 85, 87, 88, 90, 91, 93, 95, 97, 99, 100, 101, 102, 106, 107, 108, 110, 112, 122, 124, 125, 126, 128, 130, 131, 132, 137, 138, 139, 141, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 161, 167, 168], "point_alpha": 131, "pointer": [25, 77, 78, 98, 127], "pointestimates_fig": 135, "pointwis": [85, 112], "poisson": [24, 41, 48, 165], "poisson_plot": [38, 42], "poisson_pt": [38, 42, 150, 167], "poissonpropos": 156, "pol54a": [1, 67], "pol54b": [1, 67], "polar": 155, "poldeg": [39, 107], "polic": 15, "polit": 53, "polya": [1, 66], "polyfit": 100, "polym": 72, "polyni": 100, "polynomi": [5, 71, 84, 91, 93, 102, 106, 107], "polyv": [39, 100, 107], "pool": [55, 78, 80, 101, 128], "poor": [22, 24, 34, 39, 52, 58, 68, 71, 101, 122], "poorli": [48, 53, 71], "popen": 131, "popper": 67, "popul": [36, 37, 44, 68, 70, 78, 94, 135, 152, 157, 166], "popular": [52, 68, 69, 72, 100, 102, 110, 126, 135, 138, 139], "pos1": 70, "pos2": 70, "pos_": 49, "pos_i": 49, "pose": 68, "posit": [4, 6, 8, 18, 21, 24, 30, 36, 39, 42, 43, 44, 46, 47, 49, 55, 56, 58, 66, 67, 68, 69, 70, 71, 76, 77, 82, 83, 87, 88, 90, 91, 93, 95, 101, 102, 105, 110, 112, 128, 130, 132, 135, 143, 147, 148, 149, 151, 152, 153, 157, 158, 161, 164, 166], "possibl": [4, 7, 8, 9, 13, 18, 24, 30, 36, 37, 39, 43, 45, 48, 49, 50, 51, 53, 54, 58, 61, 64, 66, 67, 69, 70, 71, 72, 73, 80, 82, 88, 93, 99, 100, 104, 108, 116, 119, 122, 125, 128, 130, 135, 141, 149, 152, 157, 158, 159, 161, 164, 166], "possibli": [39, 45, 46, 51, 53, 69, 70, 72, 76, 77, 93, 107, 109, 139, 149, 151, 166], "post": [43, 77, 78, 98, 112, 149, 157], "postdoc": 61, "postenti": 153, "posterior": [1, 9, 10, 12, 15, 18, 20, 23, 24, 25, 28, 29, 30, 32, 34, 35, 42, 43, 44, 45, 46, 49, 51, 53, 54, 56, 57, 58, 64, 65, 77, 78, 79, 82, 84, 87, 88, 90, 91, 92, 95, 97, 98, 99, 100, 101, 125, 126, 147, 149, 150, 151, 152, 153, 156, 157, 158, 159, 163, 167], "posterior1": 39, "posterior_calc": 47, "posterior_func": 149, "posterior_funct": 149, "posterior_pt": 47, "posteriorbma": 53, "posteriori": [39, 77, 156], "postiv": 68, "postul": 16, "potenti": [48, 49, 50, 52, 53, 56, 66, 68, 69, 71, 72, 76, 87, 109, 124, 142, 148, 153, 156], "potest": 58, "pott": 72, "pound": 139, "pow": 76, "powel": 128, "power": [7, 30, 38, 39, 51, 60, 61, 65, 68, 70, 71, 72, 76, 78, 81, 116, 122, 126, 128, 130, 135, 139, 141], "pp": [135, 161, 166], "ppc": [78, 98], "ppd": [16, 39], "ppd_definition_b": 0, "ppf": 135, "pr": [22, 28, 35, 45, 46, 47, 49, 54, 100, 128, 156], "practic": [9, 15, 20, 32, 40, 42, 44, 45, 48, 49, 51, 53, 56, 58, 63, 64, 66, 67, 68, 71, 76, 90, 91, 93, 99, 105, 124, 130, 132, 150, 152, 153, 156, 157, 159, 161, 162, 164, 165, 166, 167], "practition": [64, 72, 93], "pradeep": 91, "pragmat": 118, "pratola": 61, "pre": [0, 48, 49, 50, 74, 78, 122], "preactiv": 122, "preced": [58, 72], "preceed": 139, "precent": 30, "precipic": 156, "precipit": 161, "precis": [5, 34, 39, 44, 45, 46, 48, 50, 51, 53, 56, 58, 68, 71, 72, 83, 84, 85, 87, 99, 101, 110, 116, 118, 130, 131, 132, 138, 152, 154, 155, 157, 158, 159, 163, 166], "preconceiv": [9, 35], "precondit": 128, "pred": [78, 98], "pred_func": 75, "predefin": [76, 139], "predetermin": [101, 158], "predic": 148, "predict": [1, 4, 7, 25, 29, 30, 34, 49, 50, 51, 53, 56, 58, 63, 65, 67, 68, 69, 70, 71, 72, 75, 76, 77, 79, 82, 83, 84, 85, 86, 87, 88, 91, 93, 94, 97, 99, 107, 110, 115, 116, 124, 125, 126, 128, 132, 138, 150, 151, 158, 161, 163, 167], "predict_quantil": [82, 88], "predicted_label": [74, 81], "predicti": 49, "predictions_arrai": [74, 81], "predictor": [39, 69, 70, 90, 93, 106, 107, 114, 115, 138], "predispos": 68, "predominantli": 139, "preexec_fn": 131, "prefer": [3, 4, 39, 48, 58, 68, 70, 71, 76, 97, 140, 156], "preferenti": 58, "prejudic": 68, "preliminari": 36, "premis": [0, 7], "prepar": [30, 58, 74, 76, 131, 138, 142], "prepend": 93, "preprint": 99, "preprocess": [74, 78, 86, 98, 128], "prescrib": 38, "prescript": 155, "presenc": [8, 27, 43, 68], "present": [0, 8, 16, 27, 30, 39, 48, 53, 54, 58, 63, 67, 69, 70, 72, 78, 86, 97, 99, 106, 108, 112, 128, 131, 138, 139, 140, 161, 166], "preserv": [49, 56, 153], "presid": 30, "presidenti": 30, "press": [1, 9, 11, 61, 69, 139], "pressur": 4, "presum": [53, 76], "presumpt": 53, "pretti": [38, 67, 78, 138, 142, 166], "prettypleas": [135, 161, 166], "preval": 93, "prevent": [68, 69, 74, 76, 77, 82, 131, 158], "preview": 139, "previou": [9, 16, 28, 35, 39, 42, 43, 44, 45, 46, 48, 49, 61, 65, 72, 73, 76, 80, 82, 97, 100, 107, 111, 116, 122, 129, 132, 139, 148, 149, 150, 152, 156, 157, 159, 161, 165, 167], "previous": [7, 18, 53, 54, 76, 77, 82, 88], "prf": 0, "price": 77, "primari": [93, 99], "primarili": [72, 78], "prime": [45, 82, 88], "primer": [1, 48], "primit": 30, "princeton": 1, "princip": [41, 52, 58, 94, 129], "principl": [1, 7, 8, 18, 25, 33, 39, 43, 44, 45, 48, 49, 52, 53, 58, 62, 64, 66, 67, 72, 78, 85, 93, 102, 109, 122, 129, 130, 138, 152, 157], "print": [1, 5, 6, 9, 22, 35, 38, 39, 42, 43, 44, 45, 46, 47, 54, 55, 70, 74, 75, 76, 78, 79, 81, 82, 83, 86, 87, 88, 98, 100, 101, 107, 128, 131, 132, 134, 135, 138, 139, 140, 141, 143, 148, 149, 150, 152, 154, 155, 156, 157, 158, 166, 167], "print_frequentist_estim": [9, 35], "print_funct": 81, "print_likely_fair_prior_measur": [9, 35], "print_likely_unfair_prior_measur": [9, 35], "print_uniform_prior_measur": [9, 35], "printopt": [45, 46, 83, 87, 101], "prior": [0, 2, 3, 7, 8, 9, 10, 11, 15, 16, 18, 20, 21, 24, 28, 30, 34, 35, 41, 42, 43, 46, 47, 49, 51, 52, 53, 56, 57, 60, 63, 64, 65, 69, 77, 78, 79, 82, 83, 87, 88, 90, 91, 92, 98, 99, 100, 101, 122, 124, 125, 126, 131, 147, 148, 156, 163], "prior_func": 128, "prior_rang": 100, "priori": [52, 53, 58, 65, 91, 156], "priorit": [124, 126], "prioriti": [65, 69], "priors_text": 9, "priors_text_w": 9, "priorsamplesslop": 3, "privaci": 68, "privat": [68, 72, 133], "privileg": [27, 142], "prize": 72, "prng": 135, "pro": 68, "prob": [0, 8, 16, 22, 27, 28, 30, 36, 37, 43, 46, 51, 55, 70, 74, 93, 128, 135, 148, 149, 157, 161], "prob_": 161, "prob_head": 9, "prob_heads_w": 9, "probab": 39, "probabilist": [16, 27, 51, 60, 63, 64, 65, 67, 69, 85, 93, 94, 98, 157, 158], "probabilit": [135, 161], "probabilitii": 31, "probabilit\u00e9": 39, "probabl": [0, 1, 5, 7, 9, 10, 11, 12, 16, 17, 18, 19, 23, 24, 25, 26, 29, 32, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 53, 54, 55, 56, 58, 60, 61, 63, 64, 65, 67, 69, 70, 72, 74, 77, 79, 83, 84, 87, 90, 91, 94, 95, 100, 101, 102, 106, 110, 115, 122, 125, 128, 129, 131, 148, 150, 152, 153, 156, 157, 158, 159, 161, 163, 167, 168], "problem": [4, 7, 8, 9, 11, 15, 16, 30, 33, 36, 39, 41, 43, 44, 45, 49, 50, 52, 53, 54, 56, 58, 61, 66, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 84, 90, 93, 95, 96, 97, 98, 99, 100, 102, 104, 105, 106, 109, 115, 118, 122, 127, 128, 131, 135, 139, 142, 147, 148, 151, 152, 153, 154, 156, 159, 161, 164], "problemat": [44, 48, 53, 72, 122, 152, 157, 158, 159], "proc": 56, "proce": [24, 32, 39, 51, 58, 71, 107, 139], "procedur": [7, 8, 15, 18, 43, 46, 49, 51, 52, 66, 68, 70, 71, 83, 87, 91, 102, 135, 139, 149, 158, 159], "proceed": 161, "process": [1, 8, 9, 16, 17, 30, 35, 39, 48, 49, 50, 51, 52, 53, 64, 65, 67, 68, 69, 70, 71, 72, 74, 76, 78, 81, 84, 92, 94, 97, 98, 102, 105, 106, 107, 111, 115, 116, 122, 123, 124, 125, 128, 135, 141, 158, 165], "process_group": 131, "process_new_macros_for_config_fil": 0, "prod": [152, 157], "prod_": [4, 24, 39, 42, 43, 44, 45, 46, 53, 54, 93, 148, 152, 157], "prod_i": 77, "produc": [0, 5, 9, 11, 24, 30, 39, 43, 48, 49, 53, 56, 65, 68, 72, 93, 107, 118, 132, 135, 138, 139, 141, 149, 159, 161, 166], "product": [7, 8, 13, 15, 16, 18, 24, 28, 36, 38, 39, 40, 44, 46, 48, 49, 50, 52, 54, 57, 58, 70, 73, 80, 82, 88, 93, 105, 122, 128, 135, 142, 152, 157, 158, 159, 161], "production_step1": 78, "production_step2": 78, "prof": 100, "profici": 139, "program": [39, 67, 68, 69, 70, 72, 77, 94, 98, 110, 138, 139, 140, 141, 142, 157, 159], "programdata": 142, "programm": 69, "progress": [8, 55, 69, 73, 76, 128, 142, 157], "progress_callback": 131, "progressbar": 78, "prohibit": [127, 129], "project": [1, 42, 50, 52, 54, 68, 70, 132, 135, 139, 151, 158, 159, 168], "project_root_dir": 138, "promin": [72, 122, 133], "promis": [78, 102], "promot": [48, 139, 158], "prompt": [139, 142], "prone": [118, 140], "pronounc": [78, 98, 133], "proof": [3, 27, 36, 37, 38, 39, 67, 71, 72, 105, 149, 161], "propag": [0, 1, 3, 7, 33, 48, 69, 75, 76, 80, 90, 93, 122, 154], "proper": [20, 48, 52, 69, 76, 110, 115, 130, 139], "properli": [4, 19, 48, 68, 76, 77, 93, 101, 135, 149, 152, 156, 157], "properti": [4, 18, 20, 22, 30, 43, 49, 52, 53, 55, 58, 71, 72, 78, 80, 82, 83, 84, 85, 87, 88, 90, 102, 125, 132, 135, 149, 155, 158, 161, 166], "proport": [4, 20, 30, 34, 39, 44, 45, 71, 77, 98, 132, 138, 148, 151, 152, 153, 157, 159, 166], "proportion": [39, 48, 58, 68, 168], "propos": [8, 30, 43, 49, 56, 97, 101, 112, 122, 148, 149, 150, 151, 153, 158, 159, 161, 166, 167], "proposal_posit": 149, "proposal_width": [149, 164], "propose_loc": 97, "proposed_posit": 149, "proposit": [8, 30, 35, 67, 115], "propsal": [149, 158], "propto": [3, 4, 13, 15, 18, 20, 21, 30, 39, 41, 44, 45, 46, 49, 53, 56, 77, 90, 101, 151, 152, 153, 156, 157, 158, 161, 163, 164, 168], "protect": 142, "protocol": [52, 58, 66], "proton": [39, 84, 104, 138, 159], "prototyp": [16, 69, 82, 84, 96, 101, 163], "prove": [24, 38, 42, 58, 130, 132, 161], "proven": [12, 72, 116, 158], "provid": [3, 4, 7, 8, 9, 18, 27, 29, 30, 33, 35, 39, 48, 49, 51, 52, 53, 56, 58, 63, 65, 67, 68, 69, 70, 71, 72, 73, 74, 76, 80, 82, 88, 91, 94, 96, 105, 115, 118, 124, 137, 138, 140, 141, 151, 152, 156, 157, 158, 161, 166], "provis": 66, "provoc": 16, "proxi": [9, 35, 77, 137], "psd": [82, 88], "pseudo": [97, 105, 111, 164], "pseudoconverg": 49, "psi": [0, 22, 28, 50, 52, 148], "psi_": [50, 148], "psi_1": 50, "psi_2": 50, "psi_chain": 148, "psi_i": [50, 52], "psi_j": [50, 52], "psi_mean": 148, "psi_mean_al": 148, "psi_n": 50, "psub": 39, "psutil": 128, "psychologi": 69, "pt": 131, "pt_sampler_t0": 101, "ptemce": [55, 56, 95], "ptemse": 55, "ptmcmc": [55, 101], "ptsampler": 101, "public": [1, 68, 69], "publica": 68, "publicli": [49, 61], "publish": [1, 15, 49, 58, 96, 115, 138], "puk94": [1, 51], "pukelheim": 51, "pukelsheim": 1, "pull": [53, 56], "pulldown": [9, 139], "punish": 69, "pure": [16, 49, 53, 58, 66, 67, 152, 157, 158], "purport": 53, "purpos": [20, 49, 53, 54, 55, 71, 72, 76, 100, 116, 151, 161], "push": 156, "put": [0, 8, 24, 25, 28, 29, 32, 36, 37, 39, 44, 45, 52, 57, 58, 61, 71, 77, 90, 138, 139, 140, 141, 148, 152, 157, 164], "px": 5, "py": [0, 42, 43, 55, 86, 101, 128, 131, 138, 156, 157], "pylab": 138, "pymc": [69, 78, 98, 148, 151, 153, 165, 168], "pymc3": [98, 156], "pymc_docs_getting_started_upd": 163, "pymc_nam": 157, "pymcinference_library_vers": 156, "pypi": 48, "pyplot": [0, 3, 5, 6, 9, 20, 21, 22, 30, 34, 35, 38, 39, 42, 43, 44, 45, 46, 47, 54, 55, 70, 74, 75, 76, 78, 81, 82, 83, 85, 86, 87, 88, 93, 97, 98, 100, 101, 107, 128, 131, 132, 134, 135, 137, 138, 139, 140, 148, 149, 150, 152, 154, 155, 156, 157, 158, 161, 166, 167], "pytensor": 76, "python": [0, 1, 5, 11, 24, 28, 31, 39, 44, 45, 48, 57, 61, 71, 74, 77, 78, 83, 90, 98, 99, 101, 107, 110, 111, 130, 135, 136, 138, 141, 142, 144, 145, 152, 157, 158, 161, 163, 166, 168], "python3": [0, 55, 86, 101, 131, 142, 145, 157], "pytorch": [69, 134], "pytorch_thread": 128, "p\u00f3lya": 66, "q": [3, 4, 24, 41, 49, 51, 77, 83, 87, 90, 130, 149, 153, 154, 159, 161], "q_": 90, "q_0": 154, "q_i": [49, 153], "qbism": 129, "qcd": 49, "qfrsaikz4ric": 1, "qft": 122, "qmn15": [1, 50], "qoi": 53, "qquad": [4, 20, 41, 56, 57, 71, 83, 125, 126, 128, 135, 153, 155, 164], "quad": [0, 3, 4, 5, 11, 13, 15, 20, 21, 22, 24, 28, 29, 38, 39, 41, 42, 47, 51, 52, 58, 71, 90, 91, 128, 130, 135, 148, 150, 153, 158, 161, 163, 167], "quadrat": [24, 39, 43, 58, 77, 82, 83, 86, 87, 88, 90, 105, 117, 120, 128], "quadratur": [56, 159], "qualifi": [68, 69], "qualit": [7, 67, 124, 135, 151], "qualiti": [39, 58, 65, 68, 77, 107], "quanta": 133, "quantif": [8, 50, 51, 52, 67, 90, 102, 127], "quantifi": [7, 8, 16, 18, 27, 48, 51, 58, 65, 67, 70, 93, 100, 116, 118, 122, 124, 125, 135, 149], "quantil": [22, 43, 46, 48, 55, 82, 88, 99, 101, 128, 135, 148, 152, 157], "quantit": [7, 8, 16, 51, 63, 67, 76, 115, 124], "quantiti": [4, 16, 18, 19, 22, 27, 28, 30, 36, 39, 46, 49, 50, 51, 52, 53, 56, 58, 69, 71, 72, 73, 77, 93, 99, 100, 106, 112, 114, 122, 124, 126, 129, 131, 135, 138, 148, 149, 158], "quantum": [1, 16, 27, 28, 50, 52, 69, 72, 109, 122, 129, 161, 166], "quarteroni": 1, "que": 39, "queri": 139, "question": [7, 8, 11, 18, 22, 30, 31, 32, 38, 44, 47, 54, 55, 57, 58, 61, 65, 66, 71, 73, 76, 78, 97, 98, 132, 141, 147, 148, 152, 157, 161, 164, 166, 167], "questionnair": 68, "quick": [132, 139, 140, 151], "quickli": [45, 52, 71, 78, 80, 141], "quickstart": 74, "quiet": 72, "quirki": 43, "quit": [39, 43, 72, 73, 78, 98, 100, 140, 149], "quod": 58, "quot": [16, 24, 44, 56, 71, 100, 109, 139, 157], "r": [0, 1, 3, 5, 6, 9, 11, 13, 15, 16, 20, 21, 22, 24, 34, 38, 39, 42, 43, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 70, 71, 72, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 98, 101, 105, 107, 109, 112, 118, 120, 125, 128, 131, 132, 134, 135, 137, 138, 139, 140, 141, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 164, 166, 167, 168], "r2": [43, 71, 83], "r2_score": 138, "r_": [90, 155], "r_0": 155, "r_dot": 155, "r_dot_0": 155, "r_dot_half": 155, "r_dot_pt": 155, "r_dot_pts_eul": 155, "r_dot_pts_lf": 155, "r_hat": [156, 157], "r_i": [43, 100, 155], "r_list": 140, "r_pt": 155, "r_pts_euler": 155, "r_pts_lf": 155, "r_sq": 43, "race": 68, "racial": 68, "radford": [49, 153], "radfriend": 159, "radial": [85, 90, 126], "radii": 52, "radio": 58, "radioact": [42, 159], "radioactive_lighthouse_exercis": 147, "radioactive_lighthouse_exercise_kei": 41, "radiu": [51, 52, 54, 120, 138, 155, 159], "rai": [47, 147], "rain": [0, 8, 16, 22, 27, 28, 135, 161], "raini": 16, "raio": 18, "rais": [38, 55, 101, 128, 131, 134, 141], "rajesh": 1, "ran_uniform_arrai": 38, "rand": [6, 22, 30, 45, 55, 76, 82, 83, 87, 88, 101, 128, 132, 141, 148, 149, 151, 152, 154, 157], "randint": [38, 141], "randn": [22, 45, 46, 78, 97, 98, 132, 138, 148, 156], "random": [3, 6, 9, 16, 18, 22, 24, 28, 29, 30, 31, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 55, 56, 58, 65, 68, 70, 71, 72, 75, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 97, 98, 99, 100, 101, 102, 107, 110, 111, 115, 122, 125, 126, 128, 132, 134, 138, 141, 147, 148, 150, 151, 152, 153, 154, 156, 157, 158, 165, 167], "random_st": [34, 75, 78, 79, 86, 98, 135, 161, 166], "randomcovariancematrix": 87, "randomli": [16, 37, 41, 45, 47, 49, 52, 54, 55, 70, 74, 76, 147, 148, 149, 153, 159], "randomst": [45, 85, 86, 148], "randomwalk": 166, "rang": [3, 5, 6, 18, 22, 30, 34, 35, 38, 39, 41, 42, 43, 46, 47, 48, 51, 52, 54, 55, 56, 63, 69, 70, 71, 74, 76, 81, 82, 83, 84, 87, 88, 90, 91, 93, 96, 100, 101, 107, 111, 122, 125, 127, 128, 131, 134, 135, 137, 139, 148, 149, 150, 152, 157, 158, 159, 161, 166, 167], "ranganath": [1, 77], "ranganathan": 91, "rangl": [4, 24, 42, 47, 50, 90, 151, 158, 164], "rangle_": 56, "rank": [39, 60, 105, 130, 132], "rapidli": [38, 69, 84, 142, 159], "rare": [38, 39, 68, 107, 124, 156], "rasmu": 131, "rasmussen": [1, 90, 91], "rasumu": 131, "rate": [1, 36, 42, 49, 52, 68, 71, 72, 73, 74, 75, 76, 93, 102, 110, 111, 112, 134, 149, 151, 153, 164, 166, 168], "rather": [4, 8, 27, 28, 30, 39, 42, 43, 44, 46, 48, 49, 51, 52, 57, 58, 60, 61, 63, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 93, 100, 111, 117, 124, 132, 138, 139, 140, 148, 152, 156, 157, 164], "ratio": [5, 7, 8, 20, 49, 55, 56, 57, 58, 83, 87, 90, 91, 101, 120, 122, 130, 135, 150, 156, 158, 159, 161, 167], "ratio_max": [83, 87], "ratio_min": [83, 87], "ration": [7, 8, 67], "rational": 66, "rationalquadrat": 86, "ravel": [42, 45, 46, 75, 85, 128], "ravin": 110, "raw": [80, 132], "razor": 58, "rbf": [82, 84, 85, 86, 88, 90, 97, 126, 128], "rbf_kernel": 128, "rbf_lengthscal": 87, "rbf_term": 128, "rbf_varianc": 87, "rbfco": 82, "rbfkernel": 87, "rbm": [52, 127], "rbrace": 53, "rc_context": 131, "rcparam": [5, 9, 42, 131, 137, 138, 154, 155], "rct1": 138, "rct2": 138, "rdbu": 75, "rdbu_r": 70, "rdot": 155, "rdylbu_r": 70, "re": [1, 3, 5, 8, 13, 16, 24, 27, 43, 45, 46, 47, 56, 68, 74, 76, 77, 83, 97, 100, 101, 139, 147, 148, 149, 151, 156, 164], "reach": [8, 16, 48, 49, 67, 68, 71, 72, 73, 93, 102, 110, 148, 156, 158, 161], "react": [30, 138], "reaction": 52, "read": [0, 11, 28, 37, 41, 64, 69, 72, 73, 77, 80, 91, 99, 100, 132, 139, 140, 141, 142, 143, 163], "read_fwf": 138, "readabl": 157, "reader": [48, 51, 64, 66, 84], "readi": [47, 66, 73, 74, 138], "readili": 46, "readm": 48, "readout": 137, "readout_format": 137, "readthedoc": [46, 157, 168], "real": [0, 7, 8, 9, 16, 28, 45, 52, 68, 72, 77, 78, 82, 87, 88, 93, 103, 109, 115, 130, 141, 151, 166], "realis": 161, "realist": [16, 39, 105, 107, 158, 159, 161], "realiti": [8, 39, 53, 66, 67, 106, 107, 115, 128, 133, 135], "realiz": [4, 8, 18, 19, 21, 27, 39, 46, 58, 70, 71, 72, 91, 105, 164, 166], "realli": [7, 13, 22, 23, 28, 36, 43, 44, 45, 47, 49, 72, 78, 90, 98, 101, 120, 122, 149, 152, 157, 158, 164], "realm": 67, "rearrang": [28, 36, 37], "reason": [0, 1, 8, 11, 16, 18, 24, 27, 30, 39, 45, 48, 58, 63, 66, 68, 76, 82, 84, 91, 101, 105, 106, 111, 135, 141, 149, 151, 152, 157, 158, 159], "recal": [4, 9, 35, 36, 39, 43, 49, 53, 54, 57, 58, 68, 73, 87, 90, 93, 97, 130, 132, 148, 153], "recalcul": 147, "recalculate_data": 9, "recalculate_data_w": 9, "recapitul": 161, "recast": [56, 109], "receiv": [72, 87], "recent": [53, 54, 55, 68, 71, 74, 75, 76, 78, 98, 101, 109, 131], "recept": 72, "recess": 135, "recession": [18, 46], "recip": [16, 39, 74, 93, 100, 164], "recogn": [26, 44, 48, 51, 52, 58, 65, 67, 124, 132, 151, 152, 157], "recognis": [4, 93], "recognit": [58, 66, 68, 69, 72, 78, 80], "recommend": [43, 45, 46, 48, 61, 68, 69, 76, 80, 112, 135, 138, 139, 144, 147, 149, 156, 157], "reconstrain": [82, 88], "reconstuct": 5, "record": [4, 5, 8, 42, 47, 55, 58, 98, 101, 126, 128, 147, 150, 166, 167], "recov": [39, 126], "recreat": [49, 71, 132], "rectangl": 154, "rectifi": [72, 76, 80], "recurr": [73, 78, 141, 149, 158, 161], "recurs": 67, "red": [5, 9, 22, 28, 35, 38, 39, 42, 43, 44, 47, 54, 70, 74, 77, 80, 81, 82, 83, 86, 93, 98, 100, 107, 126, 128, 131, 132, 135, 139, 149, 150, 151, 152, 153, 155, 157, 159, 164, 166, 167, 168], "redefin": 97, "redirect": [78, 98], "redo": 46, "redrawn": 137, "redshift": 18, "reduc": [1, 27, 34, 39, 43, 44, 48, 49, 51, 52, 58, 65, 68, 71, 77, 80, 84, 93, 102, 107, 111, 112, 122, 124, 127, 130, 132, 148, 151, 155], "reduct": [1, 49, 51, 52, 71, 129, 130, 148, 156], "redund": 130, "ref": [0, 47, 49, 50, 51, 52, 53, 168], "refactor": 131, "refer": [1, 2, 8, 16, 18, 22, 32, 39, 46, 48, 50, 51, 53, 57, 58, 61, 68, 71, 72, 77, 80, 81, 83, 86, 91, 93, 105, 107, 115, 116, 122, 123, 125, 127, 130, 135, 139, 156, 158, 168], "refin": [5, 8, 51, 64, 72], "refit": 75, "reflect": [8, 30, 48, 51, 58, 68, 69, 126, 132, 138, 152, 157, 158, 161], "reformat": 74, "refresh": [61, 136], "regain": 39, "regard": [4, 8, 9, 30, 51, 56, 61, 63], "regardless": [8, 24, 82, 88, 158, 161], "regener": 9, "regenerate_data": 9, "regim": [53, 124], "region": [22, 24, 46, 49, 51, 53, 55, 56, 57, 58, 70, 71, 72, 77, 78, 80, 82, 83, 85, 87, 88, 98, 99, 100, 151, 153, 154, 158, 159, 164], "regist": [48, 142], "registri": 48, "regress": [1, 16, 32, 33, 43, 50, 52, 60, 68, 72, 73, 76, 77, 78, 84, 91, 92, 94, 98, 100, 102, 104, 108, 109, 110, 117, 121, 138, 163], "regressor": [70, 87, 93], "regular": [65, 72, 75, 77, 78, 79, 82, 85, 88, 98, 156], "regularli": [76, 100], "reifi": 53, "reilli": 1, "reinforc": [37, 69], "reject": [4, 11, 24, 51, 58, 149, 150, 151, 153, 158, 159, 164, 167, 168], "rel": [8, 16, 36, 43, 48, 51, 52, 53, 54, 56, 58, 70, 93, 99, 101, 102, 120, 132, 139, 149, 158], "relat": [4, 15, 19, 20, 22, 24, 28, 30, 39, 43, 45, 46, 47, 48, 51, 53, 58, 64, 66, 68, 69, 71, 72, 76, 82, 88, 94, 99, 101, 104, 115, 116, 119, 120, 132, 133, 158], "relationship": [18, 19, 39, 51, 58, 64, 67, 69, 91, 115, 116, 122, 151], "relax": [52, 99], "releas": [48, 55, 61, 101], "relerr": [154, 155], "relev": [7, 9, 16, 18, 30, 39, 43, 52, 58, 66, 68, 70, 71, 72, 77, 90, 93, 99, 100, 101, 105, 107, 115, 116, 135, 139, 142, 147, 151, 161, 166, 168], "reli": [27, 30, 51, 56, 58, 69, 76, 78, 98, 115, 141], "reliabl": [41, 43, 52, 56, 93, 101, 116, 124, 127, 140], "relu": [72, 74, 75, 76, 80, 81, 122, 134], "remain": [4, 16, 49, 52, 54, 58, 61, 71, 72, 126, 156, 158], "remaind": [30, 110], "remark": [25, 30, 48, 49, 52, 72, 126, 138, 151, 158, 166], "remedi": 8, "rememb": [4, 22, 27, 39, 51, 54, 70, 71, 79, 97, 130, 140, 141, 156, 159, 161, 166], "remind": 71, "remov": [42, 43, 51, 66, 68, 75, 83, 100, 130, 132, 149, 158], "ren": 1, "renaiss": 78, "renam": [139, 156], "render": [49, 50, 75, 139], "renewcommand": 0, "renorm": [12, 122], "reoffend": 68, "reorder": 93, "reorgan": 138, "rep": [1, 48], "reparameter": 156, "repeat": [34, 38, 39, 44, 46, 47, 48, 51, 55, 58, 71, 72, 82, 83, 85, 87, 95, 97, 99, 100, 101, 122, 127, 131, 132, 135, 140, 148, 150, 152, 156, 157, 158, 159, 164, 167], "repeatadli": 78, "repeatedli": [11, 15, 44, 49, 64, 152, 157], "repercuss": 68, "repetit": 135, "rephras": 18, "replac": [16, 20, 30, 49, 50, 51, 56, 57, 68, 73, 76, 77, 82, 85, 88, 90, 100, 127, 138, 147, 158], "repli": 133, "replic": 48, "replica": 56, "replot": 22, "report": [8, 48, 52, 58, 139, 152, 157], "repositori": [45, 48, 61, 69, 136, 142, 144, 145], "repres": [3, 4, 8, 9, 16, 18, 26, 27, 28, 30, 43, 44, 46, 49, 51, 53, 54, 56, 58, 64, 65, 68, 69, 70, 71, 72, 73, 76, 80, 81, 93, 99, 100, 101, 110, 122, 124, 125, 128, 132, 135, 140, 141, 148, 149, 151, 152, 157, 158, 159, 161], "represent": [1, 4, 7, 24, 41, 52, 53, 71, 74, 75, 78, 80, 90, 115, 130, 140, 151, 158], "reproduc": [4, 13, 30, 35, 39, 49, 54, 58, 66, 68, 69, 70, 71, 73, 77, 96, 99, 101, 107, 118, 128, 132, 135, 138, 149, 159, 161, 166], "reproduct": [38, 39, 66, 71, 166], "repuls": 138, "request": [69, 82, 128, 161], "requir": [8, 19, 20, 24, 38, 39, 42, 43, 45, 48, 49, 50, 51, 52, 54, 56, 58, 64, 65, 67, 69, 72, 76, 78, 80, 81, 90, 95, 101, 102, 105, 110, 127, 128, 129, 135, 138, 141, 142, 145, 147, 153, 158, 161, 164, 166], "requires_grad": 76, "rerun": [42, 75], "resampl": [1, 51, 71, 128, 153], "rescal": [49, 75, 128], "research": [0, 1, 8, 24, 33, 39, 53, 62, 64, 65, 66, 69, 77, 78, 109, 122, 124], "resembl": [53, 149], "reserv": [39, 73], "reset": [6, 9, 43, 55, 76, 101, 128, 148, 152, 157], "reset_button_w": 9, "reset_n": 9, "reshap": [3, 6, 22, 30, 35, 39, 43, 46, 55, 75, 78, 81, 82, 85, 86, 87, 88, 97, 98, 101, 107, 128, 132, 138, 148, 151, 152, 157], "resid": [50, 51, 141], "residenti": 16, "residu": [5, 34, 39, 43, 52, 56, 100, 101, 105, 106, 110], "residual_": [39, 105], "residual_1": [39, 105], "residual_2": [39, 105], "residual_3": [39, 105], "residual_i": 39, "resist": 126, "resiz": [131, 141], "resolut": 154, "resolv": [51, 53], "reson": 52, "resort": 39, "resourc": [42, 48, 51, 139, 141], "respect": [4, 5, 8, 16, 20, 21, 29, 30, 39, 43, 48, 49, 50, 51, 52, 53, 58, 68, 69, 70, 71, 72, 73, 76, 77, 80, 90, 93, 102, 105, 111, 112, 122, 135, 138, 141, 149, 161], "respond": [8, 72], "respons": [39, 61, 68, 69, 70, 72, 76, 82, 90, 93, 107, 114, 115, 118, 133, 135, 139], "rest": [8, 51, 71, 78, 83, 87, 99, 100, 116, 119, 159], "restart": [97, 139, 142], "restore_sign": 131, "restraint": 66, "restrict": [48, 51, 52, 57, 58, 63, 72, 87, 109, 110, 139, 151, 166], "restructur": 141, "result": [3, 4, 6, 8, 9, 11, 13, 15, 16, 18, 20, 21, 24, 28, 30, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 49, 52, 53, 55, 56, 57, 58, 60, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 77, 80, 82, 83, 87, 88, 90, 93, 95, 96, 97, 98, 99, 100, 101, 105, 106, 107, 126, 128, 131, 132, 134, 135, 138, 139, 141, 147, 148, 150, 151, 152, 157, 161, 163, 164, 166, 167], "retain": [132, 140], "retriev": [74, 78], "return": [0, 4, 5, 6, 8, 9, 20, 21, 22, 30, 34, 35, 38, 39, 41, 42, 43, 45, 46, 47, 51, 54, 55, 57, 70, 74, 75, 76, 77, 78, 79, 82, 83, 87, 90, 91, 93, 97, 98, 99, 100, 101, 102, 105, 107, 111, 128, 131, 132, 134, 135, 137, 138, 139, 140, 141, 143, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 161, 164, 166, 167], "return_cov": 87, "return_inferencedata": [156, 157], "return_std": [85, 86], "reusabl": 48, "rev": [1, 83, 87, 91], "reveal": [50, 58, 68, 122, 143, 161], "revers": [27, 28, 30, 49, 77, 142, 153, 155, 166], "reversibil": 49, "reversiblemarkovprocessexampl": 161, "reversiblemarkovprocessexample_cprob_fig": 161, "reversiblemarkovprocessexample_runs_fig": 161, "review": [25, 29, 39, 41, 46, 50, 54, 68], "revis": [5, 16, 43, 55, 61, 63, 66, 82, 83, 142, 148, 154, 156], "revisit": [30, 55, 64, 71], "revolut": 56, "revolv": 115, "reward": 69, "reweight": 159, "reword": 36, "rewrit": [30, 71, 72, 73, 77, 90, 93, 148], "rewritten": [71, 161], "rf": [22, 38, 42, 45, 47, 70, 83, 87, 131, 140, 148, 150, 154, 155, 166, 167], "rg": 122, "rhat": [148, 156], "rho": [49, 77, 83, 84, 91, 135, 149, 164], "rho_": [29, 57, 87, 135], "rich": [52, 69], "richard": [1, 49, 153, 158, 159], "richardson": 1, "ridg": [1, 93], "riemann": 151, "right": [0, 3, 4, 9, 13, 15, 16, 18, 19, 20, 21, 22, 24, 27, 28, 29, 30, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 49, 52, 53, 54, 56, 57, 58, 61, 68, 69, 70, 71, 72, 73, 74, 77, 78, 81, 83, 87, 90, 93, 97, 99, 100, 101, 102, 105, 108, 110, 111, 112, 119, 122, 125, 126, 130, 131, 132, 135, 139, 142, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 161, 164, 166, 167], "rightarrow": [0, 3, 4, 7, 13, 15, 21, 24, 27, 28, 38, 39, 41, 42, 49, 53, 72, 77, 90, 91, 107, 151, 153, 159, 163], "rightli": [8, 58], "rightmost": 61, "rigidli": 61, "rigor": [48, 63, 64, 67, 69, 118, 131, 149], "rigour": 115, "ring": 56, "rise": [8, 39, 58, 132], "risk": [8, 48, 49, 51, 64, 68, 71], "ritz": 52, "rivalri": 50, "rjf": 127, "rk23": 155, "rlhick": 156, "rm": [9, 11, 16, 24, 34, 38, 42, 47, 49, 53, 54, 68, 71, 72, 76, 83, 84, 91, 99, 100, 125, 126, 135, 137, 155], "rmsprop": [72, 76], "rng": [35, 39, 85, 86, 107, 135], "rnn": 72, "roam": 164, "rob": 148, "rob21": [1, 122], "robert": [1, 122, 133, 149, 166], "roberto": 1, "robust": [1, 43, 48, 66, 68, 113, 126, 128, 156, 157, 168], "role": [48, 53, 58, 61, 69, 71, 72, 87, 91, 132, 135, 139], "roll": [4, 28, 70, 148], "rom": 52, "ron": 1, "ronald": 1, "rongzheng": 1, "rook": 84, "room": 139, "root": [29, 46, 61, 68, 69, 71, 76, 115, 135, 139, 141], "root_mean": 70, "rot": 138, "rotat": [51, 56, 132, 151], "rough": [23, 51], "roughli": [34, 38, 39, 44, 49, 56, 58, 68, 76, 130, 135, 149, 157], "round": [4, 128, 132, 138, 141], "routin": [55, 157], "row": [1, 30, 35, 37, 47, 72, 74, 83, 128, 132, 138, 139, 140, 149, 158, 161, 164], "roweth": 1, "royal": 1, "royalblu": 70, "rrapaj": 1, "rseed": [45, 148], "rsq": 43, "rst": [78, 98], "rstride": [42, 70], "rtol": [154, 155], "rub88": [1, 49], "rubin": [1, 151], "ruder": 112, "ruin": 8, "rule": [0, 1, 7, 13, 15, 16, 18, 25, 28, 32, 34, 39, 40, 42, 46, 56, 57, 58, 63, 66, 67, 68, 70, 76, 93, 112, 135, 151, 158, 161, 164, 166], "ruler": [18, 46], "rumelhart": 1, "rumelharthintonwilliams86": [1, 73], "run": [8, 9, 35, 39, 42, 43, 47, 48, 49, 51, 54, 55, 56, 61, 75, 76, 78, 81, 84, 88, 91, 98, 100, 101, 107, 111, 122, 128, 130, 131, 134, 135, 136, 138, 139, 140, 143, 148, 150, 155, 156, 157, 159, 161, 163, 164, 166, 167], "run_mcmc": [6, 43, 46, 55, 101, 128, 148, 152, 157], "run_model": 134, "rung": [153, 155], "runner": 82, "runtimeerror": 131, "runtimewarn": 43, "ruth": 1, "rutherford": 135, "rv": [9, 22, 34, 38, 42, 44, 47, 54, 70, 83, 87, 91, 131, 135, 149, 150, 152, 156, 157, 158, 167], "rvec": 56, "rvec_": 56, "rvec_i": 56, "rvert": [109, 125], "rw05": [1, 90], "rwidth": [150, 167], "ryh22": [1, 122], "r\u00e9duit": 39, "r\u00e9sum\u00e9": 68, "s1": 42, "s12918": 1, "s2": 42, "s41567": 1, "s43586": 1, "s_": 130, "s_eleph": 109, "s_i": 132, "s_j": [49, 132, 148, 156], "s_k": [130, 132], "s_n": 166, "s_shape": 132, "sa": 48, "saddl": [44, 58, 110, 152, 157], "safe": [55, 101], "safeti": [0, 68, 69], "sai": [0, 3, 4, 7, 8, 13, 16, 18, 22, 24, 27, 28, 30, 35, 36, 37, 39, 42, 43, 44, 45, 47, 48, 49, 53, 54, 58, 61, 63, 67, 71, 73, 80, 91, 93, 100, 132, 139, 141, 142, 148, 149, 151, 152, 157, 161, 164], "said": [16, 63, 70, 161], "sake": [53, 93, 138], "salutari": 20, "sam": [138, 141], "same": [0, 4, 5, 8, 9, 10, 12, 13, 15, 16, 18, 19, 21, 22, 23, 24, 27, 28, 30, 35, 36, 38, 39, 41, 42, 43, 44, 45, 47, 48, 49, 52, 53, 54, 57, 58, 60, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 82, 84, 87, 88, 91, 97, 98, 99, 100, 101, 110, 112, 122, 126, 128, 130, 131, 132, 134, 135, 138, 139, 140, 141, 147, 148, 149, 150, 151, 152, 155, 156, 157, 158, 159, 161, 164, 166, 167, 168], "samp_label": 131, "sampl": [0, 1, 3, 6, 7, 16, 24, 28, 34, 39, 42, 44, 45, 46, 47, 48, 50, 51, 52, 54, 56, 58, 64, 68, 71, 72, 74, 75, 77, 78, 84, 85, 86, 91, 93, 94, 97, 98, 99, 100, 101, 106, 107, 108, 122, 125, 126, 127, 129, 131, 132, 134, 135, 141, 147, 148, 152, 153, 163, 166, 168], "sample_i": 86, "sample_mean": 70, "sample_means_fixed_sample_s": 38, "sample_nod": [78, 98], "sample_posterior_predict": [78, 98], "sample_proba": [78, 98], "sample_s": 38, "sample_sort": 101, "sample_stat": 156, "sample_std": 70, "sampler": [1, 6, 18, 43, 46, 49, 56, 64, 78, 79, 98, 99, 148, 149, 151, 152, 153, 158, 159, 165], "sampler_object": 46, "samples_md": 128, "samples_md_poco": 128, "samples_save_dir": 128, "samples_spars": 6, "samples_unflatten": [55, 148], "samples_wmd": 128, "samples_wmd_poco": 128, "samplescor": [83, 87], "samplesuncor": [83, 87], "samplig": 159, "sampling_tim": 156, "samwis": 138, "sandbox": 91, "saniti": 141, "santayana": 51, "sarah": [1, 61], "satisfi": [3, 4, 20, 34, 36, 51, 56, 58, 100, 135, 153, 161, 164], "satur": [54, 57, 95, 101], "save": [6, 7, 24, 47, 49, 71, 74, 101, 128, 131, 138, 141, 143, 147, 152, 157], "save_fig": 138, "save_model": 74, "savefig": [6, 78, 131, 138, 139, 154, 155], "savefig_kwarg": 131, "saw": [54, 87], "sbn": 148, "scalabl": 78, "scalar": [49, 52, 55, 70, 76, 90, 91, 101, 130, 132, 134, 148, 151], "scale": [13, 22, 24, 38, 39, 42, 43, 45, 46, 47, 48, 49, 52, 55, 56, 70, 72, 74, 76, 77, 82, 83, 84, 85, 86, 87, 88, 91, 100, 101, 110, 118, 125, 128, 131, 132, 134, 135, 148, 150, 152, 156, 157, 158, 164, 167, 168], "scale_": 128, "scaled_sum": 34, "scaler": 128, "scan": 93, "scandinavian_entropi": 4, "scatter": [39, 43, 44, 46, 47, 50, 52, 70, 75, 76, 77, 78, 83, 85, 86, 87, 98, 107, 132, 138, 156, 157, 159], "scatter_joint_bnn_plot": 77, "scatterplot": 70, "scb": 135, "sccord": 135, "scenario": [4, 18, 19, 20, 48, 49, 53, 58, 69, 71, 72, 77, 126, 164, 166], "schack": 133, "sched_getaffin": 128, "schedul": [110, 112], "schemat": [52, 84, 122, 151, 164], "schematic_rbm": 52, "scheme": [51, 70, 121, 158], "school": [8, 27, 44, 58, 61, 68, 82, 88, 152, 157], "schoot": [1, 48], "schroding": [28, 52, 84], "schr\u00f6dinger": 50, "schwab": 1, "sch\u00f6n": 1, "sci": 1, "scienc": [0, 1, 8, 16, 48, 52, 53, 58, 61, 62, 63, 65, 66, 67, 68, 71, 72, 109, 122, 139, 150, 158, 167], "scientif": [7, 8, 15, 16, 30, 45, 48, 50, 51, 53, 58, 61, 63, 65, 66, 67, 69, 70, 72, 109, 115, 116, 124, 131, 133, 139, 142, 145, 166], "scientist": [1, 8, 58, 68, 69, 135], "scikit": [1, 69, 71, 86, 91, 98, 138, 141, 142], "scikitlearn": 138, "scipi": [0, 5, 6, 9, 13, 21, 24, 28, 34, 35, 38, 39, 42, 43, 44, 45, 46, 47, 54, 70, 74, 83, 87, 97, 100, 101, 128, 131, 132, 139, 141, 142, 148, 149, 150, 152, 154, 155, 156, 157, 158, 159, 167], "scope": [8, 116], "score": [72, 74, 75, 80, 138, 156], "scorn": 63, "scott": 141, "scratch": [49, 74], "screen": [36, 49, 61, 68, 154], "script": [0, 48, 134, 159, 161, 166], "scroll": [22, 135, 139], "sd": [150, 156, 157, 167], "se": [1, 16, 52, 63, 83, 87, 148, 151], "seaborn": [5, 9, 22, 38, 42, 43, 44, 45, 46, 47, 54, 55, 75, 78, 82, 83, 97, 98, 100, 101, 138, 140, 148, 149, 150, 152, 157], "seali": [0, 28], "search": [1, 51, 61, 72, 109, 110, 135, 139, 161, 166], "searchsort": [42, 45, 46], "sebastian": 112, "sec": [0, 46, 128], "second": [8, 16, 18, 20, 22, 24, 27, 28, 30, 36, 37, 39, 41, 43, 44, 46, 48, 49, 51, 53, 54, 57, 58, 69, 71, 72, 73, 74, 76, 77, 78, 90, 101, 107, 112, 115, 117, 130, 131, 135, 138, 139, 141, 149, 151, 152, 155, 156, 157, 161, 164], "secondari": 99, "secondli": 73, "section": [8, 9, 14, 28, 31, 35, 39, 41, 42, 47, 48, 53, 61, 63, 66, 70, 82, 86, 88, 91, 95, 96, 99, 101, 107, 117, 118, 123, 130, 137, 138, 142, 150, 160, 162, 167], "sector": [1, 69, 72], "sedol": 78, "see": [0, 3, 4, 5, 9, 11, 13, 15, 16, 18, 21, 24, 28, 30, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 61, 64, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 83, 84, 85, 87, 88, 90, 91, 93, 97, 98, 99, 100, 101, 102, 105, 109, 110, 117, 118, 121, 123, 126, 132, 135, 136, 138, 139, 141, 142, 144, 145, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 161, 164, 167], "seed": [6, 9, 22, 30, 35, 43, 44, 45, 70, 71, 75, 83, 87, 97, 98, 100, 101, 128, 135, 138, 148, 149, 152, 157, 161, 164, 166], "seek": [9, 10, 16, 24, 28, 35, 39, 49, 50, 52, 54, 56, 60, 61, 67, 72, 90, 102, 105, 109, 112, 126, 152, 153, 157, 158], "seem": [0, 5, 24, 27, 30, 36, 43, 44, 49, 53, 54, 58, 67, 78, 80, 82, 88, 152, 156, 157, 159, 161, 165], "seen": [8, 19, 39, 58, 67, 68, 73, 77, 80, 83, 87, 91, 93, 107, 132, 139, 149, 151, 153, 158, 159, 161, 164], "sekstromforssen22": [1, 49], "selct": 135, "seldomli": 8, "select": [1, 9, 16, 48, 52, 57, 59, 60, 61, 64, 69, 70, 71, 77, 82, 83, 85, 87, 88, 91, 94, 95, 96, 97, 101, 108, 134, 138, 139, 142, 154, 162, 166], "selection_mini": 95, "self": [9, 55, 64, 69, 76, 84, 101, 128, 131, 154, 155, 161, 166], "semi": [39, 82, 88, 97, 132], "semicolon": 143, "semidefinit": [87, 91], "semilogi": [100, 132, 154, 155], "semilogx": 167, "sen": 39, "send": 72, "sens": [4, 8, 16, 19, 30, 39, 41, 43, 45, 46, 52, 57, 64, 67, 68, 71, 78, 98, 101, 105, 106, 135, 148, 149, 151, 156, 161], "sensibl": [4, 30, 80], "sensit": [0, 5, 8, 41, 43, 45, 48, 49, 51, 52, 54, 56, 71, 99, 100, 102, 127], "sentenc": [68, 72], "sentiment": 68, "sep": 138, "separ": [8, 39, 48, 49, 52, 55, 56, 58, 68, 69, 70, 78, 82, 88, 91, 98, 101, 104, 139, 140, 147, 148, 151], "septemb": 1, "sequenc": [1, 15, 35, 49, 72, 77, 80, 93, 97, 131, 135, 141, 143, 148, 161, 164, 166], "sequenti": [15, 30, 35, 72, 74, 75, 76, 81, 126, 134, 139, 141], "seri": [1, 8, 16, 38, 39, 42, 43, 44, 54, 61, 69, 96, 99, 117, 138, 148, 152, 157, 159, 167], "serif": 138, "seriou": [8, 68, 69, 139], "serv": [49, 80, 91, 93, 125, 126, 128, 138, 163], "server": [61, 136], "servic": 69, "set": [0, 1, 3, 4, 5, 7, 8, 11, 15, 16, 20, 22, 24, 26, 27, 28, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 81, 83, 84, 85, 87, 90, 91, 93, 96, 97, 98, 99, 100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 115, 116, 120, 122, 125, 126, 131, 132, 134, 135, 136, 138, 139, 140, 142, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 161, 164, 165, 166, 167, 168], "set_alpha": 9, "set_aspect": [45, 55, 70, 83, 87, 132, 140, 154, 155], "set_axis_off": 132, "set_axisbelow": 45, "set_color": [74, 81], "set_context": [5, 9, 43, 44, 47, 75, 78, 82, 83, 97, 98, 148, 149, 152, 157], "set_data": 78, "set_limit": [83, 87], "set_printopt": 132, "set_size_inch": 22, "set_styl": [78, 83, 97, 148], "set_titl": [3, 6, 9, 22, 34, 38, 39, 42, 43, 45, 46, 47, 54, 55, 70, 82, 83, 86, 87, 88, 107, 131, 132, 134, 137, 139, 140, 148, 150, 154, 155, 166, 167], "set_tt_rng": [78, 98], "set_vis": 131, "set_xlabel": [0, 3, 5, 6, 9, 21, 22, 30, 35, 38, 39, 42, 44, 45, 46, 47, 54, 70, 75, 78, 83, 86, 87, 93, 98, 100, 101, 107, 131, 132, 134, 135, 137, 138, 139, 140, 148, 150, 154, 155, 157, 158, 166, 167], "set_xlim": [6, 34, 38, 42, 47, 54, 55, 75, 82, 83, 100, 101, 131, 134, 135, 150, 154, 155, 167], "set_xtick": [83, 87], "set_ylabel": [0, 3, 5, 6, 21, 22, 30, 35, 38, 39, 42, 44, 45, 46, 54, 55, 70, 75, 78, 83, 86, 87, 93, 98, 100, 101, 107, 131, 134, 135, 137, 138, 139, 140, 148, 150, 154, 155, 157, 158, 166, 167], "set_ylim": [3, 6, 42, 47, 54, 55, 75, 86, 100, 101, 131, 134, 135, 150, 154, 155, 166, 167], "set_ytick": [9, 47], "set_zlabel": [70, 135], "set_zlim": 70, "settl": [8, 161], "setup": [9, 30, 35, 39, 53, 55, 56, 76, 106, 107, 131, 137, 142, 148, 151, 152, 157], "setup_mod": 55, "setup_polynomial_design_matrix": [39, 107], "setup_rc_param": [128, 131], "setup_text": [9, 137], "seven": 68, "sever": [4, 8, 9, 16, 19, 22, 24, 34, 38, 43, 45, 47, 49, 51, 53, 58, 60, 61, 68, 69, 70, 71, 72, 77, 78, 80, 81, 90, 93, 97, 100, 101, 102, 109, 110, 112, 122, 132, 133, 134, 135, 138, 139, 142, 145, 155, 158, 161, 168], "sexual": 68, "sg92": [1, 49], "sgd": [72, 111], "shade": [22, 42, 58, 131, 135], "shall": [51, 97, 128], "shallow": 24, "shannon": [4, 67], "shape": [6, 13, 30, 38, 39, 42, 46, 48, 55, 58, 70, 72, 74, 75, 78, 81, 82, 83, 85, 87, 88, 93, 97, 98, 99, 100, 101, 128, 131, 132, 135, 143, 148, 150, 151, 152, 153, 154, 156, 157, 158, 159, 161, 163, 164, 167], "share": [7, 48, 55, 61, 66, 77, 78, 86, 98, 101, 131, 138, 157, 161], "sharei": [3, 6, 30, 35, 45, 70, 83, 86, 87, 93, 135, 148, 166], "sharex": [3, 6, 30, 35, 45, 46, 86], "sharp": [24, 58, 70], "sharpli": [24, 39, 56, 72], "shave": 7, "she": [67, 93], "shed": 58, "sheet": [56, 141], "shef": 82, "sheffield": [82, 88, 90], "shell": [52, 131, 138, 159], "shift": [3, 5, 16, 44, 49, 77, 84, 128, 132, 139, 141, 143, 148, 149, 152, 157, 164], "shifti": 133, "shine": [45, 56], "ship": 81, "shire": 138, "sho": 1, "shop": 142, "shore": 4, "short": [20, 27, 28, 36, 37, 45, 49, 56, 61, 68, 72, 74, 77, 101, 131, 133, 141, 157, 161, 166], "shortcut": 141, "shorten": [0, 48], "shorter": [49, 149], "shorthand": [18, 30, 35, 71, 109, 112, 138], "shortli": 8, "shoud": 35, "should": [4, 7, 8, 9, 10, 15, 16, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 32, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 48, 49, 50, 51, 53, 56, 58, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 83, 87, 88, 90, 91, 93, 98, 99, 100, 102, 107, 110, 111, 115, 116, 127, 128, 131, 132, 134, 135, 139, 141, 142, 148, 150, 152, 156, 157, 158, 159, 161, 164, 166, 167], "shouldn": [34, 142, 147], "show": [4, 9, 11, 13, 16, 20, 22, 29, 30, 35, 37, 38, 39, 41, 42, 43, 44, 45, 47, 49, 54, 55, 56, 67, 70, 71, 72, 74, 75, 76, 77, 78, 81, 82, 84, 87, 88, 90, 91, 95, 98, 99, 101, 102, 104, 125, 126, 128, 129, 130, 132, 135, 137, 138, 139, 140, 142, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 164, 166], "show_titl": [22, 43, 46, 55, 87, 99, 101, 128, 148, 152, 157], "shown": [4, 9, 18, 20, 22, 24, 30, 39, 42, 43, 49, 52, 56, 70, 71, 72, 77, 78, 82, 86, 88, 100, 112, 126, 132, 135, 138, 139, 140, 141, 149, 156, 161, 166, 168], "shrink": [22, 42, 51, 81, 131, 147], "shrinkag": 71, "shuch": 135, "shuffl": [70, 111], "side": [3, 8, 10, 16, 20, 24, 27, 28, 30, 36, 39, 44, 49, 52, 58, 70, 77, 130, 135, 147, 150, 152, 154, 155, 157, 158, 161, 164, 166], "sig": [46, 55], "sig0": [43, 100], "sig_vm": 46, "siga": 20, "sigd": [0, 21], "sigf": 20, "sigh": [0, 21], "sight": 58, "sigma": [1, 3, 4, 9, 18, 19, 21, 22, 24, 29, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 49, 55, 57, 58, 71, 75, 77, 78, 83, 84, 87, 90, 91, 97, 98, 99, 100, 101, 102, 122, 130, 131, 132, 134, 135, 148, 149, 151, 152, 153, 156, 157, 158, 159, 163, 164, 166, 167], "sigma0": [43, 100], "sigma1": [55, 135], "sigma11_sq": 39, "sigma1inv": 55, "sigma2": [22, 39, 55, 131, 135], "sigma2inv": 55, "sigma_": [18, 21, 29, 34, 39, 50, 51, 57, 71, 87, 90, 91, 95, 101, 107, 128, 130, 135, 163, 166], "sigma_0": [39, 43, 44, 57, 86, 100, 152, 157], "sigma_0_bound": 86, "sigma_1": [39, 43, 53, 77, 91, 135], "sigma_2": [77, 91, 135], "sigma_a": 20, "sigma_b": 43, "sigma_contour": 46, "sigma_error": [39, 107], "sigma_est": [44, 152, 157], "sigma_exp": 101, "sigma_f": [20, 87, 90], "sigma_f_opt": 87, "sigma_fn": 75, "sigma_h": [18, 21, 128], "sigma_i": [18, 20, 21, 34, 39, 41, 43, 53, 58, 70, 83, 87, 91, 101, 102, 118, 125, 151], "sigma_interval__": 157, "sigma_j": 87, "sigma_k": 4, "sigma_mat": 54, "sigma_mat_inv": 54, "sigma_max": 131, "sigma_mean_prior": 156, "sigma_n": [52, 91, 158], "sigma_now": 131, "sigma_nu": 87, "sigma_prior": 156, "sigma_sampl": 97, "sigma_sd_prior": 156, "sigma_t": [18, 55, 101], "sigma_tild": 38, "sigma_tru": [41, 44, 152, 157], "sigma_v": [18, 21, 46, 128, 131], "sigma_w": 77, "sigma_x": [18, 20, 21, 41, 58, 83, 91], "sigma_z": [18, 20, 21, 72, 87], "sigmacor": [83, 87], "sigmai": 39, "sigmamat": 132, "sigmamv": 87, "sigmap": 55, "sigmapinv": 55, "sigmar": 39, "sigmauncor": [83, 87], "sigmavec": [57, 84, 91, 130, 159], "sigmoid": [1, 72, 73, 75, 76, 78, 93, 98, 134], "sigmoid_functions_fig": 93, "sign": [4, 48, 56, 58, 70, 71, 93, 124, 139, 142, 148, 153, 166], "signal": [1, 7, 20, 30, 43, 49, 56, 58, 70, 75, 77, 78, 87, 90, 93, 95, 96, 101, 159], "signatur": [49, 56], "signific": [4, 55, 56, 58, 61, 110, 132, 141, 159], "significantli": [34, 50, 58, 71, 76, 102, 112, 126, 130, 141, 158, 159], "sigp": 55, "sigv": [0, 21], "silenc": [72, 138], "silicon": 142, "silver": 16, "sim": [3, 34, 39, 43, 45, 46, 49, 50, 54, 56, 77, 79, 82, 84, 87, 88, 90, 91, 100, 107, 125, 128, 131, 135, 148, 149, 150, 158, 159, 163, 164, 167], "similar": [44, 45, 48, 49, 51, 56, 58, 70, 72, 76, 78, 80, 85, 93, 101, 102, 112, 139, 147, 151, 153], "similarli": [15, 58, 77, 87, 138, 164], "simon": [8, 39], "simp": [42, 161], "simpl": [0, 1, 4, 5, 7, 18, 20, 30, 37, 39, 40, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 58, 68, 69, 70, 71, 74, 76, 77, 78, 80, 81, 85, 93, 98, 100, 101, 103, 106, 107, 112, 122, 126, 135, 138, 139, 143, 148, 149, 152, 154, 155, 156, 158, 159, 168], "simpler": [7, 57, 58, 76, 126, 135, 137, 158], "simplest": [7, 15, 52, 58, 72, 74, 80, 90, 93, 135, 139, 166], "simpli": [7, 9, 13, 18, 22, 29, 30, 39, 43, 44, 45, 46, 48, 53, 58, 61, 68, 69, 70, 72, 76, 100, 122, 124, 128, 132, 135, 138, 141, 147, 149, 151, 152, 154, 157, 158, 159, 166], "simplic": [18, 39, 43, 49, 53, 72, 76, 91, 93, 115, 126, 161], "simplif": [120, 132], "simplifi": [29, 39, 47, 49, 54, 57, 58, 70, 100, 112, 151, 158, 159], "simpson": [42, 56, 159], "simul": [1, 11, 30, 35, 48, 49, 50, 56, 63, 72, 127, 129, 148, 151, 153, 158, 159, 161, 166], "simultan": [30, 52, 67, 71, 124], "sin": [39, 76, 82, 85, 86, 88, 97, 100, 117, 119, 132, 137, 139, 140, 141, 143, 154, 155], "sinc": [4, 6, 8, 13, 16, 18, 20, 21, 24, 30, 38, 39, 41, 46, 49, 53, 58, 69, 71, 76, 77, 82, 83, 88, 90, 100, 101, 105, 109, 111, 116, 120, 126, 128, 130, 135, 138, 139, 147, 148, 149, 156, 158, 161, 166], "sine": [39, 137, 139, 140, 141], "sine_and_exp": 139, "sine_and_exp_transpar": 139, "sine_map": 140, "singer": 1, "singl": [4, 19, 35, 39, 42, 43, 44, 45, 48, 51, 52, 53, 54, 68, 70, 71, 72, 75, 76, 77, 78, 79, 80, 87, 90, 93, 100, 101, 104, 105, 111, 120, 135, 138, 139, 140, 141, 148, 149, 152, 157, 159, 166], "single_cauchy_likelihood": 43, "single_conservative_likelihood": 43, "single_gaussian_likelihood": 43, "single_neuron": 75, "single_neuron_binary_classifi": 75, "single_prior": 86, "singular": [5, 52, 71, 129, 132], "singularli": 130, "sinh": 76, "sir": 1, "sit": 39, "site": [55, 69, 86, 101, 131, 156, 157, 159], "situat": [4, 7, 8, 16, 18, 38, 39, 43, 44, 45, 49, 51, 53, 56, 57, 58, 68, 71, 76, 82, 93, 95, 106, 107, 110, 135, 149, 152, 157, 158, 159, 164, 166], "sivia": [1, 2, 7, 9, 32, 42, 43, 44, 47, 58, 61, 95, 100, 101, 152, 157], "six": [3, 4, 52, 159], "sixth": 161, "size": [3, 4, 5, 9, 18, 22, 34, 39, 41, 42, 44, 45, 47, 48, 49, 51, 52, 54, 55, 71, 72, 74, 75, 78, 79, 80, 81, 82, 84, 85, 87, 88, 91, 97, 98, 100, 101, 102, 107, 111, 116, 122, 128, 131, 132, 135, 137, 138, 142, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 164, 166, 167, 168], "sk": 101, "skate": 156, "skater": 156, "skeleton": 139, "skew": [23, 41, 58, 68, 158], "ski": 161, "skill": [1, 4, 42, 61, 69], "skimag": 132, "skin": 1, "skip": [0, 41, 84, 132, 138, 147, 150, 164, 167], "skirt": [44, 152, 157], "skl": 138, "sklearn": [55, 75, 78, 79, 85, 86, 87, 98, 128, 132, 138], "sky": [0, 1, 27, 100, 161], "slab": 78, "slant": [58, 151], "slate": 76, "slice": [141, 154, 156, 157, 161], "slide": 80, "slider": [9, 11, 137, 139], "slider_bord": 137, "slight": [48, 76], "slightli": [5, 18, 39, 43, 45, 65, 71, 156, 166], "slope": [3, 6, 28, 39, 41, 42, 43, 45, 46, 58, 91, 110, 148], "slope_limit": 45, "slope_max": 46, "slope_prior": [3, 6], "slope_rang": [45, 46], "slope_sampl": 46, "slopesamples_fig": 3, "sloppi": [28, 132], "slow": [69, 78, 110, 131, 138, 140, 156], "slowli": [71, 73, 78, 84, 111, 159], "small": [0, 5, 7, 8, 9, 19, 21, 22, 24, 28, 34, 39, 43, 44, 49, 51, 52, 53, 56, 58, 68, 71, 72, 73, 76, 77, 78, 80, 82, 83, 85, 87, 88, 90, 91, 102, 106, 110, 112, 119, 120, 126, 132, 141, 142, 149, 151, 152, 156, 157, 158, 159], "small_list_a": 140, "smaller": [4, 18, 34, 36, 38, 42, 49, 50, 51, 52, 58, 68, 71, 73, 101, 102, 110, 154, 155, 158, 166], "smallest": [46, 130, 132, 135, 138], "smartphon": 139, "smhi": 16, "smith": 1, "sml": 1, "smlbook": 1, "smooth": [4, 5, 9, 35, 50, 52, 83, 84, 87, 90, 91], "smoother": [52, 156], "sn": [5, 9, 22, 38, 42, 43, 44, 47, 55, 75, 78, 82, 83, 97, 98, 100, 101, 138, 149, 152, 157], "snapshot": [50, 52, 131], "snippet": [97, 101, 151], "snow": 161, "so": [3, 4, 5, 8, 9, 11, 13, 15, 16, 19, 20, 22, 23, 24, 27, 28, 30, 31, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 80, 81, 82, 83, 84, 87, 88, 90, 91, 93, 94, 97, 98, 99, 100, 101, 102, 105, 107, 122, 124, 128, 130, 131, 132, 135, 137, 138, 139, 141, 142, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 164, 166, 167], "social": [8, 53, 68, 69], "societ": [68, 69], "societi": [1, 68], "soft": [48, 93], "softmax": [72, 74, 76, 80, 81], "softplu": [77, 122], "softwar": [48, 56, 68, 69, 78, 81, 82, 88, 94, 98, 110, 142, 148, 151], "sol": 128, "sold": 8, "sole": [8, 48, 54, 56, 61], "solid": [20, 42, 47, 49, 54, 69, 84, 91, 93, 137, 155], "solut": [4, 17, 18, 49, 50, 52, 53, 73, 84, 105, 109, 110, 122, 128, 132, 141, 142, 153, 154, 155, 159], "solv": [3, 21, 36, 39, 44, 49, 50, 51, 52, 66, 69, 70, 71, 72, 74, 84, 90, 101, 102, 105, 106, 109, 128, 130, 139, 152, 154, 157, 161, 166], "solvabl": 158, "solve_ivp": [154, 155], "solve_od": [154, 155], "solve_ode_eul": 155, "solve_ode_leapfrog": 155, "solver": [52, 75, 153], "some": [4, 5, 7, 8, 9, 10, 16, 18, 20, 23, 24, 26, 27, 28, 29, 30, 31, 33, 35, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 60, 63, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 95, 96, 97, 98, 99, 100, 101, 102, 106, 107, 109, 110, 112, 113, 115, 118, 121, 122, 127, 132, 133, 135, 138, 139, 140, 141, 142, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 161, 164, 166, 167], "someon": [8, 53, 61], "someth": [3, 8, 16, 24, 26, 44, 47, 67, 68, 71, 76, 78, 111, 139, 142, 152, 153, 157], "sometim": [8, 16, 21, 23, 28, 39, 44, 48, 52, 53, 58, 65, 69, 72, 77, 90, 103, 124, 127, 131, 135, 139, 149, 152, 157, 158, 161], "somewhat": [8, 16, 24, 28, 39, 56, 58, 104, 112], "somewher": [39, 149], "son": 1, "soon": 58, "sophist": [51, 53, 100, 138, 149, 158], "sort": [24, 42, 45, 46, 58, 70, 72, 78, 83, 87, 101, 132, 139], "sorted_": [42, 45], "sorted_lnprob": 46, "sound": [68, 69, 139], "sourc": [0, 22, 38, 47, 48, 56, 61, 69, 71, 81, 92, 127, 138, 139, 140, 142, 147, 166], "sp": [74, 83, 97, 132, 161, 166], "space": [8, 22, 24, 26, 28, 38, 42, 43, 45, 49, 50, 51, 52, 56, 57, 58, 64, 67, 69, 70, 72, 76, 77, 78, 82, 83, 84, 87, 88, 90, 91, 98, 100, 101, 109, 124, 125, 131, 135, 139, 148, 149, 151, 153, 154, 155, 156, 158, 159, 161, 164, 166], "spacetim": 16, "span": [39, 52, 53, 71, 107, 132, 138], "spars": 76, "sparse_categorical_crossentropi": [74, 81], "sparsiti": 78, "spatial": [56, 72, 80, 122, 128, 132, 154], "speak": [8, 61, 64, 84, 135], "speci": 67, "special": [8, 16, 22, 28, 39, 43, 44, 52, 53, 58, 68, 70, 73, 78, 91, 93, 101, 135, 138, 151, 152, 153, 156, 157, 158, 159], "specif": [4, 18, 28, 30, 39, 43, 46, 48, 50, 51, 53, 55, 58, 63, 64, 66, 67, 68, 69, 70, 71, 72, 76, 77, 79, 80, 81, 83, 87, 91, 93, 101, 116, 124, 125, 128, 134, 135, 138, 141, 149, 158, 161, 166], "specifi": [3, 4, 5, 9, 10, 18, 22, 27, 28, 30, 39, 42, 43, 44, 45, 46, 47, 48, 51, 53, 54, 55, 56, 58, 60, 63, 64, 72, 74, 78, 83, 84, 85, 87, 90, 91, 93, 96, 99, 100, 122, 124, 125, 126, 128, 134, 135, 137, 141, 142, 148, 152, 154, 155, 156, 157, 158, 159, 163, 166], "specifii": 84, "speckl": 161, "spectacular": 53, "spectroscopi": 101, "spectrum": [52, 95, 101, 130], "speech": [69, 72], "speed": [52, 73, 76, 78, 98, 139, 141], "spell": [66, 139], "spend": [48, 67, 159], "spent": [7, 65], "sphere": 128, "spheric": 153, "spike": 78, "spin": [72, 122, 135], "spirit": [45, 51, 58, 63], "spite": 69, "split": [6, 48, 55, 69, 71, 72, 90, 98, 133, 148, 151, 166], "spot": [58, 68], "spread": [4, 71, 84, 135, 147, 151, 164], "springer": 1, "sqrt": [0, 4, 9, 18, 19, 20, 21, 24, 29, 34, 35, 38, 39, 42, 43, 44, 45, 46, 49, 51, 53, 54, 55, 57, 58, 71, 72, 76, 83, 84, 87, 91, 100, 101, 112, 128, 131, 134, 135, 139, 141, 143, 148, 149, 151, 152, 154, 156, 157, 158, 159, 164, 167], "squar": [4, 18, 22, 24, 28, 29, 31, 43, 46, 49, 51, 56, 57, 70, 71, 72, 76, 77, 80, 82, 83, 88, 91, 93, 99, 100, 101, 102, 106, 107, 110, 112, 115, 130, 132, 135, 138, 139, 140, 141, 159], "square_cube_list": 140, "square_loss": 43, "squared_loss": 43, "squeez": [85, 86], "sr": [152, 157], "ss06": [1, 2, 32, 41, 58, 61], "st": 68, "stabil": [6, 16, 43, 66, 77, 78, 90, 98, 128, 151, 152, 157], "stabl": [1, 42, 49, 70, 86, 98, 111, 138, 148], "stack": [0, 74, 78, 80, 81, 98, 139], "stacklevel": [55, 101], "stackoverflow": [78, 98, 143], "stackrel": [24, 38, 42], "staffwww": 82, "stage": [9, 11, 28, 39, 45, 49, 52, 68, 69, 148], "stai": [149, 150, 151, 159, 161, 167], "stan": [1, 45, 49, 77, 78, 158], "stanc": 8, "stand": [9, 11, 26, 43, 45, 69, 71, 138, 148, 153, 156], "standalon": 157, "standard": [3, 4, 15, 16, 18, 20, 24, 29, 30, 34, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 51, 53, 55, 58, 67, 68, 69, 70, 71, 72, 76, 77, 78, 79, 82, 83, 85, 86, 88, 90, 98, 99, 100, 106, 110, 112, 125, 126, 128, 131, 132, 134, 135, 138, 140, 143, 149, 150, 151, 152, 156, 157, 158, 163, 164, 166, 167], "standardize_data": 70, "standardscal": 128, "stanford": 80, "stapl": 16, "star": [53, 152, 157, 168], "start": [5, 6, 7, 9, 15, 16, 24, 30, 31, 35, 37, 39, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 60, 70, 71, 72, 73, 76, 83, 84, 85, 86, 87, 91, 97, 98, 99, 100, 101, 102, 110, 115, 119, 122, 128, 130, 131, 134, 135, 138, 139, 140, 141, 142, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 161, 164, 166, 167], "start_index": [154, 155], "start_new_sess": 131, "start_po": 149, "start_posit": 149, "start_stop_indic": [154, 155], "start_tim": 128, "starter": [18, 142], "starting_guess": [6, 43, 46, 101, 128, 152, 157], "startupinfo": 131, "startval": 156, "stat": [1, 5, 6, 9, 13, 24, 28, 34, 35, 38, 39, 42, 44, 47, 48, 54, 70, 74, 83, 87, 97, 101, 128, 131, 148, 149, 150, 152, 156, 157, 158, 159, 167], "state": [0, 4, 6, 7, 8, 9, 11, 18, 19, 26, 27, 30, 36, 37, 43, 49, 50, 51, 52, 55, 58, 61, 66, 71, 72, 76, 78, 90, 93, 128, 129, 132, 135, 138, 148, 152, 153, 156, 157, 164, 166], "statement": [0, 8, 16, 22, 24, 25, 27, 36, 38, 39, 40, 48, 51, 58, 61, 67, 69, 70, 106, 115, 116, 135, 139, 140, 145, 163, 164], "static": [138, 139, 164], "stationar": [48, 49, 52, 148, 151, 166], "stationari": [48, 49, 50, 52, 76, 82, 84, 87, 88, 148, 151, 156, 158, 166], "statisc": 125, "statist": [1, 3, 4, 7, 9, 17, 18, 22, 25, 28, 29, 30, 31, 32, 34, 35, 39, 41, 42, 44, 49, 50, 53, 56, 60, 61, 64, 65, 67, 69, 71, 72, 77, 78, 93, 94, 97, 99, 102, 107, 113, 118, 122, 123, 125, 129, 132, 138, 147, 150, 152, 156, 157, 159, 161, 163, 164, 166, 167], "statistician": [0, 1, 48, 61, 126, 135, 164], "stats_random_numb": 135, "stats_titl": 47, "statu": [39, 86, 93, 128], "std": [18, 22, 38, 43, 46, 55, 70, 72, 76, 78, 83, 86, 87, 98, 131, 134, 135, 138, 141, 148, 150, 156, 166, 167], "std_predict": 85, "std_train_data": 70, "stddev": 134, "stderr": 131, "stdin": 131, "stdmv": 87, "stdout": 131, "stdperiod": [82, 88], "steadi": 164, "steadili": [71, 102], "stealthili": 68, "steep": 156, "steer": [69, 74], "stein": 159, "stem": [52, 58, 68, 69, 124], "step": [4, 6, 9, 15, 16, 20, 27, 29, 30, 35, 39, 41, 42, 43, 47, 49, 51, 54, 58, 65, 70, 72, 73, 74, 75, 77, 81, 84, 93, 95, 97, 101, 102, 110, 111, 112, 128, 130, 135, 137, 138, 139, 140, 141, 142, 143, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 166, 167, 168], "step1": 156, "step2": 156, "step_fn": 75, "step_method": 156, "step_siz": 151, "stepfil": 149, "stepsiz": [55, 148, 151], "stereotyp": 68, "stern": 1, "stick": [8, 28, 49, 66, 139, 149, 159], "still": [3, 8, 36, 39, 46, 48, 50, 51, 52, 56, 69, 70, 71, 72, 78, 80, 90, 98, 115, 132, 137, 140, 147, 153, 155, 159], "stimuli": 72, "stirl": [4, 42], "stochast": [1, 39, 48, 53, 64, 72, 73, 76, 77, 78, 83, 87, 90, 91, 93, 102, 115, 121, 128, 135, 158, 165, 168], "stochasticprocess": [161, 166], "stochasticprocessexampl": 166, "stoke": 72, "stone": [8, 93], "stoner": 1, "stongli": [83, 87], "stop": [9, 24, 27, 85, 86, 139, 142, 153, 164], "stop_index": [154, 155], "stopiter": 131, "storag": 141, "store": [0, 39, 43, 50, 55, 74, 107, 112, 130, 138, 141, 142, 149], "stori": [100, 156], "storylin": 11, "str": [6, 74, 83, 87, 140], "straight": [28, 39, 41, 43, 58, 70, 75, 83, 99, 102, 107, 108, 110, 119, 151, 158, 159], "straightforward": [4, 18, 30, 38, 39, 43, 44, 48, 51, 52, 58, 72, 90, 117, 152, 157, 158], "straightforwardli": 43, "strainghtforward": 51, "strang": [30, 58], "strategi": [18, 21, 36, 44, 48, 51, 52, 53, 56, 71, 76, 122, 151, 152, 153, 157], "street": 133, "strength": [7, 48, 51, 52, 56, 58, 67, 69, 85, 100, 101, 115, 122, 135, 138, 151, 159], "strerror": 131, "stress": [51, 71, 118, 122, 139, 161], "stretch": [132, 151], "strftime": 131, "strict": 24, "strictli": 72, "string": [26, 47, 82, 88, 128, 140, 143], "stringent": 158, "strive": 8, "stroke": 93, "strong": [18, 43, 48, 53, 56, 70, 72, 91, 126, 151], "strongli": [18, 20, 48, 58, 68, 69, 70, 80, 83, 87, 138], "strprior": 6, "structur": [11, 16, 20, 39, 50, 51, 52, 56, 69, 70, 71, 72, 76, 80, 82, 84, 88, 122, 138, 141, 156, 158], "sts412": 1, "stuck": [36, 47, 56, 101, 132, 153, 158], "student": [0, 23, 24, 28, 37, 43, 46, 49, 61, 67, 126, 129, 135, 139], "student_t_animation_": 131, "student_t_animation_04sep2025": 131, "studi": [16, 20, 24, 45, 46, 48, 50, 51, 53, 58, 61, 67, 68, 69, 72, 94, 97, 102, 124, 149, 161, 166], "stumbl": 156, "sty": 0, "style": [0, 9, 47, 81, 101, 139, 154], "sub": [56, 67, 72, 78, 97, 141], "subclass": 81, "subdirectori": [0, 128, 142], "subfield": [69, 127], "subgradi": 1, "subject": [4, 8, 27, 43, 44, 48, 51, 66, 67, 77, 115, 135, 152, 157, 161, 166], "subplot": [0, 3, 6, 20, 21, 22, 30, 34, 35, 38, 39, 43, 44, 45, 46, 49, 54, 55, 70, 74, 75, 78, 81, 82, 83, 86, 87, 88, 93, 98, 100, 107, 134, 135, 138, 139, 140, 143, 148, 149, 157, 158, 166, 167], "subplot2grid": 157, "subplot_kw": 135, "subplots_adjust": 38, "subprocess": 131, "subprocess_creation_flag": 131, "subroutin": 138, "subscript": [5, 29, 90, 155], "subsect": [25, 48, 53, 61, 139], "subsequ": [7, 30, 48, 50, 51, 61, 72, 76, 134, 161, 166], "subset": [49, 50, 51, 52, 53, 68, 71, 72, 79, 91, 94, 109, 135, 141, 149, 153, 159, 161, 166], "subshel": 138, "subspac": [1, 50, 52, 132], "substanti": [48, 68], "substitut": [4, 13, 20, 24, 52, 58, 76, 155], "subsum": 16, "subtask": 95, "subtl": [53, 68], "subtleti": [44, 152, 157], "subtract": [27, 47, 57, 71, 76, 102, 130, 141, 164], "succe": 16, "succeed": [77, 150, 167], "succes": 49, "success": [9, 11, 24, 35, 38, 42, 44, 70, 91, 93, 124, 128, 142, 150, 156, 159, 164, 167], "successfulli": [128, 147], "succinctli": [39, 105], "suffer": [52, 71, 73], "suffici": [5, 24, 43, 48, 52, 56, 75, 76, 78, 98, 156, 158, 163], "suggest": [47, 56, 61, 68, 71, 112, 132, 139, 142, 148, 149, 151, 158], "suit": [51, 72, 76, 128], "suitabl": [48, 50, 58, 76, 125], "sum": [5, 7, 9, 13, 15, 24, 28, 31, 35, 36, 39, 40, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 58, 70, 71, 72, 73, 74, 76, 77, 82, 83, 84, 88, 95, 97, 100, 101, 104, 105, 110, 111, 112, 122, 125, 128, 130, 131, 132, 135, 139, 140, 141, 148, 151, 152, 156, 157, 158, 161, 164, 166], "sum21": [1, 68], "sum_": [4, 13, 16, 24, 29, 34, 38, 39, 41, 43, 44, 45, 46, 49, 50, 52, 53, 54, 56, 57, 58, 70, 71, 72, 73, 77, 83, 87, 90, 93, 99, 100, 101, 102, 104, 105, 111, 112, 117, 118, 130, 132, 135, 148, 149, 151, 152, 156, 157, 158, 159, 161, 164, 166], "sum_0": 42, "sum_h": 90, "sum_i": [3, 4, 27, 30, 36, 37, 71, 77, 87, 159, 161], "sum_j": [27, 36, 37, 93, 132, 161], "sum_k": [15, 73, 132], "sum_n": 77, "sum_norm_squar": 34, "sum_of_squar": 140, "sum_xsq_val": 34, "summar": [4, 9, 18, 20, 28, 29, 30, 35, 39, 48, 49, 51, 65, 71, 125, 135, 147, 164], "summari": [3, 4, 9, 22, 23, 32, 35, 43, 48, 49, 52, 56, 57, 61, 71, 73, 74, 75, 80, 81, 82, 88, 97, 99, 100, 122, 135, 136, 156, 157], "summaris": 51, "summat": [43, 49, 132, 149], "summer": [61, 82, 88], "sumpter": [1, 68], "sun": [8, 115], "sunil": [126, 128], "super": [76, 139], "superconductor": 135, "superfici": 80, "superflu": 52, "superior": [52, 140], "supermodel": 53, "supernova": 45, "superpos": [22, 38], "superposit": 1, "superscript": [72, 90], "supervis": [69, 71, 74, 93, 116, 138], "supplement": [67, 68, 93, 99, 121], "supplementari": [32, 43], "suppli": 72, "support": [1, 41, 48, 52, 56, 61, 68, 71, 78, 98, 100], "suppos": [4, 9, 13, 15, 16, 18, 20, 24, 34, 36, 38, 42, 46, 53, 55, 57, 70, 72, 91, 93, 135, 139, 140, 151, 159, 161, 164], "supposedli": [69, 101], "suppress": [13, 24, 45, 53, 78, 83, 87, 91, 93, 98, 132, 137], "suptitl": [22, 38, 42, 47, 86, 149, 154, 155], "sure": [16, 22, 23, 29, 30, 34, 39, 42, 44, 87, 90, 97, 106, 130, 132, 137, 151, 152, 156, 157], "surf": 135, "surfac": [39, 42, 70, 102, 104, 110, 112, 135, 138, 153], "surmis": 127, "surpris": [21, 22, 35, 41, 44, 46, 56], "surprisingli": [152, 157], "surrog": [97, 127], "surround": [0, 48], "survei": 53, "susan": 103, "suspect": 43, "suspici": [9, 35], "suspicion": [9, 35, 43], "svd": [52, 84, 129], "svd_shape": 132, "svensson": [1, 49, 61], "svg": 132, "svgd": 159, "svisak": [49, 135, 166], "swap": 56, "swedish": 135, "swift": 69, "switch": [16, 38, 61, 78, 91, 98, 101, 130, 131, 132, 139, 143], "sword": 52, "sy": [43, 46, 55, 98, 128, 135, 148, 161, 166], "syllog": 67, "symbol": [9, 11, 39, 58, 77, 78, 90, 98, 104], "symmet": 153, "symmetr": [22, 23, 24, 41, 43, 45, 46, 49, 57, 58, 76, 77, 83, 87, 90, 132, 141, 148, 149, 153, 158, 159, 161], "symmetri": [16, 23, 28, 30, 48, 60, 76, 130, 153], "sympi": 42, "symplect": [49, 153], "synonym": 63, "syntax": [78, 98, 130, 139, 141], "syntaxerror": 139, "synthet": [22, 68, 85], "system": [1, 4, 8, 16, 51, 52, 56, 69, 72, 73, 93, 115, 116, 122, 124, 125, 126, 128, 153, 161, 166], "systemat": [7, 18, 53, 56, 65, 67, 68, 77, 102, 109, 122], "t": [1, 5, 8, 9, 11, 13, 15, 16, 18, 21, 23, 24, 27, 28, 30, 34, 35, 36, 38, 39, 41, 43, 44, 45, 46, 47, 49, 50, 53, 54, 55, 56, 58, 61, 63, 66, 68, 69, 70, 71, 73, 75, 77, 78, 79, 82, 83, 86, 87, 88, 90, 91, 93, 98, 99, 100, 101, 102, 105, 106, 107, 108, 119, 120, 122, 126, 128, 129, 130, 132, 135, 137, 138, 139, 141, 142, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 164, 166, 167], "t0": 128, "t1_dist": 22, "t1_label": 22, "t2_dist": 22, "t2_label": 22, "t3_dist": 22, "t3_label": 22, "t_": [137, 161], "t_0": 128, "t_1": 166, "t_2": 166, "t_color": 131, "t_df": 131, "t_dist": 131, "t_dist_max": 131, "t_dist_pt": 131, "t_end": [154, 155], "t_eval": [154, 155], "t_i": [73, 166], "t_j": 73, "t_k": 166, "t_label": 131, "t_loc": 131, "t_max": 137, "t_max_w": 137, "t_min": 137, "t_min_w": 137, "t_n": 161, "t_nois": 128, "t_ob": 128, "t_old": 166, "t_pt": [137, 139, 154, 155], "t_scale": 131, "t_start": [154, 155], "t_test": 79, "t_train": 79, "t_x": 161, "t_y": 161, "tab": [5, 9, 11, 44, 61, 84, 85, 91, 132, 139, 141, 143, 152, 157, 164], "tab0": [9, 137], "tab1": [9, 137], "tab2": [9, 137], "tab3": [9, 137], "tab_height": [9, 137], "tabl": [1, 4, 25, 29, 37, 47, 54, 56, 58, 61, 68, 69, 84, 99, 100, 101, 138], "tablet": 139, "tabul": [138, 161], "tabular": 138, "tadess": 1, "tag": [0, 48, 78, 98, 128], "tail": [8, 9, 11, 12, 15, 16, 22, 23, 24, 30, 38, 43, 44, 47, 48, 49, 56, 57, 58, 131, 135, 157, 158, 166], "tak": 96, "take": [0, 4, 5, 6, 9, 11, 24, 27, 34, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 56, 57, 58, 61, 63, 65, 67, 68, 71, 72, 76, 77, 79, 80, 81, 83, 84, 86, 87, 91, 93, 96, 101, 122, 128, 132, 133, 134, 135, 136, 138, 139, 141, 142, 149, 150, 151, 152, 153, 156, 157, 158, 159, 161, 164, 166, 167], "taken": [4, 30, 34, 39, 42, 47, 52, 54, 61, 64, 65, 77, 83, 84, 91, 122, 125, 128, 141, 156], "taku": 78, "talent": [43, 44, 55, 61, 82, 100, 148, 149, 152, 157], "talk": [5, 9, 36, 43, 44, 45, 46, 47, 54, 55, 65, 75, 78, 82, 83, 91, 97, 98, 100, 127, 138, 139, 148, 149, 152, 156, 157], "tall": [18, 27, 36, 37, 115], "tan": [3, 39, 47, 54, 99, 107, 139], "tangent": [72, 122], "tangl": 24, "tanh": [72, 75, 76, 78, 93, 98, 134], "target": [49, 50, 51, 56, 69, 70, 72, 73, 75, 76, 77, 93, 128, 138, 141, 148, 151, 153, 159], "task": [7, 16, 22, 39, 42, 43, 47, 52, 54, 58, 67, 69, 70, 71, 72, 76, 77, 97, 98, 99, 100, 101, 115, 118, 132, 135, 139, 140, 141, 147, 158, 163], "tau": [49, 56, 149, 164], "tau_": 49, "tau_1": 56, "tau_2": 56, "tau_3": 56, "taught": [61, 64, 80, 132], "taylor": [1, 24, 39, 41, 54, 58, 96, 99, 154], "td": 47, "teach": 67, "teacher": 72, "tear": 1, "tech": [1, 72], "technic": 68, "techniqu": [1, 39, 56, 60, 69, 70, 71, 78, 99, 135, 153, 163], "technologi": [61, 68, 69, 109, 158], "techtarget": 94, "tediou": 18, "telescop": 67, "tell": [9, 10, 11, 16, 18, 22, 24, 27, 28, 30, 35, 36, 42, 54, 58, 63, 67, 71, 78, 84, 91, 98, 149, 151, 154, 159], "temp": [55, 101, 131], "temper": [55, 58, 95, 153, 168], "temperatur": [4, 49, 55, 56, 101, 135, 153], "tempering_ptemce": 56, "tempering_ptemcee_vs_zeu": 168, "tempor": 8, "temporarili": 28, "temps_hi": [55, 101], "temps_lo": [55, 101], "tempt": [45, 46, 120], "ten": [71, 77, 79, 97, 155, 158, 166], "tend": [9, 11, 24, 38, 47, 58, 69, 71, 73, 81, 112, 115, 135], "tendenc": [48, 68, 138, 158], "tension": [68, 71], "tensor": [78, 80, 81, 98, 134], "tensorflow": [1, 69, 71, 75, 76, 77, 78], "tensorflow_vers": 81, "term": [4, 9, 15, 16, 18, 19, 20, 24, 26, 30, 34, 35, 36, 37, 38, 39, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 63, 67, 68, 69, 70, 71, 72, 76, 77, 78, 90, 93, 94, 96, 104, 105, 106, 107, 111, 115, 120, 122, 123, 126, 128, 130, 132, 135, 138, 139, 141, 148, 149, 152, 153, 157, 161, 168], "termin": [39, 119, 128, 139, 166], "terminologi": [58, 68], "terribl": 36, "territori": 58, "test": [0, 5, 24, 27, 36, 37, 38, 39, 43, 48, 52, 54, 55, 56, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 87, 91, 98, 100, 101, 124, 125, 126, 132, 135, 139, 148, 150, 158, 161, 165, 166, 167], "test_acc": [74, 81], "test_f": 139, "test_imag": 81, "test_label": 81, "test_loss": [74, 81], "test_poisson_pt": 38, "test_siz": [78, 79], "test_valu": [78, 98], "testimoni": 8, "testinput": [69, 70, 71], "testinputs_i": 70, "testoutput": [69, 70, 71], "testval": [78, 98], "tex": 144, "text": [0, 1, 4, 9, 10, 11, 12, 13, 15, 16, 18, 20, 21, 24, 26, 28, 29, 30, 35, 36, 39, 41, 42, 43, 46, 47, 48, 49, 51, 52, 53, 56, 57, 58, 61, 62, 63, 65, 68, 70, 71, 72, 87, 95, 97, 100, 104, 109, 122, 131, 132, 135, 137, 139, 148, 151, 153, 158, 159, 161, 163, 164, 168], "text_i": [22, 131], "text_mod": 131, "text_represent": 0, "text_x": [22, 131], "text_x_mid": [22, 131], "textbf": [22, 83, 156], "textbook": [30, 51, 61, 71], "textbox0": [9, 137], "textbox1": [9, 137], "textiowrapp": 131, "textit": [41, 56], "textrm": [9, 22, 28, 35, 45, 46, 47, 54, 76, 100, 148, 156], "texttt": 126, "textur": 53, "tf": [74, 75, 81], "tf_cpp_min_log_level": 74, "th": [0, 3, 9, 11, 34, 38, 39, 41, 45, 47, 53, 54, 55, 71, 72, 73, 93, 99, 101, 112, 125, 135, 148, 159, 161, 163], "th0": 43, "th0_mcmc": 43, "th0neg": 43, "th0po": 43, "th1": [6, 43], "th1_mcmc": 43, "th1neg": 43, "th1po": 43, "than": [4, 7, 8, 9, 12, 18, 22, 23, 24, 27, 28, 30, 34, 35, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 65, 67, 68, 70, 71, 72, 76, 77, 78, 82, 83, 84, 87, 88, 93, 98, 100, 101, 102, 104, 107, 109, 110, 115, 122, 124, 125, 126, 128, 130, 132, 133, 135, 138, 139, 140, 141, 148, 149, 151, 152, 156, 157, 158, 159, 163, 164, 166], "thank": [61, 138, 142], "theano": [98, 163], "theanof": [78, 98], "theanorc": 78, "thei": [0, 7, 8, 9, 15, 16, 22, 23, 24, 26, 27, 28, 35, 36, 37, 39, 41, 48, 49, 50, 51, 52, 53, 56, 57, 64, 65, 66, 67, 68, 69, 71, 72, 73, 77, 78, 80, 81, 82, 83, 88, 91, 96, 103, 107, 109, 115, 119, 122, 124, 130, 131, 132, 134, 135, 138, 139, 141, 148, 149, 151, 153, 156, 158, 161, 164], "them": [4, 7, 16, 18, 19, 24, 27, 28, 30, 34, 36, 39, 42, 43, 44, 45, 48, 49, 50, 52, 53, 55, 57, 58, 63, 64, 68, 69, 71, 72, 73, 74, 75, 78, 80, 81, 82, 83, 87, 88, 97, 98, 100, 101, 124, 128, 132, 135, 138, 139, 141, 142, 143, 147, 149, 152, 153, 157, 161], "theme": [52, 77], "themselv": [30, 48, 52, 58, 67, 116, 138], "theorem": [7, 8, 9, 10, 13, 16, 18, 25, 29, 31, 32, 35, 36, 37, 39, 40, 41, 42, 44, 47, 48, 49, 54, 56, 57, 58, 63, 67, 72, 77, 90, 134, 147, 152, 153, 156, 157, 158, 159, 161, 163], "theoret": [0, 3, 7, 22, 28, 30, 34, 43, 44, 45, 46, 48, 54, 56, 60, 64, 67, 116, 122, 124, 125, 126, 128, 129, 148, 152, 157, 159], "theori": [1, 4, 7, 8, 16, 24, 26, 29, 34, 38, 39, 45, 46, 48, 49, 51, 54, 56, 58, 61, 63, 64, 65, 66, 67, 69, 70, 72, 77, 84, 93, 94, 96, 99, 120, 122, 124, 126, 129, 131, 133, 135, 148, 152, 157, 159, 162, 165, 166], "theorist": 58, "thereaft": 138, "therebi": [50, 51, 52, 69, 70, 87, 93, 124, 138], "therefor": [4, 8, 18, 21, 26, 28, 30, 34, 36, 39, 44, 46, 48, 50, 51, 53, 57, 58, 63, 67, 69, 70, 71, 72, 77, 83, 90, 91, 93, 101, 105, 109, 112, 115, 116, 118, 120, 135, 138, 141, 158, 161], "thermodynam": [56, 58, 149, 153], "thesi": 1, "theta": [0, 3, 6, 7, 9, 18, 24, 35, 39, 43, 45, 46, 47, 49, 53, 54, 58, 70, 71, 77, 82, 83, 86, 88, 90, 97, 100, 102, 107, 128, 132, 135, 148, 152, 156, 157, 159], "theta0": [43, 148], "theta1": [43, 148], "theta2": 43, "theta3": 43, "theta_": [18, 55, 90, 100, 132, 148, 158, 159], "theta_0": [3, 43, 45, 46, 55, 58, 106, 107, 148, 151, 158], "theta_1": [3, 43, 45, 46, 55, 106, 107, 148, 158, 159], "theta_2": 159, "theta_and_phi": 128, "theta_dist": 47, "theta_hat": 100, "theta_i": [58, 71, 100, 159, 164], "theta_j": [34, 58, 100, 132, 156], "theta_k": [47, 53, 132, 164], "theta_max": 100, "theta_min": 100, "theta_ml": [43, 46], "theta_n": 159, "theta_ol": [39, 70, 107], "theta_tru": [39, 45, 54, 107, 148], "thetavec": [9, 10, 28, 35, 56, 57, 84, 91, 130, 132, 151, 153, 159], "thetavec_": [56, 130, 132, 159, 164], "thetavec_0": 164, "thetavec_1": 159, "thetavec_2": 159, "thetavec_a": 159, "thetavec_b": 159, "thetavec_i": 159, "thetavec_j": 130, "thetavec_k": [130, 164], "thetavechat": 130, "thetavechat_": 130, "thetavechat_j": 130, "thi": [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 93, 95, 96, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 165, 166, 167, 168], "thick": 56, "thicker": 56, "thim": 61, "thin": [55, 56, 101, 157], "thing": [0, 5, 8, 9, 10, 11, 16, 22, 24, 27, 34, 35, 36, 38, 48, 56, 58, 63, 67, 76, 78, 91, 98, 139, 153], "think": [4, 8, 11, 15, 16, 30, 36, 38, 39, 45, 53, 58, 67, 68, 69, 71, 72, 74, 78, 82, 88, 91, 100, 106, 122, 135, 147, 149, 150, 159, 161, 166, 167], "third": [0, 1, 4, 16, 18, 22, 30, 37, 39, 51, 61, 69, 76, 78, 80, 83, 87, 98, 138, 149, 155, 161], "thirteenth": 58, "thisplot": [74, 81], "thoma": [8, 78, 98, 149], "thorough": [34, 51, 66], "those": [7, 8, 9, 22, 28, 30, 35, 39, 42, 48, 49, 51, 53, 56, 61, 64, 65, 67, 68, 71, 72, 76, 79, 83, 90, 99, 102, 110, 126, 132, 135, 152, 157], "though": [0, 5, 12, 27, 44, 67, 69, 77, 126, 152, 157, 164], "thought": [7, 8, 20, 57, 58, 71, 90, 130], "thousand": [50, 69, 72, 77], "thread": [55, 101, 128], "three": [0, 1, 3, 6, 8, 9, 11, 16, 17, 18, 20, 21, 22, 23, 28, 34, 37, 39, 41, 42, 46, 48, 49, 52, 53, 56, 58, 61, 66, 70, 71, 72, 73, 76, 77, 79, 80, 82, 88, 93, 98, 100, 101, 117, 120, 122, 126, 130, 131, 132, 135, 138, 139, 141, 149, 156, 161], "threlkeld": 1, "threshold": [48, 58, 72, 80, 93, 132, 166], "through": [0, 4, 7, 9, 14, 16, 18, 20, 22, 27, 28, 30, 32, 35, 38, 39, 41, 43, 46, 47, 48, 51, 52, 53, 54, 58, 61, 63, 72, 73, 74, 76, 80, 81, 82, 83, 84, 87, 88, 90, 91, 93, 94, 95, 100, 101, 108, 122, 125, 130, 139, 142, 148, 149, 150, 151, 153, 155, 159, 163, 167], "throughout": [16, 28, 49, 53, 61, 63, 67, 100, 138], "throw": [4, 46, 49, 132, 156], "thu": [11, 18, 28, 39, 43, 46, 49, 52, 53, 57, 58, 63, 68, 69, 71, 72, 73, 78, 110, 125, 132, 135, 151, 154], "thumb": 34, "thursdai": 8, "thusfar": 16, "th\u00e9ori": 39, "tibshirani": 1, "tick": [9, 47, 48], "tick_param": 38, "tight": [9, 78, 98, 131, 154, 155], "tight_layout": [5, 20, 22, 34, 38, 42, 44, 45, 46, 47, 54, 55, 70, 74, 78, 81, 82, 83, 86, 87, 88, 98, 100, 131, 132, 134, 140, 148, 149, 150, 154, 155, 157, 167], "tighter": [51, 126], "tikhonov": 85, "tild": [21, 39, 49, 50, 57, 70, 71, 84, 91, 93, 102], "tildecovparslr": 39, "tile": [87, 101], "time": [4, 7, 8, 9, 10, 11, 13, 15, 16, 18, 19, 22, 24, 27, 28, 30, 34, 35, 36, 37, 38, 39, 41, 42, 43, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 61, 68, 70, 71, 72, 74, 78, 80, 81, 82, 83, 84, 85, 87, 88, 90, 91, 93, 97, 98, 99, 101, 104, 105, 111, 112, 119, 120, 122, 125, 126, 127, 128, 130, 131, 132, 135, 137, 138, 140, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 159, 161, 166, 167, 168], "timeit": [78, 140], "times_overview_text": 137, "times_overview_text_w": 137, "times_text": 137, "timestep": [49, 141], "titl": [0, 24, 61, 76, 78, 81, 82, 85, 86, 88, 98, 139, 149, 152, 154, 156, 157], "title_fmt": 101, "title_kwarg": [22, 43, 55, 101, 128, 148, 152, 157], "title_loc": 135, "title_str": [22, 38, 47], "tmax": [55, 101], "tmp": [42, 43, 82, 87, 138, 156], "tmp2": [83, 87], "tn": [68, 69], "to_numer": 138, "to_numpi": [39, 107], "toal": 23, "toc": 61, "todai": [16, 54, 69, 131, 133, 135, 161], "togeth": [24, 30, 32, 36, 43, 44, 45, 46, 53, 54, 71, 74, 77, 78, 79, 82, 87, 88, 91, 100, 101, 138, 148, 152, 157, 164], "toggl": [61, 128], "toi": [44, 52, 78, 95, 96, 98, 152, 157], "token": 58, "tol": [5, 55, 75], "told": [4, 16, 27, 36, 153], "toler": 5, "tolist": 141, "tomorrow": [8, 16, 22, 28, 135, 161], "tone": 63, "tonight": 26, "too": [24, 34, 36, 48, 49, 58, 67, 68, 76, 84, 99, 110, 149, 151, 153, 159, 164], "took": [138, 156, 157], "tool": [1, 7, 27, 39, 45, 46, 53, 61, 63, 64, 68, 69, 78, 100, 107, 110, 122, 130, 138, 139, 148], "toolbar": 139, "tooltip": 9, "top": [0, 1, 4, 9, 24, 30, 38, 47, 49, 56, 58, 61, 78, 82, 88, 99, 100, 132, 137, 139, 149, 154, 161, 166], "topic": [8, 48, 60, 69, 93, 94, 99, 152, 157, 166], "topologi": [72, 159], "tor": 61, "torch": [76, 134], "torchvis": 76, "torqu": 56, "torsion": 56, "toss": [8, 12, 13, 15, 24, 28, 166], "toss_coin_text": 9, "tot_val": 34, "total": [6, 24, 30, 36, 37, 39, 42, 43, 46, 49, 51, 53, 55, 68, 72, 73, 74, 76, 80, 81, 93, 98, 111, 122, 128, 132, 135, 138, 139, 148, 152, 153, 156, 157], "total_count": 42, "total_draw": 38, "total_huber_loss": 43, "total_length": 156, "total_s": [78, 98], "total_sampl": 55, "totalenergi": 138, "touch": [16, 99], "tough": 159, "tour": 139, "toward": [16, 58, 63, 67, 73, 77, 83, 93, 115, 148, 156], "tower": [126, 128], "tp": [68, 69], "tr": 47, "trace": [43, 46, 48, 49, 52, 55, 76, 78, 101, 143, 148, 149, 150, 151, 156, 159, 164, 167], "trace1": 46, "trace2": 46, "trace_2_sampl": 156, "trace_arrai": 156, "trace_inferencedata": 156, "trace_mh": 156, "trace_nut": [156, 157], "trace_titl": [150, 167], "trace_two_param": 156, "trace_unord": 101, "traceabl": 65, "traceback": [55, 74, 75, 78, 98, 101, 131], "traceplot": 78, "track": [27, 50, 58], "tractabl": [7, 39], "traction": 69, "trade": [97, 153], "tradeoff": 102, "tradit": [8, 69, 78, 121], "tradition": [67, 124], "train": [52, 65, 67, 69, 72, 73, 75, 76, 78, 79, 80, 83, 84, 85, 86, 87, 91, 93, 94, 96, 98, 100, 102, 111, 116, 118, 122, 128, 134], "train_data": 70, "train_imag": 81, "train_label": 81, "train_test_split": [78, 79, 98, 138], "trainabl": [72, 74, 81], "training_err": 100, "training_indic": 85, "trainingdata": [69, 70, 71], "trainingdata_n": 71, "trajectori": [49, 50, 52, 55], "tran": [39, 77, 78], "tranform": 151, "transact": 142, "transax": [20, 30, 35, 100], "transfer": 78, "transform": [3, 4, 18, 19, 20, 21, 30, 35, 53, 58, 70, 72, 74, 77, 93, 100, 132, 151, 154, 158], "transit": [42, 43, 52, 72, 100, 149, 158, 159, 161, 164, 166], "translat": [4, 22, 24, 27, 40, 42, 47, 48, 51, 58, 122, 124, 135, 151, 153], "translation": 90, "transmiss": [70, 93], "transmit": 72, "transpar": [8, 48, 66, 68, 71, 78, 97, 98, 99, 139], "transpos": [130, 132, 141, 143, 161], "trapezoid": [101, 151], "trapz": [30, 35, 38, 101], "travel": [120, 153, 166], "travers": [71, 72, 141], "treat": [16, 33, 43, 48, 52, 60, 109, 122, 128, 153], "treatment": [33, 51, 58, 94, 101, 121, 122, 129], "tree": [72, 78], "tremend": [52, 61], "trend": [38, 48, 68, 77, 84, 126, 164], "trevor": 71, "tri": [16, 156], "trial": [9, 24, 26, 34, 50, 52, 69], "triangular": 38, "tribal": 78, "trick": [77, 78, 82, 88, 98, 149, 158], "tricki": 56, "trickier": 159, "trig": 139, "trigger": [72, 161], "trigonometr": [76, 117, 139], "trivia": [0, 28], "trivial": [8, 16, 38, 45, 70, 135, 159], "tro08": [1, 32, 56], "trotta": [1, 32, 56, 100], "troubl": [5, 68, 73, 153, 164], "troublesom": 58, "truck": [69, 81], "true": [3, 5, 6, 9, 11, 12, 15, 16, 19, 22, 24, 26, 27, 28, 30, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 55, 58, 63, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 81, 82, 83, 85, 86, 87, 88, 90, 93, 95, 97, 98, 99, 100, 101, 107, 115, 116, 125, 126, 128, 131, 132, 134, 135, 137, 139, 140, 141, 147, 148, 149, 151, 152, 155, 156, 157, 158, 161, 163, 166], "true_func": 100, "true_height": 128, "true_label": [74, 81], "true_model": 53, "true_param": [39, 107], "truli": [39, 44, 48, 53, 61, 68, 152, 157], "truncat": [16, 20, 39, 58, 117, 130, 132], "trunk": 109, "trust": [9, 35, 48, 75], "trustworthi": 68, "truth": [8, 26, 30, 58, 69, 87, 101, 115, 126, 152, 157], "truths_corn": 101, "try": [4, 8, 9, 11, 13, 15, 16, 22, 24, 28, 35, 36, 38, 39, 41, 42, 44, 45, 46, 53, 56, 58, 70, 71, 75, 81, 82, 84, 88, 91, 93, 95, 97, 99, 100, 101, 107, 124, 128, 131, 132, 137, 139, 140, 141, 147, 148, 149, 151, 152, 154, 155, 156, 157, 158, 159, 163, 164, 167], "tumor": 93, "tune": [49, 52, 71, 72, 76, 102, 110, 112, 122, 148, 151, 153, 156, 157, 158, 159, 164, 168], "tungsten": 56, "tuning_step": 156, "tupl": [134, 140, 141], "turn": [1, 4, 9, 18, 19, 22, 24, 39, 44, 47, 49, 57, 68, 69, 73, 78, 98, 100, 101, 105, 116, 120, 129, 132, 135, 138, 139, 149, 152, 153, 155, 156, 157, 158, 159, 164], "tutori": [1, 42, 44, 47, 61, 74, 76, 78, 81, 83, 87, 141, 152, 157], "tweak": [47, 76, 102, 131], "twentieth": 67, "twice": [36, 130, 148, 149], "twiecki": [78, 98], "twist": 56, "two": [0, 1, 3, 4, 7, 8, 9, 11, 13, 15, 16, 20, 21, 22, 24, 27, 29, 30, 31, 34, 42, 43, 44, 45, 48, 49, 50, 52, 54, 56, 57, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 85, 87, 88, 90, 91, 97, 98, 99, 100, 101, 106, 107, 108, 109, 115, 122, 125, 126, 130, 135, 138, 139, 140, 141, 142, 145, 147, 148, 149, 150, 151, 152, 153, 156, 157, 158, 159, 163, 166, 167, 168], "two_param_model": 156, "tx": 132, "txt": [83, 87, 138], "ty": 132, "type": [0, 11, 16, 39, 48, 50, 52, 55, 56, 65, 74, 76, 78, 80, 81, 82, 88, 90, 94, 98, 99, 100, 101, 107, 115, 124, 128, 137, 138, 139, 140, 142, 153, 159, 166], "typeerror": 70, "typic": [4, 28, 39, 43, 48, 49, 52, 53, 54, 56, 65, 68, 72, 76, 80, 81, 87, 90, 93, 107, 110, 111, 115, 123, 124, 130, 131, 132, 150, 153, 156, 159, 164, 167], "u": [1, 4, 6, 7, 8, 9, 10, 16, 18, 19, 20, 22, 24, 27, 28, 30, 35, 36, 39, 42, 43, 44, 46, 49, 50, 51, 53, 54, 55, 56, 58, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 82, 83, 84, 86, 87, 88, 90, 91, 93, 98, 100, 101, 102, 106, 107, 112, 118, 126, 130, 132, 135, 138, 139, 141, 142, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 164, 166, 167], "u_": [91, 130, 132], "u_0": 91, "u_1": [56, 91, 135], "u_deriv": 155, "u_i": [58, 158], "u_n": 135, "u_pt": 155, "u_shap": 132, "ua": 138, "ucf": 155, "ucf_deriv": 155, "ucf_pt": 155, "ud": 36, "udat": 78, "ueff": 155, "ueff_deriv": 155, "ueff_pt": 155, "ui": 143, "ui_box": [9, 137], "uid": 131, "uint8": [74, 81], "uk": [1, 55, 61, 82, 148, 149], "ul": [9, 137], "ultim": [28, 36, 53, 102, 111], "umask": 131, "un": 48, "unabl": 75, "unaccept": 49, "unaffect": 132, "unambigu": 66, "unawar": [16, 68], "unbalanc": 71, "unbias": [44, 148, 152, 157, 166], "unbow": 67, "unc": 138, "uncertain": [7, 8, 16, 39, 77, 78, 106, 131, 135, 166], "uncertainti": [0, 1, 4, 8, 16, 17, 18, 20, 22, 28, 30, 39, 46, 48, 49, 50, 51, 52, 53, 54, 56, 58, 61, 84, 85, 90, 115, 116, 118, 124, 125, 127, 128, 131, 147, 148, 151, 159], "unchalleng": 84, "unchang": [73, 80, 153], "unchart": 58, "uncheck": 142, "uncolor": 159, "uncom": 128, "uncontrain": 57, "uncontrol": 68, "uncorrel": [41, 46, 55, 77, 83, 84, 87, 125, 128, 135, 151, 153, 164], "uncov": 48, "under": [3, 4, 8, 9, 10, 16, 18, 23, 24, 34, 49, 50, 53, 56, 58, 61, 69, 71, 76, 81, 91, 100, 101, 102, 126, 134, 137, 139, 142, 148, 161, 164, 168], "underappreci": 78, "underbrac": [4, 9, 10, 28, 35, 57], "underestim": [46, 116, 148], "underfit": [76, 100, 102], "undergird": 53, "undergo": 69, "underground": 67, "underli": [7, 34, 39, 48, 49, 50, 52, 53, 54, 65, 68, 70, 71, 72, 82, 84, 88, 95, 99, 107, 124, 148, 151], "underrepresent": 68, "underscor": 139, "underset": [57, 71, 90, 97, 109], "underst": 30, "understand": [8, 11, 22, 47, 48, 50, 52, 54, 58, 63, 65, 67, 69, 70, 71, 72, 76, 80, 109, 122, 124, 130, 132, 147, 150, 161, 166, 167], "understood": [28, 39, 48, 53, 63, 68, 69, 72, 78, 122, 128, 135, 158, 161], "undetect": 69, "undoubtedli": 67, "undul": 52, "unduli": 53, "unemploy": 30, "unequ": 140, "unessenti": 129, "unexpect": [45, 58, 151], "unexpected": 58, "unfair": [9, 15, 30, 35, 68], "unfairli": 51, "unfortun": [8, 49, 73, 77, 78, 115], "uni": [85, 86], "uni_dist": 38, "uni_dist_pt": 38, "uni_gauss_pt": 38, "uni_max": 38, "uni_min": 38, "unicode_liter": 81, "unif": 66, "uniform": [3, 4, 5, 6, 9, 11, 12, 18, 21, 24, 30, 34, 35, 38, 41, 42, 43, 45, 46, 47, 48, 49, 54, 55, 56, 58, 76, 84, 86, 97, 100, 101, 107, 125, 128, 148, 149, 150, 154, 157, 159, 161, 164, 166, 167, 168], "uniform_1": [150, 167], "uniform_2": [150, 167], "uniformli": [6, 38, 41, 47, 52, 76, 82, 87, 88, 135, 147, 158, 159, 168], "uniformpropos": 156, "uniformsampl": 3, "unifrompdf": 135, "unimod": [23, 24, 51], "uninform": [11, 42, 54], "uninterest": 135, "union": [27, 53, 71, 135], "uniqu": [19, 23, 30, 49, 115, 118, 122, 135, 158, 161], "unit": [28, 39, 45, 47, 49, 65, 72, 73, 74, 76, 78, 98, 101, 135, 138, 158], "uniti": [16, 42, 58, 83, 100, 135], "unitless": [125, 126, 131], "univari": [48, 49, 87, 90, 115, 135, 156, 161, 166], "univers": [1, 8, 18, 52, 53, 61, 69, 72, 80, 84, 132, 135], "universal_newlin": 131, "unknown": [24, 27, 36, 39, 42, 48, 51, 58, 71, 90, 101, 106, 107, 125, 129, 134, 156, 163], "unknowwn": 73, "unlabel": 72, "unless": [4, 16, 51, 52, 57, 58, 76, 81, 109, 129, 138, 148, 149, 156, 158, 161, 164], "unlik": [28, 38, 42, 45, 58, 80, 139, 147, 158], "unlock": 78, "unlov": 50, "unnecessarili": [72, 152, 157], "unnorm": [13, 41, 47, 49, 58, 149, 164], "unobserv": 39, "unpack": [53, 83, 87], "unreason": [58, 122], "unrol": 81, "unround": 138, "unsatisfi": 67, "unscal": 100, "unseen": 93, "unshift": [148, 149], "unsort": 46, "unspecifi": 74, "unsqueez": 76, "unstabl": [70, 73, 84, 91], "unstack": 74, "unsupervis": [69, 72, 78], "unsur": 47, "until": [24, 68, 72, 73, 76, 93, 102, 110, 126, 149, 150, 156, 158, 159, 164, 167], "unverifi": 66, "unwant": 30, "up": [0, 4, 8, 11, 12, 16, 24, 28, 31, 38, 41, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 61, 65, 67, 68, 69, 70, 74, 76, 77, 78, 87, 98, 106, 107, 112, 116, 122, 125, 130, 131, 132, 134, 135, 136, 138, 139, 141, 142, 143, 148, 149, 150, 151, 152, 156, 159, 163, 164, 165, 167], "updat": [1, 5, 11, 12, 13, 15, 28, 30, 32, 38, 39, 42, 48, 49, 53, 54, 61, 63, 64, 67, 71, 72, 73, 74, 75, 76, 77, 78, 82, 83, 88, 97, 98, 110, 111, 112, 125, 137, 139, 149, 151, 153, 154, 155, 158, 161, 166], "update_n": 9, "update_plot": [9, 137], "update_prob_head": 9, "update_t_max": 137, "uphil": [102, 156], "uphold": 66, "upon": [16, 24, 26, 43, 48, 52, 53, 63], "upper": [9, 22, 38, 47, 54, 56, 58, 61, 77, 86, 128, 131, 142, 155, 157], "uq": [52, 127], "url": 1, "us": [0, 1, 3, 5, 6, 8, 9, 10, 11, 13, 15, 16, 17, 21, 22, 23, 28, 29, 30, 31, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 81, 82, 83, 84, 85, 86, 87, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 115, 117, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 141, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 166, 167, 168], "usag": [0, 76, 138], "usecol": 138, "usefulli": 53, "uselatex": 131, "user": [11, 43, 46, 49, 55, 68, 86, 91, 98, 112, 131, 134, 139, 142, 148, 156, 158, 166], "user_nam": 141, "userwarn": [55, 128, 157], "usetex": 128, "usr": [55, 86, 101, 131, 157], "usual": [0, 2, 4, 18, 24, 27, 29, 30, 34, 37, 39, 43, 48, 50, 51, 52, 53, 54, 57, 58, 65, 69, 70, 71, 72, 76, 77, 78, 87, 90, 93, 98, 102, 105, 111, 115, 116, 130, 132, 135, 138, 139, 149, 151, 153, 158], "util": [49, 69, 72, 82, 87, 109, 117, 124, 131, 135, 161, 166], "utmost": 69, "uvec": 91, "v": [18, 20, 22, 38, 41, 43, 46, 52, 57, 83, 87, 101, 109, 119, 120, 126, 128, 130, 132, 139, 140, 143, 154, 156, 157, 159], "v0": [0, 21, 46, 128], "v1": [101, 132, 137], "v12": 1, "v2": [48, 132], "v3": 101, "v5": [156, 157], "v_": [18, 46, 52, 53, 130, 132], "v_0": [18, 21, 50, 84, 126, 128], "v_1": 53, "v_1v_2": 53, "v_2": 53, "v_d": 158, "v_i": 50, "v_shape": 132, "v_t": [119, 120], "v_tran": 132, "va": [22, 38, 100, 154, 155], "vaiidat": 71, "vain": 58, "val": [69, 71], "val_accuraci": 81, "val_loss": 81, "vale": 4, "valid": [0, 34, 48, 49, 52, 56, 63, 64, 68, 69, 72, 82, 83, 87, 88, 90, 102, 109, 124, 126, 128, 158, 159], "validation_data": 81, "vallei": 110, "valu": [3, 4, 5, 9, 10, 11, 13, 16, 18, 20, 21, 22, 23, 27, 30, 32, 35, 38, 39, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 82, 83, 84, 87, 88, 90, 91, 93, 94, 97, 99, 100, 106, 107, 108, 109, 112, 115, 116, 118, 122, 124, 125, 126, 128, 129, 131, 132, 134, 138, 139, 140, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 161, 164, 166, 167, 168], "valuabl": [130, 139, 141], "valueconstraintsprior": 83, "valueerror": [42, 128, 134, 152, 157], "van": [1, 48, 71], "van16": [1, 71], "vander": [39, 107], "vandermond": [39, 105, 107], "vanderpla": [1, 71, 85], "vandschootdk": [1, 48], "vanish": [73, 76, 122], "vannucci": 1, "var": [18, 21, 22, 29, 49, 50, 51, 71, 82, 88, 101, 135, 141, 148, 156, 158], "var2": 22, "var_chain": 148, "var_lnl": 101, "var_nam": 157, "var_theta": 148, "varabl": 51, "varepsilon": [18, 45, 49, 53, 90, 101, 112], "varepsilon_": 53, "varepsilon_i": [45, 46, 54, 148], "vari": [24, 41, 42, 48, 50, 52, 56, 69, 70, 84, 100, 120, 125, 131, 134, 159], "variabl": [3, 4, 7, 11, 16, 17, 18, 20, 24, 27, 28, 29, 30, 31, 36, 37, 39, 42, 43, 44, 48, 49, 57, 58, 64, 66, 68, 69, 70, 71, 72, 77, 78, 83, 85, 87, 91, 93, 96, 98, 104, 105, 107, 109, 112, 114, 115, 117, 118, 119, 120, 124, 126, 131, 132, 138, 139, 140, 141, 148, 150, 152, 153, 156, 157, 158, 161, 163, 166, 167, 168], "varianc": [1, 18, 21, 22, 24, 29, 34, 38, 39, 42, 43, 44, 46, 48, 51, 53, 55, 70, 72, 76, 77, 82, 83, 84, 85, 87, 88, 90, 91, 93, 97, 100, 101, 102, 105, 106, 107, 108, 111, 125, 128, 129, 131, 132, 134, 138, 148, 150, 151, 152, 153, 156, 157, 158, 159, 163, 167], "variance3": 83, "variant": [28, 72, 100, 155, 158], "variat": [1, 4, 39, 43, 49, 50, 51, 52, 56, 69, 70, 71, 84, 102, 110, 115, 124, 132, 138, 148, 151, 156, 158, 159], "varieti": [43, 60, 72, 141, 156], "variou": [0, 16, 23, 30, 36, 38, 40, 51, 52, 61, 63, 69, 75, 76, 78, 79, 93, 99, 109, 115, 116, 136, 138, 165], "varphi": 7, "varz": 87, "vast": [50, 68], "vastli": 80, "vbox": [5, 9, 137], "vdot": [39, 57, 105, 132, 161, 166], "ve": [11, 22, 32, 34, 36, 43, 45, 57, 82, 83, 88, 132, 150, 151, 153, 156, 159, 167], "vec": [28, 90, 101], "vecor": 105, "vector": [5, 7, 9, 10, 28, 35, 39, 41, 43, 45, 46, 49, 50, 52, 54, 55, 57, 58, 70, 71, 73, 75, 77, 78, 80, 81, 82, 83, 87, 88, 90, 91, 93, 97, 98, 100, 101, 102, 105, 106, 110, 111, 112, 115, 122, 125, 128, 130, 132, 134, 135, 138, 140, 141, 143, 148, 151, 152, 153, 154, 155, 157, 158, 159, 161, 166], "vee": [78, 98], "veen": 1, "vega": 159, "vehicl": 69, "vehtari": [1, 56], "veloc": [18, 46, 119, 120, 126, 128], "venn": 8, "ventur": 69, "venv": 142, "verbos": [39, 70, 74, 75, 81, 107], "verdict": [8, 67], "veri": [4, 7, 8, 9, 16, 30, 37, 38, 39, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 58, 61, 67, 69, 70, 71, 72, 76, 77, 78, 80, 81, 83, 84, 87, 90, 91, 99, 101, 102, 105, 106, 109, 110, 115, 116, 135, 138, 140, 148, 149, 152, 153, 156, 157, 158, 159, 161, 164, 166, 168], "verif": 48, "verifi": [3, 13, 19, 24, 39, 42, 44, 47, 48, 58, 68, 74, 132, 135, 141, 142, 147, 155, 157, 158, 161], "vernon": [1, 61], "versa": [135, 161], "version": [16, 24, 28, 29, 33, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 54, 55, 56, 67, 69, 71, 72, 74, 75, 78, 81, 90, 93, 98, 112, 126, 128, 131, 132, 138, 139, 142, 144, 148, 149, 150, 151, 153, 156, 157, 158, 159, 167], "versu": [43, 57, 68, 83, 87], "vert": [35, 39, 50, 71, 93, 132, 135, 161, 164, 166], "vert_1": 71, "vert_2": 71, "vertic": [4, 9, 22, 42, 58, 99, 149], "verticalalign": [9, 47], "vgb10": [1, 51], "vgb14": [1, 51], "via": [4, 18, 19, 32, 39, 46, 48, 49, 50, 51, 52, 53, 69, 71, 72, 73, 76, 77, 80, 93, 95, 96, 100, 107, 115, 128, 130, 135, 140, 142, 143, 147, 148, 156, 158, 159, 161], "viabl": 68, "vice": [135, 161], "vicin": 56, "video": [68, 72, 131], "vien": 61, "view": [9, 28, 30, 35, 43, 44, 45, 48, 58, 61, 66, 69, 71, 72, 77, 81, 133, 138, 141, 152, 157, 161], "view_init": 70, "viewpoint": [50, 121, 135], "vincent": 85, "violat": [8, 24], "virtu": [20, 62, 64], "virtual": [73, 142], "viru": 142, "visibl": 18, "vision": [69, 76], "visit": [149, 158], "visual": [20, 24, 31, 39, 42, 43, 44, 46, 48, 49, 52, 56, 58, 69, 70, 72, 75, 76, 78, 80, 82, 88, 91, 93, 107, 131, 132, 138, 148, 149, 151, 157, 161, 166], "vlg": [1, 51], "vline": [44, 46, 157], "vm": 46, "vmatrix": 3, "vmax": 70, "vmeasur": 46, "vmin": 70, "vocabulari": [22, 37, 45], "volum": [1, 4, 6, 39, 41, 46, 49, 51, 56, 67, 104, 118, 138, 152, 153, 154, 157, 158, 159], "volume_theta": [152, 157], "von": 109, "von_neumann": 109, "vote": 70, "vp": 83, "vp_mat": 54, "vp_mat_inv": 54, "vp_tran": 132, "vsigma": 46, "vstack": 22, "vt": 132, "vulner": 68, "vw15": [1, 71], "vysochanskii": 51, "w": [1, 4, 41, 42, 49, 72, 73, 75, 77, 79, 93, 100, 101, 122, 132, 138, 148, 156], "w_": [72, 73, 93], "w_0": [70, 72, 75, 77, 79, 93], "w_1": [70, 72, 75, 77, 79, 93], "w_1_2": [78, 98], "w_1x": 93, "w_2": [70, 72, 77, 79, 93], "w_2_out": [78, 98], "w_i": [77, 158], "w_in_1": [78, 98], "w_j": 93, "w_jx_j": 72, "w_p": [72, 93], "w_pad": 38, "w_std": 134, "wa": [0, 4, 7, 8, 15, 24, 26, 28, 30, 39, 44, 45, 49, 51, 52, 53, 54, 55, 56, 58, 61, 66, 67, 68, 71, 72, 76, 77, 78, 79, 82, 84, 86, 93, 98, 100, 101, 102, 112, 115, 119, 122, 124, 128, 134, 135, 138, 142, 148, 149, 150, 152, 155, 156, 157, 158, 159, 161, 166, 167], "wahlstr\u00f6m": 1, "wai": [0, 4, 5, 7, 8, 9, 12, 13, 16, 18, 22, 23, 24, 27, 28, 30, 34, 39, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 56, 58, 60, 64, 67, 68, 69, 70, 72, 73, 74, 76, 78, 80, 83, 85, 87, 91, 93, 100, 102, 110, 111, 115, 122, 132, 135, 137, 138, 139, 147, 149, 150, 158, 159, 161, 166, 167], "waic": 56, "wak": [1, 138], "walk": [15, 41, 49, 55, 148, 153, 158, 165], "walker": [6, 41, 43, 46, 55, 56, 101, 128, 147, 148, 151, 152, 157, 164, 168], "wall": [43, 46, 55, 98, 148, 149], "wang": [1, 138], "want": [0, 9, 11, 12, 13, 16, 18, 20, 23, 24, 27, 35, 36, 39, 41, 42, 44, 45, 46, 47, 48, 49, 53, 55, 56, 61, 63, 64, 68, 73, 74, 76, 77, 78, 82, 83, 84, 86, 87, 88, 91, 95, 97, 99, 101, 103, 109, 131, 136, 139, 140, 141, 142, 145, 147, 148, 149, 151, 152, 154, 156, 157, 159, 161, 164], "wantonli": 66, "ware": 48, "warm": [43, 46, 55, 106, 132, 148, 150, 151, 159, 164, 167], "warm_up_step": [150, 167], "warmup": [43, 46, 55, 108, 148], "warn": [20, 55, 58, 74, 78, 82, 88, 97, 98, 101, 128, 138, 148, 149], "warnup": 43, "warrant": 71, "warranti": 81, "wash": 56, "washington": [56, 85], "wasn": 156, "wasserman": 58, "wast": [53, 57, 71, 80, 159], "wave": [7, 22, 28, 50, 51, 52, 137, 139], "wavelength": 125, "we": [0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 83, 84, 85, 86, 87, 88, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 165, 166, 167], "weak": [20, 48, 51, 52, 57, 58, 83, 87, 112, 151], "weaker": 87, "weakli": [45, 48, 57, 83, 87, 122], "wear": [1, 158], "weather": [16, 72], "web": [22, 139], "webpag": 54, "websit": [68, 92], "webster": 115, "week": [61, 97], "weigh": [43, 58], "weight": [1, 24, 30, 38, 39, 43, 45, 49, 53, 58, 65, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 90, 98, 100, 122, 124, 128, 134, 148, 151, 156, 158, 159], "weight_0": [69, 70], "weight_1": 70, "weight_2": 70, "weight_std": 134, "weights_1_2": [78, 98], "weights_2_out": [78, 98], "weights_in_1": [78, 98], "weiguang": [1, 49, 61], "welcom": 8, "well": [0, 3, 7, 8, 12, 18, 24, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 56, 58, 63, 64, 68, 69, 71, 72, 76, 77, 78, 82, 85, 88, 90, 93, 98, 100, 101, 102, 110, 118, 122, 128, 132, 138, 139, 142, 148, 149, 151, 152, 153, 156, 157, 158, 159, 163, 166], "went": 67, "were": [4, 16, 20, 21, 23, 28, 30, 36, 37, 39, 43, 46, 48, 49, 52, 53, 55, 56, 58, 68, 76, 78, 80, 81, 93, 101, 134, 138, 147, 149, 157, 161], "wesolowski": [61, 131], "wessel": [1, 71], "what": [0, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 22, 23, 26, 27, 28, 30, 34, 35, 36, 37, 38, 39, 42, 43, 45, 46, 47, 48, 52, 54, 55, 57, 58, 61, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 79, 80, 82, 83, 87, 88, 90, 91, 93, 95, 97, 99, 101, 119, 130, 131, 132, 135, 136, 137, 139, 140, 142, 147, 148, 149, 150, 153, 155, 156, 159, 161, 163, 166, 167, 168], "whatev": [26, 27, 42, 47, 69, 137], "when": [4, 8, 15, 16, 19, 20, 22, 27, 28, 30, 32, 34, 35, 36, 39, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 55, 56, 57, 58, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 87, 88, 90, 91, 93, 97, 100, 101, 102, 105, 108, 111, 115, 116, 117, 118, 119, 122, 126, 127, 128, 129, 132, 135, 138, 139, 141, 148, 149, 150, 152, 153, 154, 156, 157, 158, 159, 161, 164, 166, 167, 168], "whenev": [68, 85, 128, 135], "where": [3, 4, 5, 8, 9, 10, 13, 16, 18, 19, 20, 21, 22, 24, 28, 30, 34, 35, 37, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 66, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 82, 83, 84, 86, 87, 88, 90, 91, 93, 95, 97, 98, 99, 100, 101, 102, 105, 106, 107, 109, 110, 111, 112, 115, 117, 118, 119, 120, 122, 125, 126, 128, 130, 131, 132, 135, 138, 139, 140, 142, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 164, 166, 167, 168], "wherea": [8, 36, 39, 48, 58, 70, 71, 140, 141], "wherebi": 16, "wherein": [53, 67, 72], "whether": [16, 22, 27, 34, 37, 39, 42, 43, 45, 48, 54, 56, 58, 63, 68, 93, 99, 109, 135, 139, 149, 153, 158, 159, 164], "which": [0, 4, 5, 8, 9, 12, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 30, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 80, 81, 82, 83, 84, 85, 87, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 110, 111, 112, 115, 116, 117, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 137, 138, 139, 140, 141, 142, 145, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 165, 166, 168], "while": [0, 4, 18, 20, 24, 27, 28, 30, 37, 39, 43, 49, 51, 52, 53, 56, 58, 63, 68, 70, 71, 72, 73, 76, 78, 81, 83, 84, 86, 90, 91, 93, 94, 96, 110, 112, 115, 130, 135, 137, 139, 140, 141, 142, 149, 151, 152, 156, 157, 158, 159, 164, 166, 168], "whilst": [82, 88], "whistl": 139, "white": [68, 82, 87, 88, 90, 91, 122, 148], "who": [16, 48, 51, 53, 58, 61, 66, 67, 68, 69, 140], "whoever": 30, "whole": [75, 78, 80, 98, 140, 141], "whose": [22, 36, 39, 41, 58, 63, 70, 71, 90, 115, 131, 135, 159, 161], "why": [1, 5, 8, 9, 12, 15, 24, 28, 30, 31, 35, 36, 37, 39, 44, 45, 47, 49, 53, 70, 71, 75, 76, 78, 81, 82, 83, 84, 87, 93, 98, 100, 105, 106, 122, 131, 132, 138, 139, 141, 149, 152, 156, 157, 158, 161, 166], "wide": [39, 41, 48, 53, 56, 58, 69, 73, 76, 80, 90, 122, 127, 141, 159], "widehat": [49, 57, 159], "wider": [43, 78], "widespread": [153, 158, 159], "widetild": [39, 84, 91], "widget": [5, 11, 24, 35, 131, 143], "width": [9, 22, 30, 34, 38, 39, 42, 43, 47, 48, 55, 57, 58, 70, 72, 76, 80, 81, 87, 94, 95, 101, 131, 134, 137, 138, 147, 148, 149, 151, 158, 159, 164, 168], "wiecki": [78, 98, 149], "wieringen": [1, 71], "wierstra": 1, "wiggl": 109, "wigner": 122, "wiki": 109, "wikimedia": 48, "wikipedia": [24, 54, 57, 82, 94, 109, 126, 133], "wild": 54, "wildli": 42, "wilei": 1, "willemsen": 1, "william": [0, 1, 7, 28, 58, 90, 91], "willing": 8, "win": [16, 30, 82, 153], "window": [98, 128, 139, 142, 148], "wine": 7, "winner": 67, "wisdom": [53, 71], "wise": [66, 72, 76, 77, 78, 82, 83, 87, 88, 132, 141], "wish": [9, 35, 48, 49, 66, 82, 83, 87, 88, 93, 135, 138], "with_errorbar": [39, 107], "within": [3, 6, 16, 18, 19, 20, 24, 43, 44, 48, 49, 51, 52, 53, 56, 58, 63, 65, 67, 68, 69, 71, 76, 84, 93, 99, 100, 101, 105, 109, 122, 128, 135, 138, 142, 148, 149, 151, 152, 153, 156, 157, 158, 161, 166], "without": [1, 8, 39, 45, 49, 50, 51, 52, 54, 58, 61, 64, 66, 67, 69, 72, 74, 81, 84, 85, 87, 90, 91, 93, 94, 97, 98, 100, 101, 116, 120, 122, 124, 126, 132, 135, 139, 140, 148, 156, 161, 164, 168], "wm": 156, "wmap": 45, "wno": [78, 98], "women": [68, 135], "won": [43, 68, 78, 130, 137, 138, 149, 152, 153, 157], "wooff": [1, 51], "word": [26, 27, 36, 43, 45, 46, 47, 51, 54, 58, 63, 71, 80, 82, 83, 87, 88, 132, 135, 138, 140, 147, 148, 149, 161, 166], "work": [1, 3, 5, 9, 12, 13, 14, 20, 22, 24, 28, 32, 34, 37, 38, 39, 42, 43, 48, 49, 53, 54, 55, 56, 58, 61, 66, 68, 70, 72, 73, 76, 77, 78, 84, 85, 87, 91, 93, 95, 97, 98, 100, 101, 102, 106, 107, 122, 125, 126, 128, 132, 133, 135, 138, 139, 140, 141, 142, 147, 148, 149, 152, 153, 156, 157, 158, 159, 164], "worker": [68, 128], "workflow": [32, 33, 52, 62, 65, 139, 163], "workhors": 165, "world": [8, 16, 26, 45, 52, 68, 78, 82, 103, 139, 140], "worldwid": 138, "worri": [45, 48, 58], "wors": [70, 71, 80], "worsen": 68, "worst": 52, "worth": [28, 56, 66, 100, 102, 110], "worthwhil": 28, "would": [0, 3, 4, 8, 15, 16, 18, 20, 22, 23, 24, 26, 28, 30, 34, 37, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 56, 58, 61, 68, 70, 71, 72, 73, 75, 76, 77, 78, 80, 90, 93, 97, 98, 100, 104, 105, 111, 119, 120, 122, 130, 135, 138, 139, 149, 150, 152, 153, 156, 157, 158, 159, 161, 166, 167], "wreck": 68, "write": [9, 16, 24, 28, 29, 30, 35, 37, 39, 45, 46, 47, 52, 53, 54, 57, 61, 63, 69, 70, 71, 72, 73, 76, 78, 81, 82, 83, 87, 88, 90, 91, 98, 105, 107, 128, 130, 131, 132, 135, 138, 139, 149, 158], "writer": 131, "writervideo": 131, "written": [0, 3, 4, 5, 18, 19, 27, 39, 49, 50, 53, 56, 58, 68, 69, 73, 78, 82, 83, 87, 88, 90, 91, 98, 104, 128, 138, 141, 155, 158, 161, 163], "wrong": [12, 16, 20, 24, 34, 39, 41, 49, 53, 64, 68, 72, 81, 102, 103, 105, 106, 113, 151, 164], "wrote": [27, 28, 64, 67, 164], "wrt": [38, 76], "wt": 52, "wvar": 38, "www": [1, 56, 74, 81, 142], "x": [0, 1, 3, 4, 5, 6, 9, 13, 19, 20, 21, 22, 24, 27, 28, 29, 30, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 90, 91, 93, 97, 98, 99, 100, 101, 104, 105, 106, 107, 109, 122, 125, 126, 128, 130, 131, 132, 134, 135, 138, 139, 140, 141, 142, 143, 145, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 161, 164, 166, 167, 168], "x0": [45, 46, 47, 97, 101, 158], "x0_max": [47, 75], "x0_min": [47, 75], "x0_pt": 47, "x0_true": [41, 47, 147], "x1": [28, 70, 75, 83, 97, 98, 101, 128, 135], "x1_max": 75, "x1_min": 75, "x1_orig": 70, "x1sq": 83, "x1x2": [70, 135], "x1x2_grid": 70, "x2": [28, 45, 70, 75, 83, 98, 128, 135], "x27": [75, 156], "x2_orig": 70, "x2givenx0_fig": 161, "x2sq": 83, "x_": [3, 4, 19, 21, 39, 46, 47, 49, 70, 83, 87, 90, 99, 101, 105, 122, 149, 161, 164, 166], "x_0": [3, 4, 18, 20, 21, 22, 24, 28, 41, 42, 58, 70, 75, 93, 95, 101, 125, 147, 161, 166, 168], "x_1": [0, 19, 22, 24, 28, 38, 39, 44, 53, 57, 70, 72, 75, 77, 79, 83, 84, 87, 91, 93, 95, 101, 105, 106, 128, 132, 135, 152, 157, 161, 163, 166, 168], "x_2": [0, 19, 22, 24, 28, 38, 39, 57, 70, 72, 75, 77, 79, 83, 84, 87, 91, 93, 105, 106, 132, 135, 161, 163, 166], "x_3": [39, 72, 91, 166], "x_arang": 140, "x_arr": 46, "x_beta": 22, "x_co": 76, "x_col": 87, "x_cosh": 76, "x_cv": 100, "x_d": [38, 83], "x_data": 70, "x_data_pt": 54, "x_dist": [22, 47, 131], "x_exp": 76, "x_fit": 100, "x_gamma": 131, "x_i": [3, 4, 27, 29, 30, 34, 36, 37, 38, 39, 41, 43, 44, 45, 46, 49, 53, 54, 58, 70, 72, 77, 87, 91, 100, 105, 125, 128, 132, 135, 148, 151, 152, 157, 158, 161, 166], "x_ip": 29, "x_j": [4, 19, 24, 53, 87, 93, 101, 125, 151, 161, 166], "x_k": [4, 41, 42, 44, 47, 87, 101, 147, 152, 157, 166], "x_l": 72, "x_label": 47, "x_list": 140, "x_log": 76, "x_m": [19, 44, 152, 157, 161], "x_max": [38, 42, 46, 47, 54, 100, 131, 148], "x_max_index": [9, 22, 35, 131], "x_mean": 46, "x_min": [38, 42, 46, 47, 100], "x_n": [24, 38, 53, 57, 72, 87, 128, 132, 135, 158, 161, 166], "x_new": 87, "x_norm": [22, 131], "x_norm_val": 34, "x_p": 93, "x_posterior": 46, "x_pt": [5, 38, 42, 45, 47, 54, 83, 139, 140], "x_pts_all": 54, "x_rang": 140, "x_row": 87, "x_row_til": 87, "x_sampl": 97, "x_sin": 76, "x_sinh": 76, "x_sort": 101, "x_sqrt": 76, "x_squar": 76, "x_t": [22, 49, 131, 149, 164, 166], "x_tensor": 134, "x_test": [74, 76, 78, 79, 98], "x_train": [70, 74, 76, 78, 79, 85, 86, 98, 100], "x_true": 86, "x_valu": 42, "x_with_fixedh": 46, "xarrai": [138, 156], "xavier": 76, "xaxi": 131, "xbar": [132, 164], "xbin": 46, "xdata": [39, 46, 70, 107], "xfit": [43, 46], "xi": [82, 88, 97, 152, 157], "xilin": 1, "xing": 1, "xk": 101, "xk_pt": 42, "xlabel": [20, 43, 74, 76, 78, 81, 82, 83, 85, 86, 87, 98, 100, 101, 128, 139, 149], "xlim": [78, 83, 87, 98, 134, 156], "xlinspac": 3, "xmax": [39, 46, 47, 101, 107], "xmeasur": [39, 107], "xmgivenx0_fig": 161, "xmin": [39, 46, 47, 101, 107], "xmode": 135, "xnew": [82, 88], "xp": [29, 82, 83, 87, 88], "xposterior": 46, "xposterior_fixedh": 46, "xposterior_pdfh": 46, "xrealiti": [39, 107], "xrightarrow": [49, 122], "xsq": 83, "xstar": 70, "xt": [83, 87], "xtick": [74, 81], "xtrue": 82, "xu": [1, 138], "xv": 55, "xvec": [28, 83, 84, 91, 151], "xvec_1": [84, 91], "xvec_2": [84, 91], "xx": [132, 135], "xx0": 75, "xx1": 75, "xx_j": 19, "xy": [9, 20, 22, 29, 41, 42, 47, 83, 131, 132, 135, 149], "xycoord": [9, 47], "xytext": [22, 131, 149], "y": [0, 3, 4, 5, 6, 9, 13, 19, 20, 21, 22, 27, 28, 29, 30, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 53, 55, 57, 58, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 90, 93, 97, 98, 99, 100, 101, 102, 106, 107, 122, 125, 128, 130, 131, 132, 134, 135, 139, 140, 148, 150, 151, 154, 155, 157, 158, 161, 163, 166, 167, 168], "y0": [47, 166], "y0_true": [41, 47, 147], "y1": [87, 135], "y2": [45, 87, 135], "y_": [0, 3, 34, 39, 45, 87, 93, 105, 122, 130, 132, 148, 161, 163, 164], "y_0": [18, 20, 21, 41, 47, 58, 147, 161, 164, 166, 168], "y_1": [9, 19, 37, 39, 53, 57, 72, 84, 87, 93, 105, 106, 135, 161, 164], "y_2": [9, 19, 37, 39, 57, 72, 84, 87, 93, 105, 106, 135], "y_3": 9, "y_cv": 100, "y_d": 87, "y_data_pt": 54, "y_determinist": 166, "y_fit": 100, "y_i": [3, 19, 34, 39, 43, 45, 46, 53, 54, 56, 57, 70, 71, 72, 73, 87, 100, 102, 105, 130, 132, 148, 158, 166], "y_j": [19, 27, 36, 37, 71, 72, 87, 93, 151], "y_k": 87, "y_logit": 93, "y_m": [19, 43, 45, 46, 54, 100, 148], "y_max": [9, 166], "y_mean": [86, 166], "y_model": [45, 46, 54, 148], "y_n": [53, 57, 161], "y_ob": [156, 157], "y_obs_dim_0": 156, "y_obs_dim_0pandasindexpandasindex": 156, "y_perceptron": 93, "y_pt": [38, 42, 54, 139], "y_reconstruct": 5, "y_run": 166, "y_sampl": [86, 97], "y_sort": 70, "y_std": 86, "y_stochast": 166, "y_t": 164, "y_tanh": 93, "y_test": [74, 76, 78, 98], "y_train": [70, 74, 76, 78, 85, 86, 98, 100], "y_train_noisi": 85, "y_true": [5, 86], "y_vec": 54, "y_x": 87, "yaida": 1, "yau": 1, "yaxi": 131, "ybar": 132, "ybin": 46, "ydata": [39, 46, 107], "ye": [27, 39, 41, 69, 93, 161], "year": [30, 61, 67, 68, 82, 122], "yellow": 159, "yerr": [46, 101, 128], "yerror": [39, 107], "yet": [8, 16, 36, 39, 48, 54, 107, 126, 132, 161], "yexp": 0, "yfit": [43, 46], "yfunc": 82, "yhat_hard_grid": 70, "yhat_knn_grid": 70, "yhat_soft_grid": 70, "yhi95": [82, 88], "yhii": [82, 88], "yi": [83, 87, 135, 152, 157], "yield": [7, 27, 28, 30, 36, 37, 39, 43, 51, 52, 57, 58, 70, 71, 72, 91, 108, 122, 125, 131, 138], "ylabel": [20, 43, 76, 78, 81, 82, 83, 85, 86, 87, 88, 98, 100, 101, 128, 148, 149], "ylim": [74, 78, 81, 83, 86, 87, 98, 134, 148, 149, 156], "ylo95": [82, 88], "yloi": [82, 88], "ymean": [82, 88], "ymeani": [82, 88], "ymin": 101, "yml": [0, 75, 98, 142, 145], "ynew": [82, 88], "yoram": 1, "york": [55, 61, 148, 149], "yoshioka": 78, "you": [0, 3, 4, 5, 8, 9, 11, 12, 15, 16, 18, 22, 23, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 55, 56, 57, 58, 64, 67, 68, 69, 70, 71, 72, 74, 76, 78, 79, 81, 82, 84, 86, 88, 91, 93, 95, 97, 98, 99, 100, 101, 102, 105, 106, 107, 111, 122, 124, 130, 131, 132, 135, 136, 138, 139, 140, 141, 142, 144, 145, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 161, 166, 167], "young": [68, 69], "your": [0, 7, 8, 11, 12, 15, 16, 22, 24, 27, 36, 37, 39, 41, 42, 44, 45, 47, 54, 61, 67, 68, 69, 70, 71, 72, 74, 76, 78, 79, 81, 82, 90, 95, 98, 99, 100, 102, 131, 132, 135, 136, 139, 144, 145, 147, 148, 149, 150, 151, 152, 156, 157, 158, 163, 166, 167], "yourself": [16, 18, 23, 27, 35, 36, 42, 95, 101, 139], "yp": 83, "yt": [83, 87], "yth": 0, "ytick": [74, 81], "ytrue": 82, "yvar": [82, 88], "yvari": [82, 88], "yvec": [132, 151], "z": [5, 19, 20, 21, 38, 39, 42, 49, 51, 55, 56, 69, 70, 72, 73, 75, 76, 77, 82, 83, 84, 87, 88, 90, 93, 97, 101, 104, 122, 126, 132, 135, 138, 153, 156, 164], "z_": [73, 93, 122], "z_0": [18, 20, 21], "z_1": [51, 93], "z_2": [51, 93], "z_grid": [42, 70], "z_i": [43, 51], "z_j": [51, 72, 93], "z_k": 73, "z_m": [51, 77], "z_n": 90, "z_p": [58, 100], "z_q": 58, "z_w": 77, "zdir": 70, "zdist": 87, "zeiler": 1, "zeiler12": [1, 112], "zenodo": 48, "zero": [3, 6, 9, 18, 20, 21, 24, 28, 29, 30, 34, 38, 39, 42, 43, 45, 47, 53, 54, 55, 58, 61, 70, 71, 72, 73, 76, 77, 80, 82, 83, 87, 88, 90, 91, 93, 100, 101, 102, 107, 112, 122, 125, 130, 131, 132, 134, 135, 136, 138, 139, 148, 149, 150, 151, 153, 155, 159, 161, 163, 164, 166, 167], "zero_grad": 76, "zeros_lik": [0, 21, 30, 35, 46, 70, 101, 135], "zeta": [52, 125], "zeta_i": 52, "zeus_multimod": 168, "zhang": 1, "zip": [38, 43, 70, 82, 88, 101, 128, 132, 135], "zm_h": 138, "zoom": 47, "zorder": [39, 86, 107], "zrang": 87, "\u00b2": 128, "\u00e9": 1, "\u03bc": 134, "\u03c3": 134}, "titles": ["<span class=\"section-number\">34. </span>Guide to Jupyter Book markdown", "<span class=\"section-number\">33. </span>Bibliography", "<span class=\"section-number\">12. </span>Assigning probabilities", "<span class=\"section-number\">12.1. </span>Assigning probabilities (I): Indifferences and translation groups", "<span class=\"section-number\">12.2. </span>Assigning probabilities (II): The principle of maximum entropy", "<span class=\"section-number\">12.3. </span>\ud83d\udce5 Maximum Entropy for reconstructing a function from its moments", "\ud83d\udce5 Demonstration: Prior PDFs for straight lines", "<span class=\"section-number\">7.1. </span>Advantages of the Bayesian approach", "<span class=\"section-number\">4.7. </span>*Aside: Bayesian epistemology", "<span class=\"section-number\">6.7. </span>\ud83d\udce5 Demonstration: Coin tossing (with widget)", "<span class=\"section-number\">6. </span>Updating via Bayes\u2019 rule", "<span class=\"section-number\">6.1. </span>Coin tossing: Frequentists and Bayesaians", "<span class=\"section-number\">6.2. </span>When do priors matter? When don\u2019t they matter?", "<span class=\"section-number\">6.3. </span>Computing the posterior analytically", "<span class=\"section-number\">6.4. </span>Degree of belief/credibility intervals vs frequentist 1-sigma intervals", "<span class=\"section-number\">6.5. </span>Take-aways and follow-up questions from coin flipping:", "<span class=\"section-number\">4.6. </span>Data, models, and predictions", "<span class=\"section-number\">8. </span>Error propagation", "<span class=\"section-number\">8.1. </span>Error propagation (I): Nuisance parameters and marginalization", "<span class=\"section-number\">8.2. </span>Error propagation (II): Changing variables", "<span class=\"section-number\">8.3. </span>Error propagation (III): A useful approximation", "<span class=\"section-number\">8.4. </span>Solutions", "<span class=\"section-number\">5.1. </span>\ud83d\udce5 Exploring PDFs", "Follow-up questions and answers to the <em>Exploring PDFs</em> section.", "<span class=\"section-number\">5.2. </span>Gaussians: A couple of frequentist connections", "<span class=\"section-number\">4. </span>Inference and PDFs", "<span class=\"section-number\">4.1. </span>Statements", "<span class=\"section-number\">4.2. </span>Manipulating probabilities: Bayesian rules of probability as principles of logic", "<span class=\"section-number\">4.3. </span>Probability density functions", "<span class=\"section-number\">4.4. </span>Looking ahead", "<span class=\"section-number\">4.5. </span>Review of Bayes\u2019 theorem", "<span class=\"section-number\">5. </span>Bayesian posteriors", "<span class=\"section-number\">3. </span>Bayesian methods for scientific modeling", "<span class=\"section-number\">7. </span>Bayes in practice", "<span class=\"section-number\">5.4. </span>\ud83d\udce5 Demonstration: Sum of normal variables squared", "<span class=\"section-number\">6.6. </span>\ud83d\udce5 Demonstration:  Bayesian Coin Tossing", "<span class=\"section-number\">9.2. </span>Exercise: Standard medical example using Bayes", "<span class=\"section-number\">9.1. </span>Exercise: Checking the sum and product rules", "\ud83d\udce5 Visualization of the Central Limit Theorem", "<span class=\"section-number\">7.3. </span>Bayesian Linear Regression (BLR)", "<span class=\"section-number\">9. </span>Exercises for Part I", "<span class=\"section-number\">5.3. </span>Interpreting 2D posteriors", "<span class=\"section-number\">9.5. </span>\ud83d\udce5 Amplitude of a signal in the presence of background", "<span class=\"section-number\">13. </span>\ud83d\udce5 Dealing with outliers", "<span class=\"section-number\">9.3. </span>\ud83d\udce5 Parameter estimation example: Gaussian noise and averages I", "<span class=\"section-number\">9.6. </span>Parameter estimation example: fitting a straight line", "<span class=\"section-number\">9.7. </span>\ud83d\udce5 Parameter estimation example: fitting a straight line II", "<span class=\"section-number\">9.4. </span>\ud83d\udce5 Radioactive lighthouse problem", "<span class=\"section-number\">7.2. </span>Bayesian research workflow", "<span class=\"section-number\">19.1. </span>Advanced Markov chain Monte Carlo sampling", "<span class=\"section-number\">29.1. </span>Bayes goes fast: Emulators", "<span class=\"section-number\">14. </span>Bayes goes linear: History matching", "<span class=\"section-number\">29.2. </span>Emulators", "<span class=\"section-number\">15.2. </span>Model mixing", "Evidence calculation for EFT expansions", "Demo: Multimodal distributions with two samplers", "Computing the Bayesian evidence", "Evidence for an expansion", "<span class=\"section-number\">15.1. </span>Model Selection", "<span class=\"section-number\">15. </span>Multi-model inference with Bayes", "<span class=\"section-number\">10. </span>Overview of Part II: Advanced Bayesian methods", "About this Jupyter Book", "<span class=\"section-number\">2. </span>Introduction", "<span class=\"section-number\">2.1. </span>Physicist\u2019s perspective", "<span class=\"section-number\">2.2. </span>Bayesian workflow", "<span class=\"section-number\">2.3. </span>Machine learning", "<span class=\"section-number\">2.4. </span>Virtues", "<span class=\"section-number\">1. </span>Invitation to inductive inference", "<span class=\"section-number\">24.9. </span>Data bias and fairness in machine learning", "<span class=\"section-number\">24. </span>Machine learning: Overview and notation", "<span class=\"section-number\">23.5. </span>Machine Learning: First Examples", "<span class=\"section-number\">24.8. </span>Model validation", "<span class=\"section-number\">24.5. </span>Artifical neural networks", "<span class=\"section-number\">24.10. </span>*Neural networks: Backpropagation", "<span class=\"section-number\">24.6. </span>Demonstration: Neural network classifier", "<span class=\"section-number\">23.6. </span>Exercise: Logistic Regression and neural networks", "<span class=\"section-number\">24.7. </span>Feed-forward neural network for a function in PyTorch", "<span class=\"section-number\">26. </span>Bayesian neural networks", "<span class=\"section-number\">26.4. </span>Demonstration: Variational Inference and Bayesian Neural Networks", "<span class=\"section-number\">26.5. </span>Exercise: Bayesian neural networks", "<span class=\"section-number\">27. </span>*Convolutional Neural Networks", "<span class=\"section-number\">27.6. </span>Demonstration: Image recognition with Convolutional Neural Networks", "Exercise: Gaussian Process models with GPy", "Gaussian processes demonstration", "Lecture 20", "Gaussian Processes regression: basic introductory example", "Illustration of prior and posterior Gaussian process for different kernels", "Demonstration: Gaussian processes", "Exercise: Gaussian processes using <code class=\"docutils literal notranslate\"><span class=\"pre\">GPy</span></code>", "<span class=\"section-number\">22.6. </span>GPy demo notebooks", "<span class=\"section-number\">22.4. </span>Gaussian processes", "<span class=\"section-number\">22. </span>Overview of Gaussian process", "<span class=\"section-number\">22.5. </span>Scikit-learn demo notebooks", "<span class=\"section-number\">23. </span>Logistic Regression", "<span class=\"section-number\">21. </span>Machine Learning", "Overview of Mini-project IIb: How many lines?", "Overview of TALENT mini-projects", "Mini-project IIIa: Bayesian Optimization", "Mini-project IIIb: Bayesian Neural Networks", "Mini-project I: Parameter estimation for a toy model of an EFT", "Mini-project IIa: Model selection basics", "Mini-project IIb: How many lines are there?", "<span class=\"section-number\">36. </span>Gradient-descent optimization", "<span class=\"section-number\">39. </span>Linear models", "<span class=\"section-number\">39.1. </span>Definition of linear models", "<span class=\"section-number\">39.2. </span>Regression analysis with linear models", "<span class=\"section-number\">39.3. </span>Ordinary linear regression: warmup", "<span class=\"section-number\">39.4. </span>Ordinary linear regression in practice", "<span class=\"section-number\">39.5. </span>Solutions", "<span class=\"section-number\">40. </span>Mathematical optimization", "<span class=\"section-number\">40.1. </span>Gradient-descent optimization", "<span class=\"section-number\">40.2. </span>Batch, stochastic and mini-batch gradient descent", "<span class=\"section-number\">40.3. </span>Adaptive gradient descent algorithms", "<span class=\"section-number\">38. </span>Overview of modeling", "<span class=\"section-number\">38.1. </span>Notation", "<span class=\"section-number\">38.2. </span>Models in science", "<span class=\"section-number\">38.3. </span>Parametric versus non-parametric models", "<span class=\"section-number\">38.4. </span>Linear versus non-linear models", "<span class=\"section-number\">38.5. </span>Regression analysis: optimization versus inference", "<span class=\"section-number\">38.6. </span>Exercises", "<span class=\"section-number\">38.7. </span>Solutions", "<span class=\"section-number\">37. </span>Overview of scientific modeling material", "<span class=\"section-number\">25. </span>ANNs in the large-width limit", "<span class=\"section-number\">11. </span>Bayesian approach to model discrepancy", "<span class=\"section-number\">11.1. </span>KOH and BOH discrepancy models", "<span class=\"section-number\">11.2. </span>Framework", "<span class=\"section-number\">11.3. </span>The ball-drop model", "<span class=\"section-number\">29. </span>Emulators", "<span class=\"section-number\">11.4. </span>\ud83d\udce5 Model discrepancy example: The ball-drop experiment", "<span class=\"section-number\">28. </span>Overview of other topics", "<span class=\"section-number\">31. </span>PCA, SVD, and all that", "<span class=\"section-number\">30. </span>Student t distribution as a mixture of Gaussians", "<span class=\"section-number\">31.5. </span>\ud83d\udce5 Linear algebra games including SVD for PCA", "<span class=\"section-number\">32. </span>Quantum Bayesianism (QBism)", "<span class=\"section-number\">25.3. </span>\ud83d\udce5 Distributions of Randomly-Initialized ANNs", "<span class=\"section-number\">35. </span>Statistics concepts and notation", "<span class=\"section-number\">41. </span>Overview of getting started materials", "<span class=\"section-number\">43.7. </span>\ud83d\udce5 Making a simple widget-based UI", "<span class=\"section-number\">43.6. </span>\ud83d\udce5 Demonstration: Reading Data and fitting", "<span class=\"section-number\">42. </span>\ud83d\udce5 Exercise: Jupyter Notebooks and Python", "<span class=\"section-number\">43.4. </span>\ud83d\udce5 Exercise: Python lists and iterations", "<span class=\"section-number\">43.5. </span>\ud83d\udce5 Exercise: Linear algebra operations with NumPy", "<span class=\"section-number\">44.1. </span>Using Anaconda", "<span class=\"section-number\">43. </span>More on Python and using Jupyter notebooks", "<span class=\"section-number\">44. </span>Setting up to use this Jupyter book", "<span class=\"section-number\">44.2. </span>Using GitHub", "<span class=\"section-number\">19. </span>Advanced Markov Chain Monte Carlo", "<span class=\"section-number\">18.4. </span>Assignment: 2D radioactive lighthouse location using MCMC", "<span class=\"section-number\">19.2. </span>Overview: MCMC Diagnostics", "<span class=\"section-number\">17.11. </span>Exercise: Random walk", "<span class=\"section-number\">17.7. </span>Metropolis-Hasting MCMC sampling of a Poisson distribution", "<span class=\"section-number\">19.4. </span>Lecture 12", "<span class=\"section-number\">17.10. </span>Parameter estimation example: Gaussian noise and averages II", "<span class=\"section-number\">20.1. </span>Hamiltonian Monte Carlo (HMC) overview and visualization", "Liouville Theorem Visualization", "Solving orbital equations with different algorithms", "<span class=\"section-number\">20.3. </span>PyMC Introduction", "<span class=\"section-number\">20.4. </span>Comparing samplers for a simple problem", "<span class=\"section-number\">18.2. </span>Markov chain Monte Carlo sampling", "<span class=\"section-number\">18.3. </span>MCMC Intro from BUQEYE", "<span class=\"section-number\">18. </span>Overview of Markov Chain Monte Carlo", "<span class=\"section-number\">18.1. </span>Markov chains", "<span class=\"section-number\">20. </span>HMC and other samplers", "Overview of Intro to PyMC notebook", "<span class=\"section-number\">17.9. </span>Recaps", "<span class=\"section-number\">16. </span>Overview of Part III: Sampling", "<span class=\"section-number\">17. </span>Stochastic processes", "<span class=\"section-number\">17.8. </span>Demonstration: Metropolis-Hasting MCMC sampling of a Poisson distribution", "<span class=\"section-number\">20.2. </span>The Zeus Ensemble Slice Sampler"], "titleterms": {"": [7, 49, 51, 58, 63, 70, 98, 137, 141], "0": [91, 98], "05": 98, "06068": 164, "1": [0, 14, 21, 36, 37, 38, 39, 43, 46, 70, 71, 72, 79, 82, 84, 88, 90, 91, 97, 98, 108, 120, 134, 135, 137, 148, 149, 161, 166], "10": [38, 161], "100": 98, "1000": 98, "11": [148, 161], "12": [151, 159, 161], "13": 161, "14": 161, "15": 161, "16": 158, "17": [158, 166], "1710": 164, "18": [158, 161], "1d": [22, 141], "2": [5, 34, 36, 37, 39, 43, 46, 72, 79, 82, 88, 97, 98, 120, 134, 135, 137, 149, 159, 161, 166], "20": 84, "2025": 142, "23": 70, "24": [71, 72], "2d": [41, 141, 147], "3": [5, 16, 21, 36, 37, 43, 46, 72, 79, 82, 88, 97, 98, 108, 120, 135, 137, 149, 161, 166], "30000": 98, "34": 0, "35": 135, "38": 120, "39": 108, "3d": 80, "4": [5, 16, 21, 36, 37, 43, 46, 70, 72, 76, 82, 88, 97, 98, 120, 135, 137, 161], "5": [5, 16, 21, 36, 37, 70, 71, 82, 98, 135, 137, 149, 161], "50": 38, "6": [16, 21, 36, 71, 135, 137, 161], "60000": 98, "7": [16, 21, 36, 71, 137, 161], "8": [21, 36, 71, 161], "9": [36, 71, 151, 161], "A": [20, 24, 43, 53, 58, 75, 79, 82, 88, 90, 93, 97, 101, 138, 161, 164], "But": [44, 152, 157], "For": 164, "In": [39, 156, 164], "No": [83, 87], "One": [8, 45, 58], "The": [0, 4, 16, 19, 21, 24, 30, 39, 43, 45, 46, 48, 49, 51, 54, 58, 68, 70, 71, 77, 80, 82, 83, 87, 88, 90, 93, 100, 105, 126, 128, 135, 139, 148, 158, 161, 168], "To": [22, 24, 98, 138], "With": 128, "_": 90, "ab": 50, "about": [24, 44, 61, 65, 76, 143, 151, 152, 157], "abov": 164, "acceler": 76, "accept": [148, 156, 164], "accumul": 132, "accuraci": 74, "acknowledg": [61, 78], "activ": [72, 73, 93], "ad": [38, 141], "adagrad": 112, "adam": 112, "adapt": 112, "add": [81, 137], "addendum": 39, "addit": 99, "adjust": 58, "admonit": 0, "advanc": [49, 60, 139, 146], "advantag": 7, "advi": 78, "agre": 164, "ahead": 29, "ai": 68, "aka": [22, 83, 87], "al": [84, 91, 148], "aleator": 77, "algebra": [54, 57, 90, 132, 141], "algorithm": [51, 68, 69, 72, 73, 93, 97, 112, 148, 149, 153, 155, 158, 159, 164], "all": [24, 36, 37, 130, 137, 157], "amplitud": 42, "an": [28, 57, 61, 99, 164, 166], "anaconda": 142, "analogi": 164, "analys": 24, "analysi": [101, 105, 115, 118, 147], "analyt": 13, "analyz": [42, 156], "ani": [137, 164], "ann": [122, 134], "anoth": [5, 22], "answer": [0, 3, 11, 12, 15, 16, 23, 24, 27, 28, 29, 36, 37, 39, 41, 52, 100, 101, 105, 164], "appli": [28, 132, 147, 152, 157], "applic": [56, 84, 130], "approach": [7, 43, 44, 46, 90, 123, 148, 152, 157], "approxim": [20, 41], "ar": [41, 84, 101, 141, 164], "architectur": [72, 80], "argument": 4, "arrai": [139, 140, 141], "art": 158, "artif": 72, "artifici": 72, "arxiv": 164, "asid": [8, 91, 132, 139, 140], "ask": 76, "aspect": 69, "aspir": 66, "assess": [34, 148, 151], "assign": [2, 3, 4, 147], "assum": 164, "assumpt": 53, "atom": 164, "attribut": 68, "autocorrel": [49, 148, 156, 164], "autom": 68, "avail": 156, "averag": [44, 53, 141, 152], "awai": [15, 30], "axiom": 30, "b": [37, 58, 164], "back": [73, 74], "background": [39, 41, 42, 91, 157], "backprop": 77, "backpropag": [73, 76], "bad": 43, "balanc": [149, 161, 164], "ball": [126, 128], "base": [57, 81, 137, 141, 164], "basi": [39, 86, 104], "basic": [58, 76, 77, 85, 93, 100, 132, 156, 159], "batch": [78, 111], "bay": [10, 27, 28, 30, 33, 36, 50, 51, 56, 59, 77, 147], "bayesaian": 11, "bayesian": [0, 7, 8, 9, 16, 22, 24, 27, 31, 32, 35, 36, 37, 39, 43, 44, 46, 48, 53, 56, 58, 60, 64, 66, 77, 78, 79, 97, 98, 100, 123, 133, 152, 157, 158], "bayesopt": 97, "bda3": 148, "befor": 101, "behavior": [38, 57], "belief": [9, 14, 35], "benchmark": 5, "beta": [13, 22], "between": [55, 164], "beyond": 66, "bia": [35, 68, 71], "bias": 68, "bibliographi": [0, 1], "binari": [70, 75, 93], "bind": [39, 104, 138], "bivari": [83, 97, 135], "blr": 39, "bma": 53, "bmm": 53, "boh": 124, "boldsymbol": [34, 90], "bonu": [99, 100], "book": [0, 61, 142, 143, 144], "bound": 77, "boundari": 70, "breakout": 46, "bridg": 78, "brief": [29, 48, 49, 61, 64, 80, 91, 138], "bring": 73, "build": [74, 80, 97], "buqey": 159, "c": [37, 90], "calcul": [41, 54, 56, 58], "call": 164, "callback": 137, "can": [24, 164], "cancel": 164, "carlo": [49, 146, 153, 158, 159, 160], "case": [4, 5, 13, 24, 46, 83, 166], "cauchi": 43, "cell": [0, 139], "central": [24, 38, 90, 135], "certain": 57, "chain": [49, 55, 73, 146, 148, 158, 159, 160, 161], "challeng": [73, 110, 158], "chang": [19, 57, 142], "characterist": [23, 27], "chart": 164, "chatgpt": [76, 134], "cheat": 143, "check": [7, 37, 48, 55, 57, 155, 159], "checklist": [0, 48], "checkpoint": [0, 3, 15, 16, 24, 27, 28, 29, 39, 52, 105], "chi": [34, 58], "choic": 98, "choos": 90, "cifar10": 81, "class": [0, 11, 22, 24, 41, 93, 128, 154, 156], "classif": [69, 70, 75, 79, 93], "classifi": [70, 74, 75, 78, 93, 98], "close": 53, "clt": 24, "cluster": 69, "cnn": [80, 81], "code": [0, 9, 70, 73, 74, 76, 134, 135, 139, 159], "coin": [9, 11, 15, 24, 30, 35], "collect": 164, "color": 0, "colorblind": 135, "combin": [82, 88], "command": 145, "comment": 99, "common": [4, 76, 157], "compa": 68, "compact": 93, "compar": [38, 41, 157], "comparison": [7, 34, 58, 140], "compil": 81, "complex": [71, 76, 78, 98], "compon": 132, "comprehens": 140, "compress": 132, "comput": [13, 56, 76, 82, 88], "concaten": 141, "concept": 135, "conda": 142, "condit": [135, 159, 161, 164, 166], "confid": [23, 24], "conjug": [13, 54], "connect": 24, "consequ": 24, "conserv": [43, 155], "continu": [4, 39, 50, 109, 135], "continuum": 30, "contrast": [24, 53], "control": 137, "converg": [49, 55, 148, 151], "convers": 141, "convert": 39, "convolut": [72, 80, 81], "cookbook": 86, "core": [83, 87], "correct": 43, "correl": [18, 21, 41, 58, 84, 135, 151], "cost": [70, 73, 93], "could": 45, "coupl": 24, "cours": 132, "covari": [82, 83, 87, 88, 90, 132, 135], "cow": 67, "creat": [75, 81, 137, 140, 141, 142], "credibl": [14, 24, 135], "criteria": 56, "crocodil": 67, "cross": [71, 93, 100], "current": 78, "curv": [71, 102], "custom": 76, "d": [38, 164], "data": [16, 39, 42, 43, 45, 46, 54, 57, 68, 69, 70, 74, 78, 79, 81, 82, 88, 98, 101, 132, 138, 141, 142, 147, 148, 157], "dataset": [80, 81, 85, 86], "deal": 43, "debug": 139, "decis": 70, "decomposit": 130, "deep": [72, 78, 93], "default": 76, "defin": [5, 47, 128], "definit": [39, 73, 104, 135, 166], "degre": [9, 14, 35], "delta": [18, 159], "demo": [55, 89, 92], "demolit": 67, "demonstr": [6, 9, 34, 35, 74, 78, 81, 83, 87, 138, 167], "dens": 81, "densiti": [22, 28, 135, 164], "depend": [58, 83, 87, 119, 120], "derbi": 67, "deriv": [4, 73, 164], "descent": [102, 110, 111, 112], "design": [39, 105, 161], "detail": [76, 149, 159, 161, 164], "determin": [35, 48, 84, 93, 141], "develop": [74, 75], "deviat": 141, "diagnost": [49, 148, 156], "diagon": 130, "differ": [0, 5, 58, 86, 101, 155], "dimens": 159, "dimension": [69, 83, 87, 141], "dirac": 18, "discrep": [119, 120, 123, 124, 128], "discret": [3, 109, 135, 158, 161], "discuss": [8, 39, 43, 58, 135, 152, 157, 166], "displai": 137, "dissect": 132, "distanc": [18, 20, 21], "distribut": [4, 16, 22, 38, 39, 42, 48, 55, 76, 83, 87, 90, 91, 131, 134, 135, 150, 151, 158, 161, 164, 167], "diverg": 77, "do": [12, 24, 38, 45, 54, 74, 91, 97, 98, 100, 128, 132, 148, 150, 151, 164], "doe": [41, 57], "dof": 34, "don": [12, 80], "donut": 159, "dot": [86, 141], "download": 81, "dr": 58, "draw": [38, 91, 140], "drawn": 38, "drop": [39, 104, 126, 128], "duke": 132, "e": 164, "each": [24, 38, 58, 76, 137], "edwin": 67, "effect": 5, "eft": [54, 99], "eigendecomposit": 132, "eigenvalu": 141, "eigenvector": [50, 141], "elabor": 137, "eleg": 90, "element": 141, "elementwis": 141, "elicit": 48, "ellips": 41, "emce": [101, 128, 157, 158], "emul": [50, 52, 84, 127], "energi": [39, 57, 104, 138, 155], "ensembl": 168, "entropi": [4, 5, 93], "env": 142, "environ": 142, "epistem": 77, "epistemologi": 8, "equal": 13, "equat": [0, 39, 73, 105, 132, 155], "equilibrium": 164, "errat": 43, "error": [17, 18, 19, 20, 21, 39, 46, 68, 70, 71, 148], "estim": [0, 7, 16, 23, 44, 45, 46, 58, 82, 88, 99, 101, 135, 152, 157, 158], "et": [84, 91, 148], "ethic": [68, 69], "evalu": [74, 81], "event": 135, "everi": 151, "everyth": 22, "evid": [54, 56, 57, 58, 77, 100], "evolut": 131, "exampl": [3, 28, 30, 36, 38, 39, 41, 43, 44, 45, 46, 56, 68, 70, 75, 76, 80, 82, 83, 85, 87, 97, 119, 120, 128, 135, 141, 152, 156, 159, 164, 166], "exchang": 164, "exercis": [0, 11, 16, 21, 24, 36, 37, 39, 40, 45, 70, 71, 72, 75, 79, 82, 84, 88, 108, 119, 120, 130, 132, 135, 139, 140, 141, 149, 156, 158, 161, 166], "exp": 86, "expans": [54, 57], "expect": [29, 72, 135], "experi": [57, 128], "experiment": [48, 128], "explan": 76, "explicit": 137, "explor": [22, 23, 41, 74, 100, 101, 139], "exponenti": [4, 166], "express": [76, 93, 139, 147], "extend": 93, "extern": 0, "f": 159, "factor": 56, "failur": 5, "fair": [30, 68], "falsifi": 24, "fast": 50, "favorit": 101, "featur": [61, 93, 139], "feed": [72, 76, 134], "feedback": 72, "fft": 38, "fig": 148, "figur": [0, 42, 137, 139, 147, 151], "file": 0, "fill": 164, "final": 73, "find": [132, 141], "first": [13, 38, 70, 73, 137, 138, 157], "fit": [45, 46, 100, 138, 148], "fix": [38, 46], "flat": 13, "flip": [9, 15, 24, 161], "flop": 161, "fold": 71, "follow": [15, 23, 36, 42, 75, 82, 151], "foreman": 151, "form": [39, 132], "formal": 48, "formul": [43, 128], "forward": [72, 76, 134], "four": [48, 64], "fourier": 38, "fourth": 38, "framework": 125, "free": 85, "frequentist": [8, 11, 14, 24, 43, 58, 152, 157], "friend": 30, "from": [5, 15, 38, 76, 79, 82, 84, 88, 91, 101, 132, 141, 142, 145, 151, 156, 158, 159, 164], "frontmatt": 0, "full": [46, 80], "function": [5, 13, 18, 22, 28, 39, 45, 48, 68, 70, 73, 75, 76, 82, 83, 86, 87, 88, 90, 93, 104, 135, 137, 139, 154, 159], "further": 141, "g": 164, "galact": [18, 20, 21], "game": [91, 132], "gaussian": [4, 18, 20, 21, 22, 24, 38, 39, 41, 44, 54, 58, 82, 83, 85, 86, 87, 88, 90, 91, 131, 135, 152, 157, 166], "gelman": [49, 148, 156], "gener": [39, 69, 78, 85, 86, 98, 101, 128, 135, 137, 147, 157, 158], "get": [61, 82, 88, 136, 139, 159, 163], "github": [142, 145], "given": [82, 88], "global": 109, "goal": [99, 101, 147], "goe": [50, 51], "good": [43, 143], "gothenburg": 161, "gp": [83, 84, 87, 90, 91], "gpu": 76, "gpy": [82, 88, 89], "gpyopt": 97, "gradient": [76, 102, 110, 111, 112], "graphic": 139, "gregori": 159, "group": [3, 68], "growth": 166, "guid": [0, 61, 143], "guidelin": 68, "h_0": 46, "ha": [78, 98, 148], "hamiltonian": [49, 153], "handl": [46, 69], "happen": 164, "harmon": 24, "hast": [149, 150, 158, 159, 167], "have": 57, "hbar": [83, 87], "height": 128, "help": [7, 61, 139], "helper": [22, 86], "here": 101, "hick": 156, "hidden": 0, "higdon": 84, "high": [87, 159], "higher": [57, 164], "highli": 84, "hint": [24, 37, 39, 72], "histogram": 131, "histori": 51, "hmc": [153, 162], "hogg": 151, "how": [7, 45, 57, 76, 91, 95, 99, 101, 148, 164], "huber": 43, "hybrid": 7, "hydrogen": 164, "hyperparamet": 90, "hypothesi": 58, "i": [3, 13, 18, 22, 24, 30, 38, 40, 44, 65, 84, 99, 161, 164], "icon": 61, "idea": 58, "ii": [4, 13, 19, 46, 60, 152], "iia": 100, "iib": [95, 101], "iii": [20, 165], "iiia": 97, "iiib": 98, "illustr": [49, 86], "imag": [80, 81, 132], "implement": [45, 71, 156, 158], "implicit": 68, "import": [5, 43, 49, 55, 78, 81, 82, 88, 97, 100, 101, 132, 135, 137, 138, 147, 149, 156], "improv": 45, "includ": [68, 132], "independ": [58, 119, 120, 135], "index": [132, 141], "indiffer": 3, "induct": 67, "infer": [0, 7, 18, 20, 21, 25, 46, 48, 53, 59, 66, 67, 77, 78, 79, 90, 98, 115, 118, 158], "inferencedata": 156, "infinit": 83, "info": 91, "inform": [56, 76], "infti": 57, "ingredi": [30, 69], "initi": [76, 134], "initio": 50, "input": [82, 88, 134, 137], "insert": 0, "instal": [76, 142, 145], "integr": [38, 54, 101, 151, 158], "interactive_output": 137, "interfac": [9, 137], "interlud": 151, "interpret": 41, "interv": [9, 14, 23, 24, 35], "intial": 76, "intro": [159, 163], "introduct": [22, 62, 74, 91, 135, 156, 166], "introductori": 85, "intuit": [83, 151, 164], "invari": 3, "invers": [39, 141], "invit": 67, "ipython": 137, "ipywidget": 137, "ir": 49, "issu": 61, "iter": [51, 98, 140], "its": 5, "jayn": 67, "joint": [28, 135], "jupyt": [0, 6, 9, 61, 138, 139, 142, 143, 144, 145], "justifi": 24, "k": [70, 71, 83, 87], "kernel": [83, 86, 87, 90, 142], "knn": [70, 71], "know": [91, 143, 148], "known": 101, "koh": 124, "kraken": 137, "kullback": 77, "l": 73, "l1": 4, "label": 0, "langl": 159, "laplac": 58, "larg": [71, 122], "lasso": 71, "law": 158, "layer": [80, 81], "layout": 137, "learn": [65, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79, 92, 93, 94, 98, 99, 101, 102, 142, 147], "learningfromdata": 145, "least": [39, 105], "lectur": [84, 151], "leibler": 77, "length": 141, "let": [78, 98], "lighthous": [41, 47, 147], "like": 5, "likelihood": [13, 39, 41, 43, 46, 48, 55, 93, 100], "limit": [24, 30, 38, 49, 57, 68, 72, 122, 161], "line": [3, 6, 45, 46, 95, 101, 140, 145, 148], "linear": [39, 51, 54, 57, 70, 72, 90, 103, 104, 105, 106, 107, 117, 119, 120, 132, 141], "liouvil": 154, "liquid": [39, 104], "list": [140, 141], "ll": 42, "local": 109, "locat": [3, 147], "log": [4, 24, 149], "logic": 27, "logist": [75, 79, 93], "look": [5, 29, 78, 98, 163], "lorentzian": 149, "loss": 43, "lower": 77, "m": 53, "machin": [65, 68, 69, 70, 78, 94], "mackei": 151, "macro": 0, "main": [9, 69], "major": 141, "make": [74, 76, 81, 91, 131, 137, 151, 154, 164], "mani": [43, 90, 95, 101], "manipul": [27, 132, 141], "margin": [18, 28, 30, 39, 46, 135, 151], "mark": 0, "markdown": [0, 139], "markov": [49, 146, 158, 159, 160, 161], "mass": [135, 138], "match": [51, 131], "materi": [61, 121, 136], "mathbf": [82, 88], "mathcal": [53, 91], "mathemat": [72, 76, 109, 139], "matplotlib": [22, 139], "matric": [132, 141], "matrix": [39, 72, 90, 105, 130, 132, 141, 161], "matter": 12, "mat\u00e9rn": 86, "maxent": 4, "maxim": 4, "maximum": [4, 5, 46, 93, 100, 141], "mc": 159, "mcmc": [49, 79, 101, 147, 148, 149, 150, 151, 158, 159, 164, 167], "mean": [4, 38, 41, 49, 87, 90, 135, 148], "measur": 135, "mechan": 24, "median": 135, "medic": [27, 36], "meet": 138, "melendez": 91, "memori": 161, "menu": [61, 139], "method": [32, 49, 50, 51, 58, 60, 76, 137, 158], "metropoli": [149, 150, 158, 159, 161, 164, 167], "mh": [55, 148, 159, 164], "mini": [78, 95, 96, 97, 98, 99, 100, 101, 111], "minim": [5, 93, 109, 137], "minimum": 141, "misclassif": 70, "mix": 53, "mixtur": 131, "mnist": 80, "mode": 135, "model": [3, 6, 7, 16, 32, 34, 39, 43, 45, 46, 48, 50, 53, 54, 58, 59, 69, 71, 72, 73, 74, 77, 78, 81, 82, 83, 87, 88, 90, 98, 99, 100, 103, 104, 105, 113, 115, 116, 117, 119, 120, 121, 123, 124, 126, 128, 148, 156, 166], "modul": [43, 82, 88, 97, 100, 138, 149], "moment": [5, 29, 135], "monkei": 4, "mont": [49, 146, 153, 158, 159, 160], "moor": 39, "moral": 66, "more": [57, 71, 93, 119, 120, 137, 143, 159], "move": 164, "movi": 131, "multi": [53, 59], "multilay": 73, "multimod": 55, "multipl": [53, 140, 141], "multivari": [39, 58, 83, 87, 91, 97, 135], "n": [5, 38, 57, 90, 91, 98, 141, 164], "n_a": 164, "n_b": 164, "n_sampl": 98, "naiv": 159, "name": 6, "ndarrai": 141, "nearest": 70, "need": [5, 42], "neighbor": 70, "net": 75, "network": [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 98], "neural": [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 98], "neuron": [72, 80], "new": 90, "newcommand": 34, "next": [51, 78], "nn": [71, 80], "nois": [41, 44, 85, 98, 152], "noisi": [72, 85], "non": [90, 116, 117, 119, 120], "norm": 4, "normal": [4, 22, 30, 34, 39, 58, 70, 76, 83, 87, 90, 91, 105], "notat": [69, 72, 90, 93, 114, 135, 166], "note": [0, 34, 54, 159], "notebook": [24, 84, 89, 92, 138, 139, 142, 143, 145, 156, 163], "now": [55, 76, 128, 157, 164], "nuclear": [39, 50, 104, 138], "nuisanc": [18, 43, 46], "number": [19, 20, 21, 135], "numer": [38, 141, 158], "numpi": [139, 140, 141], "object": [90, 156], "observ": [128, 137], "obtain": [90, 161], "occam": 7, "odd": 100, "omega": [83, 87], "one": [38, 76], "onli": [38, 137, 164], "onlin": [61, 143], "open": [53, 61], "oper": [76, 140, 141], "optic": 161, "optim": [93, 97, 102, 109, 110, 118], "option": [97, 137, 149], "orbit": 155, "order": [50, 100, 141], "ordinari": [39, 105, 106, 107], "organ": 138, "origin": [134, 157], "oscil": 24, "other": [129, 162, 164], "our": 138, "out": 164, "outlier": 43, "output": [73, 134, 137], "over": [71, 164], "overfit": 68, "overgener": 68, "overview": [60, 69, 91, 95, 96, 113, 121, 129, 136, 148, 153, 160, 163, 165], "own": [57, 75, 97], "p": [24, 164], "pair": 84, "panda": 138, "paper": 84, "par": 34, "parallel": [56, 101], "paramet": [0, 7, 16, 18, 43, 44, 45, 46, 58, 82, 88, 93, 98, 99, 101, 140, 152, 157], "parametr": [7, 90, 116], "part": [40, 60, 88, 149, 165], "pass": 137, "pca": [130, 132], "pdf": [4, 6, 18, 22, 23, 25, 28, 42, 46, 135, 147, 149, 158], "pendulum": 154, "penros": 39, "penultim": 13, "perceptron": [70, 73, 93], "perform": 101, "permut": 3, "perspect": 63, "philosoph": 8, "physic": [65, 128, 153], "physicist": 63, "pi": 158, "pick": 155, "plausibl": 67, "plot": [5, 22, 47, 83, 87, 128, 131, 139, 140, 148, 155, 156], "plu": [97, 100], "pocomc": 128, "point": [23, 38, 135, 164], "poisson": [4, 38, 42, 150, 159, 164, 167], "polya": 67, "polynomi": [39, 100, 104, 105], "popul": 27, "possibl": [0, 11, 27, 56], "posterior": [13, 16, 22, 31, 39, 41, 47, 48, 55, 86, 128, 148, 164], "potenti": [5, 155], "power": 158, "practic": [27, 33, 39, 77, 107], "predict": [16, 39, 48, 57, 74, 78, 81, 90, 98], "preliminari": [130, 131, 132], "prelud": 39, "prepar": [42, 81], "presenc": 42, "princip": 132, "principl": [4, 27, 68], "prior": [6, 12, 13, 39, 44, 45, 48, 54, 55, 58, 84, 86, 128, 152, 157], "probabilist": [77, 78], "probabl": [2, 3, 4, 8, 22, 27, 28, 30, 36, 37, 78, 93, 98, 135, 149, 164, 166], "problem": [27, 47, 75, 79, 101, 157, 158], "proce": 99, "process": [82, 83, 85, 86, 87, 88, 90, 91, 161, 166], "product": [20, 21, 27, 30, 37, 86, 141], "prof": 58, "program": 78, "project": [22, 95, 96, 97, 98, 99, 100, 101], "prompt": 134, "proof": [13, 24], "propag": [17, 18, 19, 20, 46, 72, 73, 74], "properti": [39, 141, 164], "propos": 164, "prove": 39, "pseudo": [39, 135, 159], "pt": [55, 101], "ptemce": 101, "pukelsheim": 51, "pump": 161, "put": 101, "pymc": [156, 157, 163], "pymc3": [77, 78, 158], "pymultinest": 158, "pystan": 158, "python": [6, 9, 22, 43, 55, 69, 132, 139, 140, 143, 147], "pytorch": 76, "q": 164, "qbism": 133, "quadradt": 86, "quadrat": 41, "quadratur": 158, "qualiti": 66, "quantum": 133, "question": [0, 3, 4, 5, 12, 15, 16, 23, 24, 27, 28, 29, 36, 37, 39, 41, 46, 52, 75, 88, 90, 93, 100, 105, 149, 150, 159], "quick": [22, 135], "quot": 156, "r2": 70, "radial": 86, "radioact": [47, 147], "random": [19, 21, 90, 135, 149, 159, 161, 164, 166], "randomli": 134, "rang": [58, 140], "rangl": 159, "rank": 141, "rate": [148, 156], "rather": 38, "ratio": [100, 164], "ration": 86, "razor": 7, "rbf": [83, 87], "read": 138, "real": 138, "reason": 67, "recal": [13, 159, 164], "recap": [54, 84, 164], "recognit": 81, "reconstruct": 5, "recurr": 72, "reduc": 50, "reduct": [50, 69, 80, 132], "refer": [0, 36, 37, 90, 133], "referenc": 0, "region": [76, 135, 149], "regress": [39, 69, 70, 71, 75, 79, 82, 83, 85, 87, 88, 90, 93, 105, 106, 107, 115, 118], "regular": [71, 80, 93], "relat": 164, "releas": 137, "remark": [0, 8, 71], "remind": 138, "remnant": 161, "remov": 141, "report": 68, "reproduc": 48, "request": 101, "requir": 68, "resampl": 49, "research": 48, "reshap": 141, "result": [5, 41, 48, 54, 156], "return": 84, "revers": 161, "review": [22, 30, 49, 83], "revisit": [20, 148], "rewrit": 39, "rewritten": 93, "ridg": 71, "rightarrow": 57, "rmsprop": 112, "rob": 156, "root": [19, 20, 21], "routin": 141, "row": 141, "rubin": [49, 148, 156], "rule": [10, 24, 27, 30, 36, 37, 51, 72, 73, 147, 159], "run": [82, 142, 147, 151], "sampl": [18, 22, 23, 38, 41, 43, 49, 55, 79, 82, 83, 87, 88, 128, 149, 150, 151, 156, 157, 158, 159, 161, 164, 165, 167], "sampler": [55, 101, 128, 156, 157, 162, 168], "save": 139, "scalar": 141, "scale": [3, 78, 80, 98], "scandinavian": 4, "scienc": [7, 69, 115], "scientif": [32, 121], "scientist": 66, "scikit": [75, 79, 92], "scipi": [22, 135], "score": [70, 71], "second": [38, 137], "sect": 151, "section": [0, 23, 100, 159], "select": [39, 58, 68, 84, 100, 141], "sens": 91, "sensit": 39, "set": [6, 9, 53, 73, 79, 80, 82, 88, 128, 137, 144, 157], "setup": [128, 156], "shape": 141, "sheet": 143, "shell": [83, 87], "shortcut": 139, "should": [101, 143], "sigma": [14, 51], "sigmoid": 70, "signal": [41, 42, 72], "signific": 24, "simpl": [72, 75, 79, 137, 157, 161, 166], "sine": 86, "singl": [38, 46], "singular": 130, "sivia": 41, "size": [38, 141], "slant": 41, "slice": 168, "societi": 69, "soft": 70, "softmax": 93, "solut": [0, 16, 21, 39, 45, 70, 71, 72, 101, 108, 120, 135, 158, 161, 166], "solv": [132, 155], "some": [22, 131], "sort": 141, "sound": [0, 48], "space": 53, "spars": 141, "sparsiti": 122, "special": [24, 65, 141, 166], "specif": [78, 98], "specifi": 76, "spectral": 101, "speed": 140, "split": 141, "spot": 39, "squar": [19, 20, 21, 34, 39, 58, 86, 105], "standard": [19, 21, 22, 27, 36, 43, 93, 141, 148], "start": [61, 82, 88, 136, 163], "stat": [22, 135], "state": [24, 158, 161], "statement": [26, 101, 132], "stationari": [90, 161, 164], "statist": [0, 24, 48, 51, 54, 58, 115, 128, 135, 141, 158], "step": [24, 46, 48, 64, 76, 78], "stochast": [111, 161, 166], "stori": 58, "straight": [3, 6, 45, 46, 148], "strategi": 101, "string": 139, "structur": 159, "student": [22, 131], "studi": 71, "style": 128, "sub": 75, "subtask": [99, 101], "suggest": [76, 99], "sum": [18, 20, 21, 27, 30, 34, 37, 38, 90], "summari": [8, 19, 29, 46, 90, 138, 164], "supervis": 72, "surfac": [78, 98], "svd": [130, 132], "switch": 76, "symmetr": [130, 164], "symmetri": 3, "system": 68, "systemat": [46, 80], "t": [12, 22, 80, 131], "tab": 137, "tabl": 41, "take": [15, 20, 30], "taken": 132, "tale": 53, "talent": 96, "target": [85, 90], "task": [75, 79, 82, 149], "tell": 76, "temper": [56, 101], "tensor": 76, "tensorflow": [74, 81], "term": [73, 164], "terminologi": 72, "test": [34, 49, 58, 97], "test_siz": 98, "text": 34, "than": 38, "theano": 78, "thei": 12, "them": 0, "theorem": [24, 27, 28, 30, 38, 154], "theori": [30, 50, 128], "thermodynam": [101, 164], "theta": 34, "thetavec": 164, "thetavec_i": 164, "thi": [30, 45, 57, 61, 76, 91, 97, 100, 143, 144, 148, 164], "thing": [45, 54, 100, 132, 134, 150], "think": [24, 164], "third": [38, 137], "those": 164, "three": [51, 69], "through": 140, "time": [151, 164], "tip": 0, "togeth": 73, "toi": [54, 99], "top": [41, 81], "topic": 129, "toss": [9, 11, 30, 35], "total": 164, "trace": 141, "tradeoff": 71, "train": [68, 70, 71, 74, 77, 81], "transform": [38, 39, 80], "translat": 3, "trend": 78, "trick": 90, "true": 54, "try": [5, 55, 134, 138], "two": [18, 38, 39, 41, 53, 55, 58, 93, 161], "type": [68, 69, 72, 135, 141], "ubiqu": 24, "ui": [9, 137], "uncertainti": [7, 77, 78, 98], "uncorrel": 4, "underfit": [68, 71], "uniform": [13, 39, 135, 158], "univari": [97, 148], "up": [6, 9, 15, 23, 36, 39, 42, 73, 75, 80, 82, 137, 144, 157], "updat": [9, 10, 35, 142], "uphil": 164, "url": 0, "us": [4, 18, 20, 24, 27, 36, 46, 53, 54, 75, 76, 79, 80, 88, 90, 101, 132, 142, 143, 144, 145, 147, 149, 164], "user": [9, 137], "util": [76, 154], "v": [14, 141], "valid": [70, 71, 100], "valu": [24, 29, 78, 98, 101, 130, 135, 137, 141], "variabl": [19, 21, 34, 38, 41, 76, 90, 135], "varianc": [4, 49, 71, 135, 141], "variat": [55, 77, 78, 79, 98], "vector": 72, "verbatim": 156, "verif": 76, "verifi": [23, 81, 164], "versu": [116, 117, 118, 140, 141], "via": 10, "view": [8, 39], "virtu": 66, "visual": [22, 28, 38, 153, 154, 158, 159], "volum": 80, "walk": [149, 159, 161, 164, 166], "wamb": 48, "want": 137, "warm": 39, "warmup": [39, 106], "warn": 0, "we": [5, 42, 57, 91, 148, 159, 164], "weather": 161, "websit": [76, 91], "weight": [72, 93], "well": [80, 84], "went": 164, "were": 164, "what": [5, 24, 41, 44, 51, 65, 78, 84, 98, 100, 141, 143, 151, 152, 157, 164], "when": [12, 24, 142], "why": [4, 72, 159, 164], "wide": 72, "widget": [9, 137, 139], "width": 122, "winter": 161, "without": 128, "workflow": [39, 48, 64], "would": 164, "x": [18, 82, 88], "x_0": 47, "x_a": 164, "x_b": 164, "y": 18, "yet": 5, "you": [24, 54, 61, 137, 143, 151, 164], "your": [57, 75, 97, 101, 142], "yourself": 138, "z": 18, "z_j": 73, "zero": 141, "zeu": [55, 157, 168]}})