Search.setIndex({"alltitles": {"": [[0, "exercise:ppd_definition_b"], [16, "exercise:ppd_definition"], [16, "exercise:pdf_normalization"], [16, "exercise:rain"], [16, "exercise:monty_hall"], [16, "exercise:coin_ppd"], [34, "exercise:ols_example_1_b"], [34, "exercise:ols_example_2_b"], [34, "exercise:ols_example_3_b"], [34, "exercise:ols_example_4_b"], [34, "exercise:ols_example_5_b"], [48, "id1"], [98, "exercise:ols_example_1"], [98, "exercise:ols_example_2"], [98, "exercise:ols_example_3"], [98, "exercise:ols_example_4"], [98, "exercise:ols_example_5"], [143, "exercise:StochasticProcess:first-example"], [143, "exercise:conditional-probabilities-stochastic-process"], [143, "exercise:construct-stochastic-process"]], " (A reversible Markov chain)": [[138, "exercise:MarkovChains:reversible-chain"]], " (A reversible Markov process)": [[138, "example:reversible-markov-process"]], " (A simple Markov process)": [[138, "example:simple-markov-process"]], " (An exponential growth model)": [[143, "example:exponential-growth-models"]], " (Bayes\u2019 rule/theorem)": [[25, "property:bayes_rule"]], " (Binary classification)": [[65, "example:MLexamples:binary-classification"]], " (Bivariate pdf)": [[112, "exercise:Statistics:bivariate-pdf"]], " (Checklist for statistically sound Bayesian inference)": [[0, "remark:BayesianWorkflow:buqeye-checklist_b"], [43, "remark:BayesianWorkflow:buqeye-checklist"]], " (Conditional discrete probability mass function)": [[112, "exercise:Statistics:conditional-discrete-pmf"]], " (Conditional distributions)": [[138, "exercise:MarkovChains:conditional-distributions"]], " (Conditional expectation)": [[112, "exercise:Statistics:conditional-expectation"]], " (Conditional probabilities of a stochastic process)": [[143, "example:conditional-stochastic-process"]], " (Conditional probability for continuous variables)": [[112, "exercise:Statistics:conditional-probability-continuous"]], " (Conditional probability)": [[112, "definition:conditional-probability"]], " (Conditional probability-distribution)": [[112, "definition:conditional-probability-distribution"]], " (Correlated errors)": [[7, "exercise:BayesianAdvantage:correlated-errors"]], " (Covariance and correlation)": [[112, "definition:covariance-correlation"]], " (Detailed balance)": [[138, "exercise:detailed-balance"]], " (Eigenvector continuation in ab initio nuclear theory)": [[45, "example-0"]], " (Expectation value)": [[112, "definition:expectation-value"]], " (Expected signal)": [[67, "exercise:NeuralNet:expected-signal"]], " (Flip-flop)": [[138, "exercise:flip-flop"]], " (Gaussian process)": [[143, "definition:gaussian-process"]], " (Gaussian product of errors)": [[7, "exercise:BayesianAdvantages:gaussian-product-of-errors"]], " (Gaussian sum of errors)": [[7, "exercise:BayesianAdvantages:gaussian-sum-of-errors"]], " (Generalized normal equation)": [[34, "exercise:BayesianLinearRegression:GeneralizedNormalEquation"]], " (Global minimization)": [[99, "definition:MathematicalOptimization:global-minimization"]], " (Gothenburg winter weather)": [[138, "exercise:MarkovChains:gothenburg-winter-weather"]], " (Gradient descent optimization)": [[99, "algorithm:MathematicalOptimization:gradient-descent"]], " (Illustration of S/IR)": [[44, "example-3"]], " (Implement k-fold cross validation)": [[66, "exercise:ModelValidation:kfold-cross-validation"]], " (Independence)": [[112, "property:independence"]], " (Independent and dependent)": [[100, "exercise:OverviewModeling:independent-dependent"]], " (Independent events)": [[112, "definition:independent-events"]], " (Inferring galactic distances)": [[7, "example:BayesianAdvantage:inferring-galactic-distances"], [7, "exercise:BayesianAdvantages:inferring-galactic-distances-ex"]], " (Inferring galactic distances\u2014revisited)": [[7, "example:BayesianAdvantage:inferring-galactic-distances-revisited"]], " (Is it reversible?)": [[138, "exercise:is-it-reversible"]], " (Joint probability distribution)": [[112, "definition:joint-probability-distribution"]], " (Large training error)": [[66, "exercise:ModelValidation:large-training-error"]], " (Limiting distribution)": [[138, "definition:limiting-distribution"], [138, "exercise:limiting-distribution"]], " (Linear models)": [[100, "example:OverviewModeling:linear-models"]], " (Linear or non-linear)": [[100, "exercise:OverviewModeling:linear-nonlinear"]], " (Linear or non-linear; more examples)": [[100, "exercise:OverviewModeling:linear-nonlinear-examples"]], " (Linear signals)": [[67, "exercise:NeuralNet:linear-signal"]], " (Liquid-drop model for nuclear binding energies)": [[34, "example:LinearModels:liquid-drop-model_b"], [98, "example:LinearModels:liquid-drop-model"]], " (Local minimization)": [[99, "definition:MathematicalOptimization:local-minimization"]], " (Marginal density functions)": [[112, "property:marginal-density-functions"]], " (Markov chains)": [[138, "definition:markov-chains"]], " (Metropolis sampling of a uniform distribution)": [[135, "exercise:metropolis-sampling-uniform"]], " (Misclassification cost function)": [[65, "exercise:MLexamples:misclassification-cost-function"]], " (Model discrepancy)": [[100, "exercise:OverviewModeling:model-discrepancy"]], " (Monte Carlo estimation of \\pi)": [[135, "example-0"]], " (Non-linear models)": [[100, "example:OverviewModeling:nonlinear-models"]], " (Optical pumping)": [[138, "exercise:optical-pumping"]], " (Ordinary least squares (the normal equation))": [[34, "theorem:BayesianLinearRegression:normal-equation_b"], [98, "theorem:LinearModels:normal-equation"]], " (Polynomial basis functions)": [[34, "example:polynomial-linear-model_b"], [98, "example:polynomial-linear-model"]], " (Power-law distributions)": [[135, "exercise:power-law-distribution-sampling"]], " (Practicing the sum and product rule with population characteristics)": [[22, "exercise:Inferenceandpdfs:sumandproductrule"]], " (Prior and posterior predictive checking)": [[43, "remark:BayesianWorkflow:predictive-checking"]], " (Probability density function)": [[112, "definition:probability-density-function"]], " (Probability mass function)": [[112, "definition:probability-mass-function"]], " (Probability measure)": [[112, "definition:probability-measure"]], " (Product rule)": [[25, "property:product_rule"]], " (Prove the Gaussian likelihood)": [[34, "exercise:BayesianLinearRegression:likelihood_pars_b"]], " (R2 score)": [[65, "exercise:MLexamples:R2-score"]], " (Random and colorblind)": [[112, "exercise:Statistics:colorblind"]], " (Random variable and distribution function)": [[112, "definition:random-variable"]], " (Regression analysis)": [[100, "definition:OverviewModeling:regression-analysis"]], " (Remnant memory)": [[138, "exercise:MarkovChains:memory"]], " (Reversibility)": [[138, "exercise:MarkovChains:reversibility"]], " (Scipy.stats)": [[112, "exercise:Statistics:scipy-stats"]], " (Sigmoid decision boundary)": [[65, "exercise:MLexamples:sigmoid-decision-boundary"]], " (Simple random walk)": [[138, "exercise:MarkovChains:simple-random-walk"], [143, "example:simple-random-walk"]], " (Stationary Gothenburg winter weather)": [[138, "exercise:stationary-gothenburg-winter-weather"]], " (Stationary distribution of \u201cA simple Markov process\u201d)": [[138, "example:stationary-simple-markov-process"]], " (Stationary distribution)": [[138, "definition:stationary-distribution"], [138, "exercise:MarkovChains:stationary-distribution"]], " (Stationary processes)": [[138, "definition:stationary-processes"]], " (Stationary two-state distribution)": [[138, "exercise:stationary-2x2"]], " (Statistical inference)": [[100, "definition:OverviewModeling:statistical-inference"]], " (Stochastic matrix)": [[138, "exercise:MarkovChains:stochastic-matrix"]], " (Study of model bias and variance)": [[66, "exercise:ModelValidation:study-model-bias-variance"]], " (Sum of two Gaussian  PDFs)": [[7, "exercise:BayesianAdvantage:complete-the square"]], " (Sum rule)": [[25, "property:sum_rule"]], " (Taking the square root of a number)": [[7, "example:BayesianAdvantage:taking-square-root"]], " (The Gelman-Rubin diagnostic)": [[44, "algorithm:AdvancedMCMC:gelman-rubin"]], " (The Hamiltonian Monte Carlo method)": [[44, "algorithm:AdvancedMCMC:HMC"]], " (The Metropolis algorithm for a discrete distribution)": [[135, "exercise:MCMC:discrete-metropolis"]], " (The Metropolis design for obtaining a discrete limiting distribution)": [[138, "remark:MCMC:Metropolis-discrete"]], " (The Metropolis-Hastings algorithm)": [[135, "algorithm-1"]], " (The Sampling/Importance Resampling method)": [[44, "algorithm:AdvancedMCMC:SIR"]], " (The WAMBS checklist)": [[43, "remark:BayesianWorkflow:wambs-checklist"]], " (The bias-variance tradeoff)": [[66, "theorem:ModelValidation:bias-variance"]], " (The design matrix for polynomial models)": [[34, "example:design-matrix-polynomial-models_b"], [98, "example:design-matrix-polynomial-models"]], " (The history-matching algorithm)": [[46, "algorithm:BayesLinear:History-Matching"]], " (The square root of a number)": [[7, "exercise:BayesianAdvantages:square-root-of-a-number"]], " (The standard random variable)": [[7, "exercise:BayesianAdvantages:standard-random-variable"]], " (Using Bayesian rules of probability on a standard medical problem)": [[22, "exercise:Inferenceandpdfs:medicalexample"]], " (Validation errors)": [[65, "exercise:MLexamples:validation-errors"]], " (Variance)": [[112, "definition:variance"]], " (Warm-up Bayesian linear regression (data errors))": [[34, "exercise:BayesianLinearRegression:warmup_errors"]], " (Warm-up Bayesian linear regression (prior sensitivity))": [[34, "exercise:BayesianLinearRegression:warmup_priors"]], " (Warm-up Bayesian linear regression)": [[34, "exercise:BayesianLinearRegression:warmup"]], " (Weights and signal propagation of a simple neural network)": [[67, "exercise:NeuralNet:simple-network"]], " (Weights and signal propagation of a wide neural network)": [[67, "exercise:NeuralNet:wide-network"]], " (Z = X + Y)": [[7, "example:BayesianAdvantage:Z=X+Y"]], " (k-fold cross-validation)": [[66, "algorithm:ModelValidation:cross-validation"]], " (k=1 NN training error)": [[66, "exercise:ModelValidation:kNN-training-error"]], " (kNN for regression)": [[65, "exercise:MLexamples:kNN-regression"]], " (kNN model complexity)": [[66, "exercise:ModelValidation:kNN-model-complexity"]], " (\u201cIn practice\u201d Bayesian linear regression)": [[34, "exercise:BayesianLinearRegression:in_practice"]], "(Pseudo) random number generator": [[112, "pseudo-random-number-generator"]], "*Aside: Bayesian epistemology": [[8, null]], "*Convolutional Neural Networks": [[75, null]], "*Marking a section in a different color": [[0, "marking-a-section-in-a-different-color"]], "*Neural networks: Backpropagation": [[68, null]], "1 Getting started: The Covariance Function": [[77, "getting-started-the-covariance-function"]], "1. A univariate example with GPyOpt": [[92, "a-univariate-example-with-gpyopt"]], "1. Import ipywidgets and Ipython.display": [[114, "import-ipywidgets-and-ipython-display"], [114, "id1"], [114, "id7"]], "1. n_samples = 1000, noise = 0.2, test_size = 0.5, iterations n = 30000": [[93, "n-samples-1000-noise-0-2-test-size-0-5-iterations-n-30000"]], "1D vs 2D Array": [[118, "d-vs-2d-array"]], "2 Sampling from a Gaussian Process": [[77, "sampling-from-a-gaussian-process"]], "2. Build your own BayesOpt algorithm (optional or for your project)": [[92, "build-your-own-bayesopt-algorithm-optional-or-for-your-project"]], "2. Create a function with all inputs that makes the output figure(s).": [[114, "create-a-function-with-all-inputs-that-makes-the-output-figure-s"], [114, "id8"]], "2. Create a function with all inputs to generate the output figure(s).": [[114, "create-a-function-with-all-inputs-to-generate-the-output-figure-s"]], "2. n_samples = 1000, noise = 0.2, test_size = 0.5, iterations n = 60000": [[93, "n-samples-1000-noise-0-2-test-size-0-5-iterations-n-60000"]], "3 A Gaussian Process Regression Model": [[77, "a-gaussian-process-regression-model"]], "3. Make a widget for each value you want to control.": [[114, "make-a-widget-for-each-value-you-want-to-control"], [114, "id2"], [114, "id9"]], "3. Test on bivariate example (Do this for a plus)": [[92, "test-on-bivariate-example-do-this-for-a-plus"]], "3. n_samples = 1000, noise = 0.05, test_size = 0.5, iterations n = 60000": [[93, "n-samples-1000-noise-0-05-test-size-0-5-iterations-n-60000"]], "3D volumes of neurons": [[75, "d-volumes-of-neurons"]], "4 A Running Example": [[77, "a-running-example"]], "4.  Make any explicit callback functions and add .observe methods.": [[114, "make-any-explicit-callback-functions-and-add-observe-methods"], [114, "id3"], [114, "id10"]], "4. Multivariate test examples (optional)": [[92, "multivariate-test-examples-optional"]], "4. n_samples = 1000, noise = 0.5, test_size = 0.5, iterations n = 60000": [[93, "n-samples-1000-noise-0-5-test-size-0-5-iterations-n-60000"]], "5. Set up the interactive_output function.": [[114, "set-up-the-interactive-output-function"], [114, "id4"], [114, "id11"]], "5. n_samples = 100, noise = 0.2, test_size = 0.5, iterations n = 60000": [[93, "n-samples-100-noise-0-2-test-size-0-5-iterations-n-60000"]], "6. Make the layout of the widgets.": [[114, "make-the-layout-of-the-widgets"], [114, "id5"], [114, "id12"]], "7. Release the Kraken!": [[114, "release-the-kraken"], [114, "id6"], [114, "id13"]], "<a name=\"Python\">Python/Jupyter set up</a>": [[6, "python-jupyter-set-up"]], "A Gaussian Process Regression Model": [[83, "a-gaussian-process-regression-model"]], "A binary classifier with two parameters": [[88, "a-binary-classifier-with-two-parameters"]], "A first summary": [[115, "a-first-summary"]], "A learning algorithm": [[88, "a-learning-algorithm"]], "A more compact expression": [[88, "a-more-compact-expression"]], "A new target prediction using a GP": [[85, null]], "A simple classification problem": [[70, "a-simple-classification-problem"], [74, "a-simple-classification-problem"]], "A spectral line problem": [[96, "a-spectral-line-problem"]], "A tale of two models: contrasting BMA with BMM}": [[48, "a-tale-of-two-models-contrasting-bma-with-bmm"]], "ANNs in the large-width limit": [[102, null]], "About this Jupyter Book": [[56, null]], "Acceptance Rate for the MH Algorithm": [[125, "acceptance-rate-for-the-mh-algorithm"]], "Acceptance rate": [[133, "acceptance-rate"]], "Acknowledgements": [[73, "acknowledgements"]], "Acknowledgments": [[56, "acknowledgments"]], "Activation outputs": [[68, null]], "Activation rule": [[67, null]], "Activation rules": [[67, "activation-rules"]], "Adagrad": [[99, "adagrad"]], "Adam": [[99, "adam"]], "Adaptive gradient descent algorithms": [[99, "adaptive-gradient-descent-algorithms"]], "Add Dense layers on top": [[76, "add-dense-layers-on-top"]], "Addendum: Ordinary linear regression in practice": [[34, "addendum-ordinary-linear-regression-in-practice"]], "Adding n variables drawn from a distribution": [[33, "adding-n-variables-drawn-from-a-distribution"]], "Adding/removing elements": [[118, "adding-removing-elements"]], "Admonitions": [[0, "admonitions"]], "Advanced Markov Chain Monte Carlo": [[123, null]], "Advanced Markov chain Monte Carlo sampling": [[44, null]], "Advanced feature: Widgets for graphical exploration": [[116, "advanced-feature-widgets-for-graphical-exploration"]], "Advantages of the Bayesian approach": [[7, null]], "Aleatoric uncertainties": [[72, null]], "Algorithm pseudo-code:": [[136, null]], "Anaconda and github": [[119, "anaconda-and-github"]], "Anaconda environments": [[119, "anaconda-environments"]], "Analysis": [[124, "analysis"]], "Analyze sampling results": [[133, "analyze-sampling-results"]], "Another standard class of pdf:  Student t": [[17, "another-standard-class-of-pdf-student-t"]], "Answer": [[0, null], [3, null], [11, null], [12, null], [12, null], [12, null], [15, null], [16, null], [18, null], [18, null], [18, null], [18, null], [18, null], [19, null], [19, null], [23, null], [23, null], [23, null], [24, null], [24, null], [31, null], [31, null], [31, null], [31, null], [31, null], [31, null], [31, null], [31, null], [31, null], [31, null], [31, null], [32, null], [32, null], [32, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [35, null], [35, null], [47, null], [47, null]], "Answer (a)": [[32, null], [32, null]], "Answer (b)": [[32, null], [32, null]], "Answer (c)": [[32, null]], "Answer all the questions": [[31, "answer-all-the-questions"], [32, "answer-all-the-questions"]], "Answer these questions": [[95, "answer-these-questions"]], "Answers": [[35, null]], "Application 1: GP emulator from Higdon et al. paper": [[79, "application-1-gp-emulator-from-higdon-et-al-paper"]], "Application of Information Criteria and Bayes factors": [[51, "application-of-information-criteria-and-bayes-factors"]], "Applications of SVD": [[107, "applications-of-svd"]], "Applying the Bayesian approach": [[129, "applying-the-bayesian-approach"], [134, "applying-the-bayesian-approach"]], "Architecture": [[67, null]], "Array Manipulation Routines": [[118, "array-manipulation-routines"]], "Array shape manipulations": [[118, "array-shape-manipulations"]], "Array to/from List conversion": [[118, "array-to-from-list-conversion"]], "Arrays vs Lists": [[118, "arrays-vs-lists"]], "Artifical neural networks": [[67, null]], "Artificial neurons": [[67, "artificial-neurons"]], "Aside: List comprehensions": [[117, "aside-list-comprehensions"]], "Aside: dissection of the Python statement to find the index for accumulation": [[109, "aside-dissection-of-the-python-statement-to-find-the-index-for-accumulation"]], "Aside: how do we make draws from a multivariate     Gaussian (normal) distribution if we know how to make draws from     \\mathcal{N}(0,1)?": [[86, null]], "Aspirational virtues for Bayesian inference and beyond": [[61, null]], "Assigning probabilities": [[2, null]], "Assigning probabilities (I): Indifferences and translation groups": [[3, null]], "Assigning probabilities (II): The principle of maximum entropy": [[4, null]], "Assignment: 2D radioactive lighthouse location using MCMC": [[124, null]], "Autocorrelation": [[44, "autocorrelation"], [141, "autocorrelation"]], "Autocorrelation Plots": [[125, "autocorrelation-plots"]], "Autocorrelation plots": [[133, "autocorrelation-plots"]], "Automation bias": [[63, null]], "Available samplers": [[133, "available-samplers"]], "Average, Variance, and Standard Deviation": [[118, "average-variance-and-standard-deviation"]], "Axioms of probability theory": [[25, "axioms-of-probability-theory"]], "BDA3: Gelman et al, Fig. 11.1": [[125, "bda3-gelman-et-al-fig-11-1"]], "Background info on GPs": [[86, "background-info-on-gps"]], "Background on linear models": [[34, "background-on-linear-models"]], "Basic Mathematical Operations": [[71, "basic-mathematical-operations"]], "Basic idea": [[53, "basic-idea"]], "Basic neural network": [[72, "basic-neural-network"]], "Basic setup of a model": [[133, "basic-setup-of-a-model"]], "Basic structure of MCMC algorithm": [[136, "basic-structure-of-mcmc-algorithm"]], "Basics and notation": [[88, "basics-and-notation"]], "Batch, stochastic and mini-batch gradient descent": [[99, "batch-stochastic-and-mini-batch-gradient-descent"]], "Bayes by Backprop": [[72, "bayes-by-backprop"]], "Bayes goes fast: Emulators": [[45, null]], "Bayes goes linear: History matching": [[46, null]], "Bayes in practice": [[28, null]], "Bayes linear methods": [[46, "bayes-linear-methods"]], "Bayes linear statistics": [[46, null]], "Bayesian Approach to Outliers #1: A conservative formulation": [[38, "bayesian-approach-to-outliers-1-a-conservative-formulation"]], "Bayesian Approach to Outliers #2: Good-and-bad data": [[38, "bayesian-approach-to-outliers-2-good-and-bad-data"]], "Bayesian Approach to Outliers #3: The Cauchy formulation": [[38, "bayesian-approach-to-outliers-3-the-cauchy-formulation"]], "Bayesian Approach to Outliers #4: Many nuisance parameters": [[38, "bayesian-approach-to-outliers-4-many-nuisance-parameters"]], "Bayesian Linear Regression (BLR)": [[34, null]], "Bayesian Neural Networks in PyMC3": [[73, "bayesian-neural-networks-in-pymc3"]], "Bayesian approach to Gaussian parameter estimation": [[39, "bayesian-approach-to-gaussian-parameter-estimation"], [129, "bayesian-approach-to-gaussian-parameter-estimation"], [134, "bayesian-approach-to-gaussian-parameter-estimation"]], "Bayesian approach to model discrepancy": [[103, null]], "Bayesian approaches to erratic data": [[38, "bayesian-approaches-to-erratic-data"]], "Bayesian credible intervals and frequentist confidence intervals": [[19, "bayesian-credible-intervals-and-frequentist-confidence-intervals"]], "Bayesian evidence": [[95, "id1"]], "Bayesian evidence:": [[95, "bayesian-evidence"]], "Bayesian handling of nuisance parameters": [[41, "bayesian-handling-of-nuisance-parameters"]], "Bayesian inference for multiple models": [[48, "bayesian-inference-for-multiple-models"]], "Bayesian inference in the multi-model setting": [[48, "bayesian-inference-in-the-multi-model-setting"]], "Bayesian linear regression: warmup": [[34, "bayesian-linear-regression-warmup"]], "Bayesian methods for scientific modeling": [[27, null]], "Bayesian model averaging and the \\mathcal{M}-closed assumption": [[48, "bayesian-model-averaging-and-the-mathcal-m-closed-assumption"]], "Bayesian model selection": [[53, "bayesian-model-selection"]], "Bayesian neural networks": [[72, null]], "Bayesian neural networks in PyMC3": [[72, "bayesian-neural-networks-in-pymc3"]], "Bayesian neural networks in practice": [[72, "bayesian-neural-networks-in-practice"]], "Bayesian parameter estimation": [[16, "bayesian-parameter-estimation"]], "Bayesian posteriors": [[26, null]], "Bayesian probability": [[8, "bayesian-probability"]], "Bayesian research workflow": [[43, null]], "Bayesian updating": [[9, "bayesian-updating"], [30, "bayesian-updating"]], "Bayesian workflow": [[59, null]], "Bayes\u2019 theorem": [[22, "bayes-theorem"], [25, "bayes-theorem"]], "Bayes\u2019 theorem applied to PDFs": [[23, "bayes-theorem-applied-to-pdfs"]], "Behavior of the mean of a fixed-size sample": [[33, "behavior-of-the-mean-of-a-fixed-size-sample"]], "Benchmark case: questions": [[5, "benchmark-case-questions"]], "Bibliography": [[1, null]], "Bibliography references": [[0, "bibliography-references"]], "Binary classification": [[88, "binary-classification"]], "Bonus:  Do this section for a plus": [[95, "bonus-do-this-section-for-a-plus"]], "Bonus: additional subtasks": [[94, "bonus-additional-subtasks"]], "Breakout questions": [[41, "breakout-questions"]], "Bridging Deep Learning and Probabilistic Programming": [[73, "bridging-deep-learning-and-probabilistic-programming"]], "Brief guide to online Jupyter Book features": [[56, "brief-guide-to-online-jupyter-book-features"]], "Brief introduction to GPs from Melendez et al.": [[86, "brief-introduction-to-gps-from-melendez-et-al"]], "Brief review of the method": [[44, "brief-review-of-the-method"]], "Brief summary of expectation values and moments": [[24, null]], "Bringing it together, first back propagation equation": [[68, "bringing-it-together-first-back-propagation-equation"]], "Build the network": [[69, "build-the-network"]], "But what about the prior?": [[39, "but-what-about-the-prior"], [129, "but-what-about-the-prior"], [134, "but-what-about-the-prior"]], "CNNs in brief": [[75, "cnns-in-brief"]], "Calculating the evidence": [[51, "calculating-the-evidence"]], "Case 1: Fixed H_0": [[41, "case-1-fixed-h-0"]], "Case 2: Using the inferred pdf for H_0": [[41, "case-2-using-the-inferred-pdf-for-h-0"]], "Case I: uniform (flat) prior": [[13, "case-i-uniform-flat-prior"]], "Case II: conjugate prior": [[13, "case-ii-conjugate-prior"]], "Central moments: Variance and Covariance": [[112, "central-moments-variance-and-covariance"]], "Challenges for gradient descent": [[99, null]], "Challenges in MCMC sampling": [[135, "challenges-in-mcmc-sampling"]], "Changing to the 2025-book-env env kernel when running a Jupyter notebook": [[119, "changing-to-the-2025-book-env-env-kernel-when-running-a-jupyter-notebook"]], "Characteristics of PDFs": [[18, null]], "ChatGPT prompts for original code": [[111, "chatgpt-prompts-for-original-code"]], "Check for between chain variations": [[50, "check-for-between-chain-variations"]], "Check that with the delta functions we get the rule for \\langle f\\rangle.": [[136, null]], "Check the N\\rightarrow \\infty limit": [[52, null]], "Checklists": [[43, "checklists"]], "Checkpoint Question": [[19, null]], "Checkpoint question": [[0, null], [0, null], [3, null], [15, null], [16, null], [19, null], [22, null], [23, null], [23, null], [23, null], [24, null], [24, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [47, null], [47, null]], "Checkpoint questions": [[0, "checkpoint-questions"]], "Choosing the GP model hyperparameters": [[85, "choosing-the-gp-model-hyperparameters"]], "Class exercises": [[11, null]], "Class probabilities: The Softmax function": [[88, "class-probabilities-the-softmax-function"]], "Class: state the rule used to justify each step": [[19, null]], "Classification algorithms": [[64, null]], "Clustering algorithms": [[64, null]], "Code": [[111, "code"]], "Code and Markdown cells": [[116, "code-and-markdown-cells"]], "Code example": [[112, "code-example"]], "Code examples: binary classifiers": [[65, "code-examples-binary-classifiers"]], "Coin tossing: Frequentists and Bayesaians": [[11, null]], "Combining Covariance Functions": [[77, "combining-covariance-functions"], [83, "combining-covariance-functions"]], "Combining Covariance Functions in GPy": [[77, "combining-covariance-functions-in-gpy"], [83, "combining-covariance-functions-in-gpy"]], "Comments and suggestions": [[94, "comments-and-suggestions"]], "Common Initialization Methods": [[71, "common-initialization-methods"]], "Common set up and generating data for all samplers": [[134, "common-set-up-and-generating-data-for-all-samplers"]], "Compare Gaussian noise sampling to lighthouse calculation": [[35, "compare-gaussian-noise-sampling-to-lighthouse-calculation"]], "Compare a sum of D Poisson draws with mean 1 to a single Poisson distribution with mean D": [[33, "compare-a-sum-of-d-poisson-draws-with-mean-1-to-a-single-poisson-distribution-with-mean-d"]], "Comparing samplers for a simple problem": [[134, null]], "Comparison with parameter estimation": [[53, "comparison-with-parameter-estimation"]], "Compile and train the model": [[76, "compile-and-train-the-model"]], "Complex Expressions": [[71, "complex-expressions"]], "Computational possibilities for evidence": [[51, "computational-possibilities-for-evidence"]], "Computing the Bayesian evidence": [[51, null]], "Computing the Covariance Function given the Input Data, \\mathbf{X}": [[77, "computing-the-covariance-function-given-the-input-data-mathbf-x"], [83, "computing-the-covariance-function-given-the-input-data-mathbf-x"]], "Computing the posterior analytically": [[13, null]], "Concatenate arrays": [[118, "concatenate-arrays"]], "Confidence intervals": [[18, null]], "Consequences:": [[19, "consequences"]], "Continuing \u2026": [[34, "continuing"]], "Continuous case": [[4, "continuous-case"]], "Contrast Bayesian and significance analyses for coin flipping": [[19, "contrast-bayesian-and-significance-analyses-for-coin-flipping"]], "Convergence tests for MCMC sampling": [[44, "convergence-tests-for-mcmc-sampling"]], "Converting linear models to matrix form": [[34, "converting-linear-models-to-matrix-form"]], "Convolutional Neural Network": [[67, "convolutional-neural-network"]], "Convolutional Neural Network (CNN)": [[76, "convolutional-neural-network-cnn"]], "Correlated posteriors": [[35, "correlated-posteriors"]], "Correlations": [[53, "correlations"]], "Covariance Function Parameter Estimation": [[77, "covariance-function-parameter-estimation"], [83, "covariance-function-parameter-estimation"]], "Covariance Functions in GPy": [[77, "covariance-functions-in-gpy"], [83, "covariance-functions-in-gpy"]], "Covariance functions, aka kernels": [[78, "covariance-functions-aka-kernels"], [82, "covariance-functions-aka-kernels"]], "Covariance, PCA and SVD": [[109, "covariance-pca-and-svd"]], "Create Arrays": [[118, "create-arrays"]], "Create special ndarray": [[118, "create-special-ndarray"]], "Create the convolutional base": [[76, "create-the-convolutional-base"]], "Creating a Sparse Matrix": [[118, "creating-a-sparse-matrix"]], "Creating a conda environment": [[119, "creating-a-conda-environment"]], "Creating a list, range, numpy array": [[117, "creating-a-list-range-numpy-array"]], "Credible regions": [[112, "credible-regions"]], "Cross validation": [[95, "cross-validation"]], "Cross-validation": [[66, "cross-validation"]], "Current trends in Machine Learning": [[73, "current-trends-in-machine-learning"]], "Customizing Initialization in PyTorch": [[71, "customizing-initialization-in-pytorch"]], "Data bias and fairness in machine learning": [[63, null]], "Data bias types in machine learning, including examples": [[63, "data-bias-types-in-machine-learning-including-examples"]], "Data handling, machine learning  and ethical aspects": [[64, "data-handling-machine-learning-and-ethical-aspects"]], "Data normalization": [[65, null], [65, "data-normalization"]], "Data reduction": [[109, "data-reduction"]], "Data sets from scikit-learn": [[74, "data-sets-from-scikit-learn"]], "Data, models, and predictions": [[16, null]], "Dataset and Gaussian process generation": [[81, "dataset-and-gaussian-process-generation"]], "Dataset generation": [[80, "dataset-generation"]], "Debugging aside \u2026": [[116, "debugging-aside"], [116, "id1"]], "Deep Learning": [[73, "deep-learning"]], "Define and plot the posterior for x_0": [[42, "define-and-plot-the-posterior-for-x-0"]], "Define model discrepancy class": [[105, "define-model-discrepancy-class"]], "Define physics model": [[105, "define-physics-model"]], "Define priors": [[105, "define-priors"]], "Define the functions we will need": [[5, "define-the-functions-we-will-need"]], "Definition and examples": [[34, "definition-and-examples"]], "Definition of a stochastic process": [[143, "definition-of-a-stochastic-process"]], "Definition of linear models": [[98, "definition-of-linear-models"]], "Definitions": [[68, "definitions"]], "Degree of belief intervals": [[9, "degree-of-belief-intervals"], [30, "degree-of-belief-intervals"]], "Degree of belief/credibility intervals vs frequentist 1-sigma intervals": [[14, null]], "Demo: Multimodal distributions with two samplers": [[50, null]], "Demolition derbies, cows, and crocodiles": [[62, "demolition-derbies-cows-and-crocodiles"]], "Demonstration: Gaussian processes": [[82, null]], "Demonstration: Image recognition with Convolutional Neural Networks": [[76, null]], "Demonstration: Metropolis-Hasting MCMC sampling of a Poisson distribution": [[144, null]], "Demonstration: Neural network classifier": [[69, null]], "Demonstration: Variational Inference and Bayesian Neural Networks": [[73, null]], "Derivation of common pdfs using MaxEnt": [[4, "derivation-of-common-pdfs-using-maxent"]], "Derivative of the cost function": [[68, "derivative-of-the-cost-function"]], "Derivatives and the chain rule": [[68, "derivatives-and-the-chain-rule"]], "Derivatives in terms of z_j^L": [[68, "derivatives-in-terms-of-z-j-l"]], "Deriving the back propagation code for a multilayer perceptron model": [[68, "deriving-the-back-propagation-code-for-a-multilayer-perceptron-model"]], "Detailed Explanation of Each Step:": [[71, "detailed-explanation-of-each-step"]], "Determinant": [[118, "determinant"]], "Determination of weights": [[88, "determination-of-weights"]], "Determining the bias of a coin": [[30, "determining-the-bias-of-a-coin"]], "Determining the likelihood function": [[43, "determining-the-likelihood-function"]], "Developing a code for doing neural networks with back propagation": [[69, "developing-a-code-for-doing-neural-networks-with-back-propagation"]], "Diagnostics": [[133, "diagnostics"]], "Diagonalization of symmetric matrix": [[107, "diagonalization-of-symmetric-matrix"]], "Dimensionality reduction algorithms": [[64, null]], "Dirac delta functions": [[7, null]], "Discrete or continuous optimization": [[99, null]], "Discrete permutation invariance": [[3, "discrete-permutation-invariance"]], "Discuss": [[8, null], [34, null], [53, null], [112, null], [112, null], [112, null], [143, null]], "Discussion": [[38, "discussion"], [129, "discussion"], [134, "discussion"]], "Doing Fourier transforms by numerical integration (rather than FFT)": [[33, "doing-fourier-transforms-by-numerical-integration-rather-than-fft"]], "Dot product versus elementwise multiplication": [[118, "dot-product-versus-elementwise-multiplication"]], "Dot-product kernel": [[81, "dot-product-kernel"]], "Download and prepare the CIFAR10 dataset": [[76, "download-and-prepare-the-cifar10-dataset"]], "Edwin Jaynes and plausible reasoning": [[62, null]], "Eigendecomposition of the covariance matrix": [[109, "eigendecomposition-of-the-covariance-matrix"]], "Eigenvalues and eigenvectors": [[118, "eigenvalues-and-eigenvectors"]], "Eigenvector continuation": [[45, "eigenvector-continuation"]], "Elegant linear algebra tricks to obtain \\boldsymbol{C}_{N+1}^{-1}": [[85, "elegant-linear-algebra-tricks-to-obtain-boldsymbol-c-n-1-1"]], "Emulators": [[47, null], [104, null]], "Epistemic uncertainties": [[72, null]], "Equation references": [[0, "equation-references"]], "Error propagation (I): Nuisance parameters and marginalization": [[7, "error-propagation-i-nuisance-parameters-and-marginalization"]], "Error propagation (II): Changing variables": [[7, "error-propagation-ii-changing-variables"]], "Error propagation (III): A useful approximation": [[7, "error-propagation-iii-a-useful-approximation"]], "Ethical principles": [[63, null]], "Ethics guidelines": [[63, "ethics-guidelines"]], "Evaluate the model": [[76, "evaluate-the-model"]], "Evidence Lower Bound": [[72, "evidence-lower-bound"]], "Evidence calculation": [[49, "evidence-calculation"]], "Evidence calculation for EFT expansions": [[49, null]], "Evidence calculations": [[53, "evidence-calculations"]], "Evidence for an expansion": [[52, null]], "Evidence using conjugate prior": [[49, "evidence-using-conjugate-prior"]], "Evidence using linear algebra and Gaussian integrals": [[49, "evidence-using-linear-algebra-and-gaussian-integrals"]], "Evidence with linear algebra": [[52, "evidence-with-linear-algebra"]], "Example of a Complex Expression": [[71, "example-of-a-complex-expression"]], "Example of parallel tempering": [[51, "example-of-parallel-tempering"]], "Example with noise-free target": [[80, "example-with-noise-free-target"]], "Example with noisy targets": [[80, "example-with-noisy-targets"]], "Example: CNN architecture": [[75, "example-cnn-architecture"]], "Example: GP models for regression": [[78, "example-gp-models-for-regression"], [82, "example-gp-models-for-regression"]], "Example: Is this a fair coin?": [[25, "example-is-this-a-fair-coin"]], "Example: Random walk": [[143, "example-random-walk"]], "Example: Straight-line model": [[3, "example-straight-line-model"]], "Example: The Compas algorithm": [[63, "example-the-compas-algorithm"]], "Example: The MNIST dataset": [[75, "example-the-mnist-dataset"]], "Example: good data / bad data": [[38, "example-good-data-bad-data"]], "Examples": [[136, null]], "Examples from Rob Hicks": [[133, "examples-from-rob-hicks"]], "Examples of classifier functions used in logistic regression and neural networks": [[70, "examples-of-classifier-functions-used-in-logistic-regression-and-neural-networks"]], "Examples of information criteria": [[51, "examples-of-information-criteria"]], "Exercise": [[19, null], [19, null], [70, "exercise"]], "Exercise 1": [[77, "exercise-1"], [83, "exercise-1"]], "Exercise 2": [[77, "exercise-2"], [83, "exercise-2"]], "Exercise 3": [[77, "exercise-3"], [83, "exercise-3"]], "Exercise 4": [[77, "exercise-4"], [83, "exercise-4"]], "Exercise 5": [[77, "exercise-5"]], "Exercise: Bayesian neural networks": [[74, null]], "Exercise: Checking the sum and product rules": [[32, null]], "Exercise: Create a neural net binary classifier": [[70, "exercise-create-a-neural-net-binary-classifier"]], "Exercise: Develop your own logistic regression binary classifier": [[70, "exercise-develop-your-own-logistic-regression-binary-classifier"]], "Exercise: Gaussian Process models with GPy": [[77, null]], "Exercise: Gaussian processes using GPy": [[83, null]], "Exercise: Logistic Regression and neural networks": [[70, null]], "Exercise: Random walk": [[126, null]], "Exercise: Standard medical example using Bayes": [[31, null]], "Exercises": [[16, "exercises"], [40, "exercises"], [65, "exercises"], [66, "exercises"], [67, "exercises"], [100, "exercises"], [112, "exercises"], [135, "exercises"], [138, "exercises"]], "Exercises and solutions": [[0, "exercises-and-solutions"]], "Exercises: covariance matrix manipulations in Python (taken from the Duke course)": [[109, "exercises-covariance-matrix-manipulations-in-python-taken-from-the-duke-course"]], "Exp-Sine-Squared kernel": [[81, "exp-sine-squared-kernel"]], "Expectation values and moments": [[112, "expectation-values-and-moments"]], "Experimentation (of the statistical model)": [[43, "experimentation-of-the-statistical-model"]], "Explorations:  Things to do and Questions to answer": [[95, "explorations-things-to-do-and-questions-to-answer"]], "Explore the data": [[69, "explore-the-data"]], "Explore!": [[35, null]], "Expressions": [[124, "expressions"]], "Extending to more classes": [[88, "extending-to-more-classes"]], "Extending to more features": [[88, "extending-to-more-features"]], "External URL references": [[0, "external-url-references"]], "Fairness and error functions": [[63, "fairness-and-error-functions"]], "Feed-forward neural network for a function in PyTorch": [[71, null]], "Feed-forward neural networks": [[67, "feed-forward-neural-networks"]], "Feedback networks": [[67, "feedback-networks"]], "Figures to analyze!": [[37, "figures-to-analyze"]], "Figures to make every time you run MCMC (following Hogg and Foreman-Mackey sect. 9)": [[128, "figures-to-make-every-time-you-run-mcmc-following-hogg-and-foreman-mackey-sect-9"]], "Fill in the chart based on the Metropolis algorithm we are using and verify that the ratio of p(X_B|X_A) to p(X_A|X_B) agrees with the answer derived above.": [[141, null]], "Final back-propagating equation": [[68, "final-back-propagating-equation"]], "Final outputs": [[68, null]], "Find the Maximum and Minimum Values": [[118, "find-the-maximum-and-minimum-values"]], "First example: each sample is only one point": [[33, "first-example-each-sample-is-only-one-point"]], "First pass: only minimal controls": [[114, "first-pass-only-minimal-controls"]], "First sample with emcee": [[134, "first-sample-with-emcee"]], "First the likelihood": [[13, "first-the-likelihood"]], "Fitting a straight line - revisited": [[125, "fitting-a-straight-line-revisited"]], "Follow-up question on 2.": [[31, null]], "Follow-up question on 5.": [[31, null]], "Follow-up questions and answers to the Exploring PDFs section.": [[18, null]], "Follow-up questions to the medical example": [[31, "follow-up-questions-to-the-medical-example"]], "Follow-up task": [[77, "follow-up-task"]], "Follow-ups": [[37, "follow-ups"]], "Formalizing prior distributions": [[43, "formalizing-prior-distributions"]], "Four-step Bayesian workflow in brief": [[43, null], [59, null]], "Fourth example: each sample is 50 points": [[33, "fourth-example-each-sample-is-50-points"]], "Framework": [[103, "framework"]], "Frequentist Correction for Outliers: Huber Loss": [[38, "frequentist-correction-for-outliers-huber-loss"]], "Frequentist approach to Gaussian parameter estimation": [[129, "frequentist-approach-to-gaussian-parameter-estimation"], [134, "frequentist-approach-to-gaussian-parameter-estimation"]], "Frequentist hypothesis testing": [[53, "frequentist-hypothesis-testing"]], "Frequentist probability": [[8, "frequentist-probability"]], "Frontmatter for markdown files": [[0, "frontmatter-for-markdown-files"]], "Functions": [[116, "functions"]], "Further examples with numpy": [[118, null]], "GP models for regression": [[85, "gp-models-for-regression"]], "GPy demo notebooks": [[84, null]], "Games with Gaussian process websites": [[86, "games-with-gaussian-process-websites"]], "Gaussian Processes regression: basic introductory example": [[80, null]], "Gaussian distribution": [[112, "gaussian-distribution"]], "Gaussian processes": [[85, null]], "Gaussian processes as high-dimensional Gaussian distributions": [[82, "gaussian-processes-as-high-dimensional-gaussian-distributions"]], "Gaussian processes as infinite-dimensional Gaussian distributions": [[78, "gaussian-processes-as-infinite-dimensional-gaussian-distributions"]], "Gaussian processes demonstration": [[78, null]], "Gaussians: A couple of frequentist connections": [[19, null]], "Gelman Rubin Diagnostic": [[125, "gelman-rubin-diagnostic"]], "Gelman Rubin Diagnostic (quoted verbatim from the Hicks notebook)": [[133, "gelman-rubin-diagnostic-quoted-verbatim-from-the-hicks-notebook"]], "General problems in Bayesian inference": [[135, "general-problems-in-bayesian-inference"]], "Generate data": [[96, "generate-data"]], "Generate figures": [[124, "generate-figures"]], "Generate \u201cexperimental\u201d observations for height": [[105, "generate-experimental-observations-for-height"]], "Generating data": [[73, "generating-data"], [93, "generating-data"]], "Generating the data": [[124, "generating-the-data"]], "Generative models": [[64, null]], "Getting help": [[116, "getting-help"]], "Getting started: The Covariance Function": [[83, "getting-started-the-covariance-function"]], "Good online cheat-sheets:": [[120, "good-online-cheat-sheets"]], "Gradient Computations": [[71, "gradient-computations"]], "Gradient-descent optimization": [[97, null], [99, "gradient-descent-optimization"]], "Group Attribution Biases": [[63, null]], "Guide to Jupyter Book markdown": [[0, null]], "Guides in this Jupyter Book": [[120, "guides-in-this-jupyter-book"]], "HMC algorithm": [[130, "hmc-algorithm"]], "HMC and other samplers": [[139, null]], "HMC physics": [[130, "hmc-physics"]], "Hamiltonian Monte Carlo": [[44, "hamiltonian-monte-carlo"]], "Hamiltonian Monte Carlo (HMC) overview and visualization": [[130, null]], "Helper function": [[81, "helper-function"]], "Hidden code cell": [[0, "hidden-code-cell"]], "Hint": [[19, null], [32, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null]], "Hint (a)": [[32, null]], "Hint (b)": [[32, null]], "Hint-1": [[34, null]], "Hint-2": [[34, null]], "Hints": [[34, null], [67, null]], "Histograms matching a t distribution": [[108, "histograms-matching-a-t-distribution"]], "How are N_A and N_B related to the total N and the posteriors p(X_A|D,I) and p(X_B|D,I)?": [[141, null]], "How do we know this chain has converged to the posterior?": [[125, "how-do-we-know-this-chain-has-converged-to-the-posterior"]], "How the Bayesian approach helps in science": [[7, null]], "Hybrid Uncertainty:": [[7, null]], "Hypothesis testing with the chi-squared statistic": [[53, "hypothesis-testing-with-the-chi-squared-statistic"]], "Icons and menus": [[56, null]], "Illustration of prior and posterior Gaussian process for different kernels": [[81, null]], "Implementation": [[40, "implementation"]], "Implicit Biases": [[63, null]], "Import Python modules": [[38, "import-python-modules"]], "Import TensorFlow": [[76, "import-tensorflow"]], "Import functions": [[5, "import-functions"]], "Import modules": [[77, "import-modules"], [83, "import-modules"], [92, "import-modules"], [115, "import-modules"]], "Import of modules": [[95, "import-of-modules"], [126, "import-of-modules"]], "Import statements": [[96, "import-statements"]], "Import theano and pymc3": [[73, "import-theano-and-pymc3"]], "Important definitions": [[112, "important-definitions"]], "Important distributions": [[112, "important-distributions"]], "Imports": [[133, "imports"]], "In terms of p(X_A|X_B), p(X_B|X_A), N_A, and N_B, what is the condition that the exchanges between A and B cancel out? (For now assume a symmetric proposal distribution q.)": [[141, null]], "In-class exercise": [[133, "in-class-exercise"]], "Inference and PDFs": [[20, null]], "Inference using Gaussian processes": [[85, "inference-using-gaussian-processes"]], "Inference with parametric models": [[7, "inference-with-parametric-models"]], "InferenceData object": [[133, "inferencedata-object"]], "Information from ChatGPT about backpropagation": [[71, "information-from-chatgpt-about-backpropagation"]], "Information from ChatGPT about how to switch to normal distributions to intialize": [[71, "information-from-chatgpt-about-how-to-switch-to-normal-distributions-to-intialize"]], "Information from ChatGPT about tensor operations": [[71, "information-from-chatgpt-about-tensor-operations"], [71, "id1"]], "Information from ChatGPT about the default initialization": [[71, "information-from-chatgpt-about-the-default-initialization"]], "Ingredients of Bayes\u2019 theorem": [[25, null]], "Inserting figures and references to them": [[0, "inserting-figures-and-references-to-them"]], "Installation of LearningFromData Jupyter notebooks from GitHub by command line": [[122, "installation-of-learningfromdata-jupyter-notebooks-from-github-by-command-line"]], "Installation of PyTorch": [[71, "installation-of-pytorch"]], "Installing Anaconda": [[119, "installing-anaconda"]], "Integration": [[128, "integration"]], "Integration and marginalization by sampling: intuition": [[128, "integration-and-marginalization-by-sampling-intuition"]], "Interpreting 2D posteriors": [[35, null]], "Introduction": [[57, null], [143, "introduction"]], "Introduction to tensorflow": [[69, "introduction-to-tensorflow"]], "Intuition by sampling and plotting multivariate Gaussians": [[78, "intuition-by-sampling-and-plotting-multivariate-gaussians"]], "Intuition for detailed balance and the MH algorithm": [[141, "intuition-for-detailed-balance-and-the-mh-algorithm"]], "Inverse": [[118, "inverse"]], "Invitation to inductive inference": [[62, null]], "Iterating through a list of parameters to draw multiple lines on a plot": [[117, "iterating-through-a-list-of-parameters-to-draw-multiple-lines-on-a-plot"]], "Iteration versus array operation": [[117, "iteration-versus-array-operation"]], "Iterative history matching": [[46, "iterative-history-matching"]], "Joint PDFs, marginal PDFs, and an example of marginalization": [[23, "joint-pdfs-marginal-pdfs-and-an-example-of-marginalization"]], "KOH and BOH discrepancy models": [[103, "koh-and-boh-discrepancy-models"]], "Kernel cookbook": [[81, "kernel-cookbook"]], "Labeling and referencing a section": [[0, "labeling-and-referencing-a-section"]], "Laplace\u2019s method": [[53, "laplaces-method"]], "Large-width limit": [[102, "large-width-limit"]], "Layers used to build CNNs": [[75, "layers-used-to-build-cnns"]], "Learning algorithm": [[67, null], [67, "learning-algorithm"]], "Learning challenges": [[68, "learning-challenges"]], "Learning curves": [[66, "learning-curves"], [97, "learning-curves"]], "Learning goals:": [[94, "learning-goals"], [96, "learning-goals"], [124, "learning-goals"]], "Lecture 12": [[128, null]], "Lecture 20": [[79, null]], "Lets look at what the classifier has learned": [[73, "lets-look-at-what-the-classifier-has-learned"]], "Let\u2019s look at what the classifier has learned": [[93, "lets-look-at-what-the-classifier-has-learned"]], "Likelihood": [[50, "likelihood"]], "Likelihoods (or posteriors) with two variables with quadratic approximation": [[35, "likelihoods-or-posteriors-with-two-variables-with-quadratic-approximation"]], "Limit of Poisson distribution is Gaussian": [[33, "limit-of-poisson-distribution-is-gaussian"]], "Limitations of supervised learning with deep networks": [[67, "limitations-of-supervised-learning-with-deep-networks"]], "Limitations of training data": [[63, "limitations-of-training-data"]], "Linear algebra and numerical operations": [[118, "linear-algebra-and-numerical-operations"]], "Linear classification": [[65, "linear-classification"]], "Linear classifier(s)": [[65, "linear-classifier-s"]], "Linear models": [[98, null]], "Linear regression": [[65, "linear-regression"]], "Linear versus non-linear models": [[100, "linear-versus-non-linear-models"]], "Liouville Theorem Visualization": [[131, null]], "Location invariance": [[3, "location-invariance"]], "Log normal distribution": [[4, "log-normal-distribution"]], "Logistic Regression": [[88, null]], "Logistic regression using scikit-learn": [[70, "logistic-regression-using-scikit-learn"]], "Looking ahead": [[24, null]], "Looking at PyMC getting started notebook": [[140, "looking-at-pymc-getting-started-notebook"]], "MCMC Intro from BUQEYE": [[136, null]], "MCMC Sampling Interlude: Assessing Convergence": [[128, "mcmc-sampling-interlude-assessing-convergence"]], "MCMC diagnostics: assessing convergence": [[125, "mcmc-diagnostics-assessing-convergence"]], "MCMC random walk and sampling example": [[141, "mcmc-random-walk-and-sampling-example"]], "MH Sampling and convergence": [[50, "mh-sampling-and-convergence"]], "Machine Learning": [[89, null]], "Machine Learning: First Examples": [[65, null]], "Machine learning": [[60, null]], "Machine learning in science and society": [[64, "machine-learning-in-science-and-society"]], "Machine learning: Overview and notation": [[64, null]], "Macros": [[0, "macros"]], "Main code for coin-flipping UI": [[9, "main-code-for-coin-flipping-ui"]], "Make Liouville theorem visualization": [[131, "make-liouville-theorem-visualization"]], "Make predictions": [[76, "make-predictions"]], "Make predictions and evaluate accuracy": [[69, "make-predictions-and-evaluate-accuracy"]], "Make some plots": [[108, "make-some-plots"]], "Making a movie of the evolution of the distribution": [[108, "making-a-movie-of-the-evolution-of-the-distribution"]], "Making predictions": [[76, "making-predictions"]], "Manipulating probabilities: Bayesian rules of probability as principles of logic": [[22, null]], "Many new target predictions using a GP": [[85, null]], "Marginal posterior distributions": [[34, "marginal-posterior-distributions"]], "Marginalization": [[41, "marginalization"], [128, "marginalization"]], "Marginalization using samples": [[7, null]], "Markov Chain Monte Carlo (MCMC)": [[136, "markov-chain-monte-carlo-mcmc"]], "Markov chain Monte Carlo sampling": [[135, null]], "Markov chains": [[138, null]], "Materials to help you get started": [[56, "materials-to-help-you-get-started"]], "Mathematical functions with numpy": [[116, "mathematical-functions-with-numpy"]], "Mathematical model": [[67, "mathematical-model"]], "Mathematical optimization": [[99, null]], "Matplotlib plotting helper functions": [[17, "matplotlib-plotting-helper-functions"]], "Matrix  Operations": [[118, "matrix-operations"]], "Matrix-vector notation": [[67, "matrix-vector-notation"]], "Mat\u00e9rn kernel": [[81, "matern-kernel"]], "Maximum likelihood": [[88, "maximum-likelihood"]], "Maximum likelihood fits": [[95, "maximum-likelihood-fits"]], "Mean and covariance function": [[82, "mean-and-covariance-function"]], "Mean and the Exponential pdf": [[4, "mean-and-the-exponential-pdf"]], "Mean, median, mode": [[112, "mean-median-mode"]], "Meet the Pandas": [[115, "meet-the-pandas"]], "Metropolis Poisson example (Gregory, section 12.2)": [[136, "metropolis-poisson-example-gregory-section-12-2"]], "Metropolis condition": [[136, null]], "Metropolis design": [[138, "metropolis-design"]], "Metropolis-Hasting MCMC sampling of a Poisson distribution": [[127, null]], "Mini-batch ADVI": [[73, "mini-batch-advi"]], "Mini-project I: Parameter estimation for a toy model of an EFT": [[94, null]], "Mini-project IIIa: Bayesian Optimization": [[92, null]], "Mini-project IIIb: Bayesian Neural Networks": [[93, null]], "Mini-project IIa: Model selection basics": [[95, null]], "Mini-project IIb: How many lines are there?": [[96, null]], "Minimize the effective potential and plot results for benchmark case": [[5, "minimize-the-effective-potential-and-plot-results-for-benchmark-case"]], "Minimizing the cross entropy": [[88, "minimizing-the-cross-entropy"]], "Model Selection": [[53, null]], "Model checking:": [[7, null]], "Model comparison:": [[7, null]], "Model mixing": [[48, null]], "Model specification": [[73, "model-specification"], [93, "model-specification"]], "Model validation": [[66, null], [66, "id7"]], "Model-order reduction": [[45, null]], "Models in science": [[100, "models-in-science"]], "Monte Carlo integration": [[135, "monte-carlo-integration"]], "Monte Carlo integration in statistics": [[135, "monte-carlo-integration-in-statistics"]], "Moral qualities of the scientist": [[61, null]], "More Bayesian parameter estimation": [[36, null]], "More details on naive MC": [[136, null]], "More on Bayes\u2019 theorem": [[25, null]], "More on Python and using Jupyter notebooks": [[120, null]], "More on Ridge Regression": [[66, "more-on-ridge-regression"]], "Multi-model inference with Bayes": [[54, null]], "Multivariate Gaussian distribution": [[112, "multivariate-gaussian-distribution"]], "Multivariate normal distributions": [[82, "multivariate-normal-distributions"]], "N dimensional arrays": [[118, "n-dimensional-arrays"]], "N=2 moments": [[5, "n-2-moments"]], "N=3 moments": [[5, "n-3-moments"]], "N=4 moments": [[5, "n-4-moments"]], "N=5 moments": [[5, "n-5-moments"]], "Network training": [[72, "network-training"]], "Neural network architecture": [[67, "neural-network-architecture"]], "Neural network types": [[67, "neural-network-types"]], "Next steps": [[73, "next-steps"]], "No-core shell model \\hbar\\omega dependence": [[78, "no-core-shell-model-hbar-omega-dependence"], [82, "no-core-shell-model-hbar-omega-dependence"]], "Noisy networks": [[67, null]], "Non-parametric approach: Mean and covariance functions": [[85, "non-parametric-approach-mean-and-covariance-functions"]], "Normalization and marginalization": [[25, null]], "Normalization and marginalization in the continuum limit": [[25, null]], "Normalization of a multivariate Gaussian": [[53, "normalization-of-a-multivariate-gaussian"]], "Notation": [[64, "notation"], [85, null], [88, null], [100, "notation"], [112, "notation"], [143, "notation"]], "Note on \\chi^2/\\text{dof} for model assessment and comparison  \\newcommand{\\pars}{\\boldsymbol{\\theta}}": [[29, "note-on-chi-2-text-dof-for-model-assessment-and-comparison-newcommand-pars-boldsymbol-theta"]], "Note on donuts in high dimensions": [[136, null]], "Notebook:": [[19, "notebook"]], "Notes": [[0, "notes"], [49, "notes"]], "Now ask ChatGPT to use this code to learn a specified function in a specified region": [[71, "now-ask-chatgpt-to-use-this-code-to-learn-a-specified-function-in-a-specified-region"]], "Now do the sampling and plot the posteriors": [[105, "now-do-the-sampling-and-plot-the-posteriors"]], "Now sample with PyMC": [[134, "now-sample-with-pymc"]], "Now sample with zeus": [[134, "now-sample-with-zeus"]], "Now try it with zeus!": [[50, "now-try-it-with-zeus"]], "Numerical integration": [[135, "numerical-integration"]], "Occam\u2019s razor": [[7, null]], "Odds-ratios": [[95, "odds-ratios"]], "One adjustable parameter each": [[53, "one-adjustable-parameter-each"]], "One adjustable parameter each; different prior ranges": [[53, "one-adjustable-parameter-each-different-prior-ranges"]], "One solution (how could these functions be improved?)": [[40, "one-solution-how-could-these-functions-be-improved"]], "One solution (how could this solution be improved?)": [[40, "one-solution-how-could-this-solution-be-improved"]], "One view": [[8, null]], "Open an issue": [[56, null]], "Operating on matrices with special properties": [[118, null]], "Optimization and Deep learning": [[88, "optimization-and-deep-learning"]], "Optional task: log probabilities": [[126, "optional-task-log-probabilities"]], "Ordinary linear regression in practice": [[98, "ordinary-linear-regression-in-practice"]], "Ordinary linear regression: warmup": [[98, "ordinary-linear-regression-warmup"]], "Organizing our data": [[115, "organizing-our-data"]], "Original background": [[134, "original-background"]], "Output Distribution of Randomly-Initialized feed-forward ANN (1 Input \u2192 1 Output)": [[111, "output-distribution-of-randomly-initialized-feed-forward-ann-1-input-1-output"]], "Output Distribution of Randomly-Initialized feed-forward ANN (2 Inputs \u2192 1 Output)": [[111, "output-distribution-of-randomly-initialized-feed-forward-ann-2-inputs-1-output"]], "Over- and underfitting": [[66, "over-and-underfitting"]], "Overfitting and underfitting the data": [[63, null]], "Overgeneralization Bias": [[63, null]], "Overview of Gaussian process": [[86, null]], "Overview of Intro to PyMC notebook": [[140, null]], "Overview of Markov Chain Monte Carlo": [[137, null]], "Overview of Mini-project IIb: How many lines?": [[90, null]], "Overview of Part II: Advanced Bayesian methods": [[55, null]], "Overview of Part III: Sampling": [[142, null]], "Overview of TALENT mini-projects": [[91, null]], "Overview of getting started materials": [[113, null]], "Overview of modeling": [[100, null]], "Overview of other topics": [[106, null]], "Overview of scientific modeling material": [[101, null]], "Overview: MCMC Diagnostics": [[125, null]], "PCA (from Duke course)": [[109, "pca-from-duke-course"]], "PCA, SVD, and all that": [[107, null]], "PDFs for applying Bayes\u2019 rule": [[124, "pdfs-for-applying-bayes-rule"]], "PT Sampler": [[50, "pt-sampler"]], "Parallel tempering": [[51, "parallel-tempering"]], "Parameter Estimation:": [[0, null], [7, null]], "Parameter choices": [[93, "parameter-choices"]], "Parameter estimation example: Gaussian noise and averages II": [[129, null]], "Parameter estimation example: fitting a straight line": [[40, null]], "Parameter estimation with your favorite MCMC sampler (emcee here!)": [[96, "parameter-estimation-with-your-favorite-mcmc-sampler-emcee-here"]], "Parameters known before the analysis (explore different values for these as requested)": [[96, "parameters-known-before-the-analysis-explore-different-values-for-these-as-requested"]], "Parameters that should be learned from the data": [[96, "parameters-that-should-be-learned-from-the-data"]], "Parametric approach": [[85, "parametric-approach"]], "Parametric versus non-parametric models": [[100, "parametric-versus-non-parametric-models"]], "Part 1": [[83, "part-1"]], "Part 1: Random walk in [-5,5] region": [[126, "part-1-random-walk-in-5-5-region"]], "Part 2": [[83, "part-2"]], "Part 2: MCMC sampling of a Lorentzian pdf using the random walk Metropolis algorithm": [[126, "part-2-mcmc-sampling-of-a-lorentzian-pdf-using-the-random-walk-metropolis-algorithm"]], "Part 3": [[83, "part-3"]], "Part 3: Detailed balance and the Metropolis-Hastings algorithm": [[126, "part-3-detailed-balance-and-the-metropolis-hastings-algorithm"]], "Pendulum class and utility functions": [[131, "pendulum-class-and-utility-functions"]], "Perform thermodynamic integration from PT sampler": [[96, "perform-thermodynamic-integration-from-pt-sampler"]], "Philosophical remarks on probabilities": [[8, "philosophical-remarks-on-probabilities"]], "Physicist\u2019s perspective": [[58, null]], "Pick a potential": [[132, "pick-a-potential"]], "Plot orbit and check energy conservation": [[132, "plot-orbit-and-check-energy-conservation"]], "Plotting with Matplotlib": [[116, "plotting-with-matplotlib"]], "Point estimates": [[18, null]], "Point estimates and credible regions": [[112, "point-estimates-and-credible-regions"]], "Poisson distribution": [[4, "poisson-distribution"], [37, "poisson-distribution"]], "Polya and Jaynes": [[62, "polya-and-jaynes"]], "Polya and plausible inference": [[62, null]], "Possible answers": [[0, null], [11, null], [22, null]], "Posterior": [[50, "posterior"]], "Posterior with a Gaussian prior": [[34, "posterior-with-a-gaussian-prior"]], "Posterior with a uniform prior": [[34, "posterior-with-a-uniform-prior"]], "Predict based on your own experience: How does this behavior change if we have more data (higher energy) or more certain data?": [[52, null]], "Preliminaries": [[108, "preliminaries"]], "Preliminary exercise: manipulations using the index form of matrices": [[109, "preliminary-exercise-manipulations-using-the-index-form-of-matrices"]], "Preliminary exercises": [[107, "preliminary-exercises"]], "Prelude: ordinary linear regression": [[34, "prelude-ordinary-linear-regression"]], "Preparing data and the pdfs we\u2019ll need": [[37, "preparing-data-and-the-pdfs-well-need"]], "Principal components": [[109, "principal-components"]], "Prior": [[50, "prior"]], "Prior PDFs for straight line model": [[6, "prior-pdfs-for-straight-line-model"]], "Prior elicitation.": [[43, "prior-elicitation"]], "Probabilistic Programming at scale": [[73, "probabilistic-programming-at-scale"]], "Probabilistic model": [[72, "probabilistic-model"]], "Probability density functions": [[23, null]], "Probability surface": [[73, "probability-surface"], [93, "probability-surface"]], "Product rule": [[22, "product-rule"]], "Projected posterior plots": [[17, "projected-posterior-plots"]], "Proof of penultimate equality": [[13, null]], "Proof of the CLT in a special case:": [[19, "proof-of-the-clt-in-a-special-case"]], "Pukelsheim\u2019s three-sigma rule": [[46, "pukelsheims-three-sigma-rule"], [46, null]], "PyMC Introduction": [[133, null]], "PyMC implementation": [[133, "pymc-implementation"]], "PyMC3:": [[135, null]], "PyMultiNest:": [[135, null]], "PyStan:": [[135, null]], "PyTorch Default Initialization": [[71, "pytorch-default-initialization"]], "Python expressions and strings": [[116, "python-expressions-and-strings"]], "Python for machine learning": [[64, null]], "Python imports": [[50, "python-imports"], [109, "python-imports"], [124, "python-imports"]], "Python/Jupyter set up": [[9, "python-jupyter-set-up"]], "QBism references": [[110, "qbism-references"]], "Quadrature methods": [[135, "quadrature-methods"]], "Quantum Bayesianism (QBism)": [[110, null]], "Question": [[4, null], [12, null], [35, null], [83, "question"], [85, null], [88, null], [88, null], [95, "question"], [136, null]], "Question 1": [[31, null], [32, null]], "Question 2": [[31, null], [32, null]], "Question 3": [[31, null], [32, null]], "Question 4": [[31, null], [32, null]], "Question 5": [[31, null], [32, null]], "Question 6": [[31, null]], "Question 7": [[31, null]], "Question 8": [[31, null]], "Question 9": [[31, null]], "Questions": [[126, "questions"]], "Questions / tasks": [[126, "questions-tasks"], [126, "id2"]], "Questions and things to do": [[127, "questions-and-things-to-do"]], "Questions for the class": [[35, null]], "Questions:": [[126, "id1"]], "Quick introduction to  scipy.stats": [[17, "quick-introduction-to-scipy-stats"], [112, "quick-introduction-to-scipy-stats"]], "Quick review: To a Bayesian, everything is a PDF (probability density function)": [[17, "quick-review-to-a-bayesian-everything-is-a-pdf-probability-density-function"]], "RMSprop": [[99, "rmsprop"]], "Radial Basis Function kernel": [[81, "radial-basis-function-kernel"]], "Random Walk Metropolis-Hasting (MH)": [[136, "random-walk-metropolis-hasting-mh"]], "Random variables: probability distribution and density": [[112, "random-variables-probability-distribution-and-density"]], "Rank": [[118, "rank"]], "Rational Quadradtic kernel": [[81, "rational-quadradtic-kernel"]], "Recall Beta function": [[13, null]], "Recall Metropolis algorithm for p(\\thetavec | D, I) (or any other posterior).": [[141, null]], "Recall the basic structure of Metropolis-Hastings": [[136, null]], "Recap of GPs": [[79, "recap-of-gps"]], "Recap of Poisson MCMC example": [[141, "recap-of-poisson-mcmc-example"]], "Recaps": [[141, null]], "Recurrent neural networks": [[67, "recurrent-neural-networks"]], "Reduced-order methods": [[45, "reduced-order-methods"]], "Reference: Bayesian rules of probability": [[31, "reference-bayesian-rules-of-probability"], [32, "reference-bayesian-rules-of-probability"]], "References:": [[85, "references"]], "Regression algorithms": [[64, null]], "Regression analysis with linear models": [[98, "regression-analysis-with-linear-models"]], "Regression analysis: optimization versus inference": [[100, "regression-analysis-optimization-versus-inference"]], "Regular NNs don\u2019t scale well to full images": [[75, "regular-nns-dont-scale-well-to-full-images"]], "Regularization": [[88, "regularization"]], "Regularization: Ridge and Lasso": [[66, "regularization-ridge-and-lasso"]], "Remarks": [[0, "remarks"]], "Remarks on bias and variance": [[66, "remarks-on-bias-and-variance"]], "Reporting Biases": [[63, null]], "Reproducibility": [[43, "reproducibility"]], "Requirements for AI systems": [[63, null]], "Reshape": [[118, "reshape"]], "Results": [[43, "results"]], "Reversibility": [[138, "reversibility"]], "Review of bivariate normal case": [[78, "review-of-bivariate-normal-case"]], "Rewriting the likelihood": [[34, "rewriting-the-likelihood"]], "Row-major order": [[118, null]], "Run MCMC": [[124, "run-mcmc"]], "S/IR limitations": [[44, "s-ir-limitations"]], "SVD applied to images for compression": [[109, "svd-applied-to-images-for-compression"]], "SVD basics": [[109, "svd-basics"]], "Sampling": [[18, null], [38, "sampling"], [133, "sampling"]], "Sampling / Importance Resampling": [[44, "sampling-importance-resampling"]], "Sampling a distribution": [[138, null]], "Sampling and plotting multivariate Gaussians": [[82, "sampling-and-plotting-multivariate-gaussians"]], "Sampling from a Gaussian Process": [[83, "sampling-from-a-gaussian-process"]], "Sampling from a PDF": [[135, "sampling-from-a-pdf"]], "Sampling of 1d pdfs in Python": [[17, "sampling-of-1d-pdfs-in-python"]], "Saving a figure": [[116, "saving-a-figure"]], "Scalar operations": [[118, "scalar-operations"]], "Scale invariance": [[3, "scale-invariance"]], "Scikit-learn demo notebooks": [[87, null]], "Second example: each sample is two points": [[33, "second-example-each-sample-is-two-points"]], "Second pass: More elaborate controls and options": [[114, "second-pass-more-elaborate-controls-and-options"]], "Select element(s)": [[118, "select-element-s"]], "Selected exercises from notebook": [[79, "selected-exercises-from-notebook"]], "Selection bias": [[63, null]], "Set plot style": [[105, "set-plot-style"]], "Setting Covariance Function Parameters": [[77, "setting-covariance-function-parameters"], [83, "setting-covariance-function-parameters"]], "Setting it up": [[75, "setting-it-up"]], "Setting up the back-propagation algorithm": [[68, "setting-up-the-back-propagation-algorithm"]], "Setting up to use this Jupyter book": [[121, null]], "Setup sampling with emcee and pocomc samplers": [[105, "setup-sampling-with-emcee-and-pocomc-samplers"]], "Shape, size, length and data type": [[118, "shape-size-length-and-data-type"]], "Singular value decomposition (SVD)": [[107, "singular-value-decomposition-svd"]], "Sivia example on \u201csignal on top of background\u201d": [[35, "sivia-example-on-signal-on-top-of-background"]], "Solution strategy:": [[96, "solution-strategy"]], "Solution to": [[34, "solution:BayesianLinearRegression:likelihood_pars"], [34, "solution:ols_example_1_b"], [34, "solution:ols_example_3_b"]], "Solution to Exercise 15.1": [[143, "solution:StochasticProcess:first-example"]], "Solution to Exercise 15.2": [[143, "solution:conditional-probabilities-stochastic-process"]], "Solution to Exercise 15.3": [[143, "solution:construct-stochastic-process"]], "Solution to Exercise 16.1 (Stochastic matrix)": [[138, "solution:MarkovChains:stochastic-matrix"]], "Solution to Exercise 16.10 (Flip-flop)": [[138, "solution:flip-flop"]], "Solution to Exercise 16.11 (Gothenburg winter weather)": [[138, "solution:MarkovChains:gothenburg-winter-weather"]], "Solution to Exercise 16.12 (Stationary Gothenburg winter weather)": [[138, "solution:stationary-gothenburg-winter-weather"]], "Solution to Exercise 16.13 (Is it reversible?)": [[138, "solution:is-it-reversible"]], "Solution to Exercise 16.14 (Optical pumping)": [[138, "solution:optical-pumping"]], "Solution to Exercise 16.15 (Detailed balance)": [[138, "solution:detailed-balance"]], "Solution to Exercise 16.16 (Metropolis sampling of a uniform distribution)": [[135, "solution:metropolis-sampling-uniform"]], "Solution to Exercise 16.17 (Power-law distributions)": [[135, "solution:power-law-distribution-sampling"]], "Solution to Exercise 16.18 (The Metropolis algorithm for a discrete distribution)": [[135, "solution:MCMC:discrete-metropolis"]], "Solution to Exercise 16.2 (Simple random walk)": [[138, "solution:MarkovChains:simple-random-walk"]], "Solution to Exercise 16.3 (Remnant memory)": [[138, "solution:MarkovChains:memory"]], "Solution to Exercise 16.4 (Conditional distributions)": [[138, "solution:MarkovChains:conditional-distributions"]], "Solution to Exercise 16.5 (Stationary distribution)": [[138, "solution:MarkovChains:stationary-distribution"]], "Solution to Exercise 16.6 (Reversibility)": [[138, "solution:MarkovChains:reversibility"]], "Solution to Exercise 16.7 (A reversible Markov chain)": [[138, "solution:MarkovChains:reversible-chain"]], "Solution to Exercise 16.8 (Stationary two-state distribution)": [[138, "solution:stationary-2x2"]], "Solution to Exercise 16.9 (Limiting distribution)": [[138, "solution:limiting-distribution"]], "Solution to Exercise 21.1 (Sigmoid decision boundary)": [[65, "solution:MLexamples:sigmoid-decision-boundary"]], "Solution to Exercise 21.4 (kNN for regression)": [[65, "solution:MLexamples:kNN-regression"]], "Solution to Exercise 21.5 (R2 score)": [[65, "solution:MLexamples:R2-score"]], "Solution to Exercise 22.1 (Weights and signal propagation of a simple neural network)": [[67, "solution:NeuralNet:simple-network"]], "Solution to Exercise 22.2 (Weights and signal propagation of a wide neural network)": [[67, "solution:NeuralNet:wide-network"]], "Solution to Exercise 22.3 (Linear signals)": [[67, "solution:NeuralNet:linear-signal"]], "Solution to Exercise 22.4 (Expected signal)": [[67, "solution:NeuralNet:expected-signal"]], "Solution to Exercise 22.5 (k=1 NN training error)": [[66, "solution:ModelValidation:kNN-training-error"]], "Solution to Exercise 22.6 (kNN model complexity)": [[66, "solution:ModelValidation:kNN-model-complexity"]], "Solution to Exercise 22.7 (Study of model bias and variance)": [[66, "solution:ModelValidation:study-model-bias-variance"]], "Solution to Exercise 22.8 (Implement k-fold cross validation)": [[66, "solution:ModelValidation:kfold-cross-validation"]], "Solution to Exercise 22.9 (Large training error)": [[66, "solution:ModelValidation:large-training-error"]], "Solution to Exercise 32.1": [[0, "solution:ppd_definition_b"]], "Solution to Exercise 33.1 (Random and colorblind)": [[112, "solution:Statistics:colorblind"]], "Solution to Exercise 33.2 (Conditional discrete probability mass function)": [[112, "solution:Statistics:conditional-discrete-pmf"]], "Solution to Exercise 33.3 (Conditional probability for continuous variables)": [[112, "solution:Statistics:conditional-probability-continuous"]], "Solution to Exercise 33.4 (Conditional expectation)": [[112, "solution:Statistics:conditional-expectation"]], "Solution to Exercise 33.5 (Scipy.stats)": [[112, "colution:Statistics:scipy-stats"]], "Solution to Exercise 33.6 (Bivariate pdf)": [[112, "solution:Statistics:bivariate-pdf"]], "Solution to Exercise 36.1 (Independent and dependent)": [[100, "solution:OverviewModeling:independent-dependent"]], "Solution to Exercise 36.2 (Linear or non-linear)": [[100, "solution:OverviewModeling:linear-nonlinear"]], "Solution to Exercise 36.3 (Linear or non-linear; more examples)": [[100, "solution:OverviewModeling:linear-nonlinear-examples"]], "Solution to Exercise 36.4 (Model discrepancy)": [[100, "solution:OverviewModeling:model-discrepancy"]], "Solution to Exercise 37.1": [[98, "solution:ols_example_1"]], "Solution to Exercise 37.3": [[98, "solution:ols_example_3"]], "Solution to Exercise 4.3": [[16, "solution:ppd_definition"]], "Solution to Exercise 4.4": [[16, "solution:pdf_normalization"]], "Solution to Exercise 4.5": [[16, "solution:rain"]], "Solution to Exercise 4.6": [[16, "solution:monty_hall"]], "Solution to Exercise 4.7": [[16, "solution:coin_ppd"]], "Solution to Exercise 7.1 (Correlated errors)": [[7, "solution:BayesianAdvantage:correlated-errors"]], "Solution to Exercise 7.3 (Inferring galactic distances)": [[7, "solution:BayesianAdvantages:inferring-galactic-distances-ex"]], "Solution to Exercise 7.4 (The standard random variable)": [[7, "solution:BayesianAdvantages:standard-random-variable"]], "Solution to Exercise 7.5 (The square root of a number)": [[7, "solution:BayesianAdvantages:square-root-of-a-number"]], "Solution to Exercise 7.6 (Gaussian sum of errors)": [[7, "solution:BayesianAdvantages:gaussian-sum-of-errors"]], "Solution to Exercise 7.7 (Gaussian product of errors)": [[7, "solution:BayesianAdvantages:gaussian-product-of-errors"]], "Solutions": [[7, "solutions"], [16, "solutions"], [65, "solutions"], [66, "solutions"], [67, "solutions"], [98, "solutions"], [100, "solutions"], [112, "solutions"], [135, "solutions"], [138, "solutions"], [143, "solutions"]], "Solutions to selected exercises": [[34, "solutions-to-selected-exercises"]], "Solving matrix equations with SVD": [[109, "solving-matrix-equations-with-svd"]], "Solving orbital equations with different algorithms": [[132, null]], "Some standard pdfs: the normal (aka Gaussian) and beta distributions": [[17, "some-standard-pdfs-the-normal-aka-gaussian-and-beta-distributions"]], "Sorting": [[118, "sorting"]], "Sparsity": [[102, "sparsity"]], "Special case: Gaussian process": [[143, "special-case-gaussian-process"]], "Speed comparisons": [[117, "speed-comparisons"]], "Splitting arrays": [[118, "splitting-arrays"]], "Spot the error!": [[34, null]], "Standard Error of the Mean": [[125, "standard-error-of-the-mean"]], "Standard Likelihood Approach": [[38, "standard-likelihood-approach"]], "Standard activation functions": [[88, "standard-activation-functions"]], "State-of-the-art MCMC implementations": [[135, "state-of-the-art-mcmc-implementations"]], "Statements": [[21, null]], "Stationary and limiting distributions": [[138, "stationary-and-limiting-distributions"]], "Stationary kernels": [[85, "stationary-kernels"]], "Stationary processes": [[138, "stationary-processes"]], "Statistical Operations": [[118, "statistical-operations"]], "Statistical formulation": [[105, "statistical-formulation"]], "Statistics concepts and notation": [[112, null]], "Step 1: Maximum likelihood estimate": [[41, "step-1-maximum-likelihood-estimate"]], "Step 2: Single-parameter model": [[41, "step-2-single-parameter-model"]], "Step 3: Full Bayesian approach": [[41, "step-3-full-bayesian-approach"]], "Step 4: Error propagation": [[41, "step-4-error-propagation"]], "Stochastic processes": [[143, null]], "Student t distribution as a mixture of Gaussians": [[108, null]], "Sub-task": [[70, "sub-task"]], "Sub-tasks and follow-up questions": [[70, "sub-tasks-and-follow-up-questions"]], "Subtasks (put your answers here):": [[96, "subtasks-put-your-answers-here"]], "Suggestions for how to proceed:": [[94, "suggestions-for-how-to-proceed"]], "Sum of normally distributed random variables.": [[85, null]], "Sum rule": [[22, "sum-rule"]], "Summary": [[7, null], [8, "summary"], [41, "summary"], [85, null]], "Summary points from arXiv:1710.06068": [[141, null]], "Symmetry invariance": [[3, "symmetry-invariance"]], "Systematic error example": [[41, "systematic-error-example"]], "Systematic reduction": [[75, "systematic-reduction"]], "Systemic biases": [[63, null]], "Table of results": [[35, null]], "Take aways: Coin tossing": [[25, "take-aways-coin-tossing"]], "Take-aways and follow-up questions from coin flipping:": [[15, null]], "Task 1: Logistic regression using scikit-learn": [[74, "task-1-logistic-regression-using-scikit-learn"]], "Task 2: Bayesian logistic regression using MCMC sampling": [[74, "task-2-bayesian-logistic-regression-using-mcmc-sampling"]], "Task 3: Bayesian logistic regression using Variational Inference": [[74, "task-3-bayesian-logistic-regression-using-variational-inference"]], "Telling ChatGPT 4 to make a network for a function of one variable": [[71, "telling-chatgpt-4-to-make-a-network-for-a-function-of-one-variable"]], "Terminology": [[67, "terminology"]], "Test the sum of normal variables squared": [[29, "test-the-sum-of-normal-variables-squared"]], "The Central Limit Theorem": [[19, "the-central-limit-theorem"]], "The Data": [[40, "the-data"], [125, "the-data"]], "The Data and the question": [[41, "the-data-and-the-question"]], "The Data and the true result": [[49, "the-data-and-the-true-result"]], "The Gaussian is to statistics what the harmonic oscillator is to mechanics": [[19, "the-gaussian-is-to-statistics-what-the-harmonic-oscillator-is-to-mechanics"]], "The Gelman-Rubin test": [[44, "the-gelman-rubin-test"]], "The Jupyter Notebook menu and shortcuts": [[116, "the-jupyter-notebook-menu-and-shortcuts"]], "The Kullback-Leibler divergence": [[72, "the-kullback-leibler-divergence"]], "The Metropolis-Hastings algorithm": [[135, "the-metropolis-hastings-algorithm"]], "The Model": [[38, "the-model"], [40, "the-model"], [41, "the-model"], [95, "the-model"], [125, "the-model"]], "The Prior": [[40, "the-prior"]], "The RBF kernel (a.k.a Gaussian)": [[78, "the-rbf-kernel-a-k-a-gaussian"], [82, "the-rbf-kernel-a-k-a-gaussian"]], "The Story of Dr. A and Prof. B": [[53, "the-story-of-dr-a-and-prof-b"]], "The Zeus Ensemble Slice Sampler": [[145, null]], "The ball-drop model": [[103, "the-ball-drop-model"]], "The bias-variance tradeoff": [[66, "the-bias-variance-tradeoff"]], "The continuum limit": [[25, "the-continuum-limit"]], "The cost function rewritten as cross entropy": [[88, "the-cost-function-rewritten-as-cross-entropy"]], "The covariance matrix as the central object": [[85, "the-covariance-matrix-as-the-central-object"]], "The entropy of Scandinavians": [[4, "the-entropy-of-scandinavians"]], "The friends of Bayes\u2019 theorem": [[25, "the-friends-of-bayes-theorem"]], "The likelihood": [[34, "the-likelihood"]], "The logistic function": [[88, "the-logistic-function"]], "The monkey argument": [[4, "the-monkey-argument"]], "The near ubiquity of Gaussians": [[19, "the-near-ubiquity-of-gaussians"]], "The normal distribution": [[4, null]], "The normal equation": [[34, "the-normal-equation"], [98, "the-normal-equation"]], "The perceptron": [[88, "the-perceptron"]], "The perceptron classifier": [[65, "the-perceptron-classifier"]], "The posterior": [[34, "the-posterior"]], "The posterior predictive": [[34, "the-posterior-predictive"]], "The posterior predictive distribution": [[16, "the-posterior-predictive-distribution"]], "The prior": [[34, "the-prior"]], "The probability measure": [[112, "the-probability-measure"]], "The pseudo-inverse (or Moore-Penrose inverse)": [[34, null]], "The soft classifier": [[65, "the-soft-classifier"]], "The statistical model (recap)": [[49, "the-statistical-model-recap"]], "The tip class": [[0, "the-tip-class"]], "The toy model": [[49, "the-toy-model"]], "The uniform distribution": [[112, "the-uniform-distribution"]], "Theory": [[105, "theory"]], "Things for you to do:": [[49, "things-for-you-to-do"]], "Things to do and Questions to answer": [[95, "things-to-do-and-questions-to-answer"]], "Things to do:": [[40, "things-to-do"], [109, "things-to-do"]], "Things to try:": [[111, "things-to-try"]], "Third example: each sample is 10 points": [[33, "third-example-each-sample-is-10-points"]], "Third pass:  a more elaborate user interface with tabs": [[114, "third-pass-a-more-elaborate-user-interface-with-tabs"]], "This makes sense:": [[86, null]], "Three main ingredients of machine learning": [[64, null]], "To do": [[93, "to-do"]], "To our real data: nuclear binding energies. Brief reminder on masses and binding energies": [[115, "to-our-real-data-nuclear-binding-energies-brief-reminder-on-masses-and-binding-energies"]], "To think about \u2026": [[19, null]], "Trace": [[118, "trace"]], "Train and evaluate the model:": [[69, "train-and-evaluate-the-model"]], "Training and validation scores": [[66, null]], "Training scores": [[65, "training-scores"]], "Transformation property of multivariate normal distributions": [[34, null]], "Transforming images": [[75, "transforming-images"]], "Try it yourself with the Jupyter notebook": [[115, null]], "Trying a different function": [[5, "trying-a-different-function"]], "Two dependent parameters": [[53, "two-dependent-parameters"]], "Two independent parameters": [[53, "two-independent-parameters"]], "Two views on the likelihood": [[34, null]], "Types of Machine Learning": [[64, "types-of-machine-learning"]], "Types of probability": [[112, "types-of-probability"]], "Uncertainty in predicted value": [[73, "uncertainty-in-predicted-value"], [93, "uncertainty-in-predicted-value"]], "Uncorrelated assignments": [[4, null]], "Univariate Approaches": [[125, "univariate-approaches"]], "Updating via Bayes\u2019 rule": [[10, null]], "Updating your conda environment for Learning from Data": [[119, "updating-your-conda-environment-for-learning-from-data"]], "User-interface for coin-flipping": [[9, "user-interface-for-coin-flipping"]], "Using Anaconda": [[119, null]], "Using Bayesian model mixing to open the model space": [[48, "using-bayesian-model-mixing-to-open-the-model-space"]], "Using GitHub": [[122, null]], "Using SVD for PCA": [[109, "using-svd-for-pca"]], "Using parallel tempering: ptemcee": [[96, "using-parallel-tempering-ptemcee"]], "Utilizing GPU Acceleration": [[71, "utilizing-gpu-acceleration"]], "Variance and the Gaussian pdf": [[4, "variance-and-the-gaussian-pdf"]], "Variance of the mean": [[44, "variance-of-the-mean"]], "Variational Inference: Bayesian Neural Networks": [[93, "variational-inference-bayesian-neural-networks"]], "Variational Inference: Scaling model complexity": [[73, "variational-inference-scaling-model-complexity"], [93, "variational-inference-scaling-model-complexity"]], "Variational inference for Bayesian neural networks": [[72, "variational-inference-for-bayesian-neural-networks"]], "Verification of PyTorch installation (suggested in PyTorch website)": [[71, "verification-of-pytorch-installation-suggested-in-pytorch-website"]], "Verify the data": [[76, "verify-the-data"]], "Verifying sampling": [[18, null]], "Virtues": [[61, null]], "Visualization of MCMC sampling": [[136, "visualization-of-mcmc-sampling"]], "Visualization of PDFs": [[17, "visualization-of-pdfs"]], "Visualizations of MCMC": [[135, "visualizations-of-mcmc"]], "Visualizing PDFs": [[23, "visualizing-pdfs"]], "Warnings": [[0, "warnings"]], "What are arrays?": [[118, "what-are-arrays"]], "What does it mean that the ellipses are slanted?": [[35, null]], "What failure looks like": [[5, "what-failure-looks-like"]], "What if the only moves accepted were those that went uphill (i.e., to higher probability density)? What would happen to N_A and N_B over time? Is this stationary?": [[141, null]], "What is p(\\thetavec_i|D,I)?": [[141, null]], "What is special about machine learning in physics?": [[60, null]], "What is the ratio of p(X_B|X_A) to p(X_A|X_B) in terms of p(X_A|D,I) and p(X_B|D,I)?": [[141, null]], "What is well determined?": [[79, null]], "What next?": [[46, "what-next"]], "What order polynomial?": [[95, "what-order-polynomial"]], "What pairs are highly correlated?": [[79, null]], "What returns the prior?": [[79, null]], "What to do about sampling from correlated distributions?": [[128, "what-to-do-about-sampling-from-correlated-distributions"]], "What you should know about Python and using Jupyter notebooks": [[120, "what-you-should-know-about-python-and-using-jupyter-notebooks"]], "When do priors matter? When don\u2019t they matter?": [[12, null]], "Why MCMC?": [[136, "why-mcmc"]], "Why deep neural networks?": [[67, "why-deep-neural-networks"]], "Why do you think that this property is called detailed balance? Can you make an analogy with thermodynamic equilibrium for e.g. a collection of hydrogen atoms?": [[141, null]], "Why maximize the entropy?": [[4, "why-maximize-the-entropy"]], "With model discrepancy": [[105, "with-model-discrepancy"]], "Without model discrepancy": [[105, "without-model-discrepancy"]], "Workflow for Bayesian linear regression": [[34, "workflow-for-bayesian-linear-regression"]], "Yet another function": [[5, "yet-another-function"]], "Zero-based indexing": [[118, null]], "emcee": [[96, "emcee"]], "emcee:": [[135, null]], "k nearest neighbors classification": [[65, "k-nearest-neighbors-classification"]], "kNN classifier": [[65, "knn-classifier"]], "l1-norm": [[4, "l1-norm"]], "numpy arrays": [[116, "numpy-arrays"]], "p or \\log p?": [[19, null]], "p-values: when all you can do is falsify": [[19, "p-values-when-all-you-can-do-is-falsify"]], "\ud83d\udce5 Amplitude of a signal in the presence of background": [[37, null]], "\ud83d\udce5 Dealing with outliers": [[38, null]], "\ud83d\udce5 Demonstration:  Bayesian Coin Tossing": [[30, null]], "\ud83d\udce5 Demonstration: Coin tossing": [[9, null]], "\ud83d\udce5 Demonstration: Prior PDFs for straight lines": [[6, null]], "\ud83d\udce5 Demonstration: Reading Data and fitting": [[115, null]], "\ud83d\udce5 Demonstration: Sum of normal variables squared": [[29, null]], "\ud83d\udce5 Distributions of Randomly-Initialized ANNs": [[111, null]], "\ud83d\udce5 Exercise: Jupyter Notebooks and Python": [[116, null]], "\ud83d\udce5 Exercise: Linear algebra operations with NumPy": [[118, null]], "\ud83d\udce5 Exercise: Python lists and iterations": [[117, null]], "\ud83d\udce5 Exploring PDFs": [[17, null]], "\ud83d\udce5 Linear algebra games including SVD for PCA": [[109, null]], "\ud83d\udce5 Making a simple widget-based UI": [[114, null]], "\ud83d\udce5 Maximum Entropy for reconstructing a function from its moments": [[5, null]], "\ud83d\udce5 Model discrepancy example: The ball-drop experiment": [[105, null]], "\ud83d\udce5 Parameter estimation example: Gaussian noise and averages I": [[39, null]], "\ud83d\udce5 Parameter estimation example: fitting a straight line II": [[41, null]], "\ud83d\udce5 Radioactive lighthouse problem": [[42, null]], "\ud83d\udce5 Visualization of the Central Limit Theorem": [[33, null]]}, "docnames": ["LearningFromData-content/Backmatter/JB_tests", "LearningFromData-content/Backmatter/bibliography", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/Assigning", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/IgnorancePDF", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt2", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt_Function_Reconstruction", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/demo-straight_lines", "LearningFromData-content/BayesianStatistics/BayesianBasics/BayesianAdvantages", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_epistemology", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_updating_coinflip_interactive", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-01-coin-tossing-frequentists-and-bayesaians", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-02-when-do-priors-matter-when-don-t-they-matter", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-03-computing-the-posterior-analytically", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-04-degree-of-belief-credibility-intervals-vs-frequentist-1-sigm", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-05-take-aways-and-follow-up-questions-from-coin-flipping", "LearningFromData-content/BayesianStatistics/BayesianBasics/DataModelsPredictions", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs_followups", "LearningFromData-content/BayesianStatistics/BayesianBasics/Gaussians", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-01-statements", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-02-manipulating-probabilities-bayesian-rules-of-probability-as", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-03-probability-density-functions", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-04-summary", "LearningFromData-content/BayesianStatistics/BayesianBasics/MoreBayesTheorem", "LearningFromData-content/BayesianStatistics/BayesianBasics/Posteriors", "LearningFromData-content/BayesianStatistics/BayesianBasics/RootBayesianBasics", "LearningFromData-content/BayesianStatistics/BayesianBasics/UsingBayes", "LearningFromData-content/BayesianStatistics/BayesianBasics/chi_squared_tests", "LearningFromData-content/BayesianStatistics/BayesianBasics/demo-BayesianBasics", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_medical_example_by_Bayes", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_sum_product_rule", "LearningFromData-content/BayesianStatistics/BayesianBasics/visualization_of_CLT", "LearningFromData-content/BayesianStatistics/BayesianLinearRegression/BayesianLinearRegression_rjf", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/Interpreting2Dposteriors", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/ParameterEstimation", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/amplitude_in_presence_of_background", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/dealing_with_outliers", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_Gaussian_noise", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_I", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_II", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/radioactive_lighthouse_exercise", "LearningFromData-content/BayesianStatistics/BayesianWorkflow/BayesianWorkflow", "LearningFromData-content/BayesianStatistics/ComputationalBayes/AdvancedMCMC", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesFast", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesLinear", "LearningFromData-content/BayesianStatistics/ComputationalBayes/extra_RBM_emulators", "LearningFromData-content/BayesianStatistics/ModelMixing/model_mixing", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/Evidence_for_model_EFT_coefficients", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/MCMC-parallel-tempering_ptemcee_vs_zeus", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/computing_evidence", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/two_model_evidence", "LearningFromData-content/BayesianStatistics/ModelSelection/ModelSelection", "LearningFromData-content/BayesianStatistics/Multimodel_inference", "LearningFromData-content/BayesianStatistics/RootAdvancedMethods", "LearningFromData-content/Intro/About", "LearningFromData-content/Intro/Introduction", "LearningFromData-content/Intro/Introduction/sec-01-physicist-s-perspective", "LearningFromData-content/Intro/Introduction/sec-02-bayesian-workflow", "LearningFromData-content/Intro/Introduction/sec-03-machine-learning", "LearningFromData-content/Intro/Introduction/sec-04-virtues", "LearningFromData-content/Intro/Invitation", "LearningFromData-content/MachineLearning/ANN/DataBiasFairness", "LearningFromData-content/MachineLearning/ANN/MachineLearning", "LearningFromData-content/MachineLearning/ANN/MachineLearningExamples", "LearningFromData-content/MachineLearning/ANN/ModelValidation", "LearningFromData-content/MachineLearning/ANN/NeuralNet", "LearningFromData-content/MachineLearning/ANN/NeuralNet/NeuralNetBackProp", "LearningFromData-content/MachineLearning/ANN/NeuralNet/demo-NeuralNet", "LearningFromData-content/MachineLearning/ANN/NeuralNet/exercises_LogReg_NeuralNet", "LearningFromData-content/MachineLearning/ANN/Neural_Network_for_simple_function_in_PyTorch", "LearningFromData-content/MachineLearning/BNN/bnn", "LearningFromData-content/MachineLearning/BNN/demo-bnn", "LearningFromData-content/MachineLearning/BNN/exercises_BNN", "LearningFromData-content/MachineLearning/CNN/cnn", "LearningFromData-content/MachineLearning/CNN/demo-cnn", "LearningFromData-content/MachineLearning/GP/BUQ/Gaussian_processes_exercises", "LearningFromData-content/MachineLearning/GP/BUQ/demo-GaussianProcesses", "LearningFromData-content/MachineLearning/GP/BUQ/lecture_20", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_noisy_targets", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_prior_posterior", "LearningFromData-content/MachineLearning/GP/CF/demo-GaussianProcesses", "LearningFromData-content/MachineLearning/GP/CF/exercise_GP_GPy", "LearningFromData-content/MachineLearning/GP/GPy_demos", "LearningFromData-content/MachineLearning/GP/GaussianProcesses", "LearningFromData-content/MachineLearning/GP/RootGP", "LearningFromData-content/MachineLearning/GP/Sklearn_demos", "LearningFromData-content/MachineLearning/LogReg/LogReg", "LearningFromData-content/MachineLearning/RootML", "LearningFromData-content/Mini-projects/Mini-project_IIb_overview", "LearningFromData-content/Mini-projects/RootMiniProjects", "LearningFromData-content/Mini-projects/mini-project_IIIa_bayesian_optimization", "LearningFromData-content/Mini-projects/mini-project_IIIb_Bayesian_neural_networks_from_demo", "LearningFromData-content/Mini-projects/mini-project_I_toy_model_of_EFT", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIa", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIb_How_many_lines_ptemcee", "LearningFromData-content/ModelingOptimization/GradientDescent", "LearningFromData-content/ModelingOptimization/LinearModels", "LearningFromData-content/ModelingOptimization/MathematicalOptimization", "LearningFromData-content/ModelingOptimization/OverviewModeling", "LearningFromData-content/ModelingOptimization/RootScientificModeling", "LearningFromData-content/OtherTopics/ANNFT", "LearningFromData-content/OtherTopics/DiscrepancyModels", "LearningFromData-content/OtherTopics/Emulators", "LearningFromData-content/OtherTopics/MD_balldrop_v1", "LearningFromData-content/OtherTopics/RootOtherTopics", "LearningFromData-content/OtherTopics/SVD", "LearningFromData-content/OtherTopics/Student_t_distribution_from_Gaussians", "LearningFromData-content/OtherTopics/linear_algebra_games_including_SVD", "LearningFromData-content/OtherTopics/qbism", "LearningFromData-content/OtherTopics/random_initialized_ANN_vs_width", "LearningFromData-content/Reference/Statistics", "LearningFromData-content/Setup/RootGettingStarted", "LearningFromData-content/Setup/Simple_widgets_v1", "LearningFromData-content/Setup/demo-Intro", "LearningFromData-content/Setup/exercise_Intro_01_Jupyter_Python", "LearningFromData-content/Setup/exercise_Intro_02_Jupyter_Python", "LearningFromData-content/Setup/exercise_Intro_03_Numpy", "LearningFromData-content/Setup/installing_anaconda", "LearningFromData-content/Setup/more_python_and_jupyter", "LearningFromData-content/Setup/setting_up", "LearningFromData-content/Setup/using_github", "LearningFromData-content/StochasticProcesses/Advanced_MCMC", "LearningFromData-content/StochasticProcesses/BUQ/Assignment_extending_radioactive_lighthouse", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-diagnostics", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-random-walk-and-sampling", "LearningFromData-content/StochasticProcesses/BUQ/Metropolis_Poisson_example", "LearningFromData-content/StochasticProcesses/BUQ/intuition_sampling", "LearningFromData-content/StochasticProcesses/BUQ/parameter_estimation_Gaussian_noise-2", "LearningFromData-content/StochasticProcesses/BUQ2/HMC_intro_BUQ", "LearningFromData-content/StochasticProcesses/BUQ2/Liouville_theorem_visualization", "LearningFromData-content/StochasticProcesses/BUQ2/Orbital_eqs_with_different_algorithms", "LearningFromData-content/StochasticProcesses/BUQ2/PyMC_intro_updated", "LearningFromData-content/StochasticProcesses/BUQ2/parameter_estimation_Gaussian_noise_compare_samplers", "LearningFromData-content/StochasticProcesses/MCMC", "LearningFromData-content/StochasticProcesses/MCMC_intro_BUQ", "LearningFromData-content/StochasticProcesses/MCMC_overview", "LearningFromData-content/StochasticProcesses/MarkovChains", "LearningFromData-content/StochasticProcesses/Other_samplers", "LearningFromData-content/StochasticProcesses/OverviewIntroPyMC", "LearningFromData-content/StochasticProcesses/Recap_BUQ", "LearningFromData-content/StochasticProcesses/RootMCMC", "LearningFromData-content/StochasticProcesses/StochasticProcesses", "LearningFromData-content/StochasticProcesses/demo-MCMC", "LearningFromData-content/StochasticProcesses/zeus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["LearningFromData-content/Backmatter/JB_tests.md", "LearningFromData-content/Backmatter/bibliography.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/Assigning.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/IgnorancePDF.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt2.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt_Function_Reconstruction.ipynb", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/demo-straight_lines.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/BayesianAdvantages.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_epistemology.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_updating_coinflip_interactive.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-01-coin-tossing-frequentists-and-bayesaians.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-02-when-do-priors-matter-when-don-t-they-matter.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-03-computing-the-posterior-analytically.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-04-degree-of-belief-credibility-intervals-vs-frequentist-1-sigm.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-05-take-aways-and-follow-up-questions-from-coin-flipping.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/DataModelsPredictions.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs_followups.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Gaussians.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-01-statements.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-02-manipulating-probabilities-bayesian-rules-of-probability-as.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-03-probability-density-functions.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-04-summary.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/MoreBayesTheorem.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Posteriors.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/RootBayesianBasics.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/UsingBayes.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/chi_squared_tests.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/demo-BayesianBasics.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_medical_example_by_Bayes.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_sum_product_rule.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/visualization_of_CLT.ipynb", "LearningFromData-content/BayesianStatistics/BayesianLinearRegression/BayesianLinearRegression_rjf.md", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/Interpreting2Dposteriors.md", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/ParameterEstimation.md", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/amplitude_in_presence_of_background.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/dealing_with_outliers.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_Gaussian_noise.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_I.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_II.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/radioactive_lighthouse_exercise.ipynb", "LearningFromData-content/BayesianStatistics/BayesianWorkflow/BayesianWorkflow.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/AdvancedMCMC.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesFast.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesLinear.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/extra_RBM_emulators.md", "LearningFromData-content/BayesianStatistics/ModelMixing/model_mixing.md", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/Evidence_for_model_EFT_coefficients.ipynb", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/MCMC-parallel-tempering_ptemcee_vs_zeus.ipynb", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/computing_evidence.md", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/two_model_evidence.md", "LearningFromData-content/BayesianStatistics/ModelSelection/ModelSelection.md", "LearningFromData-content/BayesianStatistics/Multimodel_inference.md", "LearningFromData-content/BayesianStatistics/RootAdvancedMethods.md", "LearningFromData-content/Intro/About.md", "LearningFromData-content/Intro/Introduction.md", "LearningFromData-content/Intro/Introduction/sec-01-physicist-s-perspective.md", "LearningFromData-content/Intro/Introduction/sec-02-bayesian-workflow.md", "LearningFromData-content/Intro/Introduction/sec-03-machine-learning.md", "LearningFromData-content/Intro/Introduction/sec-04-virtues.md", "LearningFromData-content/Intro/Invitation.md", "LearningFromData-content/MachineLearning/ANN/DataBiasFairness.md", "LearningFromData-content/MachineLearning/ANN/MachineLearning.md", "LearningFromData-content/MachineLearning/ANN/MachineLearningExamples.md", "LearningFromData-content/MachineLearning/ANN/ModelValidation.md", "LearningFromData-content/MachineLearning/ANN/NeuralNet.md", "LearningFromData-content/MachineLearning/ANN/NeuralNet/NeuralNetBackProp.md", "LearningFromData-content/MachineLearning/ANN/NeuralNet/demo-NeuralNet.ipynb", "LearningFromData-content/MachineLearning/ANN/NeuralNet/exercises_LogReg_NeuralNet.ipynb", "LearningFromData-content/MachineLearning/ANN/Neural_Network_for_simple_function_in_PyTorch.ipynb", "LearningFromData-content/MachineLearning/BNN/bnn.md", "LearningFromData-content/MachineLearning/BNN/demo-bnn.ipynb", "LearningFromData-content/MachineLearning/BNN/exercises_BNN.ipynb", "LearningFromData-content/MachineLearning/CNN/cnn.md", "LearningFromData-content/MachineLearning/CNN/demo-cnn.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/Gaussian_processes_exercises.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/demo-GaussianProcesses.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/lecture_20.md", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_noisy_targets.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_prior_posterior.ipynb", "LearningFromData-content/MachineLearning/GP/CF/demo-GaussianProcesses.ipynb", "LearningFromData-content/MachineLearning/GP/CF/exercise_GP_GPy.ipynb", "LearningFromData-content/MachineLearning/GP/GPy_demos.md", "LearningFromData-content/MachineLearning/GP/GaussianProcesses.md", "LearningFromData-content/MachineLearning/GP/RootGP.md", "LearningFromData-content/MachineLearning/GP/Sklearn_demos.md", "LearningFromData-content/MachineLearning/LogReg/LogReg.md", "LearningFromData-content/MachineLearning/RootML.md", "LearningFromData-content/Mini-projects/Mini-project_IIb_overview.md", "LearningFromData-content/Mini-projects/RootMiniProjects.md", "LearningFromData-content/Mini-projects/mini-project_IIIa_bayesian_optimization.ipynb", "LearningFromData-content/Mini-projects/mini-project_IIIb_Bayesian_neural_networks_from_demo.ipynb", "LearningFromData-content/Mini-projects/mini-project_I_toy_model_of_EFT.ipynb", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIa.ipynb", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIb_How_many_lines_ptemcee.ipynb", "LearningFromData-content/ModelingOptimization/GradientDescent.md", "LearningFromData-content/ModelingOptimization/LinearModels.md", "LearningFromData-content/ModelingOptimization/MathematicalOptimization.md", "LearningFromData-content/ModelingOptimization/OverviewModeling.md", "LearningFromData-content/ModelingOptimization/RootScientificModeling.md", "LearningFromData-content/OtherTopics/ANNFT.md", "LearningFromData-content/OtherTopics/DiscrepancyModels.md", "LearningFromData-content/OtherTopics/Emulators.md", "LearningFromData-content/OtherTopics/MD_balldrop_v1.ipynb", "LearningFromData-content/OtherTopics/RootOtherTopics.md", "LearningFromData-content/OtherTopics/SVD.md", "LearningFromData-content/OtherTopics/Student_t_distribution_from_Gaussians.ipynb", "LearningFromData-content/OtherTopics/linear_algebra_games_including_SVD.ipynb", "LearningFromData-content/OtherTopics/qbism.md", "LearningFromData-content/OtherTopics/random_initialized_ANN_vs_width.ipynb", "LearningFromData-content/Reference/Statistics.md", "LearningFromData-content/Setup/RootGettingStarted.md", "LearningFromData-content/Setup/Simple_widgets_v1.ipynb", "LearningFromData-content/Setup/demo-Intro.ipynb", "LearningFromData-content/Setup/exercise_Intro_01_Jupyter_Python.ipynb", "LearningFromData-content/Setup/exercise_Intro_02_Jupyter_Python.ipynb", "LearningFromData-content/Setup/exercise_Intro_03_Numpy.ipynb", "LearningFromData-content/Setup/installing_anaconda.md", "LearningFromData-content/Setup/more_python_and_jupyter.md", "LearningFromData-content/Setup/setting_up.md", "LearningFromData-content/Setup/using_github.md", "LearningFromData-content/StochasticProcesses/Advanced_MCMC.md", "LearningFromData-content/StochasticProcesses/BUQ/Assignment_extending_radioactive_lighthouse.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-diagnostics.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-random-walk-and-sampling.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/Metropolis_Poisson_example.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/intuition_sampling.md", "LearningFromData-content/StochasticProcesses/BUQ/parameter_estimation_Gaussian_noise-2.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/HMC_intro_BUQ.md", "LearningFromData-content/StochasticProcesses/BUQ2/Liouville_theorem_visualization.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/Orbital_eqs_with_different_algorithms.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/PyMC_intro_updated.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/parameter_estimation_Gaussian_noise_compare_samplers.ipynb", "LearningFromData-content/StochasticProcesses/MCMC.md", "LearningFromData-content/StochasticProcesses/MCMC_intro_BUQ.md", "LearningFromData-content/StochasticProcesses/MCMC_overview.md", "LearningFromData-content/StochasticProcesses/MarkovChains.md", "LearningFromData-content/StochasticProcesses/Other_samplers.md", "LearningFromData-content/StochasticProcesses/OverviewIntroPyMC.md", "LearningFromData-content/StochasticProcesses/Recap_BUQ.md", "LearningFromData-content/StochasticProcesses/RootMCMC.md", "LearningFromData-content/StochasticProcesses/StochasticProcesses.md", "LearningFromData-content/StochasticProcesses/demo-MCMC.ipynb", "LearningFromData-content/StochasticProcesses/zeus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 3, 4, 8, 9, 11, 12, 15, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 56, 57, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 92, 94, 95, 96, 97, 98, 100, 102, 103, 105, 107, 108, 109, 110, 111, 112, 115, 116, 117, 119, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 141, 143, 144], "0": [0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 21, 22, 24, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 88, 92, 94, 95, 96, 97, 98, 99, 100, 103, 105, 107, 108, 109, 111, 112, 114, 115, 116, 117, 118, 119, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 143, 144, 145], "00": [1, 38, 39, 50, 66, 69, 77, 83, 93, 105, 109, 112, 127, 129, 132, 133, 134, 143, 144], "000": [31, 32, 43, 44, 75, 76, 115, 127, 133, 138, 141, 143, 144], "0000": 71, "000000": 115, "00000000e": [78, 109], "0000000e": 78, "00001": 1, "000054": 115, "00008": 1, "00009": 115, "0001": [31, 70], "0001013": 133, "00011": 115, "00012": 115, "00046": 115, "00049": 115, "0005": 78, "0005735": 39, "00088142": 39, "000e": [105, 109], "001": [1, 77, 82, 83, 99, 112, 132, 133], "00107510802066753": 1, "0015": 49, "0019908111153914033": 83, "001mb": 77, "002": [109, 115, 134], "00271642": 109, "00297317": 39, "0029802": 39, "003": 134, "003100": 115, "00319134": 133, "00351647": 109, "003620": 115, "0038": 76, "00398911": 39, "004": [5, 112, 133, 143], "00400084": 39, "00429143": [129, 134], "0043": 31, "00471168": 109, "004752": 78, "005": [44, 78, 82, 125, 128, 133, 144], "0051": 111, "00560623": [129, 134], "00568668": 39, "00572132e": 78, "006": 133, "007": 109, "00727646693": 115, "007315": 115, "007825": 115, "00787254": 109, "00788": 72, "00796648": 39, "00806543": 39, "00824752": 109, "0084806e": 76, "00854895": 39, "008664": 115, "0086649156": 115, "008994472236619899": 77, "009": 1, "0094": 76, "00941": 92, "00975301": 109, "00978733": 39, "009e": 105, "00arviz_vers": 133, "00it": 134, "00j": 78, "01": [3, 7, 17, 33, 34, 37, 42, 49, 65, 66, 67, 69, 70, 71, 73, 76, 77, 78, 81, 83, 92, 93, 95, 105, 109, 112, 133, 134, 143, 144], "01012718": 39, "010902": 115, "011": 109, "01120706": 39, "01125": 1, "012": 144, "0128": 111, "013": [32, 143], "01300685e": 133, "01335268": 39, "01382247": 39, "013e": 105, "014": 31, "014004": 1, "014101": 115, "01460295": 109, "015": 143, "01652757": 39, "017": [1, 143], "01715": 1, "01716473": 39, "01740941": 39, "01795589": 39, "01818182": 109, "018232": 115, "01855247": 39, "01e": 81, "01it": 134, "02": [1, 37, 42, 44, 76, 78, 80, 82, 95, 105, 108, 133, 134, 143, 144], "020": [1, 144], "02010975": 39, "021": 143, "02124813": 39, "02139": 133, "02139arrai": 133, "02186284": 39, "022": 1, "022227": 39, "02227172": [129, 134], "02230963": 109, "02289597e": 109, "023": 31, "024": 144, "02423564e": 133, "02460693": 109, "02468419": 133, "025": [115, 133], "02507": 1, "02599999": 39, "026218253x": 1, "02673241": 39, "027": 38, "02827408": [129, 134], "02941762": 39, "029733": 115, "03": [1, 4, 76, 78, 95, 105, 125, 133, 134, 144], "030002": 115, "030003": [1, 115], "0303": 82, "03085711": 39, "03224": 115, "032501": 1, "03261455": 39, "03298378": 39, "0334508": 39, "03368687": 39, "034": 109, "034047": 115, "03431": 1, "0343265": 70, "034328": [78, 82], "03466202": 133, "03493433": [129, 134], "03494359": 39, "035002": 1, "0353601": 39, "035909": 115, "0361e": 71, "0366": 71, "037": 112, "0370": 1, "03703898": 39, "0387364": 39, "0388246": 39, "03958143": 133, "03998411": 112, "03it": 134, "04": [33, 39, 50, 71, 76, 95, 105, 112, 125, 133, 134, 144], "04008915": 39, "04011": 1, "04037143": 39, "041": 109, "04183091": 39, "04221375": 39, "04278640498515118": 5, "04279159257882259": 5, "043": [38, 143], "04359686": 39, "04366899": 39, "044001": 86, "0441": 108, "044334": 115, "04444209": 39, "04457474": 39, "04481665": 133, "04499441": 39, "045": [29, 109, 133], "04527": 1, "0453": 71, "04548788": [129, 134], "0460056": 109, "04618286": [129, 134], "0462994": 39, "0462e": 71, "0465673": 39, "047": 143, "04789471": 39, "0479379": 39, "0484": 1, "048920": 115, "049": 38, "04906169": 39, "0490804": 39, "04909075": 39, "04912": 1, "04921829": 39, "04938272": 135, "049462": 115, "04it": 134, "05": [9, 17, 19, 41, 42, 46, 49, 50, 65, 71, 76, 77, 81, 82, 83, 94, 95, 96, 105, 108, 112, 133, 134, 144], "050": 38, "05031709": 39, "05080775": 39, "05111721617885": 42, "05115312": 34, "05117344": 39, "05132077": 39, "05156034": 39, "052e": 105, "053": 4, "05320065e": 78, "05340954": 39, "054": 115, "05418781": 115, "05424": 1, "0546241": 39, "05495304": 39, "055": [109, 125], "05528": 1, "0555e": 71, "055676": 115, "056": 9, "05635552": 39, "05667659": 39, "057121": 39, "05741082": 39, "05765496": 109, "058": 19, "05855716": 109, "0587121": 49, "05931904": 39, "05940548e": 133, "05e": 95, "05it": 134, "06": [38, 69, 71, 73, 77, 81, 82, 83, 93, 109, 134, 144], "06032751": 39, "060349": 115, "06056664": [129, 134], "0607502": 39, "06132457": 109, "061679": 115, "0617284": 135, "063443": 115, "063724": 115, "06421208": 109, "06423057": 39, "06439229": 112, "06471055": 34, "065026": 115, "06578332": 39, "06581816": 39, "065e": 105, "066": 4, "06608534": 39, "06623995": 109, "06695272": 109, "067": 81, "06798079e": 65, "068": 115, "06802716": 115, "0684": 49, "06897162": 39, "06898597": 39, "06900331": 109, "06903981": 133, "069584": 115, "06996554": 39, "06e": 95, "07": [4, 38, 69, 71, 78, 82, 112, 134, 144], "070": 4, "070043": 115, "07090": 1, "071": [109, 133], "07125243": 39, "0713": 115, "0719842": 109, "072": 134, "07224943": 34, "0722519": 39, "07272727": 109, "07312806": 39, "074001": 49, "07432055": 39, "07579533": 109, "0761167e": 76, "07619757": 112, "07638048": 39, "0764e": 71, "077": 109, "0770": 71, "0772": 71, "07734007": 39, "07782113": 39, "078": 9, "07941624": 134, "07e": 95, "07it": 134, "08": [69, 93, 95, 109, 129, 133, 134, 144], "08008": 133, "0803": 1, "08075099": 39, "0809271": 39, "081": [125, 133], "08155996": 39, "08176782": 39, "082": 134, "082875": 115, "083": 109, "083527": 115, "08352721390288316": 115, "084": 109, "08420815": 39, "08447057e": 133, "08457563": 39, "085": 109, "08601": 1, "08646441": 39, "087": [109, 125], "087887": 115, "087e": 105, "0883": 76, "08958761": [129, 134], "08968641": 39, "08972912": 39, "08it": 134, "09": [29, 31, 69, 82, 95], "09169": 1, "094": 125, "09499611": 39, "09542509": 39, "09574677": 39, "09811225": 39, "09836551": 39, "09899633": 39, "099": [133, 134], "09914922": [129, 134], "09it": 134, "0_": 133, "0_1": 1, "0arrai": 133, "0e": [66, 125, 131, 132], "0f": [6, 41, 69, 76, 116], "0inference_librari": 133, "0l": 67, "0m": [77, 83], "0px": 114, "0th": 76, "1": [1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 15, 16, 17, 19, 21, 22, 23, 24, 25, 27, 29, 30, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 59, 61, 63, 64, 68, 69, 70, 71, 72, 73, 75, 76, 78, 80, 81, 82, 88, 90, 94, 95, 96, 97, 99, 102, 103, 105, 107, 108, 109, 115, 116, 117, 118, 119, 124, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 140, 141, 144, 145], "10": [0, 1, 3, 4, 6, 7, 9, 17, 25, 29, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 65, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 93, 95, 96, 98, 99, 105, 107, 109, 111, 112, 114, 115, 116, 118, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 141, 143, 144], "100": [0, 3, 4, 6, 7, 9, 16, 17, 29, 33, 34, 35, 37, 38, 40, 41, 42, 45, 50, 51, 65, 66, 67, 69, 70, 71, 73, 76, 78, 79, 81, 82, 86, 96, 105, 107, 108, 109, 112, 115, 118, 119, 125, 126, 127, 129, 131, 132, 133, 134, 135, 136, 140, 141, 143, 144], "1000": [6, 9, 17, 25, 29, 30, 33, 34, 38, 39, 40, 41, 42, 50, 65, 71, 73, 78, 82, 95, 96, 98, 109, 112, 115, 116, 119, 125, 126, 127, 128, 129, 133, 134, 141, 144], "10000": [6, 9, 17, 31, 33, 38, 41, 42, 70, 82, 112, 126, 133, 143], "100000": [6, 17, 33, 41, 82, 112, 133, 144], "1000000": 17, "1000010": 133, "10000coordin": 133, "1000xarrai": 133, "10019424e": 133, "10025514": 39, "100480": 69, "1007": 1, "100_000": 133, "100coordin": 133, "100j": [73, 93], "101": [109, 111, 117, 143], "1010002": 39, "10118794": 39, "10131681": 39, "1016": 1, "10165": 1, "1017": 1, "101770": 69, "102": 109, "102001": 1, "1022": 108, "10223673": 39, "1023": 108, "1024": [50, 76, 96, 108], "10255438": 109, "1026": 108, "1027": 108, "1028": 108, "1029": 108, "1030": 108, "1031": 108, "1032": 108, "1033": 108, "1034": 108, "1035": 108, "1036": 108, "10363908": 39, "1037": 108, "1038": 1, "104": 1, "10405339": 39, "10417433": 39, "10422477": 109, "104411": 115, "10473305": 39, "104772612937847": 77, "105": [1, 9], "10581": 86, "10583157": 98, "1058809": [1, 44], "10622272": 39, "106431": 115, "1066": 109, "107": [133, 134], "10717545": 39, "10734329": 39, "10735333": 39, "10770823": [129, 134], "108": 115, "1080": 1, "10803082": 39, "10803932": 109, "10854853": [129, 134], "1086": 1, "10861676": 39, "1088": 1, "109": [109, 134], "10904708": 109, "1092931": 1, "1093": 108, "1094027": 39, "10944442": 39, "1095": 108, "1096": 108, "1097": 108, "10972845": 39, "10977284": 109, "1098": 108, "1099": 108, "10_000": 133, "10e": 95, "10it": 134, "11": [25, 30, 34, 37, 38, 39, 40, 42, 46, 50, 67, 73, 77, 78, 79, 81, 86, 93, 95, 96, 98, 99, 105, 108, 109, 115, 116, 118, 126, 128, 129, 130, 133, 134, 135, 136, 143, 144], "110": [115, 134], "1100": [71, 108], "1101": 108, "1102": 108, "1103": 1, "11055457": 133, "11060505": 39, "1108926": 49, "11089469": 49, "11091621": 49, "111": [70, 125], "1110567": 39, "1111": 1, "11113363": 49, "1112": 115, "11133727": 39, "112": [125, 143], "11223952": 109, "11236849": 39, "11237104": 39, "11241285": 133, "11248774": 39, "1132": 71, "11325333": 49, "1137": 1, "1139": 63, "114": 134, "11438298": 39, "115": [19, 138], "1157018": 39, "11584111": 39, "116": 9, "117": 41, "11719604": 112, "117430": 115, "1176": [50, 134], "1181334": 39, "118318": 115, "11858913": 39, "1186": 1, "119": 134, "11900865": 39, "1194224": 39, "1196": 1, "11981094": 39, "12": [0, 1, 5, 6, 7, 9, 16, 17, 25, 30, 33, 34, 37, 38, 39, 41, 44, 49, 50, 52, 53, 65, 66, 67, 72, 73, 75, 76, 77, 78, 79, 82, 83, 86, 93, 94, 96, 105, 108, 109, 112, 114, 115, 118, 125, 126, 127, 129, 132, 133, 134, 135, 144], "120": [75, 95, 108, 111], "1200": [1, 41, 71], "12000157": 133, "1201": 88, "12015895": 39, "121": [1, 95], "1212": 1, "1214": 1, "12141771": 39, "1216": 134, "12182127": 39, "122": 76, "12214158": 39, "122282": 115, "1223": 112, "12232832": 39, "1225": 71, "1225e": 71, "12271848": 39, "123": [126, 134], "1234": 17, "12341216": 39, "12369125": [129, 134], "124": [1, 112, 115], "12458947172849956": 77, "1249115293": 133, "125": [1, 125], "1253235": 39, "126": [112, 134], "12683902": 39, "1277": 41, "127812": 115, "128": [42, 69, 75, 109], "12805681": 109, "12837699": 39, "1287": 41, "12878515": [129, 134], "1290": 69, "12910158": 39, "12911235": 39, "12948391": 39, "12991762e": 133, "12999178": 39, "12it": 134, "13": [0, 1, 5, 32, 34, 38, 39, 51, 53, 56, 66, 67, 76, 77, 78, 81, 83, 95, 103, 109, 111, 115, 128, 133, 134, 135, 143, 144], "1300": 71, "1304781454370705": 105, "13051179": 133, "130k": 112, "13116482": 133, "13135": 115, "13162939": 39, "1318": 71, "132": 133, "13216943": 109, "13219435": 5, "13221278": 39, "13223132": 39, "13224778": 39, "13261653": 49, "1327083": [129, 134], "133": [50, 134], "13376944": 39, "1340482": 39, "13410343": 108, "13437312": 39, "13444589": 105, "134e": 105, "135": [41, 108], "13513688": [129, 134], "13559156": 109, "136": [41, 108], "1360e": 71, "1361": 1, "13622942": 5, "1365": 1, "1369": 63, "137": [108, 134], "1375": 71, "13770121": 39, "13782807": 39, "138": [95, 108], "13868364": 39, "139": [63, 108], "13920135e": 133, "13956559": 109, "13963104": 133, "13972942": 109, "13it": 134, "14": [1, 5, 9, 19, 25, 30, 37, 38, 42, 44, 53, 69, 70, 72, 78, 82, 95, 108, 109, 115, 128, 132, 133, 134], "140": [0, 7, 134], "1400": 71, "14010988": 39, "14039544": 39, "1404641": 133, "14048406": 39, "140px": 114, "1411": 40, "1412": 1, "14164054": 39, "1418": 134, "14189485": 70, "14201814": 39, "14225137": 39, "14250318": 39, "1426": 71, "14286519": 109, "143": [109, 134], "14381452": [129, 134], "144": [9, 30], "14472371": 39, "1449": 71, "144993": 115, "145": 138, "1454651347": 133, "14548": 1, "146": 109, "14676526": 39, "14690038": 39, "147": 134, "14703548": 109, "148": 134, "14854434": 39, "1489": 133, "1495e": 71, "14it": 134, "15": [1, 5, 7, 17, 19, 25, 33, 35, 37, 38, 40, 41, 42, 50, 53, 65, 76, 78, 82, 93, 108, 109, 112, 115, 128, 131, 133, 134], "150": [33, 38, 105, 134], "1500": 71, "15000": [38, 126], "15001628": 39, "1505": 1, "1506": 1, "1509": 1, "150px": 9, "15122115": 109, "152": 134, "15259914": 39, "153": 109, "153036": 115, "153e": 105, "154": 134, "15431": 1, "15479436": 39, "155": 134, "15528789": 39, "1555889246909882": 83, "156": [115, 125, 134], "15626385": 39, "1563": 76, "157": [115, 134], "1570": 76, "15713443": 109, "15754684": 109, "158": [115, 134], "15801436": 133, "158970681801711": 83, "159": 115, "1593": 1, "15it": 134, "16": [5, 17, 25, 33, 37, 38, 40, 41, 42, 50, 75, 82, 94, 95, 96, 105, 109, 111, 112, 114, 115, 117, 125, 128, 129, 131, 133, 134, 143, 144], "160": 115, "1600": [71, 105, 109], "16000": [127, 144], "16001109": 39, "16003707": 39, "1601": 1, "1603": 72, "16033857": 39, "16056499": 39, "160kb": 133, "161": 134, "16128569": 39, "1614": 1, "16143998": 39, "162": 134, "16217339": 133, "1623": 1, "162999": 115, "163": 134, "16363636": 109, "16384": 75, "164": [95, 134], "16466507": 39, "165": 134, "166": 134, "167": [30, 134], "16707517": 39, "1674": 1, "16760465": 39, "168": 134, "169": 134, "16903246": 34, "16938243": 39, "16977008": 133, "1698281": 39, "16983114": 39, "16986926": 39, "16998901": 39, "16b": 133, "16it": [50, 134], "16j": 78, "17": [1, 7, 32, 37, 44, 50, 69, 82, 95, 97, 99, 109, 115, 118, 128, 133, 134, 138, 144], "170": [125, 134], "1700": 71, "17071416": 109, "171": 134, "1711": 1, "17137202": 39, "17195713": 39, "17390257": 39, "1740e": 71, "17451805e": 109, "1749e": 71, "17516773": 39, "175300": 115, "176": 134, "17608015": 39, "17688034": 112, "177": 134, "17718772": 39, "17753281": 39, "178": 134, "17801963736677": 105, "179": [95, 109, 134], "17it": 134, "18": [1, 5, 9, 32, 33, 45, 46, 65, 71, 78, 81, 93, 112, 114, 118, 119, 133, 134, 138, 144, 145], "180": [93, 134], "1800": 71, "1800880e": 76, "1805": 100, "18060865": 109, "1809": 100, "181": 134, "18103874": 39, "1810401e": 76, "182": 134, "1825e": 71, "183": 134, "18395108": 133, "184": 134, "1841262e": 69, "184519": 115, "18496": 76, "185": [81, 134], "1850492": 70, "18515642": 39, "1853": 46, "18553562": 39, "18557541": 39, "186": [109, 134], "18656139": 39, "18665195e": 133, "1867": 46, "18697965": 39, "187": 134, "1870": 77, "188": 134, "1884062": 133, "18843153": 134, "189": 134, "1892932": 39, "189367": 115, "189496": 115, "1896": 77, "189622": 115, "18986165": 39, "18it": 134, "18th": 8, "19": [1, 5, 38, 46, 65, 66, 71, 82, 95, 96, 102, 109, 115, 133, 134, 143, 144], "190": 134, "1900": 71, "1902": 92, "1903": 133, "1904": 86, "19069973": 39, "19091548": 39, "1911528": 39, "191963": 115, "19268607": 39, "19339120e": 133, "19381518": 39, "19382179": 39, "1939": 53, "194": 134, "1943": 67, "1948": 4, "195": 1, "1950": [135, 136], "19501328": [129, 134], "1953": [108, 126], "1954": [1, 62, 108], "19540886": [129, 134], "1955": 108, "1956": 108, "1957": 108, "1960": 4, "1961": 1, "1963": 4, "19686978": 39, "1970": 126, "19783084": 39, "1979": [85, 100], "1980": [46, 135, 136], "19829972": 39, "1983": 46, "1984": [4, 5], "19846356": 49, "1986": 1, "1987": 1, "1988": [1, 4, 53, 63], "1989": 1, "19891788": 39, "1992": 1, "1994": [1, 46], "1997": 126, "19975956": 39, "19th": [8, 100], "1_": 67, "1_000": [80, 81, 117, 133, 134], "1_1": 67, "1_2": 67, "1_3": 67, "1_j": 67, "1_l": 67, "1a": 79, "1arrai": 133, "1b": 79, "1cm": 115, "1d": [26, 76, 105], "1darrai": 105, "1e": [41, 50, 78, 80, 81, 82, 105, 125], "1e15": 81, "1e2": 80, "1e30": 105, "1e5": 105, "1f": [17, 33, 37, 38, 40, 41, 42, 82, 96, 108, 112, 114, 117, 125, 127, 131, 132, 144], "1mgaussian_nois": [77, 83], "1mgp_regress": [77, 83], "1mlengthscal": [77, 83], "1mmat52": [77, 83], "1mmul": [77, 83], "1mrbf": [77, 83], "1msum": [77, 83], "1mvarianc": [77, 83], "1n": [52, 115], "1sampling_tim": 133, "1st": [15, 73, 93, 116], "1x": 115, "1xarrai": 133, "2": [0, 1, 3, 4, 6, 7, 9, 13, 15, 16, 17, 18, 19, 23, 24, 25, 26, 27, 30, 33, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 59, 63, 65, 66, 68, 69, 70, 71, 72, 73, 76, 78, 79, 80, 81, 82, 85, 86, 88, 90, 94, 95, 96, 97, 98, 99, 102, 103, 105, 107, 108, 109, 115, 116, 117, 118, 119, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 140, 141, 144, 145], "20": [0, 7, 16, 17, 19, 29, 32, 33, 35, 38, 40, 41, 44, 50, 51, 53, 65, 70, 71, 74, 77, 78, 83, 85, 95, 96, 105, 108, 114, 115, 125, 127, 132, 133, 135, 138, 143, 144], "200": [9, 12, 33, 34, 38, 40, 41, 70, 71, 75, 78, 82, 98, 105, 111, 114, 125, 126, 132, 141], "2000": [41, 44, 50, 65, 71, 105, 125, 128, 141], "20000": [105, 111, 125, 143], "20023272": 109, "2003": [1, 56], "2004": 51, "20045251": 39, "2005": [1, 56], "2006": [1, 53, 56], "2007": 1, "2008": 1, "2009": 1, "200_000": 133, "2010": [1, 134], "2011": 1, "2012": [1, 77, 110], "2013": [0, 1, 56, 110], "2014": 1, "2015": 1, "2016": [1, 72, 73, 78, 82, 93, 115], "2017": [1, 115, 130, 136], "2018": [1, 73, 78, 82, 93], "20183018": 39, "2019": [1, 5, 38, 39, 50, 53, 56, 73, 74, 76, 77, 78, 86, 91, 95, 125, 126, 129, 131, 134], "20199118": [129, 134], "2020": [6, 73], "20205486": 39, "2021": [1, 5, 63, 133], "2022": [1, 44, 65], "2023": 133, "2024": 78, "2025": [50, 67, 81, 96, 105, 108, 133, 134], "20273021": 39, "2030": 77, "20303737": [129, 134], "2030816": 133, "2032392": 109, "2035808": [129, 134], "204": 115, "20423541": 133, "20433313": 115, "20434946": 109, "20437739": 39, "2048": 105, "2048px": 0, "20491849": 78, "205231": 115, "20623823": 133, "2064754": 78, "2066079": 39, "206915": 39, "207888": 115, "208": 1, "20808241": 109, "20845633": 39, "20874614e": 78, "2088896239": 38, "209": 109, "20900359": 39, "20909668": 39, "20916214": 109, "20920005": 39, "209789": 115, "2099": 71, "20_000": 133, "20it": 134, "20px": 42, "20th": 8, "21": [1, 16, 38, 41, 43, 50, 67, 78, 79, 82, 86, 95, 96, 119, 126, 133, 134, 138], "210": 134, "2104": [1, 108], "2106": 1, "211": 134, "2110": 1, "21112476": 39, "2112": 1, "21208711": 39, "2121": 1, "21229686": 109, "213": [9, 109], "2130": 41, "2135339": 39, "21397852": 109, "214": 44, "2140": 1, "21440984": 65, "214466": 39, "2153": 1, "2159": 1, "216": [1, 108], "21612952": 133, "217": 108, "2171e": 71, "21726515": [129, 134], "21746553": 39, "2179409": 39, "218": 108, "21808832": 39, "21987438": 39, "21it": 134, "22": [1, 34, 38, 45, 46, 71, 78, 79, 82, 86, 95, 112, 133], "220": 108, "2201": 134, "2203": 1, "221": 108, "2210": 1, "221180": 115, "2212": 1, "222": [1, 9, 108], "22214117": 39, "222400": 115, "22243362": 39, "2228": 41, "223": 108, "22372221": 39, "224": [41, 98, 108, 109], "2245077": 39, "22451016": 133, "2246093": 1, "22483838": 39, "22492971": 39, "225": 109, "22515585": 39, "227": 32, "228": [109, 134], "22824714": 133, "22855362": 109, "22863013": [129, 134], "22895559": 39, "229": 134, "23": [38, 63, 67, 78, 82, 95, 96, 109, 118, 133, 134, 135, 138], "230": 31, "23009474": 39, "2305582": 39, "23066907": 5, "2320": 109, "23211577": 109, "23219625": 39, "23225307": 39, "232435": 115, "23249456": 39, "23269017": 39, "23289919": 39, "23333913": 39, "23368248": 109, "234": [50, 96, 125], "2344157": 39, "235": [50, 96], "23616403": 39, "23653978": 133, "237": [50, 96], "2373327": 39, "2387931": 39, "23931144": 39, "23948339": 133, "23it": 134, "24": [1, 5, 38, 40, 65, 72, 78, 82, 95, 109, 114, 115, 133, 134, 144], "240": 32, "2404": 5, "24050555": 39, "24069534": 49, "24069536": 49, "2406956": 49, "24069775": 49, "24071638": 49, "24073709": 39, "24085991": 49, "240kb": 133, "241": 109, "24175822": 49, "24193267": 39, "242": 133, "24266944": 39, "24378351": 78, "24407436": 39, "2441579": 109, "24433723": 39, "24454398": [129, 134], "2448e": 71, "245": [30, 134], "2453781259": 133, "24542285": 39, "24543559": 49, "24560206": 39, "24610704": [129, 134], "24796026": 133, "248": 134, "24879916": 39, "24957254": 109, "24998542": 133, "24it": 134, "25": [8, 16, 33, 35, 38, 40, 41, 46, 49, 69, 73, 76, 78, 92, 93, 94, 109, 115, 118, 126, 133, 134, 143, 144], "250": [9, 34, 73, 93, 98], "2500": [0, 7, 125], "25003038": 39, "250154": 115, "250636": 115, "251": 109, "251879": 115, "252": 133, "252436": 115, "25284171": 39, "25286816": 39, "253": [30, 38], "253775": 115, "25486821": 133, "255": [69, 76, 109], "255001": 115, "25558087": 37, "25580914": 133, "256": 42, "2562": 41, "25647226": [129, 134], "2566277": [129, 134], "25745702": 109, "258": [50, 96, 115], "25839": 5, "259": [50, 96], "2593743975": 37, "25it": 134, "26": [41, 46, 78, 95, 115, 119, 133, 134], "2607": 76, "261": [50, 96], "26188236": 109, "262": [50, 96, 134], "26246745": 39, "26271037": 39, "2632": 1, "264": [50, 96, 115], "2641": 71, "264421": 115, "265": [115, 134], "2650": 71, "26551159": [129, 134], "2656424": 39, "266": [115, 133], "26607016": [129, 134], "26666667": 135, "2667284": 39, "267": [32, 134], "2672e": 71, "2673527": 109, "2680305": [129, 134], "26815042": 133, "2684253": 1, "26846902": 39, "269": 115, "2693": 1, "26972154": 109, "26998993": 133, "27": [4, 41, 45, 47, 65, 72, 78, 82, 95, 109, 117, 133, 134, 143], "270": [42, 115], "27146251": 39, "27223658": 133, "27244608": 109, "273": 42, "2730e": 71, "27375593": 39, "27440288": 39, "27478507": 39, "275": [50, 109], "275082": 49, "27583386e": 133, "276": [30, 133], "2764993": 39, "276e": 105, "27760809": 39, "27852808": 39, "279": [81, 134], "27975894e": 133, "27991444": [129, 134], "27it": 134, "28": [50, 69, 75, 77, 78, 83, 125, 126, 130, 133, 134, 135, 136], "280179": 115, "28040686": 109, "28060553": 39, "28066508": 39, "281930": 115, "282259": 115, "282547572891495": 77, "28267571": 39, "28299553": 39, "283": 115, "284": 128, "28474811": 39, "28558733": 39, "287": [109, 134], "288": 33, "28807817": 39, "28883234": 39, "2890": 115, "2890942": [129, 134], "28916245": 109, "28923636": 112, "28957368": 109, "28it": 134, "28x28": 69, "29": [1, 37, 38, 49, 66, 85, 94, 109, 133, 134, 144], "29090909": 109, "291": 133, "2911889": 39, "2919282": 49, "29208294": 49, "29209002": 109, "2931": 115, "29322588": 39, "29354962": 39, "29371761": 39, "29415949": 39, "2949430162": 133, "295": 115, "29564967": 39, "296": [133, 134], "296247": 115, "296414": 115, "2966": 1, "2968": 115, "2970796": 39, "29774393": 109, "2979": 71, "2980": 115, "298273": 115, "298375": 115, "29865557": 39, "2990": 115, "2996015": 39, "299748": 115, "29it": 134, "2_": [35, 52, 66, 67, 96, 99], "2_000": [133, 134], "2_1": 67, "2_2": 67, "2_3": 67, "2_n": 99, "2arrai": 133, "2b": 95, "2d": [26, 33, 37, 40, 75, 77, 78, 79, 82], "2draw": 133, "2e": [50, 66, 95], "2e_i": 38, "2f": [38, 39, 41, 42, 49, 77, 83, 95, 96, 105, 112, 116, 126, 127, 129, 132, 134, 143, 144], "2k": 51, "2kb": 133, "2l": [19, 34, 35], "2m": [46, 90, 96], "2n": 44, "2nd": [1, 15, 23, 34, 37, 73, 79, 93, 98, 118, 130, 141], "2p": 19, "2px": 42, "2r": 132, "2sigma": 41, "2w": 35, "2x": [5, 34, 98], "2x2": 4, "2x3": 118, "2z": 7, "3": [0, 1, 3, 4, 6, 9, 15, 17, 19, 23, 25, 30, 33, 34, 35, 37, 39, 40, 42, 45, 46, 47, 49, 50, 51, 53, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 85, 94, 95, 96, 103, 105, 108, 109, 111, 115, 116, 117, 118, 119, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 144], "30": [0, 7, 9, 30, 37, 38, 40, 50, 76, 77, 82, 83, 95, 96, 108, 109, 112, 116, 125, 133, 134, 144], "300": [40, 71, 131], "30000": 73, "30017032": 39, "30060": 133, "3006664": 39, "301": [5, 9, 30], "30111741": 109, "30163826": 39, "30196005": 39, "30218997": [129, 134], "3024": 133, "30242319": 133, "3024arrai": 133, "3025": 5, "30253554": 39, "303": 1, "30328818e": 78, "30471708": 112, "3049": 1, "3050791": 39, "30526704": 39, "3053064": 39, "30532283": 98, "3059652": 133, "306": [1, 134], "30620607": 39, "3072": 75, "307e": 105, "30833925": 39, "30847308": [129, 134], "3085e": 71, "3088": 109, "309": [1, 108, 109], "30970591": 39, "30979757": 105, "30981676": 39, "30it": 134, "31": [35, 37, 38, 41, 67, 108, 112, 133, 134, 138], "310": 108, "31008642": 133, "31027229": 39, "310e": 105, "311": 108, "31116432": 133, "312": [1, 108], "31216994": [129, 134], "31223869": 39, "31251261": 39, "31255623": 133, "3128273": 39, "313": [76, 134], "31354772": 39, "314": 1, "31475378": [129, 134], "31515939": 39, "31563495": 39, "31594001": 39, "316": 81, "31627214": 39, "31663724": 39, "3166589": 39, "31694": 49, "31713": 115, "31749257": 108, "3180143": 39, "3181542": 39, "319": [1, 42, 50, 96, 108], "3190391": 39, "31914843": 39, "31932186": 39, "31935642": [129, 134], "31965694": 39, "31it": 134, "31t23": 133, "32": [50, 52, 67, 69, 75, 76, 78, 79, 82, 96, 108, 133, 135, 138], "320": [50, 76, 96, 108], "3200": 108, "32035417": 112, "32061622": 39, "321": [50, 96, 108], "32107876": 39, "32126591": 39, "3217": 71, "322": 108, "32201304e": 133, "323": [1, 50, 96, 108], "32344867": 133, "32352735": 39, "323533a0": 1, "324": [9, 50, 96, 108], "32427424": 39, "32513347": 98, "32519302": 109, "32534867": 133, "32580419": 39, "326": [1, 50, 96, 134], "326238": 115, "3266948": 112, "327": [50, 96], "3272": 115, "32755196": 39, "3278": 115, "327e": 109, "3285": 115, "32875387": 39, "329": [9, 82], "32933771": 39, "329492": 115, "32m": 76, "33": [25, 38, 41, 67, 78, 82, 93, 133, 134, 138, 143], "3306": 115, "33074949": 109, "331": [34, 134], "3312": 115, "33145711": 39, "3315865": [129, 134], "331939": 115, "3328e": 71, "33333333": 135, "33424548": 39, "335": 9, "33513223": 39, "3356404": 109, "33584967": 133, "33587406": 39, "33722094": 39, "33776818e": 65, "3380": 71, "3380117": 39, "33840788": 133, "33844": 49, "33865576": 39, "3389": 1, "3391e": 71, "33it": 134, "34": [38, 95, 133], "340583": 115, "34063543": 133, "342680": 115, "342e": 105, "343": 109, "3436": 115, "3437": 115, "3445": 133, "34473208": 133, "34539683": 39, "346": 134, "3465969": 109, "347": 115, "34710546": 39, "3471e": 71, "349": [63, 115, 134], "3490481": 115, "34927873": 39, "3492e": 71, "34it": 134, "35": [34, 38, 40, 82, 93, 133, 134], "35010682": 39, "35016716": 39, "35054598": 39, "3508341": 133, "3511169": 39, "35249436": 39, "352e": 105, "35308331": 39, "35323281": 105, "35356722": 39, "35379069": 105, "35387043": 39, "353e": 105, "35470721": 112, "354e": 105, "355": 105, "35528451": 39, "35571726": 39, "356": 9, "356399": 115, "357508": 115, "358": 109, "35it": 134, "36": [41, 109, 118, 133, 135, 138, 143], "36095389": 133, "36126959": 39, "361556": 115, "3615e": 71, "36180164": 39, "36184732": 39, "36255041": 39, "36300435": 39, "36320123": 133, "36347669": 5, "3646326065063477": 133, "3646326065063477tuning_step": 133, "365755": 133, "366": 134, "36623574": 78, "36633201": 39, "36723181": 39, "36820273": 109, "369": 63, "36919047": 39, "36928": 76, "36949272": 39, "36it": 134, "37": [32, 38, 66, 78, 95, 97, 99, 100, 133, 134], "370": 30, "3701e": 71, "3705584": 39, "37167029": 39, "371891": 133, "371e": 105, "37214594": 133, "37245685": 39, "37256166": 39, "3733791492": 115, "374214": 133, "374658": 39, "375": 109, "375694": 115, "37646927": 39, "376547": 115, "37756379": 39, "37975819": 39, "37996941": 133, "37999916": 39, "38": [32, 38, 78, 82, 95, 99, 100, 118, 133, 134], "38049834": 5, "38085457": 133, "3815e": 71, "38196315": 39, "382187": 115, "38263794": 39, "38271517": 39, "383": 134, "384": 82, "38422765": 39, "3845": 71, "38496733": [129, 134], "38499134": 39, "38560229": 39, "386": 134, "38631426": 39, "38653915": 39, "387": 1, "38755787": 39, "38759303": 39, "388": 9, "38824359": 39, "38847": 133, "3887794": 39, "38m": 76, "39": [34, 63, 115, 133, 134, 135], "39014596": 39, "39206493": 65, "39233491": 39, "3926716": 109, "39286306": 5, "393": [41, 109], "3930016": 39, "39310924": 39, "39334122": [129, 134], "39378773": 39, "394": 81, "39401868": 39, "39442803": 39, "3947": 71, "39470366": [129, 134], "395": 1, "3952229": 112, "39539703": 39, "39595174": 112, "39607937": 39, "397": 69, "39788042": 39, "39799638": [129, 134], "398": 1, "39859839": 39, "3988432": 39, "39977467": 39, "399836": 115, "39984394": 39, "3998612": 39, "3d": [23, 37, 65, 76, 112], "3e": 66, "3f": [6, 9, 30, 33, 34, 38, 50, 69, 81, 82, 95, 96, 98, 105, 111, 115, 125, 129, 134, 143, 144], "3gb": 119, "3m": 46, "3rd": [15, 34, 37, 78, 86, 93, 98, 141], "3x": 23, "3x3": 118, "3x4": 118, "4": [0, 1, 2, 3, 4, 6, 8, 9, 12, 17, 19, 22, 23, 25, 30, 33, 34, 35, 37, 39, 42, 43, 46, 47, 49, 50, 53, 58, 59, 61, 63, 66, 69, 70, 73, 76, 81, 82, 88, 90, 94, 95, 96, 103, 105, 108, 109, 111, 115, 116, 117, 118, 119, 125, 126, 127, 129, 132, 133, 134, 135, 143, 144], "40": [5, 33, 38, 40, 95, 105, 108, 133, 134, 135], "400": [30, 71, 78, 82, 105], "4000": [105, 127, 144], "40000": [73, 111, 138], "40019547": 39, "40020999": [129, 134], "401": [33, 134], "402": 1, "4027718": 109, "40349164": 39, "40391367": 39, "404": 30, "40433212": 39, "405": 134, "40615693": 39, "40665625": 39, "40740344": 109, "40753871": 39, "40754": 39, "4087": 133, "4089": 1, "40890054": 39, "40918865": 133, "40925339": 39, "40931389": 108, "4096": [25, 30], "40_000": 133, "40it": 134, "41": [1, 38, 77, 78, 83, 95, 118, 133], "41000": 108, "41005165": 39, "41026575": 39, "41047496": 109, "41053094": 133, "41347606": 39, "41388373": 112, "415201": 115, "41536733": 109, "417": 30, "417302": 39, "41767401": 39, "417e": 105, "418": 109, "419": 134, "41it": 134, "41m": 76, "42": [17, 34, 38, 40, 73, 82, 93, 95, 96, 105, 112, 115, 133, 134], "4202822": 39, "4206": 133, "42084371": 39, "42142": 49, "4230685e": 76, "42349435": 39, "42361443": 39, "424": 134, "42440796": 109, "4251936835166137": 83, "4254e": 71, "42567637e": 133, "42592018": 39, "426": 30, "42718291": 109, "4286283": 78, "42887697": 39, "42952614": 39, "4296e": 71, "42it": 134, "42m": 76, "43": [31, 38, 49, 71, 77, 80, 95, 133], "43049928": 133, "43085135": 39, "43103028": 109, "43181": 112, "43302619": [129, 134], "43426185": 39, "4342e": 71, "43499832": 39, "435163": 115, "4352351e": 69, "43549215": 39, "4359862": 39, "43621127": 39, "4367634": 39, "437": 134, "43739419": 112, "43769457": 39, "438136": 115, "43816635": 39, "4395e": 71, "43rd": 115, "44": [34, 38, 63, 95, 133, 134], "44031858": 39, "441": 6, "44122630e": 133, "441264": 115, "44136444": 39, "44250528": 39, "44287693": 39, "443": 134, "44305844": 39, "443217": 115, "44340345": 133, "44509671": 39, "44513761": [129, 134], "4453": 133, "446": [9, 38], "446453": 115, "44703778": 109, "44730122": 39, "44838065": 39, "4489894": 39, "44936865": 39, "44it": 134, "45": [16, 77, 78, 82, 83, 133, 134, 144], "45015551": 39, "45021774": 39, "4504": 76, "45069099": [129, 134], "45112294": 39, "45128402": 39, "45142926": 39, "45161595": 39, "45189041": 109, "45194604": 39, "452": 38, "452553": 115, "4528e": 71, "4529": 71, "45293994e": 133, "45391758": 39, "45422583": 39, "45454545": 109, "45459971": [129, 134], "455": 134, "45555682": 112, "45576187": 5, "4558919": 109, "455947": 115, "45652739": 39, "457": 1, "45794708": 39, "458027": 115, "45810824": 39, "45833711": 112, "459698": 109, "46": [1, 133, 134, 144], "46012093": [129, 134], "46031844": 39, "46089238": 39, "4609029": [129, 134], "46098868": 109, "461": [9, 63], "4611641": 39, "46120675": 39, "46197399": 133, "462": 41, "46210794": 39, "46277698": 39, "463": 134, "46353432": 39, "463861": 115, "46476976": 50, "46664327": 39, "46697967": 39, "4672017097473145": 133, "4672017097473145tuning_step": 133, "4674011": 49, "4675": 71, "46765106": [129, 134], "46776598": 39, "4696879e": 69, "469849": 115, "4698802": 39, "46m": 76, "47": [133, 134], "47016034": 39, "47054044": 50, "47055978": 133, "47070392": [129, 134], "470714": 115, "47073986": 39, "470e": 105, "47182825": 39, "472": 1, "4724e": 71, "4728e": 71, "473": 134, "47309916": 109, "474": 40, "47431968": 39, "47761018": 39, "47764353": 39, "47985237": 39, "47e": 95, "47it": 134, "47x": [49, 94], "48": [1, 34, 38, 77, 78, 82, 83, 95, 133, 134], "480": 115, "481": 9, "48185445": 39, "48290554": 39, "483": 134, "48365209": 39, "48369614": 39, "484": 81, "4840": 108, "484537": [129, 134], "4850": 71, "4853e": 71, "48550": 1, "486": [30, 133], "48851815": 39, "48909527": 133, "48938398e": 133, "48946635": 5, "48954362": 39, "48it": 134, "49": [1, 19, 38, 78, 112, 133, 134, 143], "49042732": 39, "49056104": 39, "491": 134, "49102772": 39, "49152": 75, "49154287": 39, "49167851": [129, 134], "49194925": 109, "49233656": 39, "49252129": 109, "493": 32, "49355935": 39, "49369412": 133, "493754387128709": 78, "494": 32, "4940954": 115, "49434165": 39, "49515861": 39, "49521132": 39, "49553414": 39, "49588477": 39, "49602605": 39, "49664047": 109, "49681303": 65, "497": 112, "4972691": 39, "4974": 71, "497630": 115, "49810818": 39, "4982711": [129, 134], "49it": 134, "4_000": 133, "4d": [75, 125], "4e": [71, 96], "4f": [71, 82, 96, 111], "4th": 15, "4x": 5, "4x6": 118, "5": [0, 1, 2, 3, 4, 6, 9, 11, 12, 13, 17, 19, 25, 29, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 51, 53, 67, 69, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 90, 92, 94, 95, 96, 98, 103, 105, 108, 109, 111, 115, 116, 117, 118, 119, 125, 127, 128, 129, 131, 132, 133, 134, 135, 141, 143, 144], "50": [17, 35, 38, 40, 41, 47, 50, 71, 73, 74, 76, 77, 79, 82, 83, 94, 96, 99, 108, 111, 112, 114, 115, 118, 125, 126, 129, 133, 134, 135, 138], "500": [0, 7, 17, 33, 34, 37, 42, 71, 73, 77, 83, 93, 98, 105, 108, 114, 124, 125, 126, 127, 133], "5000": [0, 7, 9, 41, 71, 73, 96, 105, 126, 133, 143], "50000": [17, 129, 134], "500000": 108, "50058034": 133, "500px": [9, 114], "501": 33, "50124914": 133, "50142959": 39, "50172511": 39, "50178644": 39, "5018": 40, "50249434": 39, "50274088": 39, "503": [9, 112, 134], "50315846": 109, "50318481": 39, "5045e": 71, "5048534": 108, "505": 63, "5053819": 39, "50580623": 39, "50598029": 39, "506": 32, "5060": 71, "508": [41, 50], "50887486": 39, "509": 134, "50it": 134, "51": [19, 34, 63, 133, 134, 144], "5103076": 39, "51063925": 49, "51064336": 49, "51066278": [129, 134], "51068175": 49, "51093777": 39, "511": 50, "51102753": 49, "512": 42, "5120": 71, "51238578": [73, 93], "51292982": 39, "5135": 76, "51350548": 39, "51395571": 49, "514219": 115, "51475524": 109, "51484355": 39, "51507361": 39, "5154138": 39, "51603322": 49, "51790686": [129, 134], "518895": 115, "51981682": 39, "51it": 134, "52": [32, 41, 63, 133, 134], "520319": 115, "52057634": 39, "52081508": 39, "5208429": 39, "52092451": 133, "52132764": 39, "52138593": 39, "522": 134, "5222": 71, "52241915": 39, "522836": 115, "52287579": 39, "52343734": 39, "52385799": [129, 134], "52462712": 39, "52475049": 39, "526": 134, "528": 50, "52800342": 39, "52832571": 39, "52880318": 109, "52884307": 39, "52887975": 39, "52946532": 39, "52976291": 39, "52it": 134, "53": [38, 95, 133, 134], "53035547": 39, "53116379": 39, "531280": 115, "53132618": 39, "5316": 71, "532": 63, "533": 1, "53384514": 39, "534362": 115, "53469234": 109, "53499597": 5, "53522913": 105, "53594643": 39, "536": 1, "5363755": 49, "53653633": 39, "53834627": 112, "5385964": 39, "53920701": 39, "53it": 134, "54": [34, 38, 69, 82, 118, 133, 134], "54005717": 39, "5400699": 39, "54026428": 109, "54028232": 39, "5407": 71, "541": 134, "541605": 115, "54167554": 39, "54264529": 39, "543": 134, "54301214": 39, "54329956": 133, "54335911": 39, "54388244": 39, "544439": 115, "5447030e": 76, "5449814": 133, "545": 30, "54520725": 133, "54747503": 39, "54755159": 5, "5476": 76, "54785821": 109, "548": 109, "54812958": 39, "54948544": 133, "55": [16, 34, 38, 78, 82, 133], "550": 5, "5505375": 39, "55126197": 39, "55155435": 109, "551e": 109, "55210482": 39, "55287144": 39, "553147368801305": 83, "5533008": 39, "55433762": 109, "555": 30, "55501599": 39, "55588619": 39, "55602974": 109, "55607351": 39, "556378888999681": 105, "55682807": 39, "55743945": 39, "55777072": 39, "558": 30, "55880554": 39, "55896032": 133, "559": 9, "55912398": 39, "5593865e": 69, "55it": 134, "56": [34, 38, 76, 95, 133, 134], "560": 134, "56020843e": 109, "560kb": 133, "561": 134, "56100234": 39, "56179973": 39, "56218": 49, "56249102": 39, "5627611": 39, "563167": 115, "56372833": 109, "56438286": 39, "565": 109, "56504332": 39, "56515267": [129, 134], "56516224": 39, "56536": 115, "56566790e": 78, "56760881": 133, "56862025e": 133, "56877654": 65, "56it": 134, "57": [32, 82, 96, 115, 133, 134], "570": 76, "5701": 1, "57030984": 109, "5707963": 49, "57085772": 39, "5716934": 133, "57180488": 39, "572069": 115, "5722": 71, "57296273": 39, "57344458": 39, "57357138": 39, "57546791": 39, "57550721": 39, "57582227": 5, "57596926": 133, "576": 76, "5765217": 39, "57709": 49, "57714304": 39, "5773025": 109, "578": 134, "57846442": 39, "57it": 134, "57x": [49, 94], "58": [16, 41, 78, 109, 119, 133, 134], "580147499327772": 78, "58033011": 39, "58085122": 39, "5810621": 39, "58144397": [129, 134], "58176792": 109, "58245670e": 133, "582511310413": 42, "58281521": 39, "583": 105, "583595": 115, "58389515": 112, "58464661": 39, "5851531": 39, "585662": 39, "58591043": 39, "586497": 39, "58662319": 39, "58697069": 39, "58770912": 133, "58830639": 133, "58836084": 39, "5889": 42, "5892963": 5, "5898": 76, "58998413": 109, "58e": 95, "59": [34, 51, 63, 82, 95, 96, 133], "59003946": 39, "5924728": 39, "59274796": 39, "59275998": 39, "59357852": 39, "594": 81, "595": 134, "597": 134, "59767085": 39, "598": 41, "59912181": 39, "59921324": 39, "59it": 134, "5a": 92, "5d": 92, "5e": 50, "5r": 79, "5th": [15, 118], "5x5": 118, "6": [0, 3, 4, 5, 8, 13, 15, 19, 22, 23, 25, 30, 33, 34, 37, 38, 39, 40, 41, 44, 47, 49, 50, 51, 53, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 82, 83, 88, 93, 94, 95, 96, 98, 103, 105, 108, 109, 111, 115, 116, 118, 125, 126, 127, 130, 132, 133, 134, 136, 143, 144], "60": [16, 34, 38, 41, 76, 96, 103, 105, 133, 134], "600": [71, 95], "6000": [53, 108], "60000": 69, "600px": 0, "60118718": 39, "602": [30, 67], "60231928": 39, "6024509": 39, "60324647": 39, "60337958": 39, "60350366": 39, "603636": 115, "60471697": 39, "60531032": 39, "60640394": 39, "6065484": 39, "6073e": 71, "60818376": 39, "60830612": 39, "6085147": 39, "60878366": 39, "6088": 1, "609": 81, "60it": 134, "61": [1, 38, 133, 134], "612": 134, "61223252": 39, "612939": 115, "61320418": [129, 134], "61330199": 109, "61336137": 39, "613579": 115, "6145": 76, "6147": 5, "61472628": 39, "61516775": 39, "61563999": 133, "61594565": 39, "616": 134, "6169496": 39, "61720311": 39, "61798553": 39, "61820903": 133, "61838026": 39, "61853913": 39, "618982": 115, "619": [1, 109], "61it": 134, "62": [34, 78, 133, 134, 144], "62048248": 39, "62060066": [129, 134], "6209": 71, "62091229": 39, "6210827": 39, "621102": 115, "62133597": [129, 134], "62157169839753": 42, "6218035": 39, "62215487": 133, "6222546e": 76, "62284909": 39, "62336218": 39, "62434536": 39, "62471505": 39, "62519531": 39, "62556168": 39, "6264": 133, "62688268": 39, "626e": 105, "62743708": 39, "62765075": 39, "62896866": 134, "629": 134, "62998964": 108, "62it": 134, "63": [4, 37, 38, 41, 46, 63, 95, 133, 134], "63019567": 39, "63043757": 39, "6307441": 39, "631": 109, "63168375": 109, "63169151": 39, "63364563": 109, "63373514": 133, "633949": 115, "63546195": 39, "636": 134, "63658341": 39, "63738791": 39, "63750082": [129, 134], "63781955": [129, 134], "6385538": 108, "63it": 134, "64": [34, 41, 42, 76, 95, 96, 115, 119, 127, 133, 134, 143], "640": 108, "6407759": 39, "64098587": 39, "6418": 76, "642": 109, "64435367": 39, "64437005": 109, "646": 134, "64659002": 39, "6471": 1, "64775015": 39, "648": 32, "64830516": 133, "64864364": 39, "64912811": [129, 134], "6497": 76, "65": [1, 82, 95, 112, 118, 133, 134, 143], "650": 76, "65032321": 39, "65065728": 39, "65101581": 39, "65130355": 39, "65223506": 39, "65297679": 49, "65458015": 39, "65498998": 39, "65501279": 39, "656": 134, "65600": 76, "65609929": 39, "65614632": 39, "656e": 105, "657041": 115, "65712464": 39, "657305": 133, "65732421": 39, "65827111": 109, "6590498": 39, "65980218": 39, "65989274": 133, "66": [76, 82, 95, 133, 134], "66023155": [129, 134], "66085975": [129, 134], "66102029": 39, "66168108": 39, "66236766": [129, 134], "663": [81, 134], "664": 109, "66412491": 133, "66479728": 39, "6649": 133, "666597": 115, "667239": 115, "66779714": 109, "66804833": 39, "668172": 115, "66871683": 39, "669": 1, "66it": 134, "67": [34, 38, 95, 133], "670067": 1, "67015631": 133, "67094845": 39, "672": 95, "67244070e": 65, "67261975": 39, "67262221": [129, 134], "672721": 115, "6735005": 39, "67387039": 133, "67393869": 39, "674": 81, "6743961": 39, "67457071": 39, "67471153": 39, "67486677": 49, "675": 134, "67545381": 39, "6755": 71, "67579578": 39, "6775828": 39, "67780757": 39, "6780": 76, "67887983": 105, "678e": 105, "68": [9, 14, 15, 17, 19, 30, 34, 35, 37, 38, 40, 41, 44, 95, 108, 112, 129, 133, 134], "68006984": 39, "680144": 115, "6801984": 39, "681": 134, "68103932": 49, "68145967": 109, "68172099e": 133, "682": 40, "68255141": 39, "683": 41, "6830988": 39, "684": 109, "68400133": 39, "68517432": 49, "6852e": 71, "68543614": 39, "68568543": 49, "68574266": 49, "68574873": 49, "68574935": 49, "6858752e": 76, "686": 125, "687": 125, "6870999932289124": 76, "6871": 76, "6875": 76, "68771659": 39, "688": 125, "68851": 49, "6890": 133, "68901502": 39, "689345": 115, "68988323": 39, "69": [34, 38, 82, 95, 133, 134], "690617": 115, "69087868": 39, "692": 30, "6924546": 39, "69257435": 39, "69336623": 39, "69346593": 39, "69379599": 39, "69380911": 39, "694": 134, "69427308": 39, "69509206": 39, "6955078": 109, "696e": 105, "698": 134, "6980": 1, "69803203": 39, "6984613": 39, "699": 30, "69902385": 39, "69942478": 5, "69it": 134, "6f": 78, "6omndqaaqbaj": 1, "7": [0, 1, 4, 5, 13, 17, 25, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 47, 49, 50, 51, 53, 69, 70, 71, 76, 78, 81, 82, 83, 92, 94, 95, 96, 99, 100, 103, 105, 108, 109, 111, 112, 115, 116, 117, 118, 125, 126, 129, 132, 133, 134, 143], "70": [0, 4, 7, 34, 76, 98, 109, 112, 133, 134], "700": 71, "70018815": 39, "70098212": 39, "70115294": 133, "70146479": 133, "70179412": 39, "70190716": 39, "70263812": 39, "70335885": 39, "7040": 76, "70459417": 39, "70474211": 39, "70548352": 39, "707": 51, "70816002": [129, 134], "7084054": 39, "709698": 115, "70it": 134, "70px": [9, 114], "71": [1, 16, 34, 38, 96, 118, 133, 134], "7103e": 71, "71066184": 39, "71100266": 39, "71146298": 109, "71195902": [129, 134], "71269214": 39, "713": 116, "71304905": 39, "713163": 115, "71361508": 39, "7138561": 98, "714": [105, 109, 134], "7141": 71, "7147896": 39, "715": 134, "7151525e": 69, "71527897": [129, 134], "71713645": 39, "71826373": 39, "71829074": 39, "719": [109, 129, 134], "71it": 134, "72": [34, 38, 63, 78, 82, 96, 133, 134, 138], "72090228": 39, "72171129": 39, "72176": 115, "722702": 39, "724": 75, "72415394": 39, "725474": 39, "72552256": 39, "72555052": 39, "72561328": 109, "72591685": 39, "72744124": 39, "7278135": 39, "72875201": [129, 134], "7288": 115, "72945097": 133, "72953922": 39, "72it": 134, "73": [72, 76, 82, 95, 127, 133, 134, 144], "731": 134, "731000": 115, "73140252": 39, "7316287": 39, "73211192": 39, "73268281": [129, 134], "73302323": 39, "733096": 115, "7334831242552866": 78, "73367312": 39, "73378149": 39, "734": 134, "73625": 49, "73953394": 39, "73977476e": 109, "73it": 134, "74": [34, 95, 105, 133, 138], "74055645": 39, "74101715": 39, "74204416": 39, "7429e": 71, "74335654": 39, "7441": 133, "74481176": 39, "74481415": [129, 134], "74488454": 39, "74545455": 109, "74582013": 39, "74639773e": 133, "74643509": 39, "747": 134, "74824483": 133, "74832579": 39, "749765": 115, "74it": 134, "75": [16, 32, 35, 41, 65, 80, 82, 112, 115, 133, 134], "750": 41, "75041164": 39, "750445": 115, "7504512": 112, "75062962": 39, "75133724": 39, "75136522": 39, "754": 134, "75539203": 39, "756352": 115, "75653272": 133, "75749229": 78, "75880566": 39, "75it": 134, "76": [133, 134, 138, 144], "760": 32, "76024923": 39, "76041518": 39, "76201118": 39, "76205806": 39, "76212473": 39, "76291349": 39, "76314662": 39, "76356305": 39, "764": 134, "7653351": 39, "76569858": 133, "76687926": 39, "76781774": [129, 134], "76795995": 39, "76916026": 39, "76994186": 39, "77": [95, 133, 134], "77042575": 39, "7707": 111, "771": 133, "77123417": 39, "77124583": 39, "77131985": 133, "77185931": 39, "77288737": 39, "773": 134, "77323981": 39, "7736060348176544": 77, "77368576": 39, "7737860054927": 42, "774": 109, "77576423": 39, "776": 6, "776e": 109, "77721369": 133, "7772263": [129, 134], "77741921": 39, "77758597": 39, "77767186": 39, "777777": [69, 76], "777e": 105, "77811": 115, "77817418": 39, "7789711": 39, "77it": 134, "78": [37, 38, 41, 78, 133, 134, 144], "78002714": 39, "7802556": 39, "78046993": 39, "781": 134, "78126654": 39, "782": [41, 115], "78265030e": 133, "784": 69, "78421011": [129, 134], "78474109": 109, "78477065": 39, "785061": 115, "78522692": 39, "78526367": 133, "78534616": 39, "78644314e": 109, "78666187": 39, "78693299": 115, "787": 115, "78730236": [129, 134], "7874": 111, "78975468": 39, "7898": 5, "789e": 105, "78arrai": 133, "79": [77, 83, 133, 134, 144], "79024706": 39, "7903551e": 69, "7908587e": 69, "791": 81, "79110577": 39, "79111527": 109, "792": 134, "79203455": 109, "79215821": 39, "79280687": 39, "793167": 115, "79354761e": 133, "79452824": 39, "79502609": 39, "7956e": 71, "7957695978": 81, "79611032": 109, "79660555": 39, "797": 95, "79764511": 112, "798": 134, "7980638": 39, "799": 81, "79924193": 39, "8": [1, 2, 7, 15, 25, 30, 33, 34, 37, 38, 39, 40, 41, 42, 46, 47, 49, 50, 63, 65, 69, 70, 71, 73, 76, 77, 78, 79, 81, 82, 83, 93, 95, 96, 98, 99, 103, 105, 108, 109, 111, 115, 116, 117, 118, 119, 125, 126, 129, 132, 133, 134, 143], "80": [1, 40, 41, 42, 77, 108, 133, 134, 144], "800": [41, 71, 105], "80043928": 39, "80073197": 39, "800b": 133, "80100182": 39, "80106255": 39, "80116214": 39, "80186103": 39, "80358898": 39, "80380385": 109, "80413849": 39, "80494266": 39, "805": 63, "80539342": 39, "80667836": 39, "8071": 115, "80745592": 39, "8079963": 39, "80816445": 39, "80875453": 133, "80884436": 39, "8094517": 39, "80977897": 39, "80e": 95, "80it": 134, "80kb": 133, "80px": 9, "81": [1, 46, 95, 133, 134, 143, 144], "810": 1, "8100e": 71, "81053491": 39, "81095167": 39, "812": 134, "81252782": 39, "81304498": 39, "81342101": 39, "81343023": 39, "814": 134, "81434313": 39, "81582367": 39, "81604368": 39, "816454": 115, "8165998": 39, "816847": 115, "81693801": 39, "81757959": 39, "81768187": 39, "818": 40, "81889683": 39, "8190797": 39, "81it": 134, "82": [95, 133], "82033": 112, "82038771": 39, "8223678": 39, "82400562": 39, "82401733": 39, "82454103": 39, "82458463": 39, "82502982": 39, "82529684": 39, "82539979": [129, 134], "82540007": 133, "82581966": 39, "82699862": [129, 134], "827": 6, "82757179": 39, "82797464": 39, "82818662": 39, "82it": 134, "83": [82, 95, 105, 133, 134, 144], "830": 134, "83180116": 39, "83189927": 109, "832": 134, "83351405": 39, "8337": 71, "83471763": 39, "83475135": 133, "83599203": 39, "83600472": 39, "8383258e": 69, "83863475": 39, "83880168": 39, "83898341": 39, "839818": 115, "8398299": 39, "8399": 76, "83it": 134, "84": [1, 5, 17, 38, 41, 50, 94, 96, 105, 112, 125, 129, 133, 134], "84086156": 39, "841": 109, "8415": 71, "84222474": [129, 134], "842436": 115, "84300633": 39, "84459755": 133, "84501737": 39, "84550881": 39, "84589891": 5, "84616065": 39, "847": 134, "84858": 1, "849": 134, "84949567": 39, "84958685": 39, "85": [9, 42, 73, 77, 83, 93, 133, 134], "851": 134, "85129577": 39, "85143789": 39, "8515102": 39, "85257974": [129, 134], "85270406": 39, "852e": 105, "85300949": 39, "85328122": 39, "85328219": 39, "85372673": 39, "853835": 115, "85386727": 112, "85555595": 39, "85565861": 39, "85680425": 39, "8574818": 39, "85753327": 39, "858185": 115, "85860200e": 109, "85987097": 39, "85it": 134, "86": [95, 133, 134, 144], "86028827": 39, "86064819": 39, "86089124": 39, "8616231": 39, "861676": 115, "86253814": 133, "86334532": 39, "86339779": [129, 134], "86355526": 39, "86402267": 39, "865": 134, "86520687": 39, "86540763": 39, "86620796": 39, "86622078": 133, "86647138": 39, "867": 133, "86828789": [129, 134], "86832437": 39, "86888616": 39, "8694594e": 76, "86977373": 133, "87": [1, 51, 77, 81, 93, 133, 134, 144], "870": 134, "8709698": 39, "8726145e": 69, "87270": 49, "87533792": 133, "87583893": 39, "87616892": 39, "87710977": 39, "87784598": 39, "87798127": 39, "87809431": [129, 134], "878123": 115, "87953543": 39, "87985002": 39, "88": [1, 38, 72, 133, 134], "8805": 50, "8808846": 39, "88094581": 39, "88122883": 39, "88176277": 109, "882": 134, "8820": [50, 130], "88268965": 39, "88288931": 39, "883": 50, "88352998": 39, "88355585": 39, "884": 50, "88401481": 39, "88490881": 39, "88501353": 112, "88512895": 39, "88514116": 39, "8858258": 39, "88583608": 39, "8865639": 39, "88772753": [129, 134], "88888889": 135, "88955297": 39, "8895a785550b": 117, "88it": 134, "89": [82, 118, 133, 134, 144], "890": 134, "89000851": 39, "89160793": 39, "8922875": 39, "89320601": 39, "89342693": 39, "89353988": 39, "89465529": 39, "896": 76, "89711278": 39, "89806796": 39, "89825413": 39, "8983e": 71, "899": 134, "89938082": 39, "89984477": 39, "89it": 134, "8e": 125, "8x8": [78, 82], "9": [0, 7, 12, 15, 34, 37, 38, 39, 41, 42, 45, 46, 47, 49, 50, 53, 69, 71, 73, 76, 78, 79, 80, 82, 92, 93, 94, 95, 98, 99, 103, 105, 108, 109, 112, 115, 117, 118, 119, 129, 133, 134, 135, 143], "90": [1, 44, 79, 109, 112, 133, 134, 144], "900": [71, 134], "90010873": 39, "90085595": 39, "90148689": 39, "90159072": 39, "902340": 1, "90245652e": 133, "90258622": 109, "90284564": 39, "903": 38, "90355016": 109, "90399917": 39, "90465871": 39, "9050": 71, "90508815": 39, "90512674": 133, "90575218": 39, "9063": 76, "9069": 71, "90756768": 39, "909": 134, "90909091": 109, "90966167": 39, "9099": 76, "90it": 134, "91": [1, 29, 78, 95, 109, 118, 133, 134, 144], "9104236": 39, "9116924877687354e": 78, "91197": 1, "91263561": 133, "91360943": 39, "9150833487510681": 69, "9154": 76, "91549197": 39, "91549927": 39, "91582": 115, "917": [133, 134], "91745894": [129, 134], "91826915": [129, 134], "91887782": [129, 134], "918992": 115, "91928931": 39, "9192e": 71, "91979229": 39, "91e": 95, "91it": 134, "92": [33, 78, 109, 133, 134, 144], "92001793": 39, "92019511": [129, 134], "92061512": 39, "921": 133, "92145007": 39, "92319798": 39, "92332064": 39, "923602": 115, "92381543": 39, "92442829": 39, "925": 1, "92550121": 39, "92590373": 133, "9268873": 39, "92703138": 39, "92703572": 39, "92763694": 133, "927732": 115, "929": 134, "92it": 134, "93": [78, 133, 134, 144], "93037546": 39, "9306713": 39, "931": 115, "93110208": 39, "93122954": 39, "93125568": 39, "93212342": 39, "9322": 133, "93258998": 39, "93272141": 39, "934": 134, "93415215": [129, 134], "93514778": 39, "93601953": 133, "937082": 115, "93752881": 39, "93808797": [129, 134], "93820324": 39, "939": 115, "93916874": 39, "93934751": 39, "93985929": 39, "93it": 134, "94": [1, 133, 144], "94056472": 112, "9406321": 39, "94092553": 109, "94317552": 39, "945": 5, "94623562": 39, "94645393": 39, "94651631": 39, "947": 81, "94750117": 39, "9477183": 112, "948": 134, "94881155": 39, "9489603": 78, "94940459": 105, "94980882": 39, "949e": 105, "94it": 134, "95": [7, 9, 17, 19, 29, 30, 35, 37, 40, 41, 53, 77, 78, 80, 82, 83, 93, 95, 96, 105, 108, 112, 114, 133, 134, 144], "95029742": 39, "95093225": 39, "951": 134, "95103519": 112, "95116949": [129, 134], "9518": 71, "952": 40, "95413331": 39, "95446575": 39, "95449567": 39, "95486746": [129, 134], "95487808": 39, "955": 41, "95541062": 39, "9560789": 39, "9561217": 39, "9578333497047424": 69, "95833569": 133, "9586027": 39, "96": [80, 82, 95, 105, 133, 144], "9603313": 39, "96081768": 39, "96082174": 39, "96130449": 39, "96279877": 39, "96284842": 133, "962990": 115, "96318234": 39, "96371871": 39, "96400982": 39, "96463208": 39, "965548": 115, "96602": 5, "96622086": 39, "96653925": 39, "966899": 115, "9670395": 134, "96710175": 39, "968": 134, "96818283": 39, "9685333371162415": 69, "969": 134, "96908858": 39, "96it": 134, "97": [77, 78, 82, 83, 95, 129, 133, 134, 144], "97061": 115, "971": 41, "97173349": 133, "97247061": 39, "9734333157539368": 69, "974": 32, "97409466": [129, 134], "9742e": 71, "9745895e": 78, "97538304": 39, "97625654": 133, "97682437": 105, "9771833419799805": 69, "97779878": 39, "97794526": 105, "977e": 105, "978": 1, "9780470015629": 1, "9780470028735": 1, "9780521642989": 1, "9781009023405": 1, "9781108843607": 1, "97811406": 39, "9781420079425": 1, "9781491912133": 1, "9781491962299": 1, "9783319154305": 1, "978e": 105, "97it": 134, "98": [16, 39, 53, 82, 83, 93, 95, 133, 144], "980": 69, "9800500273704529": 69, "98008876": 133, "98047744": 39, "98048015": 39, "980749": 133, "98076837": 39, "98099948": 39, "98108001": 133, "9811": 5, "981321": 115, "98136574": 133, "9817500114440918": 69, "98181818": 109, "98213869e": 133, "98218245": 39, "98228168": 39, "98254505": 39, "983": 134, "983310": 115, "9834499955177307": 69, "98401224": 39, "98495167": 39, "9850666522979736": 69, "98508459": [129, 134], "98519631": 39, "9857833385467529": 69, "986": [31, 134], "98633519": 39, "98635218": 39, "986489": 133, "98667091": 78, "987": 134, "9873354": 39, "9888561e": 76, "98907246": [129, 134], "99": [16, 35, 37, 79, 109, 112, 133, 134, 143, 144], "990": [63, 115, 144], "990e": 105, "99161615": [129, 134], "992": 34, "9930": 82, "994": 34, "995": 109, "996": 133, "997": [37, 40, 41, 144], "9972": 40, "99810852": 39, "998527": 78, "999": [25, 30, 99, 112], "9990": 133, "9991": 133, "9992": 133, "9993": 133, "9994": 133, "9995": 133, "9996": 133, "99962499": 39, "9997": 133, "9998": 133, "99983081": 39, "9999": 133, "9999052e": 69, "9999arrai": 133, "9999xarrai": 133, "99arrai": 133, "A": [0, 1, 4, 8, 16, 18, 21, 22, 23, 24, 25, 26, 27, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 56, 61, 62, 63, 64, 65, 66, 67, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 86, 89, 93, 94, 95, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 116, 118, 127, 128, 129, 131, 132, 133, 134, 135, 136, 143, 144, 145], "AND": [25, 79], "AS": 76, "And": [19, 35, 37, 41, 44, 48, 59, 62, 64, 66, 69, 75, 77, 83, 86, 128, 129, 134, 135, 136, 143], "As": [4, 8, 10, 17, 23, 33, 34, 38, 41, 45, 47, 48, 51, 52, 53, 59, 63, 64, 65, 67, 68, 72, 73, 75, 76, 77, 78, 82, 83, 88, 92, 98, 99, 100, 108, 109, 112, 115, 116, 117, 124, 129, 133, 134, 135, 136, 138], "At": [0, 5, 8, 16, 25, 34, 37, 40, 46, 51, 53, 56, 66, 88, 94, 99, 109, 125, 126, 130, 135], "BE": [34, 98, 115], "BY": [43, 56], "Be": [32, 67, 81, 90, 92, 99, 107, 115, 118, 119, 124, 138], "Being": 47, "But": [4, 7, 8, 13, 19, 21, 22, 23, 29, 31, 34, 38, 40, 41, 48, 51, 52, 58, 59, 60, 62, 63, 66, 73, 78, 82, 86, 95, 98, 100, 102, 103, 108, 118, 119, 125, 127, 128, 133, 135, 136, 141, 144], "By": [16, 25, 31, 33, 34, 38, 42, 48, 53, 64, 66, 71, 75, 77, 78, 82, 83, 98, 103, 105, 112, 116, 124, 127, 133, 138, 143, 144], "For": [0, 4, 7, 8, 9, 16, 17, 18, 19, 21, 25, 29, 30, 31, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 56, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 92, 93, 95, 96, 98, 99, 100, 102, 103, 107, 108, 109, 112, 113, 114, 115, 116, 118, 119, 121, 125, 126, 129, 131, 133, 134, 135, 138, 143], "If": [0, 4, 7, 9, 11, 13, 16, 17, 19, 22, 23, 25, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 56, 62, 63, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 81, 83, 85, 86, 88, 90, 95, 96, 102, 103, 105, 107, 109, 112, 113, 115, 116, 118, 119, 125, 128, 129, 130, 133, 134, 135, 136, 138, 141, 143], "In": [0, 2, 3, 4, 5, 7, 8, 9, 13, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 88, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 114, 115, 116, 117, 118, 119, 126, 127, 128, 129, 130, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145], "Ising": [67, 102, 127, 144], "It": [0, 3, 4, 7, 8, 16, 19, 21, 22, 23, 25, 31, 34, 35, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 53, 56, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 77, 78, 79, 80, 83, 85, 88, 92, 93, 94, 95, 97, 98, 99, 100, 102, 105, 109, 111, 112, 115, 116, 117, 118, 119, 124, 125, 126, 128, 129, 130, 132, 133, 134, 135, 136, 138, 141, 143], "Its": [46, 67, 78, 82, 85, 138], "No": [4, 16, 35, 44, 47, 48, 51, 59, 62, 65, 69, 70, 73, 79, 86, 93, 105, 108, 110, 133, 135, 136], "Not": [4, 35, 38, 39, 41, 42, 43, 44, 51, 64, 76, 108, 126, 129, 134, 141], "OF": 76, "OR": [25, 76, 79], "Of": [31, 34, 98], "On": [4, 21, 62, 63, 64, 66, 70, 73, 75, 105, 111, 116, 143], "One": [9, 11, 19, 29, 33, 34, 38, 46, 47, 48, 52, 55, 59, 61, 62, 65, 66, 67, 69, 73, 88, 103, 115, 118, 119, 128, 130, 135, 136, 138, 143], "Or": [17, 25, 53, 58, 77, 83, 95, 112, 115, 128], "Such": [7, 34, 43, 46, 62, 64, 66, 100, 112, 135, 138], "TO": 115, "That": [15, 17, 22, 31, 33, 34, 38, 40, 41, 47, 48, 49, 53, 62, 66, 67, 68, 72, 73, 88, 95, 98, 100, 105, 112, 116, 125, 126, 127, 128, 129, 133, 134, 135, 138, 144], "The": [1, 3, 5, 8, 9, 10, 11, 12, 13, 15, 17, 18, 20, 22, 23, 24, 26, 29, 30, 31, 32, 33, 35, 37, 39, 42, 45, 47, 48, 50, 51, 52, 55, 56, 58, 59, 60, 61, 62, 64, 67, 68, 69, 70, 71, 73, 76, 79, 80, 81, 84, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 102, 104, 106, 107, 108, 109, 111, 114, 115, 117, 118, 119, 120, 121, 122, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 140, 141, 143, 144], "Their": [47, 67, 72], "Then": [3, 4, 7, 9, 19, 22, 23, 30, 34, 37, 41, 43, 44, 51, 52, 53, 65, 70, 71, 77, 79, 85, 86, 92, 107, 109, 112, 116, 117, 119, 124, 125, 126, 128, 129, 132, 134, 135, 136, 138, 140, 141, 145], "There": [4, 8, 9, 11, 16, 19, 25, 30, 32, 37, 38, 40, 43, 44, 45, 46, 47, 51, 56, 60, 63, 66, 67, 73, 75, 82, 86, 90, 95, 97, 100, 111, 112, 114, 115, 116, 119, 125, 126, 128, 130, 133, 135, 136, 138, 145], "These": [4, 8, 22, 34, 37, 39, 43, 44, 45, 47, 48, 51, 52, 59, 61, 64, 65, 66, 67, 68, 69, 71, 72, 75, 82, 85, 88, 94, 95, 96, 98, 99, 100, 108, 109, 111, 112, 116, 129, 130, 133, 134, 136, 138, 143, 144], "To": [0, 8, 15, 16, 25, 30, 34, 35, 38, 39, 43, 44, 46, 47, 48, 50, 51, 52, 53, 59, 61, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 81, 86, 94, 96, 98, 102, 112, 116, 119, 125, 126, 128, 129, 132, 134, 135, 136, 138], "Will": [17, 23, 34, 82, 98], "With": [4, 7, 9, 16, 29, 30, 34, 35, 40, 41, 44, 46, 47, 51, 53, 62, 65, 66, 67, 68, 69, 72, 76, 79, 86, 95, 97, 99, 115, 117, 129, 133, 134, 138, 143], "_": [4, 6, 7, 9, 10, 11, 12, 19, 23, 24, 30, 33, 34, 35, 39, 44, 45, 46, 48, 52, 53, 64, 65, 66, 67, 72, 73, 77, 78, 80, 81, 82, 83, 86, 92, 93, 95, 97, 98, 99, 100, 102, 105, 107, 109, 111, 112, 117, 119, 129, 132, 134, 135, 138, 143], "_0": [4, 39, 42, 53, 97, 129, 134, 135], "_1": [0, 7, 34, 48, 65, 67, 68], "_2": [34, 48, 66, 67, 98], "__": [73, 93], "_________________________________________________________________": [69, 76], "__enter__": 108, "__former_attrs__": [50, 96], "__future__": 76, "__getattr__": [50, 96], "__init__": [9, 50, 71, 96, 105, 108, 131, 132], "__version__": [38, 41, 50, 69, 96, 125, 133, 134], "_a": 53, "_adjust_frame_s": 108, "_alpha": 96, "_amp1": 50, "_amp2": 50, "_amplitud": 96, "_background": 96, "_base": 50, "_beta": [50, 96], "_check_optimize_result": 81, "_config": 0, "_d": [103, 105, 130], "_data": 9, "_execute_child": 108, "_fig": 108, "_g": [44, 103], "_generatorcontextmanag": 108, "_gpr": 81, "_h": [105, 108], "_i": [7, 34, 44, 46, 65, 66, 67, 97, 132, 135, 138], "_imag": 109, "_is_sav": 108, "_j": 46, "_k": [48, 66, 92], "_log": 108, "_m": [66, 67, 85], "_n": [85, 92, 99, 128], "_p": [24, 112], "_pformat_subprocess": 108, "_posit": 96, "_proc": 108, "_run": 108, "_sample_proba": [73, 93], "_setattr_cm": 108, "_sig": 50, "_sort": 41, "_supports_transpar": 108, "_t": 105, "_true": [39, 129, 134], "_v": 105, "_w": [88, 108, 114], "a0": [7, 96], "a0boogfu": 115, "a1": [17, 108, 112, 115], "a2": [17, 112, 115], "a3": 115, "a4": 115, "a_": [7, 35, 96, 107, 109], "a_0": [7, 34, 35, 49, 52, 90, 96, 98, 100], "a_1": [34, 49, 52, 82, 90, 96, 98, 100, 112], "a_1a": [34, 98, 115], "a_2": [34, 52, 82, 98, 112], "a_2a": [34, 98, 115], "a_3": [34, 98, 115], "a_4": [34, 98, 115], "a_arr": 7, "a_bar": 49, "a_grid": 37, "a_hat": 49, "a_i": [49, 53, 68, 82, 94, 112, 115], "a_j": [68, 82, 96, 112], "a_k": [49, 52, 68, 82], "a_margin": 37, "a_mat": 49, "a_max": 37, "a_n": [34, 100, 112, 138], "a_posterior": 7, "a_pt": 37, "a_tru": 37, "a_w": 114, "a_x": 53, "aa": 118, "ab": [1, 3, 6, 38, 40, 78, 82, 92, 105, 107, 118, 125, 126, 132, 133, 135, 143], "abandon": 130, "abar": 49, "abar_": 49, "abbrevi": [103, 116], "abeca3": 1, "abil": [38, 46, 47, 64, 71, 73, 100, 116, 118, 135], "abl": [16, 25, 34, 38, 43, 44, 45, 47, 53, 56, 67, 71, 73, 78, 82, 88, 95, 113, 116, 124, 126, 143], "abnormal_termination_in_lnsrch": 81, "abolut": 38, "about": [0, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 22, 23, 25, 30, 31, 33, 34, 35, 37, 38, 40, 41, 42, 43, 46, 47, 48, 49, 50, 53, 58, 59, 62, 63, 64, 66, 67, 69, 72, 73, 76, 77, 78, 79, 81, 82, 83, 85, 86, 88, 90, 93, 94, 95, 96, 97, 98, 100, 102, 103, 112, 113, 114, 115, 116, 118, 119, 125, 126, 127, 133, 135, 136, 140, 141, 144], "abov": [0, 4, 5, 7, 9, 17, 19, 22, 23, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 44, 48, 49, 51, 53, 63, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 82, 83, 88, 92, 93, 98, 99, 103, 105, 109, 112, 115, 116, 118, 125, 126, 127, 128, 129, 133, 134, 135, 138, 143, 144, 145], "absenc": [8, 63, 102], "abserr": [131, 132], "absolut": [3, 4, 8, 16, 47, 65, 66, 67, 85, 100, 107, 115, 118, 135], "absolute_import": 76, "absorb": 25, "abspath": [112, 138, 143], "abstract": [8, 16, 53, 66, 73, 138, 143], "abstractmoviewrit": 108, "abund": 99, "abundantli": 38, "ac": [32, 77], "ac83dd": 1, "academ": [43, 56], "accelar": 105, "acceler": [62, 64, 103, 105], "accentu": 33, "accept": [6, 19, 29, 39, 44, 45, 46, 50, 51, 53, 61, 64, 71, 75, 105, 119, 126, 127, 128, 129, 130, 134, 135, 136, 138, 143, 144, 145], "acceptance_fract": [6, 50, 105, 125, 129, 134], "acceptance_r": 133, "access": [8, 16, 34, 43, 45, 48, 51, 53, 56, 64, 65, 71, 77, 83, 88, 98, 100, 112, 115, 116, 118, 119, 121, 135, 136], "accid": [35, 64], "accommod": [8, 88], "accompani": 64, "accomplish": [48, 50, 71, 118, 128, 136], "accor": 65, "accord": [7, 9, 16, 29, 33, 34, 41, 42, 43, 44, 46, 50, 53, 60, 67, 68, 71, 96, 102, 108, 112, 115, 126, 135, 138, 140], "accordingli": [23, 43], "account": [0, 4, 16, 23, 29, 34, 37, 38, 43, 48, 55, 59, 60, 61, 63, 72, 103, 105, 109, 115, 125, 127, 143, 144], "accumul": [7, 44, 67, 71, 99, 105, 141], "accur": [40, 45, 47, 48, 53, 63, 65, 66, 69, 80, 89, 102, 103, 104, 106, 108, 132], "accuraci": [38, 40, 41, 43, 47, 48, 49, 50, 51, 63, 65, 67, 70, 73, 76, 93, 107, 112, 125, 127, 132, 136, 144], "accus": 8, "aceept": 130, "acf": 126, "achiev": [8, 41, 44, 46, 47, 53, 64, 65, 66, 67, 76, 88, 100, 102, 103, 115, 125, 135, 138], "acknowledg": [48, 61, 63], "acor": [125, 126], "acquaint": [34, 98, 100], "acquir": [9, 10, 11, 27, 62, 67, 102], "acquisit": [58, 92], "across": [34, 40, 43, 46, 47, 48, 71, 75, 77, 83, 98, 103, 125, 130, 141], "act": [7, 8, 40, 41, 51, 53, 58, 62, 100, 102, 111, 116], "act_1": [73, 93], "act_2": [73, 93], "act_out": [73, 93], "action": [63, 64, 102, 110, 145], "activ": [8, 46, 47, 64, 65, 69, 70, 71, 72, 73, 74, 75, 76, 93, 102, 105, 111, 116, 119], "activaiton": 102, "activit": 67, "actual": [7, 8, 9, 13, 16, 19, 21, 22, 25, 30, 31, 34, 35, 38, 40, 41, 43, 46, 51, 53, 58, 63, 65, 66, 71, 72, 77, 83, 86, 88, 93, 95, 99, 100, 102, 103, 115, 124, 127, 135, 138, 141, 144], "ad": [19, 25, 37, 38, 40, 44, 50, 53, 56, 66, 69, 73, 74, 77, 79, 80, 83, 86, 92, 93, 94, 95, 96, 97, 99, 102, 103, 105, 109, 112, 116, 124, 125, 126, 129, 134, 138, 141, 143], "adadelta": [1, 99], "adagrad": [67, 71], "adam": [1, 56, 67, 69, 71, 76], "adapt": [1, 9, 33, 34, 37, 38, 39, 40, 47, 50, 56, 61, 67, 71, 77, 78, 82, 83, 87, 90, 95, 101, 102, 103, 104, 109, 124, 125, 126, 127, 129, 130, 132, 133, 134, 136, 144], "adapt_diag": [133, 134], "adaptation_lag": [50, 96], "adaptation_tim": [50, 96], "add": [0, 9, 17, 19, 31, 33, 34, 40, 47, 52, 64, 66, 68, 70, 73, 74, 75, 79, 80, 82, 86, 90, 93, 94, 95, 100, 104, 105, 112, 115, 116, 117, 118, 119, 120, 124, 125, 126, 129, 130, 132, 134, 135, 141], "add_ax": 108, "add_subplot": [5, 9, 17, 37, 38, 40, 41, 42, 49, 65, 70, 95, 108, 109, 114, 116, 117, 127, 131, 132, 144], "addbackward0": 71, "addit": [0, 2, 7, 16, 24, 25, 27, 31, 34, 42, 44, 46, 48, 51, 52, 53, 58, 61, 62, 64, 66, 67, 68, 71, 72, 73, 75, 77, 78, 80, 82, 85, 88, 93, 99, 100, 103, 106, 116, 119, 133, 136, 138], "addition": 67, "address": [38, 53, 55, 56, 57, 63, 72, 90, 95, 100, 101, 104, 129, 130, 134, 135], "adequ": [7, 63], "adher": [43, 53, 63], "adjac": [51, 67], "adjust": [9, 17, 37, 38, 42, 44, 63, 67, 69, 71, 72, 73, 86, 88, 100, 102, 108, 112, 114, 124, 130, 131, 133, 136], "admin": 119, "admir": 115, "adopt": [34, 38, 51, 63, 75, 103], "ador": 63, "adress": 44, "advanc": [8, 9, 47, 50, 56, 63, 67, 71, 91, 95, 96, 113, 119, 135, 138, 142], "advantag": [16, 27, 28, 34, 38, 43, 47, 56, 71, 75, 99], "advertis": 86, "advi": [72, 93, 133], "advic": 141, "advoc": [40, 88, 95, 130], "af_fig": 7, "affect": [19, 25, 38, 40, 41, 43, 62, 63, 64, 71, 80, 112, 131, 135], "affin": [1, 47, 105, 128, 129, 130, 134, 135], "afford": [44, 76], "after": [4, 7, 8, 9, 10, 11, 12, 16, 17, 21, 22, 23, 25, 30, 37, 38, 43, 44, 46, 47, 48, 52, 53, 59, 62, 64, 66, 67, 68, 69, 71, 77, 80, 81, 83, 85, 95, 105, 108, 115, 116, 118, 125, 126, 128, 130, 132, 133, 138, 141, 143], "afterward": 115, "ag": [63, 64], "again": [4, 7, 9, 22, 23, 30, 31, 33, 37, 44, 49, 53, 63, 65, 68, 77, 90, 95, 97, 100, 102, 107, 109, 112, 115, 116, 119, 126, 128, 129, 131, 133, 134, 135, 136, 138, 143], "against": [7, 8, 13, 14, 46, 51, 53, 63, 71, 109, 127, 143, 144], "agenc": 63, "agenda": 4, "agent": [8, 110], "aggress": 99, "agre": [13, 19, 53, 61, 76, 109, 129, 134], "agreement": [34, 39, 53, 98, 119, 129, 134], "ahead": [20, 23, 73, 93, 116], "ai": [1, 64, 89, 102], "aic": 51, "aid": [43, 46], "aim": [4, 34, 44, 46, 47, 56, 61, 62, 63, 64, 65, 66, 67, 77, 83, 98, 99, 105, 115, 143], "aip": 51, "air": [103, 105], "airplan": 76, "aka": [9, 30, 47, 85, 104], "akaiko": 51, "al": [0, 43, 44, 56, 66, 105, 108, 126], "alea": 72, "alexandr": 1, "alfio": 1, "algebra": [1, 7, 34, 50, 64, 67, 95, 98, 100, 107, 116, 120], "algorithm": [1, 19, 38, 44, 47, 53, 56, 62, 65, 66, 70, 71, 72, 73, 89, 93, 97, 100, 101, 102, 109, 112, 115, 118, 128, 133, 142], "alia": [50, 96], "alias": [50, 96], "align": [0, 4, 7, 13, 15, 19, 22, 24, 33, 34, 35, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 51, 66, 67, 72, 77, 79, 82, 83, 85, 86, 88, 95, 98, 99, 107, 108, 109, 112, 127, 128, 130, 131, 132, 133, 138, 140, 141, 144], "align_test": 0, "all": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 21, 22, 23, 25, 27, 30, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 77, 78, 79, 82, 83, 85, 86, 88, 89, 92, 94, 95, 96, 98, 99, 100, 102, 103, 105, 106, 108, 109, 111, 112, 115, 116, 118, 119, 124, 125, 126, 127, 128, 129, 130, 133, 135, 138, 140, 141, 143, 144], "all_orbit": 131, "allow": [3, 4, 7, 8, 9, 11, 12, 16, 25, 30, 34, 38, 39, 43, 44, 46, 49, 53, 64, 65, 71, 73, 75, 80, 81, 82, 85, 89, 93, 95, 98, 99, 100, 102, 105, 112, 115, 116, 118, 119, 126, 129, 133, 134, 135, 143], "allud": [0, 22], "almost": [7, 19, 63, 64, 65, 67, 73, 78, 82, 108, 130, 133, 135, 136, 143], "alo": 35, "alon": [4, 8, 51], "along": [43, 47, 62, 72, 75, 82, 90, 118, 130, 133, 138], "alongsid": [77, 83], "alp": 1, "alpha": [3, 6, 9, 13, 17, 19, 29, 30, 33, 34, 37, 39, 40, 41, 42, 47, 49, 50, 51, 65, 67, 70, 72, 73, 74, 77, 78, 80, 81, 82, 85, 88, 92, 93, 94, 95, 96, 98, 102, 105, 108, 109, 111, 112, 115, 125, 126, 132, 134, 135, 138, 140], "alpha_1": [9, 30], "alpha_1_w": 9, "alpha_2": 9, "alpha_2_w": 9, "alpha_3": 9, "alpha_3_w": 9, "alpha_bound": 81, "alpha_v": 105, "alphabet": 56, "alphavec": [23, 90], "alreadi": [7, 16, 17, 19, 31, 34, 37, 39, 49, 52, 56, 60, 63, 65, 73, 77, 83, 86, 100, 102, 109, 115, 116, 119, 126, 127, 129, 134, 136, 138, 142, 144], "also": [0, 3, 4, 5, 7, 8, 9, 16, 17, 19, 21, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 52, 53, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 78, 81, 82, 83, 85, 86, 88, 89, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 109, 111, 112, 114, 115, 116, 117, 118, 119, 124, 125, 126, 129, 130, 133, 134, 135, 136, 138, 141, 143], "alter": [8, 9, 30], "altern": [3, 4, 6, 17, 34, 38, 39, 41, 44, 46, 47, 48, 53, 61, 64, 66, 88, 92, 94, 97, 100, 104, 108, 112, 120, 124, 134, 135, 138, 142], "although": [0, 7, 8, 11, 19, 22, 25, 33, 34, 43, 45, 47, 48, 53, 56, 60, 63, 82, 97, 98, 99, 100, 112, 115, 118, 135, 138, 141, 143], "altogeth": [44, 85], "alwai": [6, 7, 8, 16, 17, 19, 22, 23, 29, 34, 40, 43, 48, 49, 53, 58, 63, 64, 65, 66, 67, 72, 85, 92, 98, 100, 111, 112, 115, 116, 117, 126, 127, 128, 133, 135, 136, 138, 140, 141, 143, 144], "am": 1, "amat": 109, "amatt": 109, "amax": [42, 96], "amaz": [64, 73], "amazon": 56, "ambigu": 67, "ambit": [45, 67], "ambiti": [58, 62], "ame2003": 115, "ame2012": 115, "ame2016": 115, "amelior": 66, "american": [1, 61, 110], "amin": [42, 96], "among": [8, 29, 38, 40, 43, 47, 48, 55, 56, 66, 75, 88, 138], "amount": [8, 9, 25, 39, 40, 51, 53, 62, 63, 66, 73, 75, 90, 97, 100, 128, 129, 134, 138], "amplifi": 63, "amplitud": [7, 34, 50, 51, 53, 80, 82, 90, 96, 114], "amplitude_in_presence_of_background_recap": 33, "an": [0, 1, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 142, 144, 145], "anaconda": [50, 56, 71, 113, 116, 121, 122], "anaconda3": [50, 119], "anal": 1, "analog": [51, 66, 94, 107, 126, 136], "analogi": [0, 1, 8, 22, 33, 51, 61, 67, 72, 126], "analys": [25, 30, 34, 43, 46, 47, 104, 108], "analysi": [0, 1, 7, 8, 16, 19, 25, 27, 29, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 56, 61, 63, 64, 65, 66, 73, 86, 88, 93, 94, 95, 101, 102, 103, 105, 106, 107, 109, 115, 116, 127, 129, 134, 135, 141, 144], "analyt": [7, 16, 30, 34, 35, 39, 40, 44, 47, 49, 53, 63, 65, 66, 67, 82, 88, 97, 98, 126, 129, 134, 138, 141], "analyz": [8, 16, 19, 25, 29, 34, 38, 49, 59, 63, 64, 75, 90, 94, 96, 98, 102, 124], "anayt": 135, "ancestor": 100, "andrea": [1, 45, 56, 78, 82], "andrei": 25, "andrew": [0, 1, 56], "ang_mom": 132, "angl": [35, 40, 42, 124], "angular": 42, "angwin": 63, "anharmon": 47, "ani": [0, 4, 5, 7, 8, 9, 11, 16, 17, 19, 22, 25, 30, 31, 32, 33, 34, 38, 40, 41, 43, 44, 45, 48, 49, 50, 51, 52, 53, 56, 58, 59, 61, 63, 64, 65, 67, 71, 73, 76, 78, 80, 82, 85, 86, 88, 92, 95, 96, 98, 102, 103, 105, 112, 116, 117, 118, 124, 125, 134, 135, 136, 138, 143, 145], "anim": [67, 108], "anindita": 1, "ankl": 76, "ann": 89, "ann_input": [73, 93], "ann_output": [73, 93], "anneal": 51, "annft": 102, "annot": [9, 17, 37, 42, 95, 108, 126], "anoth": [0, 4, 7, 9, 13, 16, 19, 23, 25, 33, 34, 37, 43, 44, 51, 53, 55, 63, 64, 65, 66, 67, 68, 75, 76, 79, 88, 90, 94, 95, 97, 100, 109, 112, 115, 116, 117, 118, 126, 127, 130, 132, 134, 136, 138, 141, 144], "ansatz": 115, "answer": [7, 8, 26, 27, 33, 39, 42, 52, 53, 59, 63, 64, 66, 77, 79, 83, 85, 92, 93, 94, 98, 105, 109, 112, 116, 126, 129, 133, 134, 136, 143], "anteced": 47, "anti": [9, 11, 12, 53, 78, 112], "antialias": [37, 112], "anticip": 63, "anymor": 85, "anyon": [59, 117], "anyth": [11, 16, 21, 42, 61, 67, 112, 116, 124, 133, 135, 136], "anywai": 126, "anywher": [0, 17, 23, 32, 43, 52, 138], "ap": 109, "apach": 76, "apart": [44, 53, 73, 79, 86], "aperiod": [126, 135, 138], "api": [73, 76, 93], "apologi": 62, "app": [1, 86], "appar": [25, 128, 141], "apparatu": 23, "appeal": [46, 112], "appear": [4, 7, 8, 22, 32, 34, 38, 42, 43, 45, 47, 53, 56, 63, 64, 66, 67, 72, 77, 83, 85, 93, 100, 107, 115, 119, 131, 135, 136, 138, 140, 143], "append": [33, 35, 38, 50, 65, 70, 96, 105, 111, 114, 115, 117, 118, 119, 125, 126, 131, 135, 141, 143], "appendix": [23, 24, 27, 56, 92, 108, 113], "appl": 119, "appli": [0, 7, 8, 15, 17, 19, 20, 22, 25, 31, 32, 34, 39, 43, 44, 47, 48, 51, 52, 53, 58, 63, 65, 67, 68, 70, 71, 72, 73, 75, 88, 94, 99, 100, 102, 105, 111, 115, 118, 127, 130, 131, 135, 136, 138, 144], "applic": [1, 7, 8, 16, 18, 23, 24, 25, 37, 39, 41, 43, 44, 45, 46, 47, 48, 52, 56, 59, 62, 63, 64, 65, 66, 67, 71, 73, 76, 86, 88, 89, 99, 100, 103, 129, 134, 138, 143], "approach": [1, 4, 8, 9, 11, 16, 17, 19, 21, 25, 28, 30, 33, 34, 35, 40, 43, 44, 45, 46, 47, 48, 51, 53, 55, 59, 60, 61, 64, 65, 66, 71, 72, 73, 74, 78, 79, 83, 88, 95, 97, 98, 100, 102, 107, 109, 110, 111, 112, 117, 130, 133, 135, 136], "appropri": [0, 4, 16, 17, 25, 34, 43, 48, 53, 63, 77, 83, 85, 103, 108, 109, 112, 116, 128, 136], "approx": [3, 4, 7, 12, 16, 19, 29, 31, 32, 38, 41, 45, 46, 52, 53, 67, 72, 73, 79, 93, 95, 100, 107, 109, 128, 135, 136, 138, 141, 143], "approxim": [1, 4, 18, 19, 29, 34, 39, 41, 44, 45, 47, 51, 52, 53, 55, 66, 67, 71, 72, 73, 90, 93, 95, 96, 98, 100, 103, 104, 109, 112, 126, 128, 129, 130, 134, 135, 136, 140], "ar": [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 143, 144, 145], "aragorn": 115, "arang": [33, 37, 39, 42, 49, 50, 65, 70, 77, 78, 80, 82, 83, 95, 96, 112, 115, 116, 117, 118, 120, 125, 131, 132, 134], "arbitrari": [23, 43, 46, 47, 67, 80, 112, 135], "arbitrarili": [34, 82, 126], "archetyp": 67, "architectur": [69, 71, 73, 76, 102], "archiv": 8, "arcsin": 3, "area": [18, 19, 43, 48, 53, 56, 64, 72, 75, 99, 115, 130, 131, 145], "aren": 63, "arg": [0, 5, 6, 7, 34, 38, 40, 41, 70, 82, 92, 96, 98, 100, 105, 108, 112, 114, 125, 128, 129, 134], "argmax": [4, 9, 17, 30, 41, 42, 69, 76, 108], "argmin": [37, 66, 85, 99, 131, 132, 143], "argsort": [41, 96], "argu": [4, 7, 8, 19, 34, 43, 46, 58, 59, 60, 62, 63, 73, 102, 115, 125, 133], "argument": [0, 7, 13, 33, 34, 38, 43, 46, 50, 52, 67, 72, 76, 79, 92, 96, 98, 99, 102, 109, 115, 116, 118, 120, 126, 138, 141], "aris": [7, 34, 47, 48, 51, 53, 66, 77, 83, 106, 115, 143], "aristotelian": 62, "arithmet": [22, 118], "arlier": 117, "around": [7, 13, 19, 23, 25, 29, 34, 35, 41, 43, 44, 53, 71, 73, 76, 77, 83, 89, 99, 100, 108, 109, 112, 125, 126, 130, 133, 141, 145], "arr": 118, "arr1": 118, "arr1_2d": 118, "arr2": 118, "arr_from_list": 118, "arr_int": 118, "arr_to_list": 118, "arrai": [3, 5, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 44, 49, 50, 65, 67, 69, 70, 73, 76, 77, 78, 79, 82, 83, 93, 94, 95, 96, 98, 105, 108, 109, 112, 115, 120, 125, 126, 128, 129, 131, 132, 133, 134, 135, 138, 143, 144], "arrang": [75, 109], "array_equ": 118, "array_lik": 105, "array_split": 118, "arrest": 63, "arriv": [8, 66, 67, 98, 115, 116], "arrow": [17, 67, 102, 108, 116, 130, 136], "arrowprop": [17, 37, 108, 126], "arrowstyl": 126, "arsen": 22, "art": [44, 73], "articl": [27, 48, 66, 76, 89, 103, 105, 110, 118], "articul": [48, 53, 57, 61], "artifact": 7, "artifici": [34, 40, 45, 47, 63, 64, 70, 74, 88, 89, 98, 99, 102], "artificialneuron": 67, "arviz": [73, 93, 133, 134], "arviz_vers": 133, "arxiv": [1, 40, 72, 86, 92, 94, 108, 133, 145], "as_cmap": [73, 93], "as_grai": 109, "asarrai": [6, 77, 83, 92, 96], "ascend": [37, 118], "ascertain": [43, 53, 135], "asid": [20, 21, 25, 39, 43, 129, 133, 134], "ask": [7, 11, 16, 22, 31, 33, 41, 42, 43, 49, 51, 53, 59, 60, 68, 98, 116, 119, 127, 128, 144], "aspect": [25, 26, 37, 47, 49, 53, 55, 56, 58, 60, 63, 77, 78, 82, 83, 88, 89, 112, 145], "aspir": 43, "ass": 73, "assembl": [75, 92], "assembli": 115, "assert": [33, 37, 50, 70, 82, 96, 126, 129, 134, 143], "assess": [7, 34, 43, 48, 51, 63], "assign": [7, 8, 21, 22, 25, 30, 34, 38, 43, 44, 46, 53, 55, 58, 65, 72, 79, 85, 88, 98, 103, 112, 118, 133, 136, 143], "assist": 116, "associ": [34, 39, 43, 45, 53, 67, 73, 77, 78, 83, 85, 97, 99, 100, 102, 115, 129, 132, 133, 134], "assum": [3, 4, 7, 8, 16, 19, 21, 22, 23, 25, 29, 31, 34, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 52, 53, 63, 65, 66, 67, 71, 72, 73, 78, 80, 82, 85, 86, 88, 90, 92, 95, 96, 98, 100, 103, 105, 108, 112, 115, 118, 119, 124, 125, 126, 129, 133, 134, 135, 136, 138, 143], "assumpt": [7, 8, 12, 34, 41, 42, 43, 46, 53, 61, 62, 63, 65, 75, 78, 82, 95, 97, 98, 103, 115, 138], "asterisk": [0, 34, 116], "astro": 80, "astronom": [1, 7, 16, 41, 58, 100, 141], "astrophysicist": 141, "astropi": 124, "astyp": [73, 93, 118], "asymmet": 19, "asymmetr": [18, 19, 126, 136, 141], "asymmetri": [63, 115], "asymptot": [23, 66], "atari": 73, "atleast_1d": 105, "atol": [131, 132], "atom": [1, 62, 115, 126], "atomic_mass": 115, "attack": 47, "attain": [8, 48], "attempt": [9, 16, 35, 44, 48, 53, 66, 72], "attend": 63, "attent": [16, 22, 63], "attitud": [61, 63, 64], "attr": [50, 96, 138], "attract": 115, "attractor": 51, "attribut": [7, 43, 50, 53, 96, 112, 118, 133], "attributeerror": [50, 96], "au": 34, "audi": [1, 115], "augment": [44, 92], "aurelien": 66, "author": [46, 56, 73, 76, 77, 80, 81, 91, 102, 103], "authorize_download": 77, "authour": 64, "auto": [78, 82, 125, 133], "autocorrel": [43, 126, 128, 145], "autoencod": 73, "automag": 64, "automat": [1, 7, 38, 64, 71, 72, 73, 89, 97, 99, 115, 118, 140], "automobil": 76, "autonomi": 63, "autoscal": [9, 42, 111], "autoscale_on": [78, 82], "autotun": 128, "auxiliari": [138, 145], "avail": [4, 9, 17, 23, 25, 39, 40, 43, 44, 46, 48, 56, 64, 73, 77, 81, 82, 83, 85, 94, 99, 103, 105, 112, 115, 116, 119, 120, 121, 126, 129, 132, 134, 135, 136], "availa": 105, "available_cor": 105, "avec": [49, 52], "avec_1": 52, "avec_2": 52, "avenu": 73, "averag": [4, 16, 18, 19, 21, 33, 35, 43, 44, 51, 52, 53, 59, 65, 66, 67, 71, 72, 75, 93, 96, 99, 100, 112, 115, 125, 126, 127, 128, 134, 135, 136, 141, 143, 144], "avg": 133, "avg_lnl": 96, "avoid": [16, 22, 31, 43, 44, 46, 50, 66, 67, 71, 72, 73, 86, 92, 96, 99, 115, 116, 119, 130], "awai": [7, 12, 34, 38, 39, 46, 53, 109, 116, 128, 129, 130, 134, 136, 141], "awar": [47, 61, 63, 81, 88, 99, 138], "award": 67, "awesom": 34, "awkward": 117, "ax": [0, 3, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 49, 50, 53, 65, 70, 73, 77, 78, 81, 82, 83, 88, 93, 95, 96, 98, 107, 108, 109, 111, 112, 114, 115, 116, 117, 118, 125, 126, 128, 129, 131, 134, 135, 138, 143, 144], "ax1": [17, 37, 39, 78, 82, 108, 109, 116, 126, 134], "ax2": [5, 17, 37, 39, 78, 82, 108, 109, 116, 126, 134], "ax2_1": 37, "ax2_2": 37, "ax2_3": 37, "ax2_4": 37, "ax3": [17, 37, 108, 109, 126], "ax3d": 112, "ax4": 37, "ax_1": [17, 42], "ax_2": [17, 42, 132], "ax_3": [17, 42], "ax_4a": 132, "ax_4b": 132, "ax_4c": 132, "ax_4d": 132, "ax_5a": 132, "ax_c": 131, "ax_pass": 117, "ax_plot": [127, 144], "ax_run": [138, 143], "ax_trac": [127, 144], "ax_tru": 37, "axes3d": [50, 65], "axhlin": [37, 108, 129, 132, 133, 134], "axi": [9, 17, 33, 35, 37, 38, 39, 40, 42, 50, 65, 66, 73, 77, 78, 81, 82, 88, 93, 94, 96, 105, 108, 109, 112, 116, 117, 118, 120, 124, 128, 131, 134, 138, 143], "axiom": [8, 16, 24], "axiomat": [25, 62], "axis_label": 131, "axs_vec": [25, 30], "axvlin": [9, 37, 42, 108, 109, 112, 126, 129, 134], "az": [133, 134], "azim": 65, "b": [0, 1, 4, 9, 13, 17, 21, 22, 23, 25, 31, 34, 35, 37, 38, 40, 41, 42, 44, 46, 47, 49, 62, 64, 65, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 82, 83, 90, 92, 93, 95, 96, 100, 102, 105, 107, 108, 109, 112, 115, 116, 117, 125, 126, 128, 133, 136], "b1": [17, 108], "b2": 17, "b_": [35, 95], "b_0": 35, "b_1": [100, 112], "b_2": 112, "b_grid": 37, "b_i": [67, 112], "b_j": [67, 68, 112], "b_k": 109, "b_m": 67, "b_margin": [35, 37], "b_max": 37, "b_n": [34, 100, 112], "b_pt": 37, "b_std": 111, "b_true": 37, "b_true_fix": [35, 37], "b_true_index": 37, "b_x": 53, "b_y": 53, "ba": 1, "ba524": 1, "baath": 108, "bacciagaluppi": 110, "back": [1, 8, 9, 10, 11, 16, 17, 25, 30, 35, 40, 51, 53, 63, 65, 66, 67, 70, 71, 75, 78, 79, 82, 88, 93, 109, 116, 117, 125, 128, 133, 135, 136, 141], "backend": [73, 116], "background": [4, 8, 16, 24, 25, 38, 43, 53, 56, 62, 63, 90, 95, 96, 104, 136, 140, 142], "backpropag": 72, "backtick": 0, "backward": [15, 67, 68, 71, 72, 109, 128, 130], "bacteri": 143, "bacteria": 143, "bad": [19, 41, 66, 73, 76], "badli": [48, 133], "bag": 16, "baggin": 115, "bailei": 108, "baishan": 1, "balanc": [51, 53, 63, 66, 130, 135], "ball": [4, 16, 129, 134], "balldrop": 103, "balzac": 45, "banana": [4, 135, 136], "band": [17, 47, 48, 79, 82, 86, 94, 138], "bandwidth_factor": 82, "bar": [4, 7, 16, 17, 22, 29, 31, 33, 37, 38, 40, 41, 44, 49, 52, 53, 65, 66, 69, 76, 77, 83, 99, 103, 105, 108, 109, 112, 115, 116, 125, 126, 128, 129, 133, 134], "bare": [35, 51, 63], "barnett": 85, "bartlett": 66, "base": [1, 4, 8, 9, 21, 22, 25, 31, 32, 33, 34, 37, 38, 39, 43, 45, 46, 47, 48, 50, 51, 53, 58, 62, 63, 64, 66, 67, 69, 71, 72, 77, 78, 82, 83, 88, 89, 92, 93, 95, 96, 98, 99, 100, 102, 103, 105, 106, 112, 115, 116, 117, 119, 120, 122, 125, 126, 129, 130, 133, 134, 135, 136], "baselin": [33, 37, 132], "basi": [1, 4, 7, 22, 45, 47, 53, 62, 63, 65, 76, 79, 80, 85, 86, 88, 100, 103, 104, 107, 109], "basic": [7, 8, 20, 22, 27, 35, 44, 47, 49, 50, 56, 62, 64, 66, 68, 69, 73, 79, 85, 87, 90, 91, 93, 99, 112, 115, 116, 120, 124, 128, 130, 131, 135, 138, 140, 141, 144, 145], "basic_model": [133, 140], "basic_model_alt": 133, "batch": [66, 67, 68, 76, 88, 97], "batch_siz": [69, 73, 99], "bay": [1, 7, 8, 9, 13, 15, 16, 19, 20, 24, 27, 30, 32, 34, 35, 37, 39, 41, 42, 43, 44, 49, 52, 53, 55, 56, 58, 59, 62, 85, 88, 95, 126, 129, 133, 134, 140], "bayes_text": 9, "bayesian": [1, 2, 11, 12, 13, 14, 18, 20, 21, 23, 24, 25, 28, 29, 35, 37, 40, 42, 44, 45, 46, 47, 49, 50, 52, 56, 57, 58, 60, 62, 64, 79, 85, 86, 88, 89, 90, 91, 94, 96, 97, 98, 100, 101, 102, 104, 105, 106, 108, 112, 124, 125, 126, 127, 133, 136, 143, 144, 145], "bayesian_7": 133, "bayesian_cr_slope_max": 41, "bayesian_cr_slope_min": 41, "bayesian_neural_network_advi": [73, 93], "bayesian_neural_networks_tif285": 93, "bayesian_research_cycl": 0, "bayesian_slope_maxprob": 41, "bayesian_slope_mean": 41, "bayesianastronomi": [37, 40], "bayesianoptim": 92, "bayesianworkflow": [0, 43], "baysian": 72, "bbox": [95, 108], "bbox_inch": [131, 132], "bbox_to_anchor": 81, "bckw15": [1, 72], "bda": [51, 128], "bda3": [0, 1, 34, 51, 53], "beach": [129, 134], "beam": 51, "bearer": 8, "beat": 73, "beaten": 62, "becaus": [5, 7, 13, 19, 23, 25, 31, 33, 34, 35, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 58, 62, 63, 66, 71, 72, 75, 76, 77, 78, 80, 82, 83, 95, 97, 107, 109, 117, 118, 125, 126, 128, 129, 130, 134, 136, 141], "bechmark": 73, "becom": [0, 4, 7, 17, 19, 25, 33, 34, 35, 39, 44, 45, 46, 48, 52, 53, 62, 64, 65, 66, 67, 72, 73, 77, 78, 82, 83, 85, 86, 89, 95, 97, 98, 99, 100, 103, 104, 115, 116, 118, 129, 134, 135, 136, 138, 143], "been": [4, 7, 8, 19, 25, 27, 31, 43, 44, 46, 47, 48, 49, 53, 56, 59, 61, 63, 64, 66, 67, 72, 73, 80, 99, 103, 105, 108, 119, 128, 133, 136, 140], "befor": [0, 7, 8, 9, 10, 16, 23, 24, 25, 31, 34, 39, 40, 42, 43, 44, 48, 52, 53, 59, 63, 65, 66, 67, 68, 69, 71, 75, 76, 77, 78, 80, 81, 82, 83, 88, 97, 99, 109, 112, 115, 118, 124, 125, 129, 130, 132, 134, 141], "beforehand": [53, 126, 135], "begin": [0, 3, 4, 7, 8, 9, 13, 15, 16, 19, 22, 24, 25, 34, 35, 37, 38, 39, 41, 44, 45, 46, 47, 48, 49, 51, 53, 63, 65, 66, 67, 68, 71, 72, 75, 77, 78, 79, 82, 83, 85, 86, 88, 95, 97, 98, 99, 100, 103, 105, 107, 109, 112, 114, 115, 116, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 143, 144], "beginn": 69, "behav": [7, 105, 136], "behavior": [11, 37, 44, 50, 53, 64, 71, 79, 90, 96, 103, 111, 115, 126], "behaviour": [53, 67, 68, 85], "behind": [16, 53, 63, 95, 115, 130], "being": [4, 7, 16, 19, 21, 22, 23, 25, 31, 32, 33, 34, 39, 40, 43, 44, 46, 47, 48, 53, 56, 58, 63, 64, 66, 67, 68, 71, 73, 77, 83, 85, 88, 89, 93, 102, 104, 108, 112, 119, 125, 126, 128, 129, 134, 136, 138, 140, 141], "belatedli": 23, "belief": [8, 10, 11, 15, 16, 17, 19, 22, 25, 34, 41, 43, 46, 61, 63, 112, 126], "believ": [10, 11, 25, 34, 42, 48, 57, 61, 63, 73, 100, 109], "bell": [108, 116], "belong": [62, 63, 65, 69, 72, 82, 86, 88, 107, 143], "below": [0, 4, 7, 17, 19, 21, 22, 33, 34, 38, 39, 43, 44, 46, 47, 50, 51, 53, 60, 63, 65, 66, 67, 69, 70, 72, 73, 76, 77, 78, 82, 83, 85, 92, 93, 95, 96, 98, 103, 108, 109, 112, 115, 116, 118, 124, 126, 127, 128, 132, 133, 135, 138, 141, 143, 144], "benchmark": 73, "benefici": 135, "benefit": [47, 56, 63, 66, 71], "benign": 66, "berg": 115, "bernardo": 1, "bernardo94": 48, "bernoulli": [8, 9, 73, 93], "besid": [16, 42, 86, 133], "best": [0, 4, 5, 7, 8, 9, 11, 17, 18, 19, 25, 29, 30, 34, 35, 38, 47, 50, 51, 53, 55, 59, 62, 65, 66, 67, 70, 71, 74, 79, 86, 88, 91, 92, 95, 97, 99, 103, 105, 112, 116, 119, 124, 135, 136, 143, 144], "bet": [8, 25, 116], "beta": [9, 18, 19, 30, 34, 38, 41, 45, 47, 50, 51, 96, 105, 108, 109, 112, 115, 126, 138], "beta0": 34, "beta1": 34, "beta1_label": 17, "beta2_dist": 17, "beta2_label": 17, "beta_": 51, "beta_0": 34, "beta_1": [9, 30, 34, 140], "beta_1_w": 9, "beta_2": [9, 51, 140], "beta_2_w": 9, "beta_3": 9, "beta_3_w": 9, "beta_dist": 17, "beta_grid": 34, "beta_i": [34, 45, 47, 51, 140], "beta_n": 51, "beta_sampl": 17, "beta_v": 105, "betai": 34, "betas0": 96, "betavec": 47, "better": [0, 4, 5, 7, 8, 23, 25, 29, 31, 33, 34, 35, 39, 40, 42, 46, 47, 53, 63, 65, 66, 67, 69, 70, 71, 73, 75, 77, 79, 83, 85, 92, 93, 96, 97, 100, 102, 105, 107, 112, 115, 117, 129, 130, 132, 133, 134, 135, 136], "betti": [21, 62], "between": [0, 4, 7, 9, 11, 15, 16, 19, 21, 22, 23, 25, 26, 30, 34, 35, 37, 38, 40, 42, 43, 44, 46, 48, 51, 52, 53, 56, 59, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 76, 77, 78, 83, 85, 86, 88, 92, 93, 95, 96, 97, 99, 100, 101, 102, 103, 105, 108, 112, 115, 116, 118, 120, 125, 128, 130, 133, 135], "beutler": 145, "bewar": 22, "beyond": [8, 19, 26, 47, 48, 53, 62, 78, 103, 127, 144], "bf": [49, 103, 105], "bf02551274": 1, "bfg": 92, "bgd": 99, "bgjm11": [1, 44], "bi": [34, 51, 82], "bia": [1, 19, 25, 34, 64, 65, 67, 68, 71, 72, 74, 77, 83, 88, 93, 95, 97, 98, 99, 102, 111], "bianca": 1, "bias": [9, 16, 23, 25, 30, 39, 59, 61, 64, 67, 68, 71, 72, 75, 93, 102, 103, 129, 134, 143], "bias_std": 111, "bib": 0, "bibtex": 0, "bic": 51, "bicyclist": 64, "bienaym\u00e9": 46, "big": [34, 60, 64, 98, 102, 136, 138], "bigg": [34, 45, 98], "bigger": [42, 56, 68], "biggest": 63, "biggl": [79, 86], "biggr": [79, 86], "bigl": [4, 19, 24, 29, 34, 35, 47, 51, 79, 86, 102, 130, 141], "bigr": [4, 19, 24, 29, 34, 35, 47, 51, 79, 86, 102, 130, 141], "bilbo": 115, "billiard": 38, "billion": 67, "bimod": [17, 67, 112], "bin": [4, 17, 19, 29, 33, 35, 37, 41, 42, 50, 82, 96, 108, 111, 112, 125, 126, 127, 128, 133, 138, 144], "bin_arrai": 33, "bin_bound": 42, "bin_edg": 108, "bin_num": [127, 144], "bin_width": [33, 42], "binari": [9, 30, 63, 64, 66, 69, 71, 72, 73, 74, 76, 93, 115], "binary_classification_data_fig": 65, "binarygibbsmetropoli": 133, "binarymetropoli": 133, "bind": 136, "binder": 119, "binomi": [13, 19, 25, 33], "biolog": [48, 67, 88, 100], "biologi": [1, 46], "bipoc": 63, "bird": 76, "birth": 115, "bit": [9, 11, 19, 38, 51, 119, 129, 134], "bitrat": 108, "bivari": [7, 44, 53, 72, 82, 86, 103, 135, 138, 143], "bivariate_fig": 112, "bla": 118, "black": [7, 17, 23, 34, 37, 38, 40, 42, 47, 60, 63, 65, 81, 88, 98, 102, 105, 108, 117, 127, 132, 144, 145], "blank": 32, "blei": [1, 72], "blind": [7, 112], "blindli": 133, "block": [7, 64, 66, 69, 85, 112, 115], "blockedstep": 133, "blog": [38, 72, 73, 93, 99, 108, 109, 116, 126, 130, 135, 136], "blond": 4, "bloodi": 62, "blow": 102, "blown": 91, "blr": [16, 28, 98, 100], "blue": [5, 9, 17, 23, 30, 31, 32, 33, 34, 37, 38, 40, 42, 44, 47, 49, 65, 66, 69, 72, 75, 76, 79, 80, 88, 93, 95, 98, 103, 108, 109, 114, 116, 125, 126, 127, 129, 132, 134, 136, 144, 145], "blundel": 1, "bmatrix": [34, 88, 98], "bmax": 96, "bmc": 1, "bn": 95, "bnn": 89, "bnn_binary_classifier_mean": 72, "bnn_binary_classifier_stddev": 72, "bo": 135, "bob": 118, "bodi": [16, 45, 62, 64, 100, 108], "bohr": 25, "boil": 8, "bold": [34, 98, 100, 116], "boldfac": [93, 102, 109], "boldsymbol": [0, 7, 9, 30, 34, 44, 65, 66, 67, 68, 72, 74, 78, 82, 88, 96, 97, 98, 99, 103, 105, 109, 112, 115, 135, 138, 143], "boltzman": 51, "boltzmann": [4, 5, 44, 51, 67], "bon": 34, "bonu": [38, 90, 96], "book": [1, 9, 23, 39, 40, 42, 50, 58, 59, 62, 63, 72, 75, 81, 95, 96, 108, 113, 122, 134], "boolean": [25, 30, 105, 109, 118, 135], "boost": [67, 73], "boot": 76, "bootstrap": [15, 44, 73], "border": [42, 114, 116, 141], "bore": 51, "bori": [1, 56], "born": 23, "borrow": 115, "boson": [19, 112], "both": [4, 7, 11, 19, 22, 25, 31, 33, 34, 37, 38, 40, 43, 44, 47, 48, 50, 53, 56, 59, 63, 65, 66, 67, 71, 72, 74, 77, 80, 81, 85, 93, 97, 99, 100, 103, 107, 108, 112, 114, 115, 116, 118, 124, 125, 126, 127, 130, 132, 133, 141, 142, 143, 144], "bother": [8, 48], "bottleneck": 99, "bottom": [10, 11, 17, 33, 37, 53, 94, 108, 136, 141], "bought": 8, "bound": [19, 34, 38, 42, 46, 47, 53, 67, 82, 92, 98, 105, 126], "boundari": [34, 47, 70, 72, 73, 74, 126, 135, 141], "bovin": 62, "bower": 1, "bowl": 130, "box": [0, 4, 9, 16, 17, 19, 32, 43, 47, 50, 56, 60, 65, 100, 102, 114, 116, 119, 141, 145], "br": 9, "bra": 47, "bracket": [77, 83], "bragg": 7, "brain": [1, 62, 67, 88], "braket": 47, "branch": [8, 43], "brand": 73, "break": [0, 3, 22, 48, 71, 115, 116], "breakdown": 71, "bremen": [80, 81], "breviti": 112, "brewer": [0, 23], "bridg": 1, "brief": [48, 53, 104, 107, 116, 140], "briefli": [16, 23, 48, 64, 97, 115], "bring": [62, 63], "british": 63, "broad": [34, 39, 41, 47, 53, 64, 129, 134], "broaden": [59, 100], "broader": [99, 100], "broadli": [45, 48, 56, 61, 89, 107], "broken": 59, "brook": 1, "brown": [22, 32], "brownian": [77, 83, 143], "browser": 116, "bruno": 46, "brynjarsd\u00f3ttir": 103, "bs06": [1, 44], "bsd": [80, 81], "bubnov": 47, "bufsiz": 108, "bug": [62, 92, 115, 116], "build": [1, 4, 7, 23, 34, 42, 45, 47, 48, 61, 62, 63, 64, 65, 66, 70, 73, 74, 77, 83, 85, 89, 93, 95, 111, 116, 119, 130, 136], "build_model": 111, "built": [17, 19, 23, 33, 47, 48, 51, 66, 71, 112, 115, 116, 117, 135], "builtin": [50, 96], "bukov": 1, "bulk": 46, "bullet": [16, 105, 116], "buqey": [0, 1, 104, 109], "burden": 46, "burn": [6, 38, 50, 89, 96, 105, 127, 128, 129, 133, 134, 136, 141, 144], "burnin": [50, 134], "busi": 63, "bution": 43, "button": [5, 9, 114, 116, 119, 120], "button_styl": 9, "bv": 100, "bvec": 52, "bx": 109, "byte": [69, 115], "b\u00e5\u00e5th": 108, "c": [0, 1, 3, 11, 16, 21, 34, 35, 38, 44, 49, 50, 51, 53, 56, 64, 65, 66, 67, 68, 70, 71, 72, 73, 77, 78, 79, 82, 83, 86, 88, 92, 93, 97, 98, 99, 100, 103, 105, 108, 109, 112, 113, 115, 116, 119, 124, 128, 132, 133, 138, 143], "c0": 105, "c2pread": 108, "c2pwrite": 108, "c41": 115, "c_": [66, 70, 82, 85, 99], "c_0": 79, "c_1": 16, "c_2": 16, "c_i": 46, "c_k": 16, "c_n": 99, "c_w": 72, "cal": [48, 68], "calcul": [0, 7, 9, 13, 16, 19, 22, 31, 33, 34, 37, 39, 42, 43, 44, 46, 47, 50, 52, 65, 67, 68, 71, 72, 86, 91, 95, 96, 98, 104, 105, 107, 108, 112, 114, 115, 116, 118, 125, 127, 128, 129, 130, 132, 133, 134, 136, 138, 140, 141, 144], "calculu": [0, 8, 16, 19, 58, 59, 136, 143], "calibr": [43, 44, 45, 47, 66, 77, 79, 86, 100, 103, 104, 126, 133], "call": [0, 3, 7, 8, 9, 11, 12, 15, 16, 17, 18, 19, 23, 25, 29, 31, 34, 37, 38, 40, 44, 46, 47, 50, 52, 53, 55, 59, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 78, 79, 86, 88, 93, 94, 95, 96, 97, 98, 99, 100, 107, 108, 109, 112, 114, 115, 116, 117, 118, 119, 125, 126, 127, 129, 130, 132, 133, 134, 135, 136, 138, 143, 144, 145], "callabl": [105, 126], "callback": [9, 108], "cambridg": [1, 56], "camco": 1, "camp": 53, "can": [0, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 116, 117, 118, 119, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 143], "canada": 1, "cancel": [4, 44, 51, 52, 53, 66, 126], "candid": [4, 25, 55, 63, 99, 135, 136, 141], "cannot": [7, 19, 21, 25, 34, 43, 46, 47, 53, 63, 65, 73, 93, 98, 112, 116], "canon": [44, 48, 130], "canva": 108, "cap": [22, 66, 112], "capabl": [17, 64, 99], "caprici": 22, "capsiz": 105, "caption": [0, 138], "captur": [43, 44, 46, 47, 63, 66, 67, 71, 103, 125], "car": [16, 64, 73], "card": 32, "care": [5, 8, 16, 17, 23, 31, 32, 35, 37, 43, 47, 51, 58, 72, 73, 90, 109, 112, 115, 117, 118], "carefulli": [43, 46, 56], "carl": [1, 85], "carlin": 1, "carlo": [1, 7, 16, 43, 64, 72, 96, 105, 127, 129, 133, 134, 139, 141, 142, 143, 144, 145], "carlsson": 56, "carmak": 64, "carmen": [124, 130], "carri": [13, 34, 37, 43, 44, 49, 53, 59, 60, 61, 62, 66, 86, 88, 102, 103, 126, 127, 136, 144], "carrol": 58, "cartesian": 132, "cartoon": 51, "case": [0, 7, 8, 9, 10, 16, 18, 21, 22, 23, 25, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 43, 44, 47, 48, 49, 52, 53, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 79, 80, 86, 88, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 105, 109, 112, 115, 116, 118, 119, 124, 126, 128, 129, 130, 133, 134, 135, 136, 138, 141, 145], "casino": 143, "cast": [47, 60, 67], "cat": [76, 102], "categor": [21, 43, 45, 64, 72, 100], "categori": [8, 47, 63, 64, 65, 67, 75, 88, 99, 106], "categoricalgibbsmetropoli": 133, "cauchi": [42, 108, 126], "cauchy_dist": 42, "cauchypropos": 133, "caus": [15, 31, 38, 48, 53, 62, 66, 71, 99, 108, 133, 136], "causal": 62, "caution": [7, 41, 117], "caveat": 119, "cbar": [50, 73, 93, 105], "cbarbieri": 45, "cbo9780511790423": 1, "cbo9780511791277": 1, "cbook": 108, "cc": [34, 43, 67, 78, 98, 115, 138], "ccc": [67, 138], "cccc": 109, "cd": [119, 122], "cdf": 92, "cdot": [13, 16, 19, 23, 31, 32, 33, 34, 42, 44, 45, 47, 48, 49, 52, 65, 67, 71, 88, 94, 103, 105, 109, 118, 124, 125, 128, 138, 141], "ceil": 118, "celebr": 46, "cell": [7, 37, 42, 50, 65, 69, 70, 73, 93, 96, 108, 115, 117, 120, 124, 126, 133, 135], "cent": 8, "center": [8, 11, 19, 33, 34, 35, 37, 42, 50, 53, 72, 73, 74, 88, 107, 108, 109, 112, 125, 126, 132], "central": [24, 26, 42, 43, 64, 94, 103, 110, 111, 132, 136], "centrifug": 132, "centuri": [8, 53, 62, 100], "certain": [7, 11, 15, 34, 43, 45, 46, 48, 58, 63, 72, 73, 75, 88, 95, 99, 103, 115, 118, 126, 135, 138], "certainli": [44, 64, 67, 99, 116, 117, 129, 134, 143], "certainti": [8, 16, 43, 72], "cf": [19, 31, 32, 35, 51, 52, 73, 79, 85, 86, 93, 104, 130, 136, 141], "cft": 33, "cft_n": 33, "cft_n_pt": 33, "ch": [38, 39, 53, 134], "chain": [1, 6, 7, 16, 38, 41, 43, 51, 59, 67, 69, 71, 96, 105, 126, 127, 128, 129, 130, 133, 134, 141, 142, 143, 144, 145], "chain1": [50, 125], "chain1d": [125, 126], "chain2": [50, 125], "chain_data": 105, "chain_length": 133, "chainpandasindexpandasindex": 133, "challeng": [8, 16, 34, 44, 48, 51, 53, 73, 88, 92, 100, 103, 104, 136], "chalmer": [1, 56, 78], "champion": 73, "chanc": [16, 19, 25, 72, 126, 141], "chang": [3, 4, 9, 11, 13, 16, 17, 22, 24, 25, 30, 33, 34, 35, 37, 39, 40, 43, 45, 47, 49, 51, 53, 56, 58, 61, 64, 67, 68, 71, 73, 77, 79, 83, 86, 92, 93, 94, 95, 96, 104, 105, 108, 109, 113, 114, 115, 116, 117, 124, 125, 126, 128, 130, 131, 132, 133, 134, 135, 138, 140, 141], "channel": [65, 73, 75, 76, 88, 119], "chapman": [0, 1, 56], "chapter": [2, 7, 16, 20, 26, 27, 28, 30, 34, 35, 37, 43, 44, 46, 53, 55, 57, 61, 63, 64, 66, 72, 75, 86, 88, 89, 98, 99, 100, 103, 106, 135, 136, 138, 142], "charact": [9, 115], "character": [8, 16, 17, 19, 35, 43, 47, 66, 67, 79, 94, 99, 100, 104, 107, 108, 125, 129, 134, 136], "characteris": 63, "characterist": [63, 71, 86], "charg": [21, 115], "charl": 1, "chart": 95, "chase": 7, "chatterji": 66, "cheat": 118, "cheatsheet": 116, "chebyshev": 46, "check": [0, 3, 4, 13, 20, 22, 34, 35, 37, 38, 42, 44, 49, 51, 59, 66, 69, 73, 77, 83, 85, 86, 92, 93, 94, 96, 105, 108, 109, 116, 118, 119, 125, 127, 128, 130, 133, 135, 138, 141, 144], "checkabl": 49, "checkbox": [5, 9, 114], "checklist": 28, "checklist_b": 0, "checkmark": 24, "checkpoint": 116, "chess": 79, "chi": [7, 18, 19, 26, 38, 45, 49, 51, 52, 95, 96, 97, 107, 109, 130, 135, 136], "chi2": 29, "chi_": 105, "chi_sqs_dof": 95, "chi_squar": 95, "chief": 59, "child": [45, 108], "child_exception_typ": 108, "children": [9, 63, 114], "chines": [1, 115], "ching": 1, "chiral": [1, 47, 108], "chisq_min": 49, "choic": [4, 8, 9, 15, 16, 17, 19, 23, 25, 30, 38, 39, 40, 41, 43, 44, 46, 53, 63, 64, 65, 66, 67, 71, 74, 77, 80, 83, 92, 94, 95, 99, 100, 102, 103, 112, 116, 120, 126, 129, 134, 135, 138, 141, 143, 145], "choleski": [78, 86], "choos": [5, 7, 13, 19, 35, 38, 40, 41, 42, 43, 44, 46, 47, 48, 53, 58, 62, 63, 66, 67, 69, 71, 72, 77, 83, 99, 116, 125, 126, 127, 128, 135, 144], "chose": [47, 96, 138], "chosen": [0, 7, 25, 35, 46, 47, 50, 51, 53, 77, 83, 85, 99, 126, 127, 133, 135, 136, 144], "chri": [85, 110], "christian": [1, 38, 39, 44, 50, 56, 73, 77, 78, 93, 95, 125, 126, 129, 134], "christoph": [1, 110], "chromosom": 112, "ci": [9, 30, 105], "cifar": 76, "circ": [68, 78], "circl": [4, 34, 35, 38, 67, 72, 78, 135], "circular": 135, "circumst": [8, 19, 43, 63], "circumstanti": 62, "circumv": 53, "citat": [0, 63], "cite": [0, 43, 48, 72], "citizen": 64, "clabel": 112, "claim": [21, 42, 44, 51, 63, 64, 79, 86, 100, 102, 109, 133, 136], "clang": [73, 93], "clariti": [78, 102], "class": [9, 28, 34, 46, 47, 53, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 81, 93, 96, 97, 99, 107, 112, 115, 119, 127, 132, 138, 141, 143, 144], "class_i": 65, "class_mean": 65, "class_mean_list": 65, "class_nam": 76, "class_weight": 70, "classic": [8, 25, 39, 42, 51, 115, 129, 130, 134, 135], "classif": [43, 47, 62, 66, 67, 69, 71, 72, 73, 75, 76, 91, 93], "classifi": [63, 64, 66, 67, 72, 74, 76], "classifier_elbo": [72, 73], "classmat": 34, "claus": [80, 81], "clean": [71, 108], "cleaner": 73, "cleans": 92, "cleanup": 108, "clear": [7, 10, 19, 23, 34, 38, 40, 44, 51, 53, 59, 61, 71, 72, 73, 78, 90, 95, 96, 97, 98, 112, 116, 138], "clearer": [31, 43], "clearli": [7, 12, 34, 38, 43, 61, 63, 66, 73, 75, 79, 98, 138, 141], "clever": [34, 138], "clf": [70, 108, 115], "click": [17, 56, 116, 119, 143], "clickabl": 56, "climat": 46, "climb": 126, "clint": 1, "clip": 38, "clockwis": 109, "clone": [119, 121, 122], "close": [0, 12, 16, 29, 31, 33, 34, 37, 38, 40, 43, 44, 49, 53, 56, 64, 67, 68, 72, 73, 77, 80, 83, 86, 89, 95, 96, 97, 99, 103, 107, 109, 115, 125, 126, 133, 135, 136], "close_fd": 108, "closer": [17, 38, 86, 133], "closest": [7, 9, 30, 37, 53, 65, 109], "cloth": 76, "cloud": [0, 22, 56, 113, 119], "clt": [33, 111], "clt_pdf": 33, "cluster": [47, 62, 66, 130], "cluster_std": 74, "clutter": [19, 86], "cm": [34, 37, 49, 50, 65, 69, 70, 76, 108, 112], "cmap": [34, 37, 40, 50, 65, 69, 70, 73, 76, 93, 109, 112], "cnn": [67, 89], "cntl": 136, "co": [33, 34, 46, 51, 71, 77, 82, 83, 92, 100, 116, 131, 132], "code": [7, 13, 17, 30, 33, 34, 35, 38, 40, 42, 43, 47, 50, 51, 56, 64, 70, 73, 76, 77, 83, 87, 92, 93, 94, 95, 96, 98, 99, 105, 115, 120, 124, 126, 127, 128, 133, 135, 140, 143, 144], "codebas": 43, "codec": 108, "codeloc": [105, 138, 143], "coef": 115, "coef_": [70, 115], "coeffici": [4, 7, 24, 47, 49, 65, 66, 67, 73, 86, 88, 94, 105, 112, 115, 118], "coerc": 115, "coher": [8, 110], "coin": [8, 13, 16, 23, 100, 143], "coin_data": 9, "coin_ppd": 0, "coinflipping_fig_1": 25, "col": [25, 30, 115, 116, 117], "colab": 76, "collabor": [16, 56], "collaps": 52, "collat": 77, "colleagu": [56, 63], "collect": [8, 12, 16, 25, 34, 37, 39, 43, 44, 46, 47, 48, 62, 63, 64, 65, 66, 68, 69, 78, 79, 82, 85, 86, 98, 100, 102, 105, 106, 110, 112, 126, 129, 134, 135, 138, 143], "collid": 21, "collis": 143, "colon": [0, 116], "color": [3, 4, 5, 9, 17, 23, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 49, 63, 65, 66, 69, 71, 73, 75, 76, 77, 78, 80, 81, 82, 83, 88, 93, 95, 98, 103, 105, 108, 109, 112, 114, 116, 117, 125, 126, 127, 129, 131, 132, 134, 138, 143, 144], "color_channel": 76, "colorbar": [34, 50, 69, 73, 78, 82, 93, 134], "colour": 4, "columbia": 1, "column": [7, 31, 32, 34, 38, 45, 65, 95, 98, 107, 110, 115, 116, 118, 125, 126, 128, 135, 138, 141], "com": [1, 73, 80, 81, 93, 109, 112, 117, 119, 122, 143], "combin": [0, 8, 16, 19, 31, 33, 34, 37, 39, 43, 44, 46, 47, 48, 50, 53, 55, 59, 62, 66, 67, 71, 73, 78, 79, 82, 85, 86, 88, 93, 99, 102, 103, 105, 107, 109, 124, 128, 129, 134, 135, 138, 140], "come": [0, 4, 8, 9, 10, 11, 16, 17, 19, 21, 29, 30, 34, 35, 38, 40, 43, 49, 51, 53, 62, 63, 66, 67, 72, 73, 79, 86, 92, 93, 98, 108, 115, 119, 125, 126, 128, 129, 134, 136, 140, 141, 145], "comet": 100, "comfort": [19, 46], "comm": 1, "command": [0, 64, 69, 71, 77, 83, 94, 108, 115, 116, 117, 119, 124, 133], "comment": [17, 19, 35, 37, 40, 43, 49, 50, 51, 53, 65, 73, 96, 109, 116, 132, 136, 140], "commiss": 63, "commit": 63, "common": [0, 7, 11, 19, 26, 34, 38, 40, 41, 43, 44, 46, 47, 48, 53, 56, 58, 60, 62, 65, 66, 67, 68, 70, 73, 76, 78, 82, 85, 86, 88, 95, 97, 98, 99, 100, 102, 108, 112, 114, 115, 117, 118, 130, 131, 132, 133, 135, 136, 143], "common_num": 117, "commonli": [4, 40, 66, 88, 99, 102, 133, 135], "commun": [19, 56, 61, 64, 67, 97, 138], "comp": 1, "compact": [23, 65, 67, 68, 105], "compani": 63, "compar": [1, 6, 7, 9, 11, 14, 17, 19, 29, 30, 34, 37, 38, 42, 43, 44, 47, 50, 51, 53, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 77, 78, 82, 83, 86, 92, 93, 94, 95, 103, 107, 109, 111, 112, 115, 126, 132, 133, 138, 140, 141, 143, 145], "comparison": [16, 17, 33, 34, 38, 43, 47, 51, 52, 62, 73, 93, 95, 98, 99, 101, 103, 108, 126, 128, 132, 138], "compat": [43, 88, 92, 109, 128], "compel": 61, "compet": [7, 48, 53, 61, 62, 64], "competit": 47, "compil": [34, 64, 69, 73, 93, 115], "compl": 66, "complaint": 133, "complementari": 53, "complet": [0, 3, 7, 16, 22, 25, 28, 31, 32, 34, 37, 38, 43, 46, 48, 49, 51, 52, 65, 67, 71, 76, 82, 85, 86, 101, 105, 112, 115, 116, 133, 135, 138, 143], "completemodel": 48, "completenn": 67, "complex": [1, 7, 44, 46, 47, 48, 62, 64, 67, 70, 74, 95, 102, 103, 118, 133, 136], "complianc": 76, "complic": [16, 34, 38, 51, 53, 64, 67, 70, 95, 97, 98, 99, 100, 126, 129, 133, 134, 135, 136], "compon": [41, 47, 53, 64, 71, 85, 106, 107, 128, 131, 132, 136], "compos": [47, 67, 96, 138], "compoundstep": 133, "comprehens": [37, 43], "compress": [47, 107, 115, 116, 118], "compromis": [63, 71], "comput": [1, 5, 9, 11, 16, 19, 25, 30, 34, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 53, 56, 58, 59, 60, 62, 64, 65, 66, 67, 68, 70, 72, 73, 75, 76, 78, 79, 80, 82, 85, 86, 88, 89, 92, 95, 96, 97, 98, 99, 103, 104, 105, 106, 109, 112, 113, 115, 116, 118, 119, 122, 125, 126, 127, 128, 129, 133, 134, 135, 138, 141, 144], "computation": [7, 38, 44, 51, 71, 76, 79, 85, 99, 100, 104], "compute_sigma_level": 41, "compute_test_valu": [73, 93], "concat": 115, "concaten": [50, 96, 105, 116, 120, 144], "concentr": [9, 43, 72, 135], "concept": [1, 23, 24, 38, 43, 48, 61, 66, 73, 77, 83, 102], "conceptu": [19, 48, 66, 67], "concern": [7, 8, 34, 45, 46, 53, 64, 65, 73, 88, 99, 110, 112, 115, 138], "concic": 115, "concis": 66, "conclud": [19, 31, 34, 39, 40, 50, 51, 63, 66, 98, 109, 134], "conclus": [12, 17, 34, 35, 37, 40, 51, 58, 61, 62, 67, 95, 96, 100, 112, 132], "concret": [16, 24, 102, 125, 135, 136], "conda": [70, 71, 73, 93, 116, 124], "condemn": 46, "condens": 43, "condit": [4, 8, 16, 19, 20, 21, 22, 23, 24, 25, 29, 30, 31, 32, 34, 37, 43, 44, 47, 53, 58, 61, 76, 77, 83, 85, 86, 103, 105, 107, 109, 111, 130, 131, 132, 135], "condition": 16, "conduct": [8, 21, 43, 48], "conf": 51, "confid": [9, 11, 16, 17, 25, 26, 29, 30, 41, 43, 46, 53, 55, 76, 77, 80, 83, 88, 103, 129, 134], "config": [73, 93, 111, 119], "configur": [43, 51, 76, 111, 119, 138], "confin": 141, "confirm": [46, 63, 67], "confiur": 128, "conflict": [43, 116], "conform": 62, "confront": [25, 30, 46, 62, 64], "confus": [32, 41, 63, 65, 96], "conisd": 100, "conjectur": 61, "conjug": [9, 34, 40, 44, 52, 95, 108, 118], "conjugaci": 52, "conjunct": 47, "connect": [4, 8, 23, 26, 33, 44, 46, 48, 51, 60, 61, 63, 66, 67, 68, 69, 73, 75, 90, 96, 99, 102, 109, 117], "consecut": 118, "consensu": [43, 61], "consequ": [8, 20, 24, 33, 34, 45, 46, 47, 58, 61, 63, 65, 66, 67, 68, 111, 126, 128, 131, 135], "conserv": [7, 44, 79, 103, 130, 133], "consid": [3, 4, 5, 6, 7, 8, 9, 10, 16, 19, 22, 25, 26, 29, 33, 34, 37, 38, 39, 43, 44, 45, 46, 47, 48, 49, 52, 53, 57, 62, 63, 64, 65, 66, 67, 68, 72, 73, 74, 75, 77, 82, 85, 86, 88, 93, 96, 98, 99, 100, 102, 105, 106, 107, 112, 126, 129, 130, 131, 132, 134, 136, 138, 140, 141, 142, 143], "consider": [10, 48, 51, 61, 62, 71, 98], "considerd": 105, "consist": [4, 8, 17, 22, 32, 34, 43, 47, 48, 49, 51, 53, 58, 59, 62, 65, 66, 67, 69, 71, 72, 74, 75, 79, 93, 103, 105, 108, 116, 118, 124, 127, 138, 144], "consolid": 111, "consruct": 73, "constant": [3, 4, 5, 7, 13, 25, 33, 34, 35, 37, 38, 40, 41, 42, 43, 45, 49, 51, 53, 67, 73, 78, 80, 85, 88, 90, 93, 94, 95, 96, 98, 100, 103, 104, 105, 112, 115, 116, 125, 126, 130, 135, 136, 141, 143], "constant_": 71, "constant_valu": 82, "constantkernel": [81, 82], "constantli": 136, "constitu": 115, "constitut": [12, 66, 72, 85], "constrain": [39, 40, 46, 47, 52, 53, 60, 66, 73, 75, 77, 83, 85, 100, 103, 129, 134, 138], "constrain_posit": [77, 83], "constrained_layout": [105, 108], "constraint": [4, 8, 29, 38, 43, 46, 47, 66, 77, 83, 99, 108, 138, 143], "construct": [0, 7, 8, 21, 22, 25, 38, 39, 43, 44, 45, 46, 47, 48, 49, 50, 53, 64, 65, 67, 70, 72, 73, 77, 82, 83, 85, 96, 100, 103, 111, 112, 116, 117, 128, 129, 131, 133, 134, 135, 138], "construct_nn": [73, 93], "constructor": 71, "consum": [60, 63], "contact": 115, "contain": [7, 8, 9, 15, 17, 19, 25, 30, 41, 44, 46, 48, 62, 67, 69, 72, 73, 75, 76, 88, 93, 100, 105, 109, 112, 115, 118, 124, 129, 133, 134, 135, 138], "contemp": 1, "contemporari": 130, "content": [9, 43, 56, 91, 103, 104, 107, 114, 115, 118, 119], "context": [2, 4, 7, 16, 22, 23, 29, 34, 43, 44, 47, 48, 50, 53, 57, 58, 59, 60, 61, 63, 65, 66, 71, 72, 77, 83, 85, 96, 99, 100, 106, 107, 112, 128, 132, 133, 140], "contextlib": 108, "contextmanag": 108, "contigu": 118, "contin": 86, "conting": [4, 10, 21, 22, 23, 58, 106], "continu": [1, 9, 11, 16, 17, 20, 22, 23, 24, 25, 26, 44, 46, 47, 48, 49, 53, 63, 64, 65, 66, 67, 71, 72, 82, 86, 88, 97, 98, 104, 133, 135, 136, 138, 141, 143], "continuo": 65, "continuosli": 64, "continuous_upd": [9, 114], "continuum": [4, 23, 30, 43], "contour": [35, 37, 40, 41, 44, 50, 53, 65, 70, 73, 78, 82, 93, 112, 133, 134], "contour_func": [50, 134], "contour_level": [37, 40, 41], "contourf": [34, 37, 40, 50, 65, 70, 73, 93], "contract": 109, "contradict": [22, 61], "contrari": [39, 59, 129, 134], "contrast": [8, 26, 29, 35, 49, 62, 67, 72, 103, 143], "contribut": [38, 51, 52, 53, 56, 61, 64, 85, 115, 135], "contributor": 64, "control": [1, 9, 11, 47, 64, 70, 71, 74, 76, 80, 94, 103, 115, 124], "controversi": [39, 129, 134], "conv": 75, "conv2d": [71, 76], "conv2d_1": 76, "conv2d_2": 76, "convei": 47, "conveni": [34, 35, 37, 38, 39, 40, 41, 47, 49, 67, 68, 73, 102, 114, 116, 125, 129, 134], "convent": [0, 34, 47, 53, 67, 98, 101, 109, 114, 116, 136], "convention": [23, 116], "converg": [5, 12, 25, 41, 43, 46, 49, 68, 71, 73, 81, 92, 93, 99, 133, 134, 135, 141, 142, 145], "convergencewarn": [50, 81], "convers": [19, 110, 112, 138], "convert": [19, 42, 48, 69, 115, 116, 118, 133], "convex": [88, 97, 99], "convexhul": 131, "convinc": [4, 16], "convolut": [7, 71, 73, 89], "cookbook": 86, "coolwarm": [65, 112], "coordin": [8, 40, 47, 53, 65, 96, 109, 125, 130, 132, 133], "copi": [9, 44, 76, 78, 93, 96, 115, 117, 124, 125, 126, 133, 136, 141], "copyright": 76, "core": [8, 105, 115, 133], "cornebis": 1, "corner": [7, 8, 17, 25, 35, 38, 41, 50, 51, 72, 74, 82, 94, 96, 105, 112, 119, 124, 125, 128, 129, 134, 138, 143], "cornerplot": [50, 134], "corollari": 15, "corrcoef": 118, "correct": [7, 12, 16, 22, 23, 43, 48, 51, 52, 53, 65, 66, 69, 76, 85, 86, 99, 100, 102, 115, 116, 124, 130, 135, 136, 141], "correctli": [16, 18, 34, 69, 98, 117, 118, 129, 132, 134, 141], "correl": [0, 4, 24, 43, 44, 46, 47, 50, 64, 67, 73, 78, 82, 85, 86, 93, 94, 100, 102, 103, 109, 118, 126, 135, 136, 141, 143, 145], "corrent": 99, "correspond": [4, 7, 24, 25, 34, 37, 38, 41, 43, 44, 46, 47, 48, 50, 53, 60, 61, 65, 66, 67, 68, 70, 72, 74, 75, 76, 77, 78, 81, 82, 83, 86, 88, 96, 97, 98, 99, 100, 102, 103, 109, 112, 115, 116, 118, 126, 128, 131, 135, 138, 143], "correspondingli": 67, "cortex": 67, "cosh": 71, "cosin": [33, 34, 116], "cosineft": 33, "cosineft2": 33, "cosmo": 51, "cosmolog": 51, "cosmologi": [1, 21, 40, 95], "cosmologist": 141, "cost": [34, 44, 45, 46, 51, 53, 63, 64, 66, 67, 69, 70, 72, 85, 97, 99, 100, 105, 136], "cost_funct": 99, "costli": [44, 73, 99], "couch": [58, 62], "could": [3, 5, 8, 9, 11, 19, 21, 22, 25, 34, 43, 44, 46, 47, 48, 51, 52, 53, 58, 61, 65, 66, 67, 70, 72, 73, 75, 77, 83, 88, 96, 97, 98, 99, 100, 103, 106, 108, 112, 114, 115, 117, 126, 128, 133, 135, 136, 138, 140], "coulomb": [34, 98, 115], "count": [4, 8, 9, 17, 33, 35, 37, 39, 42, 60, 67, 102, 105, 108, 115, 125, 134], "countabl": [86, 99, 112, 138], "counter": [16, 39, 42, 63, 109, 129, 134], "counterexampl": 138, "counterpart": [31, 88], "coupl": [23, 26, 40, 47, 52, 53, 102, 104, 116], "courag": 61, "cours": [1, 4, 19, 25, 30, 31, 34, 38, 39, 40, 50, 56, 63, 72, 77, 79, 88, 91, 94, 95, 97, 98, 116, 120, 125, 126, 129, 134], "cov": [24, 34, 46, 50, 65, 78, 82, 95, 109, 112, 125, 128, 143], "cov_exp": 105, "cov_mat": 49, "cov_matrix": 105, "cov_new": 82, "cov_opt": 82, "cov_rbf": [78, 82], "cov_tot": 105, "covari": [4, 7, 24, 34, 41, 46, 47, 49, 53, 72, 79, 80, 86, 92, 95, 103, 105, 107, 128, 130, 135, 143], "covariancematrix": 82, "cover": [19, 44, 63, 72, 101, 103, 105, 116, 136], "coverag": [89, 135], "covparslr": 34, "covr": 34, "cow": 21, "cox": [1, 22, 31, 32], "cox61": [1, 22], "cprob": [16, 21, 22, 46, 112, 138], "cpu": [38, 41, 50, 73, 93, 105, 118, 125, 145], "cpu_affin": 105, "cpu_count": 105, "cr": [38, 41], "crank": 133, "crash": [64, 120], "crc": [0, 1, 56], "creat": [6, 7, 34, 35, 37, 38, 40, 41, 47, 64, 65, 66, 67, 71, 73, 74, 75, 77, 80, 81, 82, 83, 88, 92, 93, 94, 95, 98, 100, 105, 108, 109, 111, 112, 116, 122, 125, 126, 130, 131, 133, 135, 136, 138, 143], "create_multiple_process": [138, 143], "created_at": 133, "creation": [73, 117, 118], "creationflag": 108, "creativ": 56, "cred68": [9, 17, 30, 108], "cred95": [9, 17, 30, 108], "credibl": [9, 17, 18, 26, 30, 41, 43, 44, 62, 82, 86, 94, 108], "credible_range_dist": 82, "credibleregions_fig": 112, "credit": 125, "creep": 63, "cri": 62, "cricl": 70, "crime": 63, "crimin": 63, "crit": 19, "criterion": [53, 71, 130, 135, 136], "critic": [8, 38, 43, 53, 61, 63, 64, 66, 67, 71, 73, 102, 110, 112, 118, 130], "cross": [4, 47, 51, 64, 65, 67, 70, 72, 110], "crossval_err": 95, "croupier": 143, "crowd": 66, "crucial": [16, 22, 43, 48, 53, 63, 71], "crudest": 132, "cs231": 75, "cset": [50, 134], "csr": 118, "csr_matrix": 118, "cstride": [37, 65], "csv": 77, "cubehelix_palett": [73, 93], "cubehelix_r": 50, "cubic": 53, "cubism": 110, "cuda": 71, "cultur": [63, 143], "cumsum": [37, 40, 41, 109, 115, 118], "cumul": [44, 109, 118], "cup": [22, 112], "cup_": 112, "current": [9, 21, 25, 34, 44, 46, 49, 50, 51, 53, 67, 69, 71, 76, 77, 83, 95, 99, 116, 119, 125, 126, 130, 133, 135, 136, 138], "current_posit": [126, 141], "curs": 135, "cursor": 116, "curv": [17, 19, 38, 47, 71, 78, 82, 103, 108, 109, 111, 112, 126, 143], "curvatur": [34, 41], "cusp": 73, "custom": [73, 105, 135], "cut": [7, 17, 49, 52, 53, 95, 115, 117], "cutoff": [37, 38, 40, 41, 46], "cv": [64, 66, 70, 95], "cwd": 108, "cxxflag": [73, 93], "cyb89": [1, 67], "cybenko": 1, "cycl": [43, 67], "cycle_b": 0, "cycler": 49, "d": [0, 1, 3, 7, 8, 9, 10, 11, 15, 16, 17, 19, 23, 25, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 44, 48, 49, 51, 52, 53, 56, 66, 67, 71, 72, 77, 78, 79, 82, 83, 85, 86, 88, 92, 93, 95, 96, 98, 100, 102, 103, 105, 107, 108, 112, 115, 125, 126, 127, 128, 129, 130, 132, 134, 135, 136, 140, 144], "d0": [0, 7, 41], "d1": 37, "d1_": 49, "d1_c_5": 94, "d2": 37, "d_": [25, 30, 35, 72], "d_1": [15, 34], "d_2": [15, 34], "d_3": 15, "d_i": [38, 39, 51, 129, 134], "d_k": [4, 15, 35, 37, 96], "d_list": 33, "d_max": 37, "da": [7, 35, 52], "daan": 1, "dagger": [45, 48], "dai": [1, 16, 53, 138], "daili": 63, "damian": [78, 82], "damp": 131, "dan": [102, 129, 134], "danc": 125, "danger": [43, 45, 63], "daniel": [1, 5, 56, 115, 133, 141], "dare": 46, "dark": [17, 38, 56, 112], "darkgreen": [9, 23, 30], "darkgrid": [78, 92], "dash": [7, 9, 37, 38, 44, 94, 112, 129, 132, 134], "dat": [94, 115], "dat_id": 115, "data": [0, 1, 3, 4, 7, 8, 9, 10, 11, 12, 15, 17, 19, 20, 21, 23, 24, 25, 29, 30, 35, 39, 42, 43, 44, 46, 47, 48, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 66, 67, 68, 70, 71, 72, 78, 79, 80, 81, 82, 85, 86, 88, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 102, 103, 105, 107, 108, 111, 112, 113, 116, 120, 126, 127, 128, 129, 133, 135, 136, 140, 141, 144], "data1": 17, "data2": 17, "data_": [7, 34, 64, 66], "data_batch": 99, "data_fram": [34, 98], "data_generating_process": 66, "data_generating_process_measur": [34, 98], "data_generating_process_r": [34, 98], "data_i": [34, 66, 99], "data_id": 115, "data_in": 133, "data_inst": 99, "data_panda": 115, "data_path": 115, "dataarrai": 133, "databin": 37, "datacamp": 120, "datafil": 115, "datafram": [34, 98, 115, 125], "dataframegroupbi": 115, "datapoint": [34, 80, 88, 98], "dataset": [37, 38, 39, 40, 52, 63, 66, 67, 69, 70, 71, 72, 73, 74, 77, 88, 93, 100, 102, 105, 124, 129, 133, 134], "dataset_mirror": 77, "datasetdimens": 133, "datat": 65, "date": [8, 45, 51, 63, 64, 108, 115, 119, 135, 136], "date_format": 108, "datetim": 108, "datum": [34, 38, 66, 72, 98], "daughter": 45, "dave": 103, "david": [1, 46, 56, 63, 72, 108, 110, 141], "db": 35, "dbeta": 96, "dc": 77, "ddot": [34, 52, 98, 132], "de": [1, 34, 43, 45, 46, 80, 81], "deactiv": 119, "deal": [7, 8, 17, 25, 34, 41, 48, 51, 52, 53, 55, 59, 62, 64, 65, 67, 75, 100, 102, 107, 112, 115, 138], "dealt": 4, "dean": 1, "death": [129, 134], "debat": [129, 134], "debug": [71, 108, 120], "dec": 133, "decad": 64, "decai": [37, 47, 71, 72, 74, 88, 99, 115, 135, 138], "decemb": 1, "decid": [4, 15, 19, 23, 25, 34, 38, 48, 49, 64, 65, 71, 75, 92, 98, 114, 126, 128, 130, 135, 136, 141], "decim": [32, 105, 109, 115, 116, 136], "decis": [8, 16, 51, 61, 63, 70, 72, 73, 74, 88, 100, 135, 136, 138], "deck": 32, "declar": [9, 53, 62, 114, 116, 118], "decompos": [47, 48, 53, 109], "decomposit": [47, 67, 78, 86, 106, 109], "decreas": [25, 33, 46, 49, 52, 64, 66, 71, 95, 99, 103, 126, 133, 135, 136, 141], "decri": 135, "deduc": [16, 37, 62, 64], "deduct": 62, "deem": 46, "deep": [1, 68, 69, 71, 75, 93, 102, 143], "deeper": [43, 45, 62, 63, 64, 73, 76], "deeplearn": [73, 93], "deepli": 62, "deer": 76, "def": [0, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 40, 41, 42, 49, 50, 65, 69, 70, 71, 73, 76, 77, 78, 81, 82, 88, 92, 93, 95, 96, 98, 105, 108, 109, 111, 112, 114, 115, 116, 117, 120, 125, 126, 127, 129, 131, 132, 133, 134, 138, 143, 144], "defalt": 9, "default": [9, 23, 30, 33, 34, 49, 50, 66, 69, 77, 79, 82, 83, 92, 95, 96, 98, 99, 105, 108, 111, 115, 116, 118, 119, 120, 128, 131, 132, 133], "default_rng": [30, 34, 98, 112], "defect": [23, 53, 59], "defend": 63, "defer": 7, "defici": 41, "defin": [0, 6, 7, 8, 11, 13, 16, 17, 18, 19, 23, 34, 35, 37, 38, 40, 41, 43, 44, 46, 47, 49, 50, 51, 53, 56, 59, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 80, 81, 82, 83, 85, 86, 88, 89, 92, 93, 94, 95, 96, 98, 99, 100, 102, 103, 107, 108, 112, 115, 116, 119, 120, 125, 126, 127, 129, 132, 133, 134, 138, 141, 143, 144], "definit": [0, 8, 9, 11, 16, 17, 19, 21, 23, 24, 25, 30, 40, 41, 42, 44, 46, 49, 61, 62, 65, 66, 70, 71, 77, 78, 82, 83, 85, 86, 88, 95, 96, 100, 103, 109, 116, 120, 126, 138, 141], "deform": 79, "deg": [21, 95], "degener": 50, "degeneraci": 47, "degre": [4, 8, 15, 17, 19, 22, 25, 29, 34, 38, 39, 43, 44, 46, 53, 55, 66, 86, 95, 96, 98, 102, 108, 109, 112, 129, 134], "degree_max": 95, "degreef": 112, "del": 108, "del_x": 37, "delet": [34, 95, 98, 116, 118], "deliber": 126, "delimit": [0, 116], "deliv": 97, "delta": [4, 15, 16, 17, 19, 23, 29, 34, 35, 37, 38, 40, 41, 45, 46, 49, 51, 52, 53, 68, 85, 88, 99, 103, 105, 112, 115, 125, 128, 130, 132, 135, 138, 140, 143], "delta_": [29, 65, 66, 85, 107, 109], "delta_bin": 108, "delta_h": 115, "delta_i": 38, "delta_j": 68, "delta_k": 68, "delta_n": 115, "delta_t": [131, 132], "delta_x": 37, "deltah": [0, 7], "delv": 143, "demand": [56, 85, 100], "demetropoli": 133, "demetropolisz": 133, "demo": [7, 70, 86, 93, 130, 135, 136], "democraci": 63, "demograph": 63, "demonst": 109, "demonstr": [7, 11, 19, 26, 34, 39, 44, 47, 59, 62, 66, 71, 72, 86, 87, 89, 97, 98, 118, 129, 134, 135, 142], "den": 126, "denisti": 138, "denomin": [7, 10, 13, 16, 25, 34, 42, 46, 49, 52, 53, 99, 124, 125, 135], "denot": [4, 16, 19, 23, 25, 29, 34, 42, 44, 45, 46, 63, 66, 67, 68, 72, 78, 82, 85, 86, 88, 95, 96, 97, 98, 99, 100, 103, 105, 112, 125, 128, 133, 135, 136, 138], "dens": [34, 69, 86, 98], "dense_1": [69, 76], "denser": [34, 98], "densest": 82, "densiti": [8, 9, 11, 19, 20, 22, 25, 27, 29, 30, 33, 34, 35, 37, 42, 43, 44, 46, 48, 51, 53, 79, 82, 85, 105, 108, 111, 126, 130, 133, 135, 136, 138, 143], "depaoli": 1, "departur": 51, "depend": [4, 12, 13, 16, 18, 19, 25, 34, 35, 37, 38, 40, 43, 45, 46, 47, 48, 51, 52, 61, 63, 64, 65, 66, 67, 68, 71, 72, 76, 79, 85, 86, 88, 94, 96, 97, 98, 99, 102, 103, 111, 116, 117, 119, 122, 128, 129, 132, 133, 134, 135, 136, 138, 143], "depict": 138, "deploi": 63, "deploy": 63, "deprec": [37, 50, 70, 96, 115], "deprecationwarn": 37, "depth": [46, 53, 67, 71, 75, 102, 111, 116, 142], "deriv": [0, 7, 8, 16, 19, 25, 31, 33, 34, 37, 38, 39, 42, 43, 44, 45, 46, 47, 52, 53, 66, 71, 72, 88, 90, 96, 97, 98, 99, 100, 102, 103, 105, 129, 130, 133, 134, 140], "derivati": 130, "desai": 51, "descend": [100, 109, 118], "descent": [65, 66, 67, 68, 70, 71, 73, 75, 88, 100, 101, 136], "describ": [4, 7, 16, 19, 34, 37, 38, 39, 41, 43, 44, 46, 47, 48, 49, 55, 56, 63, 64, 65, 66, 67, 71, 72, 73, 85, 88, 93, 95, 97, 98, 99, 100, 101, 102, 103, 112, 115, 119, 124, 125, 126, 129, 130, 132, 134, 135, 138, 142, 143], "descript": [9, 23, 34, 42, 43, 65, 98, 100, 114, 116, 118, 133, 138], "deserv": [66, 97], "desiderata": 62, "design": [0, 8, 16, 23, 35, 37, 43, 44, 46, 47, 51, 53, 56, 60, 65, 67, 71, 72, 77, 83, 85, 88, 104, 112, 115, 132, 135, 143], "desir": [7, 19, 25, 38, 41, 43, 47, 51, 53, 64, 66, 71, 86, 98, 102, 112, 125, 130, 138], "despin": [73, 93], "despis": 63, "despit": [7, 39, 43, 47, 63, 65, 66, 67, 100, 129, 134, 135], "desrib": 19, "destroi": [129, 134], "det": [49, 50, 52, 53, 78, 86, 95, 96, 105, 118, 138], "deta": 66, "detail": [9, 11, 16, 19, 20, 22, 23, 24, 27, 28, 34, 35, 38, 40, 43, 44, 45, 47, 50, 51, 52, 59, 60, 69, 72, 77, 86, 95, 96, 100, 101, 107, 108, 116, 119, 121, 124, 128, 129, 130, 133, 134, 135, 140, 142], "detect": [7, 38, 42, 43, 62, 66, 67, 124], "detector": 51, "determin": [3, 4, 7, 9, 11, 19, 23, 34, 35, 37, 41, 49, 52, 53, 62, 63, 65, 66, 67, 68, 78, 82, 85, 86, 90, 96, 98, 100, 102, 103, 112, 115, 126, 129, 132, 134, 135, 136, 138, 143], "determinist": [48, 66, 72, 88, 100, 102, 105, 112, 127, 130, 143, 144], "determmin": 65, "detour": 44, "dev": [17, 81, 108], "devalu": 63, "devdoc": [50, 96], "develop": [8, 16, 33, 46, 47, 56, 61, 63, 64, 65, 67, 73, 103, 116], "devianc": 51, "deviat": [3, 4, 7, 12, 17, 19, 24, 29, 33, 34, 35, 37, 38, 39, 40, 41, 43, 46, 50, 53, 65, 71, 72, 73, 74, 78, 80, 81, 93, 94, 95, 103, 105, 108, 111, 112, 115, 117, 125, 126, 127, 128, 129, 133, 134, 140, 141, 144], "devic": [25, 51, 73], "devinderjit": 7, "devis": [44, 67], "df": [7, 108, 112, 115], "df1": 115, "df_chain": 125, "dfm": 141, "dft": 79, "dgrid": [0, 7], "dh": [7, 103, 105], "dh_0": 41, "dhdt": 105, "dhs11": [1, 99], "di": [0, 7], "diag": [34, 47, 49, 50, 82, 105, 109], "diagnos": [43, 63], "diagnost": [43, 73, 93, 94, 123, 128, 134, 135, 141, 142], "diagon": [34, 41, 45, 47, 50, 53, 66, 72, 78, 82, 85, 86, 94, 99, 109, 112, 118, 128, 129, 130, 134, 138, 143], "dialect": 64, "dic": 51, "dice": [3, 72], "dick": [0, 5, 38, 50, 56, 77, 78, 114, 119, 125, 131, 133], "dick_in_tailcoat": 109, "dict": [9, 17, 37, 95, 108, 114, 126], "dict_kei": 69, "dictat": [8, 34, 37, 67, 78, 135], "dictionari": 115, "did": [7, 25, 34, 40, 50, 63, 73, 96, 112, 126, 127, 129, 132, 134, 144], "didn": [31, 49, 50, 108, 135, 136], "die": [4, 8, 23], "diederik": 1, "diff": [96, 108], "diffeq": 132, "differ": [3, 4, 6, 7, 8, 9, 11, 12, 15, 16, 17, 18, 19, 22, 23, 25, 26, 27, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 55, 56, 59, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 87, 88, 90, 92, 93, 94, 95, 97, 98, 99, 100, 102, 105, 108, 111, 112, 115, 116, 117, 118, 119, 124, 125, 126, 127, 128, 129, 130, 133, 134, 135, 136, 138, 141, 143, 144], "different": [72, 73], "different_num": 117, "differenti": [1, 7, 35, 51, 64, 67, 71, 72, 73, 75, 78, 82, 85, 93, 97, 99, 112, 130, 131, 132, 140, 143, 145], "differentialmov": 50, "difficult": [25, 43, 44, 47, 52, 63, 67, 95, 97, 99, 103, 128, 130, 136, 138, 141], "difficulti": [53, 99], "diffus": [43, 130, 136], "digit": [63, 107, 115, 144], "dillon": 1, "dim": [41, 50, 67, 92, 96], "dimenion": 18, "dimens": [8, 23, 34, 44, 45, 47, 50, 60, 67, 75, 76, 77, 78, 79, 82, 83, 85, 86, 96, 97, 98, 99, 100, 105, 108, 109, 115, 118, 125, 126, 128, 129, 130, 133, 134, 135], "dimensin": 118, "dimension": [16, 17, 19, 23, 26, 33, 34, 40, 43, 44, 45, 46, 47, 49, 51, 53, 67, 69, 72, 73, 77, 80, 83, 85, 86, 92, 93, 100, 106, 107, 109, 111, 112, 115, 126, 128, 129, 130, 134, 135, 136, 138, 143, 145], "dimensionalisti": 51, "dimensionless": [23, 44, 100, 112], "diminish": 103, "dip": 43, "dir": 133, "dirac": [23, 105], "direc": 105, "direct": [4, 8, 13, 19, 34, 48, 53, 66, 67, 69, 88, 97, 99, 105, 109, 116, 126, 128, 129, 130, 132, 134, 135, 136, 141], "directli": [19, 23, 32, 33, 42, 44, 46, 47, 72, 73, 85, 93, 94, 103, 106, 109, 112, 143], "directori": [0, 105, 108, 112, 119, 122], "disabl": [9, 63, 108, 114], "disadvantag": [38, 63], "disappear": [53, 135, 138], "discard": [6, 44, 48, 50, 125, 129, 133, 134], "disciplin": [64, 67], "disclaim": 64, "discov": [16, 19, 110], "discoveri": [61, 62, 67], "discrep": [16, 29, 34, 48, 55, 59, 140], "discret": [4, 9, 11, 16, 17, 22, 23, 24, 25, 37, 44, 64, 65, 67, 72, 88, 100, 103, 105, 127, 128, 143, 144], "discrimin": [53, 63, 88], "discuss": [7, 16, 19, 21, 23, 25, 29, 33, 37, 39, 40, 41, 44, 46, 48, 56, 58, 59, 60, 63, 64, 66, 68, 72, 73, 88, 94, 95, 96, 98, 99, 100, 102, 103, 109, 125, 133, 136, 138, 141], "diseas": [22, 31, 63, 88], "dishonest": 61, "disjoint": 112, "disk": [51, 116], "dismiss": 138, "disord": 88, "disp": 38, "dispers": 44, "displai": [3, 5, 7, 9, 48, 65, 66, 67, 69, 76, 78, 88, 108, 112, 115, 116, 126, 133, 134, 135, 138, 143], "display_nam": 0, "displaystyl": [34, 98, 141], "dispos": 128, "disproportion": 38, "disregard": 63, "disrupt": 64, "dist": [9, 17, 30, 42, 82, 108], "dist_hist_plot": 42, "dist_label": [17, 108], "dist_mod": [9, 17, 30, 108], "dist_plot": [17, 108], "dist_pt": 42, "dist_pts_alt": 42, "dist_stuff": [9, 17, 30, 108], "distanc": [34, 41, 47, 51, 65, 70, 78, 82, 100, 105, 130, 143], "distant": 53, "distinct": [4, 7, 43, 46, 48, 58, 75, 89, 99, 103, 117], "distinguish": [22, 48, 51, 57, 58, 97, 135], "distract": 43, "distrbut": 143, "distri": 43, "distribut": [1, 5, 6, 7, 8, 9, 11, 13, 18, 19, 20, 23, 24, 25, 26, 27, 29, 30, 35, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 51, 53, 60, 63, 67, 72, 73, 74, 76, 77, 81, 83, 88, 89, 92, 93, 94, 95, 96, 98, 100, 102, 103, 105, 106, 119, 124, 125, 126, 129, 130, 133, 134, 136, 140, 142, 143, 145], "distrubt": 138, "div": 0, "dive": [38, 115], "diverg": [19, 68], "diverging_palett": [73, 93], "divers": [23, 63], "divid": [4, 27, 29, 33, 38, 43, 53, 66, 67, 69, 76, 92, 93, 95, 99, 118, 125, 126, 128, 141], "divis": [66, 71, 76, 99, 118], "divorc": 23, "dj\u00e4rv": 56, "dk": [37, 96], "dk_pt": 37, "dkpr87": [1, 44], "dl": [19, 35], "dlnz": 96, "dmat": [34, 98], "dmf": [1, 45], "dna": 88, "dnn": 67, "do": [0, 1, 3, 4, 5, 7, 8, 9, 11, 13, 15, 16, 17, 18, 23, 24, 25, 29, 30, 31, 32, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 59, 61, 62, 64, 65, 66, 67, 68, 71, 73, 74, 75, 76, 77, 79, 83, 85, 89, 90, 94, 96, 97, 98, 99, 102, 107, 111, 112, 114, 115, 116, 117, 118, 119, 124, 126, 129, 130, 132, 133, 134, 135, 136, 138, 144, 145], "dob": [9, 17, 19, 25, 30, 41], "dobrow": 143, "doc": [17, 73, 93, 112, 133], "docstr": [79, 116, 118, 133], "doctor": 63, "document": [9, 11, 13, 37, 39, 42, 43, 70, 71, 77, 83, 87, 94, 109, 116, 117, 118, 119, 127, 128, 129, 130, 133, 134, 140, 144, 145], "documentari": 62, "doe": [1, 5, 7, 8, 9, 12, 16, 18, 19, 22, 25, 29, 30, 31, 32, 34, 37, 38, 39, 40, 42, 44, 47, 48, 49, 50, 51, 53, 62, 63, 64, 65, 66, 67, 70, 71, 75, 77, 83, 85, 86, 90, 93, 94, 95, 96, 99, 103, 106, 111, 112, 115, 116, 117, 118, 124, 125, 126, 128, 129, 130, 132, 133, 134, 136, 138, 141, 143], "doesn": [5, 13, 22, 29, 31, 33, 38, 39, 51, 63, 68, 75, 129, 130, 131, 134, 136, 141], "dof": [95, 102], "dog": [76, 116], "doi": [1, 43], "dollar": 8, "domain": [0, 8, 17, 23, 43, 46, 47, 48, 53, 60, 64, 66, 82, 100, 103, 105, 112, 128], "domin": [12, 19, 29, 48, 52, 53, 65, 73, 85, 100, 107], "don": [9, 11, 15, 17, 23, 25, 29, 30, 31, 33, 34, 35, 40, 42, 49, 58, 61, 63, 64, 65, 66, 72, 77, 78, 82, 83, 85, 94, 95, 96, 102, 115, 116, 127, 128, 133, 135, 136, 141, 144], "donald": [1, 135], "done": [0, 34, 35, 38, 41, 43, 48, 49, 50, 53, 58, 62, 66, 71, 72, 73, 97, 107, 108, 109, 117, 119, 125, 130, 136], "donut": [130, 135], "door": 16, "dordrecht": 1, "dot": [4, 34, 44, 48, 65, 66, 67, 68, 70, 73, 75, 78, 80, 82, 88, 93, 98, 105, 109, 124, 125, 126, 131, 132], "dot_product_term": 105, "dotproduct": [81, 105], "doubl": [25, 43, 47, 63, 72, 107, 116, 117, 119, 143], "doubt": [19, 56], "dougla": 56, "down": [0, 7, 8, 17, 22, 52, 59, 67, 68, 71, 73, 78, 82, 93, 100, 102, 112, 116, 118, 138], "downhil": [97, 99], "download": [56, 70, 77, 115, 116, 119, 121, 122], "downsampl": 75, "downward": 105, "dozen": 109, "dp": [3, 19, 131], "dp_h": [11, 13, 25, 30], "dp_i": 130, "dp_phi": 131, "dphi": [131, 132], "dpi": [105, 108, 131, 132], "dq": 131, "dq_i": 130, "dr": [95, 105, 132], "draft": [1, 77, 83], "drag": [100, 103, 105], "drastic": [102, 126], "draw": [16, 17, 19, 23, 29, 32, 35, 38, 42, 44, 47, 51, 58, 66, 67, 72, 73, 74, 77, 79, 81, 83, 89, 96, 100, 103, 108, 112, 126, 128, 129, 133, 134, 135, 136, 138, 141], "draw_ev": 108, "drawback": [43, 66, 73, 95, 116], "drawn": [19, 29, 37, 41, 44, 71, 72, 81, 88, 95, 102, 105, 129, 130, 134, 141, 145], "drawpandasindexpandasindex": 133, "drawstyl": 37, "dream": 64, "dress": [65, 116, 120], "drink": 7, "drischler": 1, "drive": [50, 51, 58, 64, 96, 131, 138], "driven": [45, 47], "driver": 64, "drop": [16, 51, 73, 112, 115, 133, 141, 145], "drop_const": [34, 98], "dropbox": 50, "dropdown": [0, 5, 9, 114], "dropna": 115, "dropout": [67, 69], "drug": 63, "dry": [16, 64], "dsdt": 7, "dstack": [34, 65, 78, 82], "dt": [7, 13, 38, 103, 105, 130, 131, 132, 143], "dtp2023": 45, "dtype": [6, 33, 37, 50, 69, 71, 73, 76, 93, 95, 96, 111, 115, 118, 127, 133, 144], "du": [53, 132], "du_": 132, "du_1": 112, "du_cf": 132, "du_eff": 132, "du_i": 53, "du_n": 112, "dual": 70, "dualiti": 44, "duan": [1, 44], "dubourg": 80, "duchi": 1, "duchi11a": 1, "duco": 1, "due": [4, 7, 34, 38, 40, 46, 51, 53, 67, 71, 72, 73, 96, 97, 98, 99, 103, 105, 115, 125, 135, 138, 143], "dumb": 126, "dummi": [70, 117, 126], "dummy_out": [73, 93], "dumpti": 58, "dunson": 1, "duplic": 109, "durat": 100, "dure": [8, 44, 46, 67, 69, 71, 72, 73, 77, 83, 99, 100, 105, 118, 129, 133, 134, 143], "durham": 56, "durrand": [77, 83], "dustin": [1, 73], "duvenaud": 86, "dvdt": 105, "dwell": 8, "dx": [3, 4, 7, 17, 19, 23, 24, 25, 35, 52, 82, 112, 128, 135], "dx1": 50, "dx2": 50, "dx_1": [19, 33, 112], "dx_2": [0, 17, 23, 33, 112], "dx_j": 19, "dx_k": 42, "dx_n": [19, 33], "dxdy": 7, "dxp": 50, "dy": [7, 35, 38, 40, 41, 67, 95, 112, 125, 128, 135, 143], "dy2": 40, "dy_data": 49, "dy_dt": [131, 132], "dy_pt": 49, "dynam": [44, 47, 67, 71, 73, 93, 105, 130, 143], "dz": [7, 112], "e": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 82, 83, 85, 86, 88, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 109, 112, 113, 115, 116, 118, 119, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 142, 144, 145], "e1": 109, "e2": 109, "e_": [34, 45, 66, 109, 115, 141], "e_1": 109, "e_2": 109, "e_i": [34, 38, 98], "e_tot_0": 132, "e_tot_0_eul": 132, "e_tot_0_lf": 132, "e_tot_pt": 132, "e_tot_pts_eul": 132, "e_tot_pts_lf": 132, "e_tot_rel_pt": 132, "e_tot_rel_pts_eul": 132, "e_tot_rel_pts_lf": 132, "e_w": [72, 88], "each": [4, 6, 7, 8, 9, 11, 15, 17, 24, 25, 29, 30, 31, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 56, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 76, 78, 79, 81, 82, 83, 86, 88, 90, 93, 96, 98, 99, 100, 102, 103, 105, 107, 108, 109, 111, 112, 115, 116, 117, 118, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 138, 141, 143, 144], "eapprox": 115, "earli": [8, 12, 46, 48, 73, 99, 103], "earlier": [34, 49, 53, 68, 71, 88, 103, 109, 119, 138], "earliest": 100, "earn": 135, "earth": 100, "easi": [0, 11, 13, 19, 21, 33, 42, 43, 44, 51, 66, 68, 73, 77, 83, 88, 112, 115, 116, 117, 125, 135, 138, 141], "easier": [6, 7, 40, 42, 51, 53, 64, 66, 67, 94, 103, 115, 133], "easiest": [46, 52], "easili": [0, 4, 34, 37, 43, 47, 53, 64, 68, 73, 77, 83, 88, 95, 98, 115, 116, 117, 118, 130, 135], "eat": [21, 62], "ebegin": 66, "ebind": 115, "ec": [47, 95, 108], "eccentr": [35, 53, 78, 132], "ecolor": 96, "econometr": 115, "economist": 62, "ed": 89, "edg": [47, 95, 99, 108, 141], "edgecolor": [37, 38, 65], "edit": [0, 1, 56, 86, 111, 116, 119], "edu": [0, 1, 51, 78, 80, 114, 119, 131, 133], "educ": [63, 64], "edward": [1, 64, 72, 73, 85], "eff": [44, 132], "effect": [1, 7, 16, 19, 25, 34, 38, 40, 43, 44, 46, 47, 48, 49, 50, 51, 53, 57, 62, 63, 66, 71, 72, 77, 80, 83, 94, 96, 100, 102, 105, 108, 109, 115, 128, 132, 133, 136, 145], "effectivepotenti": 5, "effici": [1, 33, 38, 44, 46, 47, 51, 67, 71, 73, 75, 93, 94, 99, 109, 115, 118, 130, 133, 135, 136, 142, 145], "effort": [48, 56, 60, 63, 129, 134, 145], "eft": [45, 47, 52, 91], "ei": [32, 92], "eig": [77, 83, 109, 118], "eigen": 47, "eigen_galerkin": 47, "eigenenergi": 45, "eigensolut": 120, "eigenst": 45, "eigenvalu": [45, 47, 53, 77, 78, 79, 82, 83, 107, 109, 135, 138], "eigenvector": [1, 35, 47, 53, 104, 107, 109, 135, 138], "eigh": [109, 118], "eigval": [77, 78, 82, 83, 109], "eigvec": 109, "einstein": [8, 16, 109, 116], "einstein_equ": 0, "either": [0, 7, 8, 9, 11, 19, 38, 40, 43, 51, 53, 56, 63, 65, 66, 67, 72, 76, 86, 88, 112, 115, 116, 117, 119, 126, 143], "ek": 96, "ekstr\u00f6m": [1, 45, 56], "el": 115, "elabor": [11, 25, 27, 43], "elad": 1, "elast": 66, "elbo": [72, 73, 93], "eleanor": [1, 56], "elect": 25, "electr": [67, 115], "electromagnet": 90, "electron": [21, 112, 138], "elegantli": 7, "element": [1, 3, 9, 34, 37, 41, 43, 44, 45, 47, 53, 63, 64, 66, 67, 71, 72, 77, 78, 82, 83, 85, 88, 96, 98, 99, 107, 109, 115, 116, 117, 120, 130, 132, 135, 138, 143], "elementwis": 75, "eleph": [99, 109], "elessar": 115, "elev": 65, "elevanth": [130, 136], "elif": [34, 78, 82, 96, 98, 105, 111, 116, 131], "elimin": [7, 12, 17, 63, 108, 109], "ell": [78, 79, 82, 86, 102, 103, 105], "ell_rbf": 78, "ellips": [37, 53, 78, 86, 128], "ellipsoid": 46, "ellipt": 35, "els": [3, 6, 8, 34, 37, 38, 40, 42, 48, 50, 69, 70, 76, 78, 82, 96, 98, 105, 108, 111, 124, 125, 126, 127, 129, 131, 134, 135, 136, 138, 141, 143, 144], "elsewher": [7, 34, 40, 42, 95, 112, 125, 140], "elu": [67, 70, 111], "em": [9, 45], "email": 119, "emce": [1, 6, 35, 38, 41, 50, 51, 90, 94, 124, 125, 128, 129, 130, 136, 141, 145], "emcee_lnprob": 41, "emcee_sampl": 105, "emcee_trac": 41, "emerg": [19, 51, 56], "emilia": 116, "emiss": 53, "emit": [42, 124], "emph": [48, 104], "emphas": [21, 31, 34, 47, 57, 65, 103, 112, 136], "emphasi": [31, 34, 115, 128], "empir": [4, 40, 43, 45, 53, 88, 89, 95, 100, 102, 111, 115, 126], "emploi": [7, 9, 16, 30, 34, 46, 51, 53, 62, 66, 67, 72, 96, 99, 103, 126, 138], "employ": [63, 64], "employe": 64, "empti": [93, 96, 108, 111, 112, 116, 125, 126], "empty_lik": [73, 93], "emptyset": [66, 112], "emul": [1, 46, 62, 67, 106, 107], "en": [41, 99, 134, 145], "enabl": [8, 25, 34, 38, 43, 45, 47, 51, 53, 58, 62, 71, 79, 116, 128, 135, 136], "encapsul": 25, "enclos": 19, "encod": [19, 38, 39, 40, 49, 53, 58, 75, 78, 82, 103, 108, 129, 134, 140], "encompass": [8, 11, 46, 50, 51, 53], "encount": [8, 16, 25, 26, 38, 53, 57, 60, 64, 65, 66, 68, 88, 97, 99, 100, 116, 126, 135, 143], "encourag": [27, 43, 46, 59, 72, 115, 116, 119], "end": [0, 3, 4, 7, 8, 9, 12, 13, 15, 16, 19, 22, 23, 24, 25, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 53, 63, 64, 65, 66, 67, 68, 72, 75, 77, 78, 79, 82, 83, 85, 86, 88, 92, 95, 97, 98, 99, 100, 105, 107, 108, 109, 112, 114, 116, 118, 119, 128, 129, 130, 131, 132, 133, 134, 135, 138, 140, 141, 143], "end_tim": 105, "endeavor": 47, "endeavour": 100, "endow": 48, "endpoint": [9, 17, 112, 117, 130], "energi": [21, 44, 45, 47, 51, 72, 78, 79, 82, 91, 99, 112, 130, 133, 136, 138], "energy_0": 132, "enforc": [7, 33, 47, 67, 73], "engin": [1, 47, 63, 64, 67, 71], "english": [20, 53, 143], "enlighten": 4, "enorm": 45, "enough": [5, 9, 12, 19, 29, 30, 34, 37, 40, 43, 44, 45, 47, 53, 56, 63, 67, 77, 83, 86, 109, 113, 127, 128, 136, 138, 144], "ensambl": [72, 129, 134], "ensembl": [1, 50, 67, 72, 73, 96, 129, 134, 135], "ensemblesampl": [6, 38, 41, 50, 96, 105, 125, 128, 129, 134], "ensur": [4, 5, 43, 46, 47, 63, 71, 72, 77, 78, 82, 83, 105, 138, 140], "entail": [8, 34, 53, 98], "enter": [0, 25, 34, 43, 46, 64, 77, 83, 96, 98, 99, 100, 116, 122, 135, 136], "entir": [19, 34, 43, 48, 50, 51, 52, 63, 66, 75, 88, 114, 116], "entireti": 48, "entiti": 23, "entitl": [61, 64, 102], "entri": [0, 32, 38, 39, 42, 52, 63, 68, 72, 86, 108, 109, 115, 133, 134, 135, 136, 138], "entropi": [7, 8, 38, 40, 42, 43, 55, 62, 65, 67, 70, 72], "enumer": [0, 3, 6, 7, 33, 38, 41, 42, 46, 65, 77, 78, 81, 82, 83, 95, 96, 105, 112, 117], "env": [50, 70, 81, 96, 108, 134], "envelop": 79, "envi": 45, "environ": [35, 56, 69, 70, 93, 113, 116, 121, 124], "environment": 63, "environment_jb": [119, 122], "environment_window": 93, "envis": 44, "eotwash": 51, "epidemiologi": [46, 48], "epistemologi": [20, 21, 25], "eplac": 33, "epoch": [66, 67, 68, 69, 70, 71, 76, 88, 99], "epsilon": [3, 4, 34, 66, 72, 77, 79, 83, 98, 99, 105, 130, 132], "epsilon_i": [3, 34, 66, 95, 98, 103], "epsrel": 5, "eq": [0, 7, 16, 25, 34, 44, 45, 46, 47, 48, 53, 65, 66, 97, 99, 100, 103, 105, 112, 128, 131, 135, 138, 143], "eq_ppd": 0, "eqn": [48, 53], "equal": [3, 4, 8, 11, 19, 22, 23, 25, 31, 32, 33, 34, 35, 37, 38, 40, 44, 46, 50, 53, 63, 65, 66, 68, 71, 72, 77, 78, 82, 83, 98, 105, 107, 109, 112, 117, 118, 126, 127, 128, 132, 135, 138, 141, 144], "equat": [1, 3, 4, 7, 8, 16, 22, 23, 25, 39, 44, 45, 46, 47, 48, 49, 51, 53, 56, 64, 65, 66, 67, 72, 75, 79, 85, 88, 97, 99, 100, 103, 105, 107, 112, 116, 124, 129, 130, 131, 134, 135, 138, 141, 143], "equilibr": [127, 136, 138, 141, 144], "equilibrium": [126, 135, 138, 143], "equip": 16, "equiv": [3, 4, 7, 13, 17, 19, 21, 24, 29, 34, 35, 39, 45, 46, 49, 51, 53, 65, 66, 68, 72, 79, 82, 85, 86, 88, 94, 95, 96, 98, 99, 107, 112, 125, 129, 131, 134, 135, 136, 138], "equival": [3, 4, 7, 19, 25, 34, 38, 39, 47, 48, 49, 53, 72, 78, 94, 96, 116, 128, 129, 134, 138], "ergod": 130, "eriador": 115, "ermal": 1, "ernest": 112, "err": 94, "err_filenam": 108, "err_msg": 108, "err_slop": 41, "err_slope_max": 41, "err_slope_min": 41, "err_theta_ml": 41, "err_v0": 41, "errno": 108, "errno_num": 108, "erron": [55, 63, 99], "error": [0, 1, 3, 4, 16, 17, 28, 29, 33, 38, 40, 43, 44, 46, 47, 48, 49, 50, 53, 55, 56, 59, 60, 64, 67, 68, 71, 72, 73, 77, 79, 85, 88, 93, 94, 95, 96, 97, 98, 100, 103, 105, 107, 108, 109, 115, 116, 117, 118, 128, 129, 133, 134, 135], "errorbar": [34, 38, 40, 41, 49, 80, 95, 96, 98, 105, 125], "errread": 108, "errstat": 92, "errwrit": 108, "esc": 116, "especi": [25, 67, 71, 73, 100], "ess": 44, "ess_bulk": [133, 134], "ess_tail": [133, 134], "essai": 102, "essenc": 71, "essenti": [1, 5, 8, 47, 48, 51, 57, 58, 61, 64, 67, 68, 103, 126, 130], "est": 34, "establish": [8, 47, 48, 62], "estim": [1, 5, 9, 11, 14, 17, 19, 20, 21, 22, 24, 25, 27, 30, 34, 35, 37, 38, 42, 43, 44, 46, 49, 51, 55, 59, 60, 64, 65, 66, 71, 72, 73, 79, 80, 88, 90, 91, 93, 95, 98, 99, 100, 103, 105, 106, 108, 109, 115, 124, 125, 127, 128, 133, 136, 138, 144], "et": [0, 43, 44, 56, 66, 105, 108, 126], "eta": [7, 49, 68, 70, 79, 88, 97, 99, 103, 105], "eta0": 70, "eta_n": 99, "etc": [4, 7, 8, 9, 11, 17, 58, 60, 64, 67, 75, 77, 83, 88, 96, 100, 119, 138], "ethic": 1, "eti": 112, "euclidean": [34, 65, 78, 98, 99], "euclidean_dist": 65, "euler": [130, 132], "euro": 143, "european": 63, "evalu": [0, 1, 7, 13, 16, 25, 29, 34, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 53, 63, 65, 66, 67, 71, 72, 73, 82, 85, 92, 93, 95, 98, 99, 103, 105, 109, 115, 116, 117, 120, 125, 126, 127, 129, 132, 134, 135, 136, 138, 144], "evaluate_gradi": 99, "evd": 107, "even": [0, 5, 7, 8, 12, 16, 17, 21, 25, 34, 39, 43, 44, 45, 47, 48, 49, 53, 56, 58, 63, 64, 65, 66, 67, 72, 73, 75, 76, 78, 79, 82, 85, 86, 98, 103, 115, 116, 124, 129, 130, 133, 134, 135, 138, 141], "evenli": [37, 40, 77, 83, 118], "event": [4, 8, 16, 17, 22, 23, 25, 37, 63, 138], "eventu": [12, 19, 25, 40, 49, 52, 56, 66, 67, 97, 99, 113, 116, 125, 126, 138, 141], "ever": [8, 16, 53, 62, 63], "everi": [6, 9, 11, 12, 19, 23, 25, 44, 49, 50, 51, 63, 67, 71, 75, 76, 78, 79, 82, 85, 96, 99, 105, 108, 134, 141], "everybodi": 53, "everydai": [53, 56], "everyon": 8, "everyth": [16, 23, 68, 73, 107, 116, 136], "everywher": [9, 48, 63, 67, 117], "evid": [3, 7, 8, 9, 10, 16, 23, 25, 29, 30, 34, 39, 50, 59, 62, 63, 90, 91, 96, 105], "evluat": 65, "evolut": [25, 72, 130, 135, 138], "evolv": [25, 30, 56, 64, 102, 131, 138, 143], "exac": 144, "exact": [37, 44, 45, 47, 48, 49, 51, 68, 72, 94, 99, 100, 115, 127, 130, 141, 144], "exact_data": 37, "exact_fev": 92, "exactli": [16, 29, 30, 34, 40, 48, 66, 68, 75, 98, 107], "examin": [38, 43, 44, 51, 69, 76, 103, 125, 133], "exampl": [0, 4, 6, 7, 8, 9, 11, 16, 17, 19, 20, 21, 22, 27, 30, 32, 37, 43, 44, 45, 46, 47, 48, 50, 52, 53, 55, 64, 66, 67, 68, 69, 72, 73, 74, 76, 79, 81, 83, 85, 87, 88, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 107, 109, 111, 114, 115, 116, 117, 119, 126, 127, 130, 134, 135, 138, 140, 142, 144, 145], "example_revers": 138, "exce": [53, 67, 105, 143], "exceed": 105, "excel": [56, 64, 72, 126, 129, 130, 134, 135, 136, 145], "except": [31, 34, 37, 43, 65, 66, 71, 76, 96, 105, 108, 129, 134, 135, 141], "excercis": 133, "excerpt": 48, "excess": [97, 115], "exchang": [19, 51, 61], "excit": [11, 47, 64, 138], "exclud": [25, 46, 63, 66, 95, 115, 143], "exclus": [22, 23, 25, 31, 32, 48, 63, 66, 68, 76, 115], "execut": [71, 108, 117, 119], "exemplifi": [34, 112], "exercis": [9, 13, 20, 22, 30, 38, 49, 56, 69, 91, 92, 113, 125], "exercisesp": 143, "exert": 38, "exhaust": [22, 23, 25, 31, 32, 46, 66, 112], "exhibit": 128, "exist": [4, 8, 19, 25, 34, 39, 48, 50, 60, 61, 62, 63, 64, 76, 92, 96, 98, 102, 112, 115, 116, 124, 129, 131, 134, 138], "exit": 116, "exp": [0, 4, 5, 7, 24, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 48, 49, 50, 53, 65, 67, 68, 70, 71, 72, 78, 82, 85, 88, 90, 92, 95, 96, 100, 103, 105, 111, 112, 116, 120, 125, 126, 127, 129, 134, 140, 143, 144], "expand": [8, 19, 22, 23, 31, 32, 34, 35, 38, 43, 47, 48, 53, 88, 89, 102, 145], "expans": [7, 16, 19, 34, 47, 53, 58, 67, 94, 102], "expect": [4, 7, 8, 9, 10, 12, 13, 19, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 65, 66, 68, 72, 73, 79, 86, 92, 93, 98, 100, 108, 115, 118, 124, 125, 127, 128, 133, 134, 135, 136, 138, 140, 141, 143, 144], "expected_improv": 92, "expens": [31, 47, 79, 95, 104, 106], "experi": [4, 8, 9, 11, 16, 19, 21, 25, 30, 35, 37, 40, 42, 43, 51, 59, 60, 61, 62, 63, 64, 71, 80, 86, 89, 92, 96, 100, 103, 109, 110, 112, 115, 135], "experienc": 141, "experiment": [0, 7, 9, 17, 23, 25, 29, 30, 37, 39, 41, 47, 48, 51, 53, 58, 60, 62, 66, 96, 100, 103, 104, 106, 112, 115, 129, 134], "expert": [0, 16, 43, 47, 62, 63, 67, 109], "expertis": 47, "explain": [7, 12, 19, 34, 43, 48, 59, 63, 65, 66, 71, 79, 90, 94, 96, 98, 108, 109, 115, 116, 124, 127, 135, 143, 144], "explan": [7, 19, 53, 62, 66, 99, 138, 140], "explanatori": 100, "explcitli": 85, "explic": 63, "explicit": [7, 9, 17, 34, 39, 43, 44, 47, 53, 59, 67, 75, 85, 102, 109, 116, 129, 134, 138], "explicitli": [4, 16, 22, 23, 25, 33, 42, 48, 53, 64, 71, 73, 80, 85, 86, 89, 105, 114, 115, 118, 143], "explod": [68, 71, 102], "exploit": [9, 11, 38, 44, 47, 67, 92], "explor": [9, 23, 26, 27, 30, 34, 37, 38, 41, 42, 44, 45, 47, 49, 51, 53, 59, 63, 65, 66, 73, 86, 91, 92, 94, 97, 98, 99, 100, 102, 103, 105, 108, 117, 118, 128, 130, 135, 136, 138, 141, 143], "exploratori": [73, 93], "expon": [7, 34, 44, 52], "exponenti": [19, 34, 35, 44, 50, 67, 71, 77, 78, 82, 83, 85, 99, 100, 116, 120, 126, 135], "expos": [59, 66], "exposit": 43, "express": [4, 7, 9, 15, 16, 19, 22, 30, 31, 34, 38, 39, 40, 41, 44, 45, 46, 48, 49, 51, 53, 58, 59, 65, 66, 67, 68, 73, 75, 76, 77, 83, 85, 93, 96, 97, 98, 99, 100, 102, 103, 107, 109, 112, 115, 125, 126, 129, 134, 135, 138], "expsinesquar": 81, "expt": [29, 140], "extend": [4, 23, 27, 39, 47, 55, 56, 59, 62, 63, 65, 73, 78, 94, 116, 134, 143], "extens": [0, 20, 23, 43, 47, 63, 64, 67, 71, 85, 95, 99, 103, 109, 115, 116], "extent": [8, 17, 34, 37, 46, 64], "extern": [9, 114, 143], "extra": [35, 43, 52, 53, 67, 76, 86, 138, 145], "extra_anim": 108, "extra_arg": 108, "extra_group": 108, "extra_rbm_emul": 104, "extract": [7, 17, 23, 34, 38, 41, 44, 50, 69, 73, 74, 77, 82, 83, 88, 94, 95, 96, 98, 100, 103, 105, 112, 119, 126, 129, 133, 134, 144], "extrapol": [45, 47, 48, 71, 79, 104, 115], "extrem": [8, 16, 19, 25, 38, 43, 48, 53, 63, 64, 66, 67, 73, 115, 116, 141], "extremum": [16, 34, 98], "ey": [22, 32, 38, 43, 49, 50, 64, 78, 82, 118, 125, 128], "e\u00f6t": 51, "f": [0, 1, 3, 4, 5, 6, 7, 9, 13, 16, 17, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 44, 49, 50, 64, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 80, 81, 82, 83, 86, 88, 92, 93, 95, 96, 98, 102, 103, 105, 108, 109, 111, 112, 114, 115, 116, 117, 118, 119, 125, 127, 128, 132, 133, 134, 135, 141, 143, 144, 145], "f11": 115, "f12": 115, "f13": 115, "f9": 115, "f_": [34, 47, 48, 67, 98], "f_0": [7, 34, 98], "f_1": [48, 86], "f_2": [48, 67, 86], "f_arr": 7, "f_j": [34, 98], "f_k": [48, 96], "f_likelihood": 7, "f_posterior": 7, "f_r": 117, "fab": [37, 131, 132], "face": [4, 16, 52, 135], "facecolor": [17, 37, 96, 108], "facet": 55, "facilit": [34, 43, 47, 73], "fact": [3, 4, 7, 15, 16, 23, 25, 34, 35, 38, 41, 44, 53, 62, 63, 64, 65, 66, 67, 72, 75, 82, 85, 98, 100, 112, 115, 125, 135, 136, 138, 143], "factor": [5, 7, 10, 16, 19, 25, 33, 34, 35, 38, 42, 43, 44, 47, 48, 49, 50, 52, 53, 61, 63, 90, 95, 96, 105, 109, 112, 124, 125, 126, 132, 133, 135, 136, 141], "factori": [4, 33, 37, 127, 144], "fail": [5, 7, 19, 22, 38, 42, 43, 44, 51, 53, 55, 59, 63, 81, 108, 115, 116, 119, 128], "failur": [29, 44, 48, 88], "fair": [3, 8, 9, 11, 13, 16, 19, 30, 43, 53], "fairli": [39, 62, 129, 134], "faith": 34, "fake": 130, "fall": [19, 34, 43, 46, 53, 63, 80, 98, 100, 105], "fallaci": 31, "fallen": 100, "fals": [3, 7, 9, 21, 29, 31, 33, 34, 37, 38, 40, 41, 50, 63, 64, 65, 70, 73, 76, 78, 80, 82, 88, 92, 95, 98, 105, 108, 109, 112, 114, 115, 125, 126, 131, 135, 138, 143], "falsif": 61, "falsifi": [53, 62], "famili": [47, 56, 63, 66, 67, 86, 88, 100, 115, 138, 143], "familiar": [4, 7, 22, 23, 29, 31, 34, 37, 47, 53, 62, 65, 102, 115, 117, 127, 143, 144], "famou": [16, 46, 67, 68], "fan_out": 71, "fantast": 64, "far": [7, 8, 16, 25, 33, 34, 44, 47, 53, 63, 67, 71, 73, 76, 79, 80, 86, 108, 126, 128, 130, 135], "farther": 51, "fashion": 61, "fast": [17, 19, 46, 47, 68, 99, 106, 108, 112, 116, 117, 133, 141, 145], "faster": [45, 46, 47, 71, 73, 93, 117, 133], "fastest": 12, "fat": 135, "favor": [19, 38, 51, 52, 63, 65, 88, 97, 130, 135], "favour": [4, 37, 53], "fc": [75, 95], "feasibl": [99, 135, 136], "featur": [9, 11, 34, 37, 38, 39, 41, 46, 47, 53, 55, 60, 62, 63, 64, 65, 66, 67, 68, 71, 73, 78, 86, 93, 94, 97, 98, 99, 102, 107, 109, 111, 112, 115, 118, 129, 130, 134, 140], "fed": 69, "federico": 1, "feed": [41, 68, 69, 70, 72, 76, 78, 102, 115], "feedforward": 67, "feel": [16, 25, 30, 37, 63, 126], "femal": 112, "feng": [7, 130, 135, 136], "feroz": 1, "few": [4, 7, 9, 11, 17, 23, 37, 38, 40, 42, 47, 53, 63, 64, 67, 69, 71, 75, 76, 80, 92, 108, 109, 112, 115, 130, 133, 135, 138, 143], "fewer": [29, 47, 53, 65, 66, 107, 115, 130], "ffmpeg": 108, "ffmpegwrit": 108, "ffnn": 67, "fhb09": [1, 135], "fhi": [1, 45], "fiber": 51, "fictiti": 130, "fiddl": 73, "fidel": [45, 46, 47, 104], "field": [1, 8, 16, 43, 47, 49, 62, 63, 64, 67, 73, 89, 91, 93, 94, 99, 102, 108, 136], "fieri": 53, "fifth": [53, 115, 125, 126], "fig": [0, 3, 4, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 50, 53, 65, 66, 67, 70, 72, 73, 75, 77, 78, 79, 81, 82, 83, 88, 93, 95, 96, 97, 98, 103, 105, 108, 109, 111, 112, 114, 115, 116, 117, 126, 127, 129, 131, 134, 135, 138, 143, 144, 145], "fig1": [39, 134], "fig2": [37, 39, 134], "fig3": 33, "fig3d": 112, "fig_2": 132, "fig_4": 132, "fig_5": 132, "fig_af": 7, "fig_corn": [138, 143], "fig_cprob_revers": 138, "fig_cr": 112, "fig_id": 115, "fig_knn_classifi": 65, "fig_linear_classifi": 65, "fig_linear_classifier_plan": 65, "fig_pdfi": 112, "fig_point": 112, "fig_run": [138, 143], "fig_runs_revers": 138, "fig_slopesampl": 3, "fig_train_data": 65, "fig_tru": 37, "fig_x1x2": 112, "fig_x2givenx0": 138, "fig_xmgivenx0": 138, "figsiz": [5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 50, 65, 69, 70, 73, 76, 77, 78, 81, 82, 83, 88, 93, 95, 98, 105, 108, 109, 111, 112, 115, 116, 117, 125, 126, 127, 131, 132, 133, 134, 135, 143, 144], "figur": [5, 7, 9, 17, 25, 33, 35, 38, 39, 40, 41, 42, 49, 50, 51, 53, 65, 66, 68, 69, 70, 72, 76, 77, 78, 79, 80, 82, 83, 86, 88, 92, 93, 94, 95, 96, 103, 105, 108, 109, 115, 117, 119, 120, 127, 130, 131, 132, 134, 138, 141, 144, 145], "figure1": 17, "figure2": 17, "figure_id": 115, "figure_titl": 42, "figurefil": 115, "file": [9, 43, 50, 70, 76, 93, 96, 105, 108, 114, 115, 116, 119, 121, 122], "filenam": [69, 108], "filenotfounderror": 108, "fill": [9, 30, 32, 34, 42, 46, 47, 52, 77, 79, 94, 96, 107, 108, 115, 124, 136], "fill_between": [9, 17, 41, 80, 81, 82, 94, 96, 108, 112], "filter": [75, 108, 109, 133], "filterwarn": [73, 93, 125], "final": [4, 6, 7, 23, 25, 31, 34, 38, 40, 41, 42, 43, 44, 46, 50, 53, 57, 62, 64, 65, 66, 67, 69, 71, 72, 74, 75, 76, 85, 92, 97, 98, 99, 100, 103, 107, 115, 125, 129, 134, 138, 140, 145], "financi": 64, "find": [0, 3, 4, 5, 7, 9, 16, 17, 19, 22, 23, 25, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 51, 52, 53, 56, 63, 64, 65, 66, 67, 68, 70, 71, 72, 77, 83, 85, 86, 88, 89, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 105, 107, 108, 112, 113, 114, 115, 116, 117, 120, 124, 125, 126, 127, 129, 130, 131, 133, 134, 135, 136, 138, 140, 141, 143, 144], "find_contour_level": 37, "find_index": 37, "find_map": [133, 134], "findabl": 43, "fine": [47, 66, 71], "finer": [50, 51, 96], "finetti": 46, "finish": [40, 93, 119], "finit": [16, 19, 33, 34, 43, 44, 47, 66, 67, 78, 82, 85, 86, 91, 102, 107, 126, 138, 143], "firmli": 8, "first": [1, 3, 5, 7, 8, 9, 11, 15, 16, 17, 18, 19, 22, 23, 25, 26, 27, 31, 32, 34, 35, 38, 39, 42, 43, 44, 47, 48, 49, 50, 51, 53, 57, 59, 63, 64, 66, 67, 69, 71, 72, 73, 75, 76, 77, 78, 80, 82, 83, 85, 86, 88, 92, 93, 94, 95, 96, 99, 100, 102, 103, 107, 108, 109, 112, 116, 117, 118, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 138, 140, 141, 142, 143, 144], "first_nam": 116, "fisher": [1, 95], "fission": 47, "fist": 138, "fit": [7, 17, 23, 29, 34, 35, 38, 43, 47, 49, 51, 52, 53, 63, 65, 66, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 92, 93, 94, 96, 97, 98, 99, 100, 103, 106, 109, 120, 128, 135], "fit_degree_n": 95, "fit_intercept": [70, 115], "fit_transform": 105, "fiti": 115, "five": [25, 34, 37, 98, 99, 103, 112, 115], "fix": [3, 7, 9, 19, 22, 23, 34, 37, 43, 49, 50, 51, 53, 66, 71, 72, 75, 77, 82, 83, 85, 96, 99, 102, 103, 105, 110, 111, 112, 114, 115, 116, 125, 126, 127, 130, 132, 135, 136, 138, 140, 143, 144], "fk": 96, "flag": [37, 38], "flash": 35, "flat": [6, 8, 21, 25, 34, 35, 37, 38, 39, 40, 50, 52, 68, 86, 96, 105, 129, 134], "flatchain": [38, 41, 50, 125], "flatlnprob": 41, "flatten": [6, 33, 35, 41, 49, 50, 69, 75, 76, 77, 82, 83, 108, 118, 125, 128, 129, 133, 134], "flavor": 8, "flavour": 99, "flaw": 59, "flexibl": [37, 38, 47, 53, 66, 67, 71, 73, 85, 100, 115], "flexibli": 73, "flick": 130, "flip": [11, 13, 16, 25, 30, 130, 143], "flipper": 9, "float": [42, 50, 69, 70, 82, 96, 105, 111, 115, 116, 118, 131, 132], "float32": [69, 71, 73, 76, 111], "float64": [50, 96, 115, 133], "float640": 133, "float641": 133, "float6410": 133, "float6411": 133, "float644": 133, "float_widget": 114, "floatslid": [5, 9, 114, 116], "floatx": [73, 93], "floor": 118, "florian": 145, "flow": [44, 67, 102, 105, 135], "flowchart": 120, "fluctuat": [11, 23, 29, 35, 37, 40, 42, 90, 94, 96, 99, 133, 136, 141], "fluid": 143, "flux": 53, "fly": [73, 93], "fm": 47, "fmhlg13": [1, 135], "fmin": 38, "fmt": [34, 38, 40, 41, 49, 95, 96, 98, 105, 125], "fn": [63, 64], "fnois": 92, "focu": [23, 43, 44, 64, 66, 72, 77, 83, 85, 99, 115, 124, 135, 138], "focus": [34, 43, 49, 62, 64, 73, 88, 89, 135], "fold": 95, "folder": 115, "follow": [4, 7, 8, 9, 11, 12, 16, 17, 19, 22, 25, 26, 34, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 53, 57, 61, 62, 64, 65, 66, 67, 69, 71, 72, 73, 75, 83, 85, 88, 92, 93, 94, 95, 96, 98, 99, 100, 102, 103, 105, 107, 108, 109, 112, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 129, 130, 133, 134, 135, 136, 138, 141, 142, 143, 144], "font": [5, 9, 34, 37, 42, 100, 108, 109, 114, 115, 131, 132], "font_siz": [5, 9, 114, 131, 132], "font_size_w": 114, "fontsiz": [7, 17, 33, 38, 42, 50, 81, 96, 105, 112, 125, 129, 134], "food": 143, "fool": 31, "foolish": 66, "foral": [47, 65, 99, 138], "forc": [1, 51, 53, 59, 65, 100, 103, 105, 108, 132, 136], "forcefulli": 130, "forecast": [16, 67], "forefront": 7, "foreman": [1, 129, 134, 141], "forest": [67, 73], "forestgreen": 103, "forev": 125, "forg": [73, 119], "forget": [21, 30, 65, 73, 93, 116], "forgotten": 115, "fork": 50, "form": [0, 4, 7, 8, 13, 19, 23, 25, 33, 37, 38, 40, 43, 47, 48, 49, 52, 53, 58, 63, 64, 65, 67, 68, 70, 71, 73, 75, 77, 78, 80, 82, 83, 86, 88, 91, 93, 95, 97, 98, 99, 100, 102, 103, 107, 112, 116, 124, 126, 130, 132, 133, 135, 136, 138], "formal": [8, 25, 34, 47, 48, 53, 82, 98, 100, 109, 138], "format": [0, 1, 25, 30, 38, 39, 40, 41, 42, 49, 50, 56, 69, 71, 73, 76, 92, 95, 96, 114, 115, 116, 117, 118, 125, 127, 129, 134], "format_nam": 0, "former": [8, 34, 43, 53, 66, 85, 98, 99, 100, 107], "formul": [0, 4, 5, 8, 9, 12, 25, 39, 43, 47, 59, 60, 65, 81, 90, 96, 100, 129, 134, 138, 143], "formula": [19, 37, 42, 47, 48, 49, 51, 53, 79, 85, 86, 90, 109, 115, 116, 126, 128], "forssen": [38, 39, 50, 77, 78, 95, 125, 126, 129, 134], "forss\u00e9n": [1, 44, 56, 73, 78, 93], "forth": [51, 67, 116], "fortran": [64, 115], "fortun": [43, 73, 119, 143], "forward": [8, 13, 41, 68, 70, 72, 75, 88, 97, 99, 100, 102, 130, 135], "fou": 51, "found": [4, 5, 8, 15, 17, 19, 21, 27, 29, 35, 38, 40, 44, 46, 47, 51, 53, 56, 63, 65, 67, 71, 72, 92, 99, 112, 118, 119, 126, 127, 132, 133, 135, 136, 141, 144, 145], "foundat": [25, 62], "four": [4, 37, 47, 50, 51, 63, 67, 68, 85, 86, 99, 103, 116, 138, 143], "fourier": [19, 34, 109], "fourth": [15, 68, 115], "fp": [63, 64, 108], "fphy": 1, "fr": [29, 33, 37, 112, 125, 138, 143], "frac": [3, 4, 7, 8, 9, 10, 13, 16, 19, 22, 23, 24, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 46, 48, 49, 51, 52, 53, 65, 66, 67, 68, 72, 78, 79, 82, 85, 86, 88, 94, 95, 96, 97, 98, 99, 100, 103, 105, 107, 108, 109, 112, 115, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 141, 143, 144], "frac12": [49, 78, 94, 131], "fraction": [4, 6, 9, 32, 42, 50, 53, 63, 65, 66, 69, 97, 99, 100, 105, 109, 112, 125, 126, 129, 134, 135, 136], "fraction_100_after_10min": 143, "fraction_kept": 109, "fragoso2018": 48, "frame": [1, 48, 108, 115, 138], "frame_skip": 108, "frame_switch": 108, "frameon": 29, "framework": [8, 16, 25, 27, 28, 30, 43, 46, 48, 60, 61, 71, 73, 78, 85, 102, 105], "franci": [1, 100], "franciscan": 53, "frederi": 56, "free": [30, 38, 41, 49, 51, 67, 72, 95, 100, 102, 105, 107, 145], "freedom": [19, 29, 39, 44, 53, 95, 102, 108, 112, 129, 134, 141], "freeli": [64, 73], "freq": 116, "frequenc": [4, 8, 32, 33, 34, 38, 90, 112, 114, 116, 131], "frequent": [4, 7, 23, 38, 39, 64, 88, 99, 129, 134, 135, 136], "frequentist": [9, 20, 21, 22, 23, 25, 26, 30, 32, 34, 35, 39, 41, 43, 51, 95, 98, 112], "fresh": 129, "frictionless": 130, "friedman": 1, "friedrich": 1, "friend": 116, "friendli": 27, "frivol": 21, "frobeniu": 109, "frodo": 115, "frog": 76, "from": [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 16, 17, 19, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 78, 80, 81, 82, 85, 88, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 124, 125, 126, 127, 129, 130, 131, 132, 134, 138, 140, 143, 144, 145], "front": [1, 39, 44, 116, 117, 134], "fruition": 8, "frustra": 53, "fstring": [39, 116, 120, 134], "ft": 33, "ft_pt": 33, "ft_uniform": 33, "ft_uniform_pt": 33, "ft_valu": 33, "fuch": 110, "fuction": 111, "fulfil": [4, 43, 99, 112, 135, 138, 143], "full": [7, 17, 18, 19, 34, 38, 40, 43, 44, 46, 47, 49, 51, 53, 56, 61, 67, 72, 76, 78, 79, 80, 82, 91, 93, 95, 96, 98, 99, 107, 109, 112, 118, 119, 125, 128, 130, 131, 133, 136, 141, 145], "full_cov": [77, 83], "full_matric": 109, "full_nam": 116, "fulli": [10, 43, 46, 51, 66, 67, 69, 73, 75, 103, 138, 141, 143], "fun": [33, 73, 92, 105], "func": [95, 108], "funcanim": 108, "function": [1, 3, 4, 8, 9, 11, 15, 16, 19, 20, 24, 25, 26, 27, 30, 33, 35, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 64, 66, 67, 69, 72, 73, 74, 75, 79, 80, 86, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 111, 115, 117, 118, 120, 125, 126, 128, 129, 130, 132, 133, 134, 135, 138, 141, 143], "fundament": [8, 16, 25, 34, 39, 56, 60, 66, 98, 129, 134], "fungibl": [9, 11], "furnstah": 50, "furnstahl": [0, 1, 5, 38, 50, 56, 77, 78, 114, 119, 125, 131, 133], "further": [4, 7, 20, 21, 23, 24, 34, 35, 46, 48, 52, 53, 72, 73, 75, 78, 82, 86, 116, 117, 128, 130, 133, 135, 136, 138], "furthermor": [7, 25, 34, 38, 39, 41, 44, 46, 47, 49, 60, 66, 67, 72, 75, 77, 82, 83, 85, 88, 112, 115, 129, 134, 135, 143], "futur": [16, 24, 25, 34, 43, 50, 63, 65, 66, 73, 96, 100, 115, 133, 138, 143], "futuredata": 16, "futurewarn": [50, 96, 115, 133], "fvec": 86, "fvec_1": [79, 86], "fvec_2": [79, 86], "fwhm": 126, "g": [0, 1, 3, 4, 7, 8, 16, 17, 18, 19, 21, 23, 25, 33, 34, 35, 38, 44, 45, 46, 47, 48, 49, 51, 52, 53, 56, 60, 61, 63, 65, 66, 67, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 86, 92, 93, 94, 95, 96, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 112, 113, 115, 116, 119, 124, 126, 128, 130, 131, 135, 136, 142, 143, 145], "g1": 38, "g2": 38, "g_": [49, 94], "g_1": 38, "g_2": 38, "g_fun": 49, "g_i": 38, "gabri": 51, "gain": [43, 47, 52, 53, 56, 64, 73, 109], "galact": 41, "galaxi": [1, 7, 41, 53, 56, 62], "galerkin": 47, "galerkin_ortho": 47, "galleri": [7, 64, 116, 135], "galton": 100, "gambl": 8, "gambler": 143, "game": [16, 47, 72, 73, 107, 143], "gamge": 115, "gamma": [13, 17, 38, 42, 44, 99, 108, 124], "gamma2_dist": 108, "gamma_1": 99, "gamma_2": 99, "gamma_a": 108, "gamma_dist": 108, "gamma_label": 108, "gamma_scal": 108, "gap": [66, 97], "garcia": 1, "gate": 67, "gather": [19, 53, 67, 86, 138, 143], "gaug": [67, 71], "gauss": 100, "gaussian": [0, 1, 3, 16, 23, 24, 26, 29, 37, 38, 40, 41, 42, 44, 45, 47, 50, 51, 52, 60, 70, 71, 72, 73, 74, 79, 87, 89, 90, 92, 94, 95, 96, 102, 103, 105, 106, 111, 124, 125, 128, 130, 135, 136, 140], "gaussian_model": 134, "gaussian_nois": [77, 78, 83], "gaussian_norm": 49, "gaussian_process": [80, 81, 82, 104, 105], "gaussianmov": [50, 125, 128], "gaussianprocessregressor": [80, 81, 82, 92], "gave": [9, 63], "gc": [0, 1, 34, 51, 53, 56], "gca": [50, 78, 82, 95, 96, 109, 131], "gcc": [73, 93], "gcf": [96, 108], "gd": 68, "ge": [7, 67, 72, 88], "gedankenmodel": 48, "gelfand": 1, "gelman": [0, 1, 51, 56, 61, 72, 86, 126, 128], "gelman2013bayesian": 0, "gelman_rubin_diagnostic_calc": 125, "gelmen": 133, "gen": 108, "gen_gaussian_sampl": 78, "gen_plot_gaussian_sampl": 78, "gene": [1, 112], "gener": [0, 3, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 22, 23, 26, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 56, 57, 59, 61, 62, 65, 66, 67, 68, 70, 71, 72, 74, 77, 78, 79, 82, 83, 85, 86, 89, 90, 92, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 115, 116, 119, 121, 125, 126, 127, 128, 129, 131, 132, 133, 136, 138, 140, 142, 143, 144], "generaliz": 89, "generallay": 67, "generate_binaryclass_data": 65, "generate_data": 9, "genesi": 56, "gentli": 126, "geoff": 99, "geoffrei": 1, "geometr": 8, "geometri": 16, "georg": [1, 16, 46, 61, 62, 63, 100], "geq": [4, 29, 35, 37, 38, 46, 82, 92, 99, 112, 127, 135, 136, 138, 141, 143, 144], "geron": 66, "geron17": [1, 66], "get": [0, 4, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 23, 25, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 42, 44, 46, 48, 49, 50, 51, 53, 65, 67, 68, 72, 73, 79, 86, 88, 90, 92, 93, 94, 95, 96, 98, 105, 107, 108, 109, 111, 112, 114, 118, 119, 120, 121, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 138, 141, 143, 144], "get_ax": 17, "get_batch": 99, "get_chain": [50, 105, 134], "get_cmap": 49, "get_fram": 9, "get_param": 82, "get_subplotspec": 3, "gev": 112, "gewek": 133, "gg": [4, 29, 37, 44, 48, 52, 53, 67], "gibb": 133, "gid": [70, 108], "gif": 108, "gif_filenam": 108, "gilk": 126, "git": [44, 64, 119, 122], "github": [40, 43, 56, 64, 70, 73, 76, 84, 93, 104, 112, 113, 118, 121, 130, 135, 136, 143], "githubusercont": 109, "gitlab": 64, "give": [0, 3, 4, 7, 9, 12, 13, 16, 17, 22, 23, 24, 25, 28, 30, 31, 32, 34, 35, 38, 40, 44, 45, 46, 48, 51, 53, 55, 63, 64, 65, 66, 67, 70, 71, 72, 73, 76, 77, 78, 79, 81, 82, 83, 85, 88, 94, 101, 106, 107, 109, 111, 112, 114, 115, 116, 118, 126, 128, 135, 137, 138, 141, 142, 143], "given": [0, 4, 5, 7, 8, 9, 10, 11, 16, 17, 18, 19, 21, 22, 23, 24, 25, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 62, 64, 65, 66, 67, 68, 70, 71, 72, 78, 79, 80, 82, 85, 86, 88, 90, 91, 93, 95, 98, 99, 100, 102, 103, 104, 105, 108, 109, 111, 112, 115, 116, 118, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 143, 144, 145], "glanc": 8, "glass": 58, "glean": 62, "glib": 119, "global": [1, 38, 50, 51, 53, 88, 97, 108, 141, 145], "globalmov": 50, "glorot": 71, "gloss": [39, 129, 134], "glue": [3, 7, 65, 88, 112, 135, 138, 143], "gm": 100, "gmail": [80, 81], "go": [4, 9, 11, 13, 15, 16, 19, 22, 25, 29, 30, 33, 44, 52, 53, 56, 59, 63, 68, 73, 76, 86, 93, 97, 102, 109, 114, 115, 116, 118, 119, 122, 126, 127, 128, 129, 130, 134, 138, 141, 144], "goal": [7, 9, 17, 22, 30, 31, 32, 34, 35, 37, 42, 43, 44, 46, 48, 55, 58, 61, 64, 72, 79, 88, 89, 91, 97, 98, 99, 100, 102, 109, 129, 133, 134, 143], "goat": 16, "god": 19, "goe": [4, 7, 32, 52, 55, 66, 128, 138], "goggan": 51, "gold": [16, 77], "goldstein": [1, 46], "goldstein2009reifi": 48, "gone": 141, "good": [1, 2, 19, 22, 27, 29, 33, 34, 35, 39, 40, 42, 43, 44, 46, 47, 51, 53, 61, 63, 64, 66, 67, 68, 71, 73, 75, 77, 83, 85, 86, 92, 97, 98, 99, 103, 107, 108, 116, 118, 125, 126, 129, 130, 133, 134, 141], "goodman": [1, 135], "googl": [1, 17, 23, 42, 76, 79, 112, 114, 116, 120], "googlenet": 73, "gossett": [0, 23], "got": 29, "gothenburg": 16, "gotten": 19, "govern": [16, 63, 76, 103], "gp": [47, 77, 83, 87, 89, 92, 102, 103, 104, 105], "gp_kernel": 81, "gp_regress": [77, 78, 83], "gp_sklearn": 82, "gpkernel": 92, "gpplot": 82, "gpr": [81, 92], "gpr_model": 81, "gpr_sklearn": 82, "gpregress": [77, 78, 79, 83], "gpu": [73, 93], "gpy": [78, 79, 85, 86, 92], "gr92": [1, 44], "grab_fram": 108, "grad": 71, "grad_fn": 71, "grade": 8, "gradient": [34, 44, 65, 66, 67, 68, 70, 72, 73, 75, 88, 98, 100, 101, 102, 133, 136, 140, 145], "gradienttap": 76, "gradual": 47, "graduat": 56, "grai": [37, 38, 40, 96, 108, 109, 130], "grand": 32, "graph": [1, 9, 17, 35, 42, 64, 71, 73, 76, 77, 93, 99, 114, 117, 127, 136, 144], "graphic": [108, 119], "graphs_rjf": 108, "grass": [21, 62], "grate": 56, "gratefulli": 9, "gravit": [7, 51, 100, 103], "gravitation_orbit_1": 132, "graviti": [51, 103, 105], "grayscal": 75, "gre05": [1, 2, 27, 53, 56, 136, 144], "great": [7, 16, 47, 56, 73, 87, 119, 141], "greater": [19, 33, 37, 38, 44, 51, 53, 77, 83, 103, 105, 125, 133], "greatest": [16, 93], "greatli": 65, "greedi": 47, "greek": 112, "green": [9, 33, 44, 69, 75, 96, 103, 108, 112, 116, 126, 130, 132, 136, 141, 145], "greenfield": 98, "gregori": [1, 2, 27, 37, 53, 56, 127, 144], "gregory_7_2": 53, "grei": [47, 65], "grid": [0, 7, 34, 37, 40, 41, 50, 51, 65, 70, 72, 73, 74, 76, 86, 93, 96, 98, 116, 138], "grid_2d": [73, 93], "griffith": 110, "grist": 58, "ground": [8, 47, 48, 103, 105, 115, 138], "groundwork": 34, "group": [4, 37, 64, 73, 77, 83, 85, 102, 108, 115, 118], "groupbi": 115, "grow": [29, 68, 86, 100, 102, 129, 134, 135, 136, 143], "growth_fig": 143, "growth_quest": 143, "gsl": 34, "gt": [100, 133, 136, 141], "guarante": [8, 16, 34, 47, 78, 82, 98, 126, 132, 138], "guess": [7, 17, 38, 82, 86, 92, 105, 129, 134, 138], "guesswork": 138, "gui": 108, "guid": [1, 11, 27, 41, 53, 62, 64, 69, 71, 81, 94, 102, 103, 113, 114, 119, 121], "guidanc": [50, 96, 108], "guidelin": [43, 94], "guido": 110, "guillaum": [80, 81], "guilti": 63, "guin": 23, "guiness": 0, "gull": [4, 42, 53], "gw07": [1, 46], "gw10": [1, 135], "h": [0, 1, 7, 8, 16, 24, 25, 31, 34, 44, 45, 46, 47, 53, 70, 85, 95, 100, 103, 105, 107, 112, 115, 126, 130, 131, 141, 143], "h0": [0, 7, 41, 105], "h2mc": 136, "h_": [7, 34, 41, 47, 53], "h_0": [7, 103, 105], "h_1": 25, "h_3": 16, "h_i": 25, "h_j": 16, "ha": [0, 4, 7, 8, 9, 10, 16, 17, 19, 22, 23, 25, 28, 29, 30, 31, 34, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 59, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 76, 77, 78, 79, 80, 82, 85, 86, 88, 89, 90, 92, 94, 95, 96, 97, 99, 100, 102, 103, 105, 107, 109, 112, 113, 115, 116, 117, 118, 119, 126, 127, 128, 129, 130, 133, 134, 135, 136, 138, 142, 143, 144], "habit": 43, "hackernoon": 117, "had": [4, 13, 16, 17, 19, 25, 41, 53, 56, 72, 112, 115, 126, 128, 136, 141], "hadamard": [68, 118], "hagan": 103, "hair": 4, "hal21": [1, 102], "half": [8, 17, 35, 37, 38, 40, 41, 44, 53, 70, 125, 130, 138], "halfnorm": 133, "halfwai": [51, 132], "hall": [0, 1, 16, 56], "halt": 99, "halv": [46, 125], "halverson": 1, "hamilton": [44, 130, 131], "hamiltonian": [1, 45, 47, 104, 131, 135, 136, 139, 142], "hamiltonianmc": 133, "hamiltonianpendulum": 131, "hammer": 1, "hand": [0, 1, 4, 7, 9, 16, 21, 22, 25, 26, 34, 38, 53, 62, 64, 66, 67, 69, 72, 73, 75, 77, 83, 97, 109, 119, 131, 132, 135, 138, 143, 145], "handbook": [1, 44, 66], "handed": 4, "handl": [44, 67, 70, 71, 82, 95, 100, 115], "handle_color": 9, "handsid": 68, "hang": 51, "hanin": 1, "hao": 1, "happen": [5, 7, 8, 11, 12, 29, 34, 35, 37, 40, 41, 49, 58, 66, 68, 76, 77, 86, 90, 96, 109, 112, 126, 128, 133], "happend": 34, "happi": 114, "hard": [1, 31, 44, 49, 65, 67, 73, 88, 102, 126, 133, 136], "harder": [34, 67, 133], "hardest": 72, "hardli": 67, "hardwar": [64, 119], "hare": 67, "harm": [63, 66], "harmon": 47, "harsher": 53, "hashtag": 116, "hast": [50, 51, 125, 128, 130, 133, 141, 142], "hasti": [1, 66], "hat": [29, 38, 43, 44, 49, 51, 52, 63, 85, 99, 103, 105, 125, 133], "have": [0, 3, 4, 5, 7, 8, 9, 10, 11, 13, 16, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 53, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 80, 82, 83, 85, 86, 87, 88, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 105, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144], "haven": 53, "hazan": 1, "hbox": [5, 9, 114], "hbox0": [9, 114], "hbox1a": [9, 114], "hbox1b": [9, 114], "hbox2": [9, 114], "hbox3": [9, 114], "hbox_1": 114, "hbox_2": 114, "hd": 7, "hdi_3": [133, 134], "hdi_97": [133, 134], "hdr": 112, "he": [1, 8, 16, 25, 37, 46, 47, 53, 61, 62, 71, 88, 102, 108], "head": [0, 8, 9, 11, 13, 16, 19, 23, 25, 30, 52, 115, 116, 143], "header": [115, 116], "headlin": 73, "heads_in_data_to_n": 9, "headstart": 109, "health": 73, "healthcar": 63, "hear": 64, "heart": [58, 103], "heavi": [12, 17, 18, 47, 64, 108], "heavili": [51, 64, 65, 99, 136], "heavisid": 44, "hei": 73, "height": [0, 9, 17, 35, 53, 75, 76, 100, 103, 108, 114, 128, 145], "heisenberg": 16, "held": [22, 50, 130], "hello": [116, 117], "hello_funct": 116, "help": [9, 38, 42, 43, 44, 58, 63, 64, 66, 67, 69, 71, 73, 85, 93, 99, 100, 105, 114, 120, 121, 125], "help_bayes_w": 9, "help_max_height": [9, 114], "help_overview_w": [9, 114], "help_parameters_w": 114, "help_priors_w": 9, "help_setup_w": [9, 114], "help_tab": [9, 114], "help_times_w": 114, "help_toss_coin_w": 9, "helper": [34, 69, 70, 76, 98], "henc": [0, 22, 23, 34, 53, 66, 78, 82, 85, 91, 98, 115, 138], "henceforth": 138, "hendrik": [80, 81], "hennig": 61, "hensman": [77, 83], "her": [53, 63], "here": [0, 4, 5, 7, 9, 13, 16, 17, 19, 23, 24, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 83, 85, 86, 87, 88, 89, 92, 93, 95, 98, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144], "hereaft": 19, "hermitian": [47, 118], "heroic": 62, "hesian": 136, "hesit": 22, "hess_inv": 41, "hessian": [34, 35, 41, 53, 95], "heurist": [73, 141], "hexp_err": 105, "hexp_err_sc": 105, "hexp_mean": 105, "hexp_mean_sc": 105, "hexp_std": 105, "hg": [1, 44, 112], "hi": [0, 23, 25, 37, 53, 62, 99, 103, 133, 136], "hi95": [77, 83], "hick": 125, "hidden": [7, 43, 51, 63, 65, 67, 68, 70, 71, 73, 75, 93, 102, 111, 112], "hidden1": 71, "hidden2": 71, "hidden3": 71, "hide": 0, "hierarch": 73, "hierarchi": [40, 73], "higdon": [103, 105], "higdon2004combin": 48, "higg": [19, 112, 136], "high": [1, 5, 9, 21, 31, 34, 38, 43, 44, 45, 46, 47, 49, 51, 56, 63, 64, 66, 67, 72, 73, 75, 96, 97, 98, 99, 100, 104, 109, 115, 126, 128, 130, 131, 135], "higher": [9, 16, 19, 23, 34, 40, 47, 63, 64, 66, 73, 77, 80, 95, 105, 115, 126, 130, 131, 138], "highest": [19, 46, 50, 51, 73, 76, 79, 96, 107, 112, 133, 145], "highli": [27, 41, 44, 47, 52, 64, 66, 73, 78, 82, 86, 99, 115, 116, 134, 141], "highlight": [0, 33, 43, 55, 56, 63, 95, 107, 116], "hilbert": 47, "hill": 126, "him": [99, 102, 110], "himself": 53, "hinder": 99, "hint": [0, 7, 16, 31, 37, 39, 51, 77, 83, 88, 96, 124, 134, 138, 143], "hinton": [1, 99], "hist": [17, 29, 33, 39, 42, 50, 73, 82, 93, 108, 111, 112, 125, 126, 127, 133, 134, 144], "hist_kwarg": 105, "hist_norm": 108, "hist_pt": 108, "hist_pts_al": 108, "histogram": [17, 19, 29, 33, 35, 39, 42, 43, 44, 50, 79, 82, 111, 112, 125, 126, 127, 128, 129, 133, 134, 135, 136, 138, 141, 143, 144], "histogram2d": 41, "histogram_ax": 33, "histor": [46, 48, 63, 88, 89, 99], "historam": 33, "historgram": 141, "histori": [1, 55, 67, 69, 76, 99, 100, 138, 143], "historian": [8, 62], "histplot": 126, "histtyp": [112, 126], "hit": [11, 17, 35, 112, 116], "hitchhik": 56, "hjorth": 56, "hmc": [44, 133, 136, 140, 141, 142], "hmodel_sc": 105, "hms21": [1, 102], "hmv": 130, "ho": 47, "hobson": 1, "hoc": 38, "hoffman": 1, "hogg": [1, 95, 141], "hold": [9, 11, 31, 34, 47, 48, 63, 66, 73, 75, 93, 105, 118, 130, 135, 138], "holdout": 66, "hole": [7, 51], "home": [0, 77], "homemad": 132, "homogen": [67, 118], "honest": [4, 61], "honesti": 61, "honor": 45, "hood": 71, "hope": [48, 58, 59, 61, 88], "hopefulli": [45, 69, 73, 109], "hopfield": 67, "hopkin": 1, "horizont": [17, 19, 50, 78, 82, 114, 118, 125], "horizontalalign": [7, 9, 42], "hors": [76, 88], "hospit": 63, "host": 16, "hour": 37, "hous": 16, "how": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 22, 23, 24, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 47, 49, 50, 51, 53, 56, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 77, 78, 79, 80, 82, 85, 88, 91, 92, 93, 95, 98, 100, 102, 103, 105, 106, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 124, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 138, 143, 144, 145], "howard": 112, "howev": [4, 7, 8, 11, 16, 25, 34, 38, 39, 43, 44, 45, 46, 47, 48, 51, 53, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 77, 83, 85, 88, 92, 93, 97, 98, 99, 100, 102, 103, 104, 112, 115, 116, 117, 118, 119, 126, 128, 129, 133, 134, 135, 138, 143], "hp_bound": 105, "hpd": [19, 133], "hspace": 115, "hsplit": 118, "htf09": [1, 66], "html": [0, 1, 9, 17, 41, 42, 50, 70, 73, 81, 93, 96, 104, 112, 114, 116, 133, 134, 145], "htmlmath": [5, 9, 114], "http": [0, 1, 17, 40, 41, 50, 51, 69, 73, 76, 77, 81, 93, 96, 99, 104, 109, 112, 117, 119, 122, 130, 133, 134, 136, 143, 145], "hu": 1, "huang": [1, 115], "hubbl": [7, 41], "huber_loss": 38, "huge": [4, 7, 60, 62, 73, 75], "hugh": 112, "human": [62, 63, 64, 67], "hump": 19, "humpti": 58, "hundr": [67, 109], "hungarian": 61, "hungri": 67, "hunt": 53, "hw": [78, 82], "hybrid": [1, 44, 47, 73], "hydrogen": [115, 126], "hyper": [48, 73, 133], "hyperbol": [67, 71], "hypercub": [47, 79, 135], "hyperlink": [0, 56], "hyperparamet": [9, 17, 43, 44, 47, 66, 67, 69, 71, 72, 75, 78, 80, 82, 83, 86, 88, 97, 99, 102, 103, 105, 140], "hyperparmet": 105, "hyperrectangl": 46, "hyperreduct": 47, "hypothes": [7, 25, 53, 63, 67, 100, 103], "hypothesi": [8, 11, 19, 25, 39, 52, 63, 129, 134], "hypothet": [19, 53], "i": [0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 15, 16, 18, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 140, 142, 143, 144, 145], "i1": 67, "i10": 143, "i3": 115, "i5": 115, "i6qkdaeacaaj": 1, "i_": [46, 86, 109, 138], "i_0": 138, "i_1": 138, "i_2": 138, "i_d": [0, 7, 86], "i_i": 46, "i_m": 46, "i_n": [135, 138], "i_num": 135, "i_rel_error": 135, "i_sort": 41, "i_unsort": 41, "ia": 7, "ian": [1, 56], "iax": 3, "ib": 96, "ichain": [50, 125], "iclass": 65, "iclass_mean": 65, "icol": [50, 125], "id": [1, 116], "idata": 65, "idea": [9, 19, 24, 30, 33, 38, 43, 44, 47, 51, 56, 63, 64, 66, 67, 73, 77, 79, 83, 85, 92, 94, 97, 102, 108, 109, 124, 126, 128, 130, 133, 141, 145], "ideal": [4, 34, 44, 62, 64, 96], "ideg": 95, "idenitfi": 138, "ident": [34, 47, 51, 53, 58, 62, 66, 72, 73, 96, 98, 103, 105, 115, 118, 130, 138], "identif": [46, 99, 112], "identifi": [4, 8, 19, 26, 34, 38, 41, 43, 44, 46, 48, 63, 64, 65, 67, 69, 86, 88, 94, 100, 107, 112, 116, 118, 128, 136, 138, 145], "idx": 81, "iexp": 135, "iexp_i_num": 135, "ignor": [3, 4, 7, 8, 9, 13, 17, 25, 29, 38, 41, 42, 44, 46, 48, 49, 53, 61, 73, 76, 93, 108, 112, 125, 126, 128, 135], "ii": [1, 34, 37, 38, 43, 52, 53, 59, 63, 82, 94, 95, 99, 103, 107, 109, 112, 115, 130, 138], "iia": 91, "iib": 91, "iib_how_many_lines_ptemce": 90, "iid": [53, 83, 96, 105, 125], "iii": [43, 53, 59, 94, 103, 138], "iiia": 91, "iiib": 91, "iint": 44, "ij": [29, 34, 47, 53, 67, 68, 82, 86, 95, 107, 109, 125, 138, 143], "ik": [65, 82, 107, 109], "il": 67, "ill": [107, 109], "illustr": [7, 31, 32, 41, 47, 48, 49, 51, 53, 66, 67, 77, 80, 82, 83, 87, 103, 112, 145], "ilogp": 38, "ils": 1, "im": [34, 65, 96], "imag": [63, 67, 69, 102, 107, 108, 116], "image_height": 76, "image_path": 115, "image_width": 76, "imagemagick": 108, "imagenet": 73, "imagin": [4, 16, 25, 31, 37, 40, 48, 65, 66, 73, 96, 108, 128, 135, 136, 141], "img": [69, 76, 109], "img2": 109, "img99": 109, "img995": 109, "img_orig": 109, "immedi": [4, 16, 19, 53, 58, 60], "imp": 92, "impact": [23, 43, 63, 64, 71, 90, 94], "imparti": 61, "imper": 43, "imperfect": [23, 48], "impi": 138, "implaus": [46, 72], "implement": [22, 27, 34, 35, 38, 42, 43, 44, 47, 48, 51, 58, 63, 70, 71, 72, 73, 74, 75, 77, 82, 83, 90, 92, 96, 99, 115, 117, 118, 127, 128, 131, 132, 138, 141, 143, 144, 145], "impli": [3, 4, 7, 19, 22, 23, 29, 31, 32, 34, 38, 39, 40, 41, 44, 45, 47, 48, 49, 53, 62, 64, 65, 66, 67, 72, 75, 76, 78, 82, 85, 95, 97, 98, 99, 100, 103, 109, 112, 116, 117, 125, 126, 129, 134, 138, 143], "implic": [10, 59], "implicit": [9, 23, 30, 34, 39, 49, 78, 82, 85, 129, 134], "implicitli": [19, 29, 40, 42, 125], "import": [0, 1, 3, 6, 7, 8, 9, 12, 17, 19, 24, 25, 28, 29, 30, 33, 34, 37, 39, 40, 41, 42, 43, 46, 47, 49, 53, 55, 56, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 78, 79, 80, 81, 82, 85, 88, 93, 97, 98, 99, 103, 105, 107, 108, 111, 116, 117, 118, 120, 125, 127, 129, 131, 132, 134, 135, 136, 138, 141, 143, 144], "importantli": [25, 37, 43, 78, 82, 100], "impos": [46, 60, 66, 79, 143], "imposs": [7, 34, 47], "impract": 135, "impress": [129, 134], "imprint": [64, 138], "improv": [5, 7, 15, 16, 43, 48, 50, 51, 53, 64, 66, 71, 73, 89, 92, 93, 96, 99, 102, 117, 128, 130, 132, 133, 144], "imput": 62, "imread": 109, "imshow": [69, 76, 78, 82, 109], "in_featur": [71, 111], "inaccur": [63, 65, 103], "inaccuraci": 46, "inact": [46, 67], "inadequ": 136, "inadvert": 56, "inappropri": 108, "inch": 131, "includ": [0, 4, 7, 8, 12, 15, 16, 22, 24, 25, 26, 27, 28, 29, 33, 34, 35, 39, 41, 43, 46, 47, 48, 50, 51, 55, 56, 59, 64, 65, 66, 67, 70, 71, 72, 73, 74, 77, 82, 83, 85, 86, 88, 89, 92, 93, 96, 98, 100, 101, 102, 103, 104, 105, 107, 108, 112, 114, 115, 116, 119, 123, 126, 129, 133, 134, 135, 138, 143, 145], "include_group": 115, "inclus": [39, 43, 52, 63, 129, 134], "incom": 67, "incomplet": [8, 46, 53, 63, 135], "inconsist": 63, "incorpor": [0, 4, 7, 16, 25, 43, 61, 66, 67, 103, 132], "incorrect": [69, 76, 103, 105, 118], "increas": [16, 17, 23, 25, 33, 34, 41, 46, 47, 49, 50, 64, 65, 66, 67, 71, 72, 82, 95, 96, 97, 98, 99, 103, 105, 124, 125, 126, 128, 133, 135, 136, 141, 143], "increasingli": [25, 33, 40, 47, 48, 51, 53, 63, 78, 103, 116, 128, 129, 134], "incredibli": 64, "increment": [9, 11, 71, 141], "inde": [8, 9, 16, 19, 22, 25, 30, 34, 53, 58, 60, 64, 98, 115, 135, 138, 143], "indent": [116, 120], "independ": [3, 4, 7, 9, 12, 15, 16, 19, 20, 22, 23, 25, 29, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 63, 65, 66, 67, 72, 78, 80, 85, 86, 88, 95, 96, 98, 103, 105, 109, 125, 130, 135, 136, 138, 143], "index": [5, 33, 34, 37, 44, 65, 76, 82, 85, 86, 88, 98, 102, 103, 107, 108, 112, 115, 117, 131, 132, 133, 134, 138, 143, 145], "index_col": 115, "index_cv": 95, "index_max": 108, "indiana": 56, "indic": [0, 4, 9, 17, 25, 29, 34, 38, 40, 41, 44, 46, 49, 51, 53, 63, 65, 69, 71, 72, 82, 99, 100, 107, 108, 109, 112, 115, 118, 119, 125, 128, 129, 130, 133, 134, 136, 138, 143], "indiffer": [7, 8, 43, 62], "indigen": 63, "indirect": 53, "indirectli": [43, 44], "individu": [22, 32, 33, 34, 38, 40, 41, 43, 44, 46, 48, 49, 63, 67, 73, 79, 81, 88, 95, 119, 125, 131, 143], "induc": [46, 51, 102], "induct": [1, 7, 42, 61, 100], "industri": 67, "ineffici": [44, 67, 99], "inequ": 46, "inevit": 112, "inexpens": [31, 47], "inf": [6, 33, 37, 38, 40, 42, 96, 105, 112, 125, 129, 134], "infeas": [43, 44, 47], "infer": [1, 8, 16, 24, 25, 27, 28, 30, 34, 42, 47, 53, 55, 56, 57, 58, 59, 64, 65, 71, 89, 91, 95, 96, 98, 103, 106, 112, 125, 128, 133, 143, 145], "inference_librari": 133, "inference_library_vers": 133, "inferenti": [16, 48], "infil": 115, "infin": [7, 19, 38, 102, 108, 125], "infinit": [7, 38, 53, 64, 77, 82, 83, 85, 86, 100, 102, 135, 138], "infinitesim": [7, 25, 30, 53, 99], "influenc": [4, 16, 25, 38, 43, 46, 63, 66, 77, 83, 85, 103], "influenti": [43, 62], "info": [35, 73, 93, 105, 108, 115, 118, 121, 133], "inform": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 16, 18, 19, 22, 23, 24, 25, 29, 30, 31, 32, 34, 37, 38, 39, 40, 43, 44, 46, 47, 48, 49, 52, 53, 55, 56, 58, 59, 61, 62, 63, 65, 66, 67, 72, 73, 79, 85, 88, 94, 95, 98, 99, 100, 102, 103, 105, 109, 112, 114, 115, 117, 119, 125, 129, 133, 134, 136, 141], "informatik": [80, 81], "infrastructur": 63, "infti": [0, 4, 7, 15, 17, 19, 23, 24, 33, 34, 35, 37, 38, 41, 44, 48, 49, 53, 72, 98, 112, 125, 128, 135, 138, 143], "ingredi": [7, 20, 24, 27, 46, 47, 51, 59, 67, 124], "inher": [43, 44, 53, 66, 71, 72, 73, 103, 143], "inherit": 71, "inhibit": 66, "init": [50, 71, 111, 141], "init_1": [73, 93], "init_2": [73, 93], "init_out": [73, 93], "init_weight": 71, "initi": [9, 11, 16, 23, 30, 37, 41, 42, 46, 47, 50, 51, 52, 53, 56, 66, 67, 73, 77, 79, 82, 83, 92, 93, 96, 97, 99, 102, 103, 105, 109, 112, 117, 119, 125, 127, 128, 131, 132, 133, 134, 135, 136, 138, 140, 141, 143, 144, 145], "initial_text": [9, 114], "initial_text_w": [9, 114], "initialis": [50, 134], "initialize_model": 111, "initio": [1, 92], "initv": 133, "inlin": [5, 33, 37, 38, 39, 40, 41, 42, 49, 70, 73, 77, 78, 83, 92, 93, 95, 96, 109, 112, 115, 116, 125, 126, 127, 129, 131, 134, 144], "inner": [8, 68, 77, 83], "innov": 73, "innovi": 73, "input": [0, 5, 9, 34, 40, 43, 46, 48, 56, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 82, 85, 86, 88, 89, 92, 93, 96, 98, 99, 100, 102, 103, 105, 113, 116, 118, 140, 141, 143], "input_dim": [77, 78, 83, 92], "input_shap": [69, 76], "input_v": 111, "inputs_i": [34, 64, 65, 66, 99], "inputs_j": 66, "inputt": [34, 98, 100], "inputt_": 100, "inputt_1": [65, 67, 100], "inputt_2": [65, 67, 100], "inputt_i": 100, "inputt_p": 67, "inquiri": 103, "insensit": 65, "insert": [16, 22, 31, 32, 47, 68, 70, 77, 83, 92, 112, 116, 118, 138, 143], "insid": [71, 95, 115, 116, 117, 131, 135, 145], "insight": [7, 20, 24, 26, 34, 45, 46, 48, 53, 64, 71, 73, 77, 83, 98, 100, 103], "inspect": [8, 34, 38, 98], "inspir": [64, 66, 67, 72, 73, 118, 126], "instal": [70, 73, 116, 124], "instanc": [7, 16, 62, 63, 65, 67, 71, 85, 88, 99, 100, 112, 133, 138, 143], "instanti": [79, 105, 131, 133], "instead": [7, 8, 16, 19, 34, 38, 39, 43, 44, 46, 48, 49, 51, 52, 53, 58, 62, 65, 71, 72, 73, 74, 75, 77, 78, 79, 82, 83, 85, 97, 99, 112, 116, 117, 118, 119, 126, 128, 129, 133, 134, 138, 141, 143], "institut": [63, 64, 112], "instruct": [17, 25, 30, 43, 53, 64, 119, 124], "insuffici": 53, "insur": 56, "int": [4, 7, 9, 17, 19, 23, 25, 33, 34, 37, 41, 42, 44, 49, 51, 52, 53, 70, 72, 73, 81, 82, 85, 93, 95, 105, 108, 118, 125, 127, 131, 135, 136, 141, 144], "int64": 133, "int640": 133, "int8": [73, 93], "int_": [0, 3, 4, 7, 16, 19, 23, 24, 33, 38, 41, 48, 53, 112, 128, 135], "int_0": [4, 7, 11, 13, 25, 35, 38, 51, 112], "int_1": 112, "int_a": [17, 23, 112, 136], "int_v": 136, "integ": [9, 13, 33, 35, 37, 39, 44, 69, 99, 100, 105, 111, 116, 117, 125, 127, 136, 138, 144], "integr": [0, 4, 5, 7, 16, 17, 18, 19, 23, 24, 31, 32, 34, 35, 37, 38, 43, 44, 47, 50, 51, 52, 53, 60, 71, 72, 73, 93, 95, 105, 108, 112, 116, 129, 130, 131, 132, 134, 136, 141], "integrand": [24, 33, 34, 38, 49, 52, 112, 135, 136], "integrand_pt": 33, "integration_fig": 135, "intel": 119, "intellectu": 61, "intellig": [1, 63, 64, 89, 99], "intend": [51, 61, 71], "intens": [38, 56, 79, 90], "intent": 43, "interact": [0, 7, 16, 25, 27, 43, 45, 56, 67, 102, 114, 115, 116, 130, 135, 136, 141], "interactive_output": 9, "interc": [52, 79, 86, 107, 128, 130], "intercept": [3, 6, 23, 34, 35, 38, 40, 41, 53, 98, 115, 125], "intercept_": 70, "intercept_limit": 40, "intercept_rang": 40, "intercept_sc": 70, "interchang": 138, "interdepend": 46, "interest": [4, 7, 8, 16, 17, 19, 23, 25, 31, 34, 40, 41, 43, 44, 45, 46, 47, 48, 53, 58, 60, 64, 66, 67, 68, 73, 77, 83, 88, 96, 99, 100, 101, 109, 112, 115, 117, 128, 130, 135, 143], "interestingli": 73, "interfac": [11, 116, 135], "interior": [99, 115], "interlaboratori": 108, "intermedi": [25, 79, 90, 126, 130], "intern": [0, 1, 67, 128], "internet": 135, "interoper": 43, "interplai": 67, "interplo": 45, "interpol": [37, 41, 45, 47, 48, 78, 79, 80, 86], "interpret": [4, 5, 7, 8, 11, 16, 19, 20, 21, 22, 23, 25, 26, 32, 34, 37, 39, 43, 46, 51, 53, 60, 61, 62, 68, 72, 77, 80, 83, 89, 94, 95, 102, 103, 106, 110, 112, 129, 134, 135, 138], "intersect": [21, 22, 145], "interv": [4, 7, 11, 15, 17, 25, 26, 35, 37, 41, 43, 51, 79, 80, 82, 86, 88, 92, 96, 108, 112, 129, 133, 134, 143, 145], "interview": [63, 110], "intial": [105, 138], "intimid": 115, "intp": [73, 93], "intract": [47, 72, 129, 134], "intric": 16, "intrins": [25, 60], "intro": 43, "introduc": [4, 7, 16, 18, 21, 22, 24, 25, 27, 34, 38, 40, 42, 43, 44, 45, 46, 48, 51, 53, 58, 59, 63, 64, 65, 66, 67, 71, 88, 95, 97, 98, 99, 100, 101, 103, 112, 116, 126, 128, 138, 145], "introduct": [1, 20, 27, 39, 47, 53, 55, 72, 89, 104, 107, 129, 134, 135, 136, 140, 142], "introductori": [87, 106, 115], "intrus": [45, 47], "intslid": [5, 9, 114], "intuit": [7, 8, 11, 16, 22, 31, 35, 38, 39, 42, 44, 51, 62, 66, 67, 72, 73, 93, 102, 109, 115, 116, 129, 134], "inv": [34, 49, 50, 65, 95, 98, 105, 118], "invalid": [116, 141], "invalu": 128, "invari": [1, 4, 8, 40, 41, 43, 44, 55, 85, 95, 102, 125, 128, 129, 130, 132, 134, 135, 138], "invcft": 33, "invent": [37, 94], "inventor": 99, "invers": [7, 8, 23, 33, 41, 49, 51, 53, 66, 85, 98, 105, 107, 108, 109, 120, 135, 138], "invert": [34, 48, 65, 85, 88, 97, 98, 99, 107, 128, 130, 131], "invest": 66, "investig": [58, 61, 64, 77, 82, 83, 92, 124, 125, 140, 143], "invft": 33, "invft_uniform_pt": 33, "invgamma": 112, "invit": [21, 48], "invok": [0, 132, 133], "involv": [7, 22, 25, 34, 38, 39, 43, 46, 48, 53, 62, 63, 64, 66, 67, 71, 72, 73, 82, 88, 93, 99, 100, 127, 129, 134, 135, 136, 143, 144], "io": [41, 73, 93, 104, 108, 109, 130, 133, 134, 136, 145], "ipad": 116, "ipr": 6, "ipsen": 1, "ipykernel_5270": 37, "ipykernel_5301": 38, "ipykernel_6197": 115, "ipykernel_6411": 133, "ipynb": [33, 35, 38, 41, 51, 70, 90, 93, 94, 109, 116, 124, 125, 128, 130, 132, 136, 140, 141, 145], "ipython": [5, 9, 108, 115, 116], "ipywidget": [5, 9, 108, 116], "ironclad": 62, "irow": [50, 125], "irreduc": [66, 97, 126, 135, 138], "irregular": 43, "irrelev": [34, 37, 44], "irrespect": [25, 126], "irun": 143, "is_avail": 71, "is_first_col": 3, "isak": [1, 44, 56], "isbn": 1, "iscalar": [73, 93], "isinst": [33, 37, 71, 105, 111], "isn": [63, 73, 130], "isnet": 56, "iso": [53, 82], "isol": [56, 107, 109], "isotrop": 128, "issu": [38, 63, 71, 95, 97, 99, 100, 125, 133, 135, 138], "isupp": 133, "ital": [39, 42, 116], "item": [3, 71, 111, 118], "iter": [1, 15, 38, 43, 44, 50, 51, 66, 67, 70, 71, 72, 73, 79, 81, 92, 96, 97, 99, 115, 116, 120, 125, 126, 128, 130, 133, 134, 135, 138], "itila": 1, "its": [0, 4, 7, 8, 9, 11, 12, 17, 19, 22, 24, 25, 34, 37, 38, 40, 41, 43, 46, 47, 49, 52, 53, 60, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 75, 77, 78, 80, 82, 83, 85, 88, 96, 98, 99, 103, 107, 109, 112, 114, 115, 116, 117, 118, 120, 125, 126, 129, 131, 133, 134, 135, 138, 143], "itself": [4, 7, 9, 19, 31, 33, 39, 40, 43, 44, 47, 50, 53, 58, 59, 63, 64, 67, 86, 96, 97, 102, 109, 114, 129, 132, 134], "iv": [60, 138], "ix": [41, 77, 83], "ix1": 65, "ix2": 65, "j": [1, 4, 5, 16, 19, 29, 34, 37, 44, 46, 48, 49, 56, 66, 67, 68, 78, 79, 82, 96, 98, 99, 102, 107, 109, 112, 115, 125, 128, 131, 133, 135, 138, 143], "j_": [72, 99], "jacob": 8, "jacobian": [3, 7], "jaiswal": [103, 105], "jake": [66, 80], "jame": [1, 77, 83], "jan": [80, 81], "januari": 21, "javascript": [135, 136], "jax": 99, "jay03": [1, 56], "jay2020": 48, "jay88": [1, 62], "jayn": [1, 4, 40, 56], "jb": [0, 56, 113], "jb_test": 0, "jefferi": 53, "jeffrei": [3, 8, 38, 40, 51, 53], "jen": 1, "jensen": 56, "jeopard": 61, "jet": 37, "jforssen22": [1, 44, 46], "jhm": [80, 81], "ji": [67, 68, 107, 138], "jiang": [1, 44, 56], "jimmi": 1, "jitter": [78, 133, 134], "jk": [68, 107, 109], "jmlr": 1, "joanna": 63, "job": [63, 90, 133, 134], "john": [1, 8, 99, 145], "johnson": 4, "join": [115, 118], "joint": [4, 7, 17, 22, 31, 32, 34, 35, 41, 42, 44, 53, 78, 82, 85, 86, 103, 124, 128, 129, 130, 134, 135, 138, 143, 145], "jointli": [85, 130], "jonathan": 1, "jone": 1, "jordan": 56, "joukj": 1, "journal": [1, 15, 43, 63], "jpeg": 75, "jpg": 109, "jstor": 1, "judg": [29, 60, 66, 128], "judgement": [43, 46, 53], "judgment": [47, 100], "jul": 119, "juli": 105, "julia": 63, "julien": 1, "jump": [9, 11, 23, 35, 51, 108, 126, 136], "jump_w": 9, "june": [5, 38, 50, 77, 95, 125, 126], "junli": 1, "jupyt": [23, 26, 27, 70, 103, 105, 107, 111, 113, 114, 118], "jupytext": 0, "juri": 62, "just": [0, 6, 7, 9, 11, 13, 17, 19, 22, 23, 24, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 72, 73, 76, 77, 82, 83, 85, 86, 88, 90, 93, 95, 96, 97, 98, 99, 100, 109, 112, 113, 114, 115, 116, 119, 126, 128, 129, 134, 135, 136, 138, 141, 145], "justic": 63, "justif": [15, 64], "justifi": [24, 42, 44, 103], "k": [1, 3, 4, 6, 9, 15, 16, 19, 29, 35, 37, 38, 40, 41, 42, 44, 48, 49, 51, 52, 53, 67, 68, 71, 72, 77, 79, 83, 85, 86, 88, 92, 94, 95, 96, 99, 102, 103, 105, 107, 109, 112, 115, 124, 127, 128, 130, 132, 135, 136, 138, 141, 143, 144], "k0": [127, 144], "k1": 82, "k1__constant_valu": 82, "k1__constant_value_bound": 82, "k2": 82, "k2__length_scal": 82, "k2__length_scale_bound": 82, "k99": 109, "k995": 109, "k_": [49, 78, 79, 86, 127, 144], "k_0": [67, 127, 144], "k_1": [67, 77, 83, 127, 144], "k_2": [52, 67, 77, 83, 127, 144], "k_3": [127, 144], "k_arrai": [127, 144], "k_b": [4, 51], "k_i": [67, 127, 144], "k_l": 67, "k_list": 65, "k_max": 49, "k_now": [127, 144], "k_order": 49, "k_rbf": [78, 82], "kaim": 71, "kaiming_normal_": 71, "kalman": 107, "kami\u0144ska": 63, "kangaroo": 4, "kappa": [79, 85, 86, 105, 107], "kappa_": 79, "karamani": 145, "karl": 62, "kaspar": 1, "kati": 118, "kavukcuoglu": 1, "kazantzidi": 51, "kb": [69, 119], "kb1": [77, 83], "kb2": [77, 83], "kbf": 86, "kde": [126, 134], "keegan": 1, "keep": [6, 15, 19, 22, 25, 33, 34, 37, 39, 40, 41, 43, 44, 45, 64, 69, 71, 73, 96, 98, 99, 100, 107, 109, 116, 126, 127, 128, 129, 133, 134, 135, 141, 144], "kei": [9, 11, 21, 22, 23, 24, 34, 43, 44, 45, 48, 58, 62, 63, 65, 67, 69, 71, 77, 79, 82, 83, 85, 88, 102, 106, 107, 109, 116, 126, 128, 135, 136, 138, 141], "keith": 1, "kejzlar2019bayesian": 48, "kejzlar2020": 48, "kennedi": [1, 103], "kept": [9, 23, 30, 44, 56, 107, 109, 144], "kera": [64, 69, 70, 72, 76, 118], "kern": [77, 78, 79, 83, 92], "kern1": [77, 83], "kern2": [77, 83], "kernel": [47, 77, 79, 80, 83, 86, 87, 92, 102, 103, 105, 116, 126, 136], "kernel_": [80, 81, 82], "kernel_func": 105, "kernel_rbf": 82, "kernelspec": 0, "ket": 47, "kev": 115, "keyboard": 116, "keyword": [94, 116, 120, 132], "kg": [103, 105], "ki": [65, 107], "kick": 73, "kill": 33, "kilomet": 77, "kind": [8, 19, 34, 58, 64, 66, 67, 73, 76, 78, 82, 88, 97, 98, 100, 134, 143], "kinet": [44, 45, 130, 133], "king": 1, "kingma": 1, "kingmaba14": [1, 99], "kj": [67, 68, 109], "kk": 107, "kl": 72, "km": [7, 41, 77], "kmax": 49, "knew": [39, 129, 134], "knn_classifi": 65, "know": [3, 4, 7, 8, 9, 11, 13, 16, 17, 18, 19, 21, 22, 23, 25, 30, 31, 34, 40, 41, 42, 47, 48, 56, 59, 63, 64, 65, 72, 73, 79, 81, 107, 113, 115, 116, 118, 127, 128, 135, 136, 138, 141, 144], "knowledg": [4, 7, 8, 9, 11, 13, 16, 21, 25, 27, 34, 37, 39, 40, 41, 43, 44, 46, 47, 53, 56, 58, 59, 60, 61, 64, 67, 73, 90, 100, 103, 106, 112, 129, 133, 134], "known": [4, 7, 8, 16, 17, 25, 29, 34, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 53, 60, 62, 63, 65, 66, 67, 68, 71, 72, 73, 75, 77, 78, 79, 80, 82, 83, 85, 88, 90, 95, 97, 98, 99, 100, 102, 109, 112, 124, 125, 126, 133, 135, 138, 143], "knuth": 135, "ko": 96, "kochurov": [73, 93], "koh": 48, "kohn": 47, "kolmogorov": [8, 25], "kondev": [1, 115], "korai": 1, "kp": [127, 144], "kr": 132, "kramer": 1, "krasser": 72, "krgb15": [1, 72], "krishak": 51, "kroneck": 7, "kucukelbir": [1, 72], "kullback": 4, "kutta": [130, 132], "kwarg": [34, 41, 50, 98, 108, 133, 134], "kwd": 108, "kx": [77, 83], "l": [1, 4, 7, 13, 19, 34, 35, 38, 39, 41, 44, 53, 67, 73, 82, 85, 86, 88, 92, 93, 102, 105, 112, 129, 130, 131, 132, 134, 143, 145], "l1": [67, 73], "l1_ratio": 70, "l2": [70, 73, 74], "l_": 67, "l_1": 88, "l_2": 88, "l_cumsum": 41, "l_h": 105, "l_i": 85, "l_j": [67, 68], "l_opt": 82, "l_pt": 42, "l_v": 105, "l_x": 53, "l_y": 53, "la": [34, 109], "la_i": 68, "la_k": 68, "lab": [41, 51, 64, 105], "label": [3, 5, 7, 9, 15, 17, 19, 29, 30, 33, 34, 35, 37, 38, 40, 41, 42, 43, 46, 47, 48, 49, 50, 53, 63, 64, 65, 67, 69, 70, 71, 72, 73, 75, 76, 77, 80, 81, 82, 88, 93, 95, 96, 97, 98, 99, 100, 102, 105, 108, 109, 111, 112, 114, 115, 116, 117, 125, 126, 129, 131, 132, 134, 135, 138, 143, 144], "labels": 33, "labels_corn": 96, "labor": 64, "laboratori": 16, "lack": [4, 8, 40, 66, 100, 102, 112], "ladder": [50, 51, 96], "lag": [44, 125, 126, 141], "lagrang": [4, 5], "lagrangian": [17, 131], "lai": [25, 34], "lam": 143, "lambda": [3, 5, 33, 35, 38, 53, 66, 70, 77, 105, 109, 115, 133, 138, 143], "lambda_": 53, "lambda_0": [4, 53, 138], "lambda_1": [4, 35], "lambda_2": 35, "lambda_i": 53, "lambda_mat": 49, "lambda_mat_inv": 49, "lambdas0": 5, "lambdas_min": 5, "land": 8, "landmark": 79, "landscap": 44, "lang": 1, "langermann": 92, "langevin": 136, "langl": [4, 19, 37, 42, 45, 51, 85, 128, 135, 141], "languag": [0, 34, 43, 58, 62, 63, 64, 65, 71, 76, 90, 96, 99, 116, 118, 134, 135], "lapack": 118, "laplac": [8, 34, 51, 62, 72, 95], "laplacepropos": 133, "laps": 56, "larg": [3, 4, 7, 17, 19, 25, 29, 33, 34, 37, 38, 40, 41, 44, 45, 46, 47, 48, 51, 53, 55, 58, 60, 62, 64, 67, 68, 71, 72, 73, 89, 97, 99, 100, 106, 109, 111, 112, 126, 128, 131, 135, 136, 138, 143], "larger": [4, 23, 25, 29, 33, 35, 37, 38, 40, 41, 45, 46, 51, 53, 66, 75, 77, 78, 80, 82, 86, 103, 107, 108, 126, 133, 136], "largest": [4, 41, 44, 63, 66, 69, 78, 82, 107, 109, 135, 145], "lasagn": 73, "laser": [51, 138], "last": [15, 16, 32, 34, 35, 37, 44, 48, 50, 51, 56, 64, 66, 68, 69, 70, 72, 73, 75, 76, 78, 92, 93, 95, 96, 98, 105, 108, 109, 112, 115, 116, 119, 126, 131, 133, 136, 138, 140], "last_nam": 116, "lastli": 56, "later": [9, 10, 11, 19, 25, 33, 34, 35, 38, 40, 41, 46, 63, 64, 67, 73, 78, 82, 88, 93, 95, 97, 98, 100, 103, 115, 116, 117, 119, 124, 125, 126, 128, 136, 138, 141], "latest": [1, 41, 70, 71, 133, 134, 145], "latex": [0, 40, 41, 42, 49, 95, 108, 116, 117, 124], "latex_macro": 0, "latin": [47, 53, 72, 79], "latter": [24, 34, 42, 43, 48, 49, 51, 53, 62, 66, 85, 86, 99, 100, 103, 106, 107, 115, 126, 138], "lattic": [44, 67], "launch": 62, "laundri": 128, "law": [39, 51, 62, 63, 64, 76, 102, 112, 129, 134], "lawrenc": [77, 83], "lawyer": 62, "lay": 0, "layer": [67, 68, 69, 70, 71, 72, 73, 93, 102, 111], "layout": [5, 9, 118], "lbfg": [70, 81], "lbrace": 48, "lcb": 92, "ldot": [7, 15, 17, 18, 19, 23, 29, 33, 34, 35, 37, 39, 46, 47, 48, 51, 52, 53, 66, 67, 82, 86, 88, 90, 92, 96, 98, 100, 107, 112, 120, 127, 128, 129, 130, 134, 135, 136, 138, 141, 143, 144], "le": [4, 7, 25, 34, 96], "lead": [7, 15, 22, 23, 25, 37, 38, 40, 43, 46, 47, 48, 49, 53, 55, 56, 57, 59, 62, 63, 64, 66, 67, 68, 71, 72, 73, 75, 88, 94, 99, 102, 103, 105, 107, 112, 115, 116, 118, 125, 128], "leaki": [67, 70, 111], "leaky_relu": 111, "leakyrelu": [71, 111], "leap": 34, "leapfrog": [44, 130, 132], "leapfrog_energy_test_1": 132, "leapfrog_orbit_1": 132, "learn": [1, 8, 17, 23, 25, 29, 34, 35, 39, 41, 47, 50, 56, 57, 58, 59, 61, 62, 69, 72, 75, 81, 85, 86, 95, 98, 99, 100, 102, 103, 106, 109, 113, 115, 116, 118, 125, 126, 129, 134, 135], "learnabl": 75, "learner": 73, "learning_curv": 97, "learning_r": 99, "learningfromdata": [104, 109, 119], "least": [4, 7, 8, 9, 16, 19, 23, 30, 37, 39, 43, 44, 46, 59, 62, 65, 66, 69, 88, 94, 95, 100, 105, 109, 112, 114, 129, 133, 134, 143], "leav": [23, 25, 38, 44, 51, 52, 66, 68, 75, 95, 129, 130, 133, 134], "lebesgu": 4, "lec": [45, 47, 52], "lectur": [1, 3, 33, 43, 45, 46, 53, 56, 63, 64, 66, 67, 68, 70, 72, 88, 92, 95, 97, 100, 109, 115, 116, 125, 141], "lecturenot": 109, "lee": [1, 73], "left": [0, 3, 4, 7, 9, 10, 13, 16, 17, 19, 22, 24, 25, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 56, 64, 65, 66, 67, 68, 72, 78, 81, 82, 85, 88, 92, 94, 95, 96, 97, 98, 99, 100, 102, 103, 107, 108, 109, 112, 125, 126, 127, 128, 129, 132, 133, 134, 135, 138, 141, 143, 144], "leftarrow": [68, 138], "leftmost": 107, "leftrightarrow": [7, 35, 99, 107, 138], "leg": 9, "legal": 8, "legend": [0, 5, 7, 9, 17, 29, 33, 34, 37, 38, 49, 70, 71, 73, 76, 77, 80, 81, 82, 83, 88, 93, 95, 98, 105, 108, 109, 111, 112, 115, 116, 117, 125, 126, 131, 132, 135, 143, 144], "legendr": [100, 131], "lemaitr": [80, 81], "lemaitre58": [80, 81], "len": [5, 25, 30, 34, 37, 38, 41, 42, 49, 50, 65, 70, 77, 78, 79, 82, 83, 95, 96, 98, 105, 109, 115, 118, 125, 126, 129, 132, 133, 134, 143], "lend": 43, "length": [1, 7, 8, 23, 34, 38, 42, 44, 47, 51, 65, 77, 78, 79, 82, 83, 85, 86, 88, 95, 96, 99, 103, 105, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 143], "length_scal": [80, 81, 82, 105], "length_scale_bound": [80, 81], "lengthscal": [77, 78, 79, 82, 83, 92], "lenp": 47, "leprechaun": 7, "leq": [7, 9, 11, 13, 17, 23, 29, 35, 38, 44, 46, 49, 51, 53, 65, 66, 82, 95, 96, 99, 103, 112, 127, 135, 136, 138, 141, 143, 144], "less": [4, 11, 21, 37, 38, 44, 52, 53, 58, 60, 62, 63, 66, 67, 80, 95, 109, 112, 115, 118, 125, 126, 136, 141], "lesson": [12, 63], "lesssim": 45, "let": [4, 6, 7, 8, 9, 11, 15, 16, 19, 25, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 53, 59, 63, 64, 65, 66, 67, 68, 69, 71, 72, 76, 77, 78, 80, 82, 83, 85, 86, 88, 95, 96, 97, 98, 99, 100, 103, 105, 109, 112, 115, 116, 117, 118, 125, 126, 128, 129, 130, 133, 134, 135, 136, 138, 141, 143], "lett": 1, "letter": [23, 88, 112], "level": [8, 9, 16, 19, 29, 35, 37, 40, 41, 43, 47, 53, 56, 59, 63, 65, 72, 73, 74, 80, 82, 112, 114, 118, 125, 128, 138], "level_1sigma": 41, "leverag": [48, 71, 103], "lewi": 58, "lfd": 104, "lfd_develop": 122, "lfd_for_physicist": 119, "li": [7, 8, 9, 25, 30, 46, 47, 53, 62, 63, 78, 82, 114, 118], "li6e_nnloopt_nmax10": [78, 82], "lib": [50, 81, 96, 108, 134], "libcxx": 119, "librari": [17, 26, 34, 56, 64, 72, 73, 76, 93, 99, 115, 116, 118, 119, 135], "licat": 43, "licens": [56, 76, 80, 81, 119, 135], "lie": [25, 51, 53, 66], "life": [37, 56, 64, 67, 98, 115], "light": [7, 17, 25, 30, 34, 47, 53, 56, 58, 73, 79, 93, 112], "lightest": 115, "lightgrai": 41, "lighthous": 136, "lighthouse_stat": 42, "like": [0, 4, 9, 11, 12, 16, 17, 18, 19, 21, 22, 23, 30, 31, 33, 34, 35, 37, 39, 41, 42, 43, 44, 47, 48, 50, 51, 52, 56, 58, 62, 63, 64, 65, 66, 67, 71, 73, 77, 78, 79, 82, 83, 86, 88, 92, 93, 99, 100, 102, 107, 109, 112, 113, 115, 116, 118, 119, 125, 126, 127, 128, 129, 130, 133, 134, 135, 138, 141, 144], "likelihoo": [50, 51], "likelihood": [4, 7, 8, 9, 10, 16, 23, 25, 29, 30, 37, 39, 40, 42, 44, 46, 47, 49, 51, 52, 53, 66, 72, 73, 74, 77, 80, 81, 83, 85, 93, 94, 96, 105, 109, 112, 124, 125, 126, 129, 133, 134, 136, 140], "likewis": 108, "lim_": [7, 44, 138], "limit": [1, 4, 7, 8, 9, 17, 23, 26, 30, 34, 37, 40, 42, 43, 51, 53, 58, 61, 65, 66, 76, 78, 82, 89, 94, 98, 100, 103, 108, 111, 112, 114, 135, 136, 143], "limits_": 44, "lin": [78, 82], "linalg": [34, 49, 50, 65, 77, 78, 82, 83, 95, 98, 105, 109, 118], "lindholm": 1, "lindsei": 1, "lindsten": 1, "line": [0, 4, 7, 9, 10, 15, 19, 21, 23, 34, 35, 37, 38, 44, 50, 53, 64, 65, 66, 69, 70, 72, 73, 76, 77, 78, 79, 82, 83, 86, 88, 91, 93, 94, 98, 102, 108, 112, 114, 115, 116, 119, 120, 124, 126, 127, 128, 129, 131, 132, 133, 134, 136, 140, 141, 144], "line1": 9, "line2": 9, "line3": 9, "linear": [1, 3, 7, 16, 27, 28, 38, 40, 41, 45, 47, 48, 50, 53, 55, 64, 66, 70, 71, 72, 73, 75, 77, 78, 82, 83, 86, 88, 95, 97, 99, 101, 102, 105, 107, 108, 111, 115, 116, 120, 128, 140], "linear_model": [70, 74, 115], "linearli": [29, 34, 46, 53, 73, 85, 93, 96, 98, 100], "linearregress": 115, "liner": [65, 117], "lineshap": 53, "linestyl": [9, 34, 37, 40, 42, 49, 71, 77, 80, 81, 83, 98, 116, 126, 131, 132], "linewidth": [17, 37, 38, 40, 42, 49, 50, 112, 134], "link": [0, 1, 8, 17, 43, 44, 56, 67, 112, 113, 114, 116, 130], "linspac": [0, 5, 7, 9, 17, 25, 29, 30, 33, 34, 38, 40, 41, 42, 49, 71, 77, 78, 79, 80, 81, 82, 83, 88, 95, 96, 98, 105, 108, 111, 112, 114, 116, 117, 118, 126, 132, 135, 143], "linux": [93, 105, 116, 119], "liouvil": [44, 130], "liouville_test": 131, "liouville_theorem_visu": 130, "liquid": 115, "list": [1, 7, 9, 17, 25, 30, 37, 41, 42, 43, 44, 46, 56, 61, 62, 63, 65, 67, 75, 82, 93, 96, 103, 105, 108, 111, 112, 114, 115, 116, 119, 120, 122, 126, 128, 133, 135, 138, 140], "list_a": 117, "list_b": 117, "list_lik": 82, "liter": 38, "literatur": [10, 17, 23, 38, 43, 47, 48, 51, 56, 67, 68, 85, 88, 94, 104], "littl": [8, 40, 53, 68, 71, 72, 109, 125, 130], "liu": 1, "live": [40, 48, 63, 130, 135, 136], "liz": 118, "ll": [3, 6, 7, 9, 10, 11, 15, 17, 19, 21, 23, 25, 30, 31, 33, 34, 38, 39, 40, 41, 42, 45, 49, 52, 59, 65, 67, 71, 77, 78, 79, 82, 83, 85, 93, 94, 95, 103, 107, 108, 109, 112, 114, 116, 119, 125, 126, 127, 128, 129, 130, 134, 135, 136, 138, 141, 144], "ln": [4, 37, 44, 51, 67, 95, 96, 112], "lnlike": [50, 96], "lnpost": [38, 50, 125], "lnprob": [50, 96], "lnprobabl": [38, 41, 50, 125], "lnz": 96, "lnzl": 96, "lo95": [77, 83], "load": [69, 70, 77], "load_data": [69, 76], "load_model": 69, "loadtxt": [78, 82], "loc": [0, 7, 9, 17, 29, 33, 34, 38, 42, 50, 70, 76, 77, 80, 81, 82, 83, 88, 95, 96, 108, 112, 115, 132, 135, 143, 144], "local": [4, 17, 48, 51, 67, 73, 75, 88, 92, 97, 102, 105, 112, 115, 119, 135], "locat": [6, 16, 34, 40, 42, 43, 53, 77, 82, 83, 92, 94, 95, 96, 112, 118, 119, 122, 128, 129, 134, 135], "log": [3, 5, 6, 17, 34, 35, 37, 38, 39, 40, 41, 42, 44, 49, 50, 51, 53, 66, 71, 72, 74, 77, 79, 81, 83, 88, 94, 95, 96, 105, 118, 125, 129, 130, 133, 134], "log10": 77, "log_evidence_estim": 96, "log_flat_prior": [6, 40], "log_jeffreys_prior": 6, "log_l_pt": 42, "log_likelihood": [37, 38, 40, 41, 42, 50, 77, 95, 96, 105, 124, 125, 129, 134], "log_likelihood_singl": 41, "log_likelihood_v": 105, "log_likelihood_valu": 105, "log_marginal_likelihood": 81, "log_p1": [40, 41], "log_p1_1": 41, "log_p2": 40, "log_posterior": [37, 38, 41, 50, 96, 105, 124, 125, 128, 129, 134], "log_posterior_cauchi": 38, "log_posterior_conserv": 38, "log_posterior_gaussian": 38, "log_prior": [6, 37, 38, 41, 42, 50, 96, 105, 124, 125, 129, 134], "log_prior_": 105, "log_prior_cbar": 105, "log_prior_l": 105, "log_prior_param": 105, "log_prior_phi": 105, "log_prior_pt": 42, "log_prior_r": 105, "log_prior_theta": 105, "log_prior_v": 105, "log_priors_mdgp": 105, "log_priors_model": 105, "log_priors_thetaphi": 105, "log_prob_cutoff": 41, "log_prob_max": 41, "log_symmetric_prior": [6, 40], "logaddexp": [38, 50], "logarithm": [3, 4, 19, 37, 38, 40, 41, 53, 71, 72, 88, 95, 96, 124], "logic": [1, 4, 8, 9, 11, 16, 20, 53, 56, 62, 64, 127, 144], "logical_and": [37, 112, 129, 134], "logist": [63, 65, 67, 68, 73, 89, 93], "logisticregressioncv": 70, "logisticregressioncvifit": 70, "logit": [65, 67, 88], "logl": [41, 50, 96, 105], "logl1": 38, "logl2": 38, "loglarg": [50, 96], "loglikelihood": 96, "loglkwarg": [50, 96], "loglog": [131, 135], "logp": [6, 38, 50, 96, 105, 133], "logparg": [50, 96], "logpkwarg": [50, 96], "logpr": 6, "logz": 105, "logz_err": 105, "long": [15, 16, 17, 21, 34, 37, 38, 43, 46, 47, 51, 52, 53, 56, 66, 67, 94, 112, 115, 118, 119, 126, 128, 134, 138], "longer": [8, 12, 47, 51, 66, 67, 88, 103, 125, 128, 133], "longleftarrow": [120, 130], "longrightarrow": [0, 3, 11, 12, 13, 15, 16, 17, 19, 24, 31, 32, 33, 34, 35, 37, 51, 52, 120, 128, 141], "loocv": 66, "look": [0, 2, 9, 11, 13, 16, 17, 18, 19, 20, 26, 27, 31, 33, 34, 35, 37, 38, 39, 42, 44, 49, 50, 51, 52, 53, 55, 58, 63, 67, 69, 76, 77, 78, 82, 83, 86, 90, 92, 96, 98, 99, 100, 107, 109, 112, 115, 116, 119, 123, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138, 139, 141, 142, 144], "loop": [34, 68, 71, 99, 117, 127, 129, 134, 144], "loos": 67, "lorentzian": 53, "lose": [48, 53, 143], "loss": [8, 69, 71, 72, 75, 76, 82, 88, 93, 99, 101, 102, 109], "lost": [38, 107, 109], "lot": [7, 19, 22, 29, 33, 63, 73, 93, 117, 126, 136, 141], "love": 62, "low": [1, 11, 31, 34, 43, 44, 45, 46, 47, 50, 51, 63, 66, 72, 79, 91, 96, 98, 109, 118, 128, 131, 133, 135, 136], "lower": [19, 25, 34, 38, 42, 50, 51, 53, 63, 68, 71, 73, 76, 103, 105, 111, 112, 117, 129, 133, 134, 138, 141], "lowest": [47, 94, 138], "lp": 105, "lr": 71, "lra": [0, 3, 4, 51, 52, 79, 86, 90, 107, 128, 130, 136, 141], "lstsq": 109, "lt": [78, 133, 141], "luck": 16, "lvert": [72, 99, 103], "lw": [9, 29, 34, 38, 42, 65, 88, 98, 109, 111, 112, 114, 115, 116, 126, 143], "lwahlstromlschon21": [1, 63], "m": [1, 4, 7, 16, 34, 35, 37, 38, 39, 40, 41, 44, 45, 46, 49, 50, 51, 52, 53, 66, 67, 70, 71, 72, 77, 78, 79, 82, 83, 85, 86, 90, 92, 95, 96, 98, 99, 100, 103, 105, 107, 109, 111, 112, 115, 116, 125, 129, 130, 131, 133, 134, 136, 138], "m_": [52, 68, 130], "m_0": 95, "m_1": [0, 7, 52, 79, 86, 95], "m_2": [7, 52, 79, 86], "m_h": 115, "m_i": [4, 7, 34, 46, 98, 130], "m_j": [4, 7], "m_k": [52, 65], "m_l": 68, "m_n": 115, "m_p": 115, "ma_theta0": 125, "ma_theta1": 125, "mac": [93, 116, 119], "mac03": [1, 56, 72], "mach": 1, "machin": [1, 34, 47, 50, 56, 57, 62, 66, 67, 71, 72, 85, 86, 87, 88, 93, 95, 98, 99, 100, 102, 106, 107, 109, 113, 115, 125, 126, 135, 140], "machineri": [41, 112], "mackai": [1, 56, 72], "mackei": [1, 129, 134, 141], "maco": [105, 119], "macosx": [73, 93], "macroscop": 4, "made": [7, 9, 11, 33, 34, 41, 43, 44, 51, 52, 53, 56, 61, 63, 64, 71, 72, 75, 80, 85, 88, 100, 101, 103, 109, 114, 115, 116, 117, 126, 135, 143], "mae": [65, 66, 67], "magazin": 110, "magic": [116, 117, 126], "magnifi": 107, "magnitu": 79, "magnitud": [7, 37, 46, 47, 49, 51, 53, 63, 71, 96, 97, 105, 109], "mahalanobi": 105, "mahlet": 1, "mai": [1, 7, 18, 19, 21, 22, 23, 34, 37, 43, 46, 47, 48, 49, 51, 53, 56, 58, 59, 61, 62, 63, 64, 66, 67, 68, 75, 76, 77, 83, 88, 94, 96, 99, 106, 108, 109, 113, 115, 116, 119, 127, 131, 136, 144], "main": [8, 43, 46, 47, 53, 72, 75, 79, 88, 90, 99, 109, 133, 135], "mainli": [43, 45, 63, 64, 73, 99, 100, 115, 126], "maintain": [35, 44, 48, 67, 71, 105, 118, 138], "maiti": 1, "major": [35, 38, 63, 65, 73, 99, 115], "make": [0, 4, 6, 7, 8, 9, 11, 16, 17, 18, 19, 23, 24, 29, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 62, 63, 64, 65, 66, 67, 70, 72, 73, 74, 75, 77, 78, 79, 82, 83, 85, 88, 89, 92, 93, 94, 95, 96, 97, 98, 99, 100, 109, 111, 112, 115, 116, 117, 120, 124, 125, 126, 127, 129, 130, 133, 134, 135, 136, 140, 143, 144], "make_blob": 74, "make_circl": 93, "make_data": [40, 125], "make_dataset": 37, "make_fig": 37, "make_matric": 49, "make_moon": [70, 73, 93], "make_plot": 111, "makedir": 115, "mala": 136, "male": [63, 112], "manag": [9, 44, 48, 63, 75, 108, 119, 140], "mandat": 59, "mani": [4, 7, 8, 9, 11, 12, 17, 19, 21, 23, 25, 27, 29, 30, 32, 33, 34, 35, 39, 40, 43, 44, 45, 47, 48, 49, 51, 53, 56, 57, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 77, 78, 79, 82, 83, 88, 91, 93, 97, 98, 99, 100, 102, 103, 104, 108, 111, 112, 115, 116, 117, 118, 119, 126, 127, 128, 129, 130, 133, 134, 135, 136, 138, 141, 143, 144], "manifest": 63, "manifestli": 47, "manifesto": 48, "manifold": 45, "manipul": [8, 20, 25, 34, 79, 86], "mankind": 8, "manner": 75, "manual": [17, 23, 43, 64, 112, 116, 120, 128, 129, 134], "manufactur": 73, "manzoni": 1, "map": [7, 8, 34, 38, 46, 48, 64, 65, 67, 72, 88, 96, 98, 100, 105, 117, 128, 130, 133, 141], "map_estim": 134, "mapsto": [48, 99], "mar": [1, 78, 115, 131], "marathon": 77, "march": [53, 115], "margin": [0, 10, 15, 16, 17, 19, 20, 22, 31, 32, 35, 37, 38, 40, 43, 44, 49, 52, 53, 72, 77, 82, 83, 85, 94, 96, 105, 106, 108, 129, 130, 134, 135, 136, 138, 141, 143, 145], "margina": 37, "marin": 1, "marina": 1, "mark": [17, 65, 108, 109, 116, 127, 144], "markdown": [120, 124], "marker": [34, 38, 49, 72, 78, 80, 82, 98, 115, 126, 127, 133, 144], "markers": [49, 80, 105], "markov": [1, 7, 16, 38, 43, 51, 125, 126, 127, 128, 129, 130, 133, 134, 141, 142, 143, 144, 145], "markovprocessexampl": 138, "markovprocessexample_corner_fig": 138, "markovprocessexample_runs_fig": 138, "martin": 72, "masquerad": 7, "mass": [1, 7, 8, 19, 23, 33, 34, 37, 43, 44, 46, 48, 51, 72, 79, 82, 98, 99, 100, 103, 105, 130, 131, 135, 136, 143], "mass16": 115, "mass16round": 115, "massag": 115, "masses2016": 115, "masseval2016": 115, "massiv": [44, 73], "master": [1, 16, 56], "match": [1, 38, 43, 55, 67, 77, 83, 103], "materi": [27, 66, 75, 106], "matern": [77, 79, 81, 83, 86], "matern32": [77, 83, 92], "matern52": [77, 79, 83], "math": [1, 5, 33, 37, 43, 73, 93, 114, 118, 127, 144], "mathbb": [0, 17, 24, 25, 34, 44, 66, 67, 72, 82, 85, 86, 88, 98, 99, 100, 109, 112, 128, 130, 143], "mathbf": [23, 34, 65, 78, 82, 85, 92, 98, 103, 109, 132], "mathcal": [0, 3, 4, 7, 13, 16, 19, 24, 29, 34, 38, 39, 40, 41, 44, 46, 47, 49, 53, 67, 72, 77, 79, 82, 83, 85, 88, 92, 95, 98, 99, 102, 103, 112, 125, 126, 129, 131, 134, 135, 136, 138, 140, 141, 143], "mathemat": [1, 8, 9, 11, 17, 19, 23, 25, 40, 56, 58, 61, 62, 64, 65, 73, 78, 82, 88, 93, 100, 101, 102, 112, 115, 126, 135], "mathematica": [1, 37, 116], "mathematician": [0, 43, 61, 62], "mathop": [34, 98, 100], "mathrm": [3, 4, 7, 9, 17, 25, 30, 33, 34, 37, 41, 44, 45, 46, 47, 48, 53, 64, 65, 66, 67, 72, 75, 78, 82, 85, 88, 95, 96, 98, 99, 100, 105, 109, 112, 115, 126, 138], "matlab": 116, "matmul": [34, 65, 71, 98, 135], "matplotlib": [0, 3, 5, 6, 7, 9, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 50, 65, 69, 70, 71, 73, 76, 77, 78, 80, 81, 82, 83, 88, 92, 93, 94, 95, 96, 98, 105, 108, 109, 111, 112, 114, 115, 117, 119, 120, 125, 126, 127, 129, 131, 132, 133, 134, 135, 138, 143, 144], "matric": [34, 45, 47, 49, 52, 67, 75, 77, 79, 82, 83, 85, 86, 88, 98, 107, 115, 135, 138], "matrix": [7, 35, 38, 41, 44, 45, 47, 49, 52, 53, 63, 65, 66, 68, 71, 72, 73, 75, 77, 78, 79, 80, 82, 83, 86, 88, 93, 95, 97, 99, 102, 104, 105, 112, 115, 120, 128, 130, 135, 143], "matrix_larg": 118, "matrix_large_spars": 118, "matrix_rank": 118, "matshow": [77, 83], "matt": 56, "matter": [19, 35, 37, 44, 47, 53, 62, 136, 138], "matthew": 1, "matur": 47, "max": [4, 7, 9, 23, 29, 33, 35, 37, 40, 41, 42, 44, 49, 50, 53, 67, 69, 70, 75, 76, 78, 82, 92, 94, 95, 96, 108, 114, 115, 116, 118, 120, 127, 135, 143, 144], "max68": 112, "max90": 112, "max_": 46, "max_arg": 41, "max_height": [9, 114], "max_i_num": 135, "max_it": [50, 70], "max_lag": [125, 126], "max_lik": 105, "max_mode_theta": 41, "max_n": [33, 37], "max_n1": 37, "max_n2": 37, "max_norm_pt": 108, "max_of_mod": 41, "max_param": 105, "max_pooling2d": 76, "max_pooling2d_1": 76, "max_posterior": 42, "max_sigma_v": 108, "max_theta": [129, 134], "maxa": 7, "maxent": 5, "maxim": [8, 13, 35, 38, 39, 40, 41, 49, 51, 72, 73, 77, 83, 85, 88, 93, 95, 99, 129, 134], "maxima": [53, 115], "maximimum": 72, "maximum": [7, 8, 9, 13, 16, 17, 19, 25, 30, 33, 34, 35, 37, 38, 39, 40, 42, 43, 46, 47, 49, 51, 53, 55, 62, 72, 73, 75, 78, 79, 80, 90, 92, 96, 105, 108, 109, 111, 115, 124, 129, 133, 134], "maxlik": 35, "maxlike_result": [129, 134], "maxpooling2": 76, "maxpooling2d": 76, "may22": [1, 46], "mayb": [10, 31, 90, 112, 133, 136], "mb": [99, 119], "mb_k": 65, "mbgd": 99, "mbox": [9, 11, 13, 15, 17, 19, 30, 35, 37, 38, 42, 47, 78, 86, 107, 125, 127, 144], "mbpt": 47, "mbw": [1, 66, 102], "mc": [0, 116, 124, 128, 135], "mcculloch": 67, "mcelreath": [44, 130, 135, 136], "mchain": 125, "mcmc": [1, 6, 7, 38, 41, 42, 43, 45, 46, 50, 51, 72, 73, 93, 105, 123, 129, 130, 133, 134, 137, 142, 145], "mcmc_data0": 50, "mcmc_data_nt": 50, "mcmc_random_walk_and_sampl": 136, "mcmc_sampling_i": 141, "mcmc_sampling_ii": [130, 140], "mcmcsampl": [129, 134], "mcse_mean": [133, 134], "mcse_sd": [133, 134], "md": [0, 103, 105], "md2": 105, "md_kernel": 105, "mdc": 105, "mdf": [1, 45], "mdn": 73, "me": [21, 22, 78, 82, 111], "mead": 5, "mean": [0, 6, 7, 9, 11, 12, 13, 16, 17, 18, 19, 21, 23, 24, 25, 29, 30, 31, 34, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50, 51, 52, 53, 58, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 83, 86, 88, 93, 94, 95, 96, 97, 98, 100, 102, 103, 105, 107, 108, 109, 111, 115, 117, 118, 124, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138, 140, 141, 143, 144, 145], "mean1000": 144, "mean100000": 144, "mean100000b": 144, "mean100000c": 144, "mean1000b": 144, "mean1000c": 144, "mean16000": 144, "mean16000b": 144, "mean16000c": 144, "mean4000": 144, "mean4000b": 144, "mean4000c": 144, "mean_": 105, "mean_68cr": 38, "mean_absolute_error": 115, "mean_dist": 42, "mean_k": 65, "mean_posterior": 42, "mean_predict": 80, "mean_squared_error": 115, "meaning": [43, 46, 69, 100, 103], "means_arrai": 33, "meant": 64, "meanwhil": 9, "measur": [4, 7, 8, 16, 23, 25, 34, 37, 38, 39, 40, 41, 43, 46, 49, 51, 53, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 79, 96, 97, 98, 100, 103, 105, 106, 108, 115, 117, 125, 129, 134, 138, 143], "mechan": [4, 16, 22, 23, 34, 43, 47, 62, 64, 67, 71, 98, 106, 110, 119, 127, 138, 141, 144], "medal": 77, "media": 1, "median": [9, 17, 18, 25, 30, 43, 108], "medic": [20, 63, 112], "medicin": [48, 64, 67, 108], "mediev": 7, "mediocr": 48, "medium": 114, "meet": [56, 63, 118], "mehta": [1, 66], "mel": 47, "melendez": [1, 56, 78], "member": [22, 51, 63, 125], "memor": 102, "memori": [67, 71, 115, 118], "men": [77, 112], "meng": 1, "mention": [8, 39, 43, 48, 51, 66, 67, 73, 97, 129, 134], "menu": 119, "mere": [47, 103], "merg": 7, "merger": 56, "merit": [8, 53], "mermim": 110, "mermin": 110, "merriam": 100, "mesh": [5, 9, 30, 47, 112], "meshgrid": [37, 50, 70, 78, 82, 112], "messag": [78, 105, 116, 119], "messeng": 62, "met": 43, "meta": 19, "metadata": [43, 108], "meterologist": 138, "method": [1, 4, 5, 7, 8, 16, 17, 19, 25, 34, 38, 39, 43, 47, 48, 50, 51, 56, 58, 60, 61, 62, 63, 64, 65, 66, 67, 72, 73, 77, 83, 88, 89, 92, 93, 95, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 109, 112, 115, 116, 118, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 138, 142, 143, 144, 145], "methodologi": 46, "metr": 8, "metric": [46, 63, 65, 66, 69, 76, 97, 100, 112, 115, 117], "metropoli": [44, 50, 51, 125, 128, 130, 133, 142], "metropolis_poisson_exampl": [136, 141], "metropolis_r": [127, 144], "metzen": [80, 81], "mev": [47, 78, 82, 115], "mew": [77, 83], "mg": [100, 103], "mgl": 131, "mgrid": [34, 65, 73, 93], "mh": [51, 128, 130, 133], "mi": [43, 46], "michael": [1, 46, 75], "michigan": 56, "micro": [4, 115], "micron": 51, "microst": 4, "mid": [9, 30, 31, 32, 33, 37, 38, 40, 41, 49, 62, 78, 95, 103, 125], "middl": [12, 56, 112], "might": [3, 4, 7, 8, 19, 21, 23, 25, 29, 31, 34, 38, 39, 40, 41, 43, 44, 45, 46, 48, 51, 52, 53, 56, 60, 62, 63, 64, 65, 66, 67, 71, 73, 81, 85, 92, 94, 95, 96, 98, 99, 100, 107, 109, 112, 114, 116, 117, 118, 119, 125, 126, 129, 133, 134, 135, 136, 138, 143], "mild": 65, "mill": [58, 109], "millimet": 51, "million": [7, 63, 115], "mimic": [67, 88], "min": [4, 7, 9, 34, 41, 42, 44, 49, 51, 53, 70, 77, 78, 82, 95, 96, 98, 100, 114, 115, 116, 118, 120, 130, 135, 138, 143], "min68": 112, "min90": 112, "min_": 109, "min_height": [9, 114], "min_obj": 92, "min_param": 105, "min_theta": [129, 134], "min_val": 92, "min_x": 92, "mina": 145, "mind": [9, 25, 30, 40, 43, 44, 63, 64, 102, 129, 134], "mine": 1, "minfunc": [40, 41], "mini": [49, 66, 68, 97, 145], "minibatch": [73, 93], "minibatch_i": 73, "minibatch_x": 73, "miniconda": 119, "miniconda3": [50, 81, 96, 108, 134], "minim": [8, 11, 22, 29, 34, 38, 40, 41, 47, 49, 51, 62, 65, 66, 67, 68, 69, 71, 72, 91, 92, 97, 98, 101, 102, 105, 109, 136, 141], "minima": [73, 88, 97, 99], "minimum": [4, 5, 7, 9, 34, 39, 42, 51, 65, 69, 78, 92, 97, 98, 99, 105, 111, 114, 129, 134, 136, 138], "minka": 95, "minor": [5, 35, 117], "minu": [19, 29, 40, 41, 44, 72, 130], "minut": [38, 53, 77, 79, 105, 126, 143], "mirror": [51, 138], "misclassif": [63, 66], "misclassifi": [65, 66], "misconcept": 56, "miser": 7, "misfit": 43, "misinterpret": 53, "mislead": [43, 48], "mismatch": [16, 34, 53], "miss": [25, 31, 43, 44, 46, 63, 100, 103, 135], "misspel": 116, "mistak": 7, "misus": 43, "mit": [1, 135], "mith": 118, "mitig": [45, 63], "mix": [44, 51, 54, 55, 66, 67, 125, 128, 133], "mixtur": [38, 50, 72], "mkdir": 115, "mkl": 34, "ml": [60, 63, 73, 77, 83, 88, 89, 97, 109], "mle": [38, 41, 51, 52, 72, 88, 107, 109], "mlmodel": [64, 65], "mloutput": [64, 65, 66], "mloutput_": 65, "mloutput_i": 65, "mltestoutput": [65, 66], "mm": 138, "mnemon": [0, 22], "mnist": 69, "mock": 103, "mod": [0, 118], "modal": [51, 145], "mode": [0, 9, 17, 18, 25, 29, 30, 34, 40, 41, 42, 46, 47, 50, 51, 53, 56, 67, 71, 96, 108, 116, 125, 135, 141], "model": [0, 1, 4, 8, 19, 20, 23, 24, 28, 35, 39, 44, 46, 47, 50, 51, 52, 55, 58, 59, 60, 61, 62, 63, 65, 70, 71, 79, 80, 81, 88, 90, 91, 92, 96, 97, 99, 102, 104, 106, 107, 109, 111, 112, 115, 126, 127, 128, 129, 134, 135, 136, 138, 140, 144], "model_func": 96, "model_height": 105, "model_i": 96, "model_param_bound": 105, "model_select": [73, 74, 93, 115], "model_typ": [34, 92, 98], "modeldiscrep": 105, "modeloutput": [34, 98], "modeloutput_i": 34, "moder": 48, "modern": [1, 7, 51, 64, 88, 118, 125], "modif": [43, 51, 53, 72, 95, 126], "modifi": [10, 25, 30, 34, 37, 38, 40, 41, 42, 50, 51, 56, 63, 66, 67, 68, 70, 71, 72, 77, 83, 93, 95, 96, 99, 105, 113, 116, 117, 126, 133], "modul": [6, 8, 50, 69, 70, 71, 73, 81, 93, 96, 105, 111, 112, 116, 118, 119, 122, 129, 134, 138, 143], "modulenotfounderror": [69, 70, 73, 93, 116], "modulu": 7, "molecular": 44, "mom": [44, 99], "mom_": 44, "mom_i": 44, "moment": [67, 71, 99, 143], "momenta": 130, "momentum": [44, 67, 99, 130, 131], "monetari": 43, "monitor": [43, 44, 62, 66, 67, 69, 71, 97, 128, 141], "monk": 53, "monoton": [4, 67, 99, 141], "mont": [1, 7, 16, 43, 64, 72, 96, 105, 127, 129, 133, 134, 139, 141, 142, 143, 144, 145], "montepython": 44, "monthli": 1, "monti": 16, "moo": 62, "mor": 47, "moral": 141, "more": [0, 3, 4, 7, 8, 9, 11, 13, 15, 16, 17, 19, 20, 23, 24, 28, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 79, 81, 82, 83, 85, 89, 91, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 105, 109, 110, 112, 113, 115, 116, 117, 118, 119, 123, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 138, 140, 141, 142, 143], "more_replac": [73, 93], "moreov": [16, 43, 48, 63, 73, 75, 100, 103], "morn": 8, "morten": 56, "most": [4, 8, 11, 12, 16, 18, 19, 25, 33, 34, 37, 40, 41, 43, 44, 46, 48, 49, 50, 53, 56, 57, 58, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 76, 85, 86, 88, 93, 95, 96, 97, 99, 100, 102, 107, 108, 109, 110, 112, 115, 116, 118, 125, 129, 130, 133, 134, 135, 143], "mostli": [34, 38, 68, 73, 98, 100, 138], "mot": 44, "motion": [16, 100, 103, 105, 130, 132, 143], "motiv": [7, 16, 19, 38, 44, 48, 60, 65, 73, 88, 102, 130, 135, 140], "mount": 51, "move": [4, 9, 15, 25, 42, 44, 48, 50, 67, 68, 71, 88, 99, 114, 116, 125, 126, 128, 133, 138, 145], "movement": 126, "moviewrit": 108, "mp4": 108, "mpc": [0, 7, 41], "mpl": [108, 115], "mpl_toolkit": [37, 50, 65], "mplot3d": [37, 50, 65], "mr": 53, "mr_k": 65, "mrg_randomstream": 73, "mse": [65, 66, 67, 71], "mseloss": 71, "msg": 116, "mu": [4, 5, 7, 17, 19, 24, 33, 34, 35, 37, 39, 41, 44, 46, 52, 53, 72, 77, 78, 79, 82, 83, 85, 86, 92, 108, 109, 111, 112, 126, 127, 129, 132, 133, 134, 136, 140, 143, 144, 145], "mu0": 50, "mu1": [34, 50], "mu2": [17, 50, 108], "mu_": [53, 112, 140], "mu_0": [5, 39, 52, 53, 129, 134], "mu_est": [39, 129, 134], "mu_i": [4, 78, 82, 86, 143], "mu_interval__": 134, "mu_j": 4, "mu_k": 4, "mu_mean_prior": 133, "mu_new": 82, "mu_opt": 82, "mu_prior": 133, "mu_sampl": 92, "mu_sample_opt": 92, "mu_sd_prior": 133, "mu_tru": [35, 39, 129, 134], "mu_x": [78, 86], "mu_z": [67, 82], "much": [8, 12, 17, 25, 29, 31, 34, 35, 38, 43, 44, 45, 46, 47, 51, 52, 53, 56, 60, 62, 63, 64, 65, 66, 67, 68, 73, 93, 94, 95, 97, 98, 99, 100, 109, 112, 115, 116, 117, 124, 126, 129, 134, 135, 136, 143], "multi": [16, 26, 46, 50, 55, 59, 71, 73, 88, 91, 93, 95, 96, 118, 135, 143, 145], "multi_class": 70, "multiclass": [63, 88], "multidimension": [17, 34, 51, 67, 79, 95, 104, 115, 118, 130, 136], "multilay": [67, 71], "multimod": [18, 19, 51, 73, 96, 112, 130, 135, 136, 145], "multinest": [1, 51, 135], "multinomi": 88, "multipl": [1, 11, 16, 33, 34, 37, 39, 42, 43, 44, 46, 47, 51, 52, 55, 61, 64, 66, 67, 68, 71, 72, 79, 88, 95, 106, 107, 108, 109, 125, 128, 129, 133, 134, 135, 136, 143, 145], "multipli": [4, 5, 32, 33, 34, 38, 40, 41, 47, 49, 53, 67, 72, 77, 79, 83, 85, 109, 118, 120, 125, 128], "multiprocess": [105, 133, 134], "multivari": [4, 7, 43, 44, 49, 64, 79, 85, 133, 135, 136, 143], "multivariate_norm": [34, 65, 69, 77, 78, 82, 83, 92, 109, 112], "multivariatenormalpropos": 133, "multivers": 112, "mumv": 82, "mup": 50, "mus2": 5, "mus3": 5, "mus4": 5, "mus5": 5, "must": [4, 5, 7, 8, 16, 19, 25, 33, 34, 37, 38, 43, 44, 45, 48, 53, 58, 62, 63, 64, 65, 67, 78, 85, 92, 96, 99, 103, 105, 109, 112, 117, 118, 129, 134, 135, 136, 138, 141, 143], "mutat": 88, "mutual": [22, 23, 31, 32, 66, 76], "muvec": [78, 86], "muz": 82, "mvec": 86, "mvec_1": [79, 86], "mvec_2": 86, "mvn": 82, "mx": [40, 41, 125], "my": [0, 9, 30, 73, 119, 126], "my_ax": [111, 116], "my_bin": 33, "my_fig": [111, 116], "my_funct": [114, 116, 120], "my_metropolis_model": 133, "my_model": 133, "my_mu": 111, "my_multinorm_rv": 112, "my_norm_rv": 112, "my_normal_rv": 112, "my_nuts_model": 133, "my_output": 111, "my_rv": 112, "my_sigma": 111, "my_student_t_rv": 112, "my_suptitl": 17, "my_titl": [77, 133], "mymodel": 71, "myst": 0, "myst_nb": [3, 7, 65, 88, 112, 135, 138, 143], "mysteri": 110, "m\u00e4rten": 1, "n": [1, 3, 4, 7, 8, 9, 11, 13, 15, 17, 19, 24, 25, 29, 30, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 51, 53, 63, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 83, 88, 92, 95, 96, 97, 98, 99, 100, 102, 103, 105, 107, 108, 109, 112, 115, 117, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138, 140, 143, 144], "n_": [29, 42, 44, 45, 47, 51, 64, 66, 67, 71, 75, 78, 82, 99, 102, 141], "n_0": [35, 37, 67], "n_1": [79, 86], "n_2": [79, 86], "n_a": 8, "n_activ": 105, "n_active_mltpl": 105, "n_b": 47, "n_col": 82, "n_color": 108, "n_d": [34, 98, 99, 100], "n_dim": [49, 105], "n_eff": 105, "n_effect": 105, "n_effective_mltpl": 105, "n_epoch": 99, "n_evid": 105, "n_featur": 74, "n_gamma": 108, "n_h": 47, "n_hidden": [73, 93], "n_i": [4, 117], "n_in": 71, "n_job": 70, "n_k": [35, 37, 65], "n_l": 67, "n_max": 42, "n_max_step": 105, "n_max_valu": 42, "n_mean": 33, "n_means_arrai": 33, "n_new": 82, "n_p": [34, 98, 99], "n_prior": 105, "n_pt": [33, 37, 125, 127, 144], "n_restart": 92, "n_restarts_optim": [80, 82], "n_row": 82, "n_sampl": [73, 74, 81, 111], "n_step": 105, "n_steps_mltpl": 105, "n_total": 105, "n_trials_max": 9, "n_trials_max_w": 9, "n_uncertainty_digit": 112, "n_val": 33, "n_w": 9, "nabla": [34, 79, 96, 97, 98, 99], "nabla_": 34, "naimi": [1, 115], "naiv": [7, 43, 53, 88], "name": [0, 4, 7, 10, 17, 23, 25, 34, 39, 41, 42, 44, 49, 51, 53, 63, 64, 67, 68, 69, 70, 73, 75, 76, 77, 79, 83, 91, 93, 94, 95, 96, 98, 99, 105, 107, 109, 112, 115, 116, 118, 119, 120, 126, 128, 129, 133, 134, 136], "namespac": 116, "nan": [38, 118], "narrow": [7, 9, 11, 12, 15, 25, 29, 30, 38, 41, 53, 73, 93, 103, 135], "nasti": [9, 30], "nat": 1, "nation": 63, "nativ": 63, "natur": [1, 7, 8, 16, 25, 34, 37, 38, 42, 43, 44, 47, 49, 52, 53, 60, 62, 64, 67, 69, 71, 72, 73, 80, 86, 96, 100, 102, 103, 112, 118, 131], "navier": 67, "navig": 99, "nb": 47, "nbin": 41, "nbsp": 70, "nburn": [6, 38, 96, 105, 129, 134], "nburnin": [50, 96], "nbviewer": 70, "nc": 56, "nchain": 125, "ncol": [3, 25, 30, 33, 39, 78, 82, 88, 93, 95, 112, 116, 126, 134, 135, 143], "ncore": 105, "ncorr": 6, "ncross": 95, "ncsm": [78, 82], "nd": [34, 98], "ndarrai": [42, 82, 105], "ndata": [34, 96, 98], "ndiffer": 133, "ndim": [6, 17, 38, 41, 50, 96, 105, 125, 128, 129, 134], "ndimens": 94, "ndoubl": [25, 30], "neal": [44, 130], "nearbi": [19, 44], "nearest": 118, "nearli": [34, 103, 109], "neat": 115, "necess": [8, 39, 129, 134, 136], "necessari": [4, 16, 42, 53, 69, 71, 93, 112, 115, 119, 124], "necessarili": [0, 8, 21, 23, 25, 34, 39, 43, 46, 64, 66, 98, 112, 119, 126, 129, 134], "necessit": [130, 136], "need": [6, 7, 17, 19, 22, 25, 31, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 56, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 79, 85, 86, 88, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 108, 109, 112, 113, 114, 115, 116, 118, 119, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 138, 140, 141, 143, 144], "needless": 56, "neg": [4, 19, 21, 31, 33, 34, 37, 40, 41, 44, 50, 63, 64, 65, 71, 72, 77, 83, 88, 92, 96, 99, 115, 138, 141], "negat": 44, "neglect": [16, 19, 29, 45, 53, 100, 103], "neglig": [34, 41, 51, 52, 85, 100], "negri": 1, "neighbor": [11, 19, 42], "neighborhood": [47, 65], "neighbourhood": 53, "neil": [77, 83], "neither": [58, 67, 71, 128], "neq": [0, 4, 7, 22, 31, 32, 34, 53, 66, 72, 107, 112, 138, 141, 143], "nest": [0, 51, 52, 53, 67, 135, 136], "net": [66, 67, 71, 73, 93, 111], "netherland": 1, "network": [1, 45, 47, 60, 88, 89, 91, 99, 101, 102, 111, 118], "neumann": 99, "neural": [1, 45, 47, 60, 88, 89, 91, 99, 101, 102, 118], "neural_network": [73, 93], "neural_network_minibatch": 73, "neuralnet": 70, "neuron": [1, 68, 69, 70, 71, 72, 73, 74, 88, 93, 102, 111], "neutral": 115, "neutron": [1, 34, 79, 98, 115, 136], "never": [16, 34, 53, 66, 68, 77, 83, 98, 116], "nevertheless": [16, 39, 98, 129, 134], "new": [0, 7, 9, 10, 11, 13, 15, 16, 25, 34, 37, 38, 40, 43, 44, 46, 48, 49, 50, 51, 53, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 70, 71, 72, 73, 76, 77, 79, 82, 86, 88, 89, 93, 95, 102, 108, 109, 113, 115, 116, 117, 118, 119, 124, 125, 126, 127, 130, 132, 133, 135, 136, 138, 144, 145], "new_arr": 118, "new_data": 73, "new_data_button_w": 9, "new_hobbit": 115, "newarr": 118, "newaxi": [78, 82], "newcommand": [0, 9, 30, 40, 41, 42, 44, 49, 78, 95, 99, 109, 133], "newer": 51, "newli": [44, 116], "newton": [51, 100], "newtonian": [16, 51], "next": [8, 9, 11, 16, 25, 30, 31, 34, 37, 39, 40, 41, 43, 47, 48, 51, 63, 64, 69, 75, 80, 92, 98, 99, 102, 108, 115, 116, 118, 119, 125, 126, 127, 129, 133, 134, 138, 141, 144], "next_button_w": 9, "nfev": 105, "nframe": 108, "nh": 85, "ni": 46, "nice": [38, 48, 69, 95, 103, 126, 129, 134], "nicer": [17, 33, 38, 39, 115, 126, 127, 129, 134], "nicola": [77, 83], "niel": 25, "nielsen": 75, "nifti": 7, "nine": [77, 83, 135], "nist": 63, "nit": 105, "niter": [50, 96], "nk_pt": 37, "nll": 105, "nlp": 105, "nm": [67, 79], "nm_n": 115, "nmap": 105, "nmax": [42, 78, 82], "nmaximum": 105, "nn": [65, 71, 85, 111], "nnloopt": [78, 82], "no_grad": [71, 111], "no_of_chain": [50, 125], "no_of_head": [25, 30], "no_of_sampl": 126, "no_of_tail": [25, 30], "nobel": 67, "node": [67, 68, 69, 73, 93], "nois": [3, 7, 19, 29, 38, 40, 41, 49, 63, 66, 70, 72, 73, 77, 78, 79, 82, 83, 85, 86, 90, 92, 94, 95, 96, 105, 109, 124, 125, 134, 140], "noise_std": 80, "noise_var": 79, "noisi": [65, 66, 71, 88, 90, 91, 92, 95, 96, 97, 105], "nomin": [4, 126], "non": [6, 11, 23, 24, 29, 31, 33, 34, 37, 38, 40, 43, 45, 46, 47, 48, 63, 65, 66, 67, 69, 70, 71, 72, 73, 75, 76, 82, 88, 89, 93, 96, 98, 101, 102, 109, 112, 115, 118, 128, 138], "nonconvex": 99, "none": [4, 6, 17, 29, 33, 34, 37, 41, 42, 49, 50, 65, 69, 70, 76, 77, 78, 80, 82, 83, 92, 96, 98, 105, 108, 109, 111, 115, 125, 126, 129, 131, 134], "nonetheless": 63, "noninform": [39, 129, 134], "nonlinear": [34, 53, 67, 71, 98, 135], "nonlinearli": 47, "nonloc": 51, "nonneg": 66, "nonparametr": [78, 82, 86], "nonsens": [107, 112], "nonsequenti": 118, "nonstandard": 135, "nonstationari": 103, "nontreiv": 130, "nonumb": [48, 88], "nonzero": [19, 67, 118, 141], "nor": [8, 58, 64, 67, 71, 90], "norm": [5, 6, 9, 17, 25, 29, 30, 33, 34, 37, 39, 45, 49, 50, 65, 66, 73, 82, 92, 95, 98, 108, 109, 112, 125, 126, 129, 133, 134], "norm1": 50, "norm1_dist": 17, "norm2": 50, "norm2_dist": [17, 108], "norm_dist": [17, 108], "norm_label": [17, 108], "norm_loc": 108, "norm_pt": 108, "norm_sampl": 17, "norm_scaled_v": 108, "norm_x_pt": 33, "norm_y_pt": 33, "normal": [0, 7, 10, 13, 15, 16, 18, 19, 23, 24, 26, 30, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 48, 49, 50, 51, 52, 66, 67, 69, 70, 72, 73, 76, 77, 79, 80, 83, 88, 92, 93, 95, 96, 97, 99, 100, 105, 108, 109, 111, 112, 125, 126, 127, 129, 130, 133, 134, 135, 136, 138, 140, 141, 143, 144], "normal_": [71, 111], "normal_distribut": 34, "normaliz": 19, "normalize_i": 82, "normalized_posterior_funct": 126, "normalpropos": 133, "normp": 50, "northpoint": 63, "northwestern": 56, "notabl": 103, "notag": 47, "notat": [13, 16, 17, 20, 21, 23, 24, 31, 32, 34, 35, 37, 38, 42, 47, 48, 49, 65, 66, 68, 72, 89, 98, 99, 102, 105, 126, 127, 135, 138, 140, 144], "note": [1, 3, 4, 5, 7, 8, 9, 11, 13, 16, 17, 18, 19, 22, 23, 25, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 56, 63, 64, 65, 66, 67, 68, 72, 73, 75, 76, 77, 79, 80, 82, 83, 85, 86, 88, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 105, 107, 108, 109, 112, 114, 115, 116, 117, 118, 119, 124, 125, 126, 127, 128, 129, 130, 133, 134, 135, 138, 140, 141, 143, 144], "notebook": [5, 9, 11, 14, 16, 17, 23, 26, 27, 31, 33, 34, 35, 37, 39, 41, 49, 50, 52, 55, 56, 70, 71, 72, 73, 76, 86, 89, 90, 92, 93, 94, 95, 96, 98, 103, 105, 106, 107, 111, 113, 114, 117, 118, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 136, 141, 144, 145], "noth": [3, 8, 19, 34, 35, 43, 47, 66, 67, 73, 93], "notic": [1, 4, 23, 39, 53, 68, 72, 78, 79, 82, 85, 88, 129, 134, 136, 141], "notin": [46, 112], "notion": [8, 9, 25, 30, 43], "notori": [44, 64, 117], "novel": 66, "novemb": [5, 77], "now": [0, 3, 4, 5, 7, 9, 15, 16, 17, 19, 21, 23, 25, 29, 30, 31, 33, 34, 35, 37, 38, 40, 41, 42, 46, 48, 49, 52, 53, 59, 63, 64, 65, 66, 67, 68, 73, 77, 78, 80, 82, 83, 85, 86, 88, 92, 93, 94, 96, 98, 109, 111, 114, 115, 116, 117, 118, 119, 125, 126, 128, 129, 130, 131, 132, 133, 135, 136, 138], "nowadai": [8, 64, 135], "np": [0, 3, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 48, 49, 50, 65, 69, 70, 71, 73, 76, 77, 78, 79, 80, 81, 82, 83, 88, 92, 93, 94, 95, 96, 98, 99, 105, 108, 109, 111, 112, 114, 115, 116, 117, 118, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 138, 141, 143, 144], "np_random_numb": 112, "npl": 51, "nprop": [50, 96], "npropos": 126, "npy": [73, 93], "nrow": [3, 25, 30, 33, 39, 78, 81, 82, 88, 93, 95, 112, 116, 134, 135, 143], "nsampl": [17, 77, 79, 83, 94, 144], "nstep": [6, 38, 41, 50, 96, 105, 125, 129, 134], "nswap": [50, 96], "nswap_accept": [50, 96], "nt": 50, "ntemp": [50, 96], "ntemper": 50, "ntemps_hi": [50, 96], "ntemps_lo": [50, 96], "ntest": 69, "nthin": [50, 96], "nthread": [50, 96], "ntk": 102, "nu": [17, 29, 44, 81, 85, 108, 112], "nu1": 17, "nu2": 17, "nu3": 17, "nuclear": [1, 44, 46, 47, 48, 79, 91, 92, 108, 136], "nucleartal": [119, 122], "nuclei": [47, 79, 115], "nucleon": [1, 45, 108, 115], "nucleu": [47, 79, 115, 136], "nugget": [78, 79, 82, 86], "nuisanc": [17, 23, 25, 35, 96, 128, 141], "null": [11, 19, 53, 115], "num": [29, 41, 80, 81, 88, 114, 117, 135, 143], "num_bin": [17, 108, 133], "num_burn": 105, "num_coin_toss": 30, "num_col": [69, 76], "num_cor": 105, "num_data": 95, "num_data_per_class": 65, "num_draw": 33, "num_imag": [69, 76], "num_it": 125, "num_mean": 65, "num_model_param": 105, "num_param": 105, "num_plot": 95, "num_pt": [17, 42], "num_row": [33, 69, 76], "num_run": 143, "num_sampl": [17, 42, 78, 82, 131, 133, 135], "num_step": [105, 127, 144], "num_t": [114, 131], "num_t_pt": 132, "num_t_w": 114, "num_walker_per_dim": 105, "num_x_pt": 49, "number": [4, 6, 8, 9, 11, 16, 18, 19, 23, 25, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 83, 86, 88, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 105, 106, 107, 108, 109, 111, 114, 115, 116, 117, 118, 119, 124, 125, 126, 127, 129, 130, 133, 134, 135, 138, 141, 143, 144], "numer": [0, 7, 8, 16, 29, 34, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 65, 67, 72, 77, 79, 83, 85, 86, 90, 94, 95, 96, 98, 99, 107, 109, 112, 115, 125, 126, 138], "numpeak": [90, 96], "numpi": [0, 3, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 50, 65, 69, 70, 71, 73, 76, 77, 78, 80, 81, 82, 83, 88, 92, 93, 95, 96, 98, 105, 108, 109, 111, 112, 114, 115, 119, 120, 125, 126, 127, 129, 131, 132, 133, 134, 135, 138, 143, 144], "numpt": 112, "numref": 0, "nut": [44, 73, 130, 133, 134, 136], "nwalker": [6, 38, 41, 50, 96, 105, 125, 128, 129, 134], "nwarmup": [38, 41, 50, 125], "nwe": 96, "nx": 49, "nx_iy_i": 109, "nz": 115, "o": [1, 3, 19, 34, 38, 40, 41, 49, 67, 69, 77, 78, 82, 95, 98, 102, 103, 105, 108, 112, 115, 125, 126, 127, 133, 138, 143, 144], "o1": 132, "ob": [7, 25, 30, 34, 133], "obei": [8, 13], "object": [6, 8, 9, 16, 17, 23, 30, 38, 43, 48, 50, 53, 71, 72, 73, 77, 78, 83, 92, 93, 96, 99, 103, 108, 112, 114, 115, 116, 117, 118, 120, 131], "oblig": 53, "observ": [0, 1, 3, 4, 7, 9, 10, 11, 12, 16, 19, 23, 25, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 53, 58, 60, 61, 62, 63, 64, 65, 66, 67, 71, 73, 75, 77, 80, 81, 83, 85, 86, 92, 93, 96, 98, 99, 100, 102, 103, 106, 108, 109, 112, 124, 126, 127, 128, 129, 133, 134, 136, 138, 140, 143, 144], "observed_data": 133, "obtain": [4, 7, 8, 9, 14, 16, 23, 25, 30, 34, 35, 41, 43, 44, 45, 47, 48, 58, 59, 63, 65, 66, 67, 68, 71, 72, 76, 77, 82, 83, 86, 88, 92, 97, 98, 103, 107, 112, 126, 127, 128, 132, 133, 135, 136, 143, 144, 145], "obviou": [16, 19, 34, 65, 138], "obvious": [4, 7, 8, 16, 25, 33, 34, 45, 66, 72, 73, 85, 88, 94], "occam": [51, 52, 53], "occasion": [56, 119, 138], "occupi": [4, 130], "occur": [8, 22, 25, 56, 63, 65, 88, 112, 115, 138], "occurr": 8, "ockham": [7, 53, 90], "oct": [78, 133], "octob": 1, "od": [130, 131, 132], "odd": [24, 25, 34, 53, 88, 115], "odds_ratio": 95, "odeint": 105, "odot": [45, 66, 72], "ofeffect": 91, "off": [7, 9, 17, 33, 35, 42, 48, 49, 51, 52, 53, 73, 92, 93, 109, 112, 115, 130, 133, 143], "offenc": 63, "offend": 63, "offer": [7, 41, 44, 46, 71, 100, 102, 116, 118, 133], "offici": 133, "offlin": [45, 47], "offset": [38, 41, 51, 53, 105, 115, 125], "often": [3, 4, 7, 13, 15, 16, 19, 23, 29, 31, 34, 38, 39, 40, 41, 43, 44, 45, 46, 47, 53, 55, 58, 60, 62, 63, 64, 65, 66, 67, 68, 71, 73, 85, 86, 88, 95, 97, 98, 99, 100, 103, 104, 106, 108, 112, 116, 117, 118, 125, 126, 128, 129, 134, 135, 136, 141, 143], "ohio": [21, 56], "oin": 9, "ok": [0, 22, 37, 42, 96, 109, 116, 133, 136, 141], "okai": 19, "ol": [34, 65, 66, 98, 141], "old": 135, "older": [38, 116], "oliv": 56, "ols_cov": [34, 65, 98], "ols_d": [34, 98], "ols_ep": [34, 98], "ols_s2": [34, 98], "ols_theta": [34, 65, 98], "ols_xtd": [34, 65, 98], "olymp": 77, "olympic_marathon_men": 77, "olympicmarathontim": 77, "omega": [16, 19, 33, 34, 114, 135], "omega_0": 131, "omega_i": 44, "omega_j": 44, "omega_pt": 33, "omega_w": 114, "omit": [16, 22, 24, 49, 53, 56, 73, 85, 102, 126], "on_click": 9, "onc": [4, 8, 9, 12, 15, 16, 22, 25, 30, 35, 37, 38, 40, 42, 43, 47, 48, 53, 59, 66, 67, 73, 85, 97, 116, 119, 135, 136, 143], "one": [0, 4, 5, 7, 8, 9, 11, 16, 17, 18, 19, 22, 23, 24, 25, 26, 29, 31, 32, 34, 35, 37, 38, 39, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 77, 78, 79, 80, 82, 83, 86, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 107, 108, 109, 111, 112, 115, 116, 117, 118, 119, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 138, 140, 141, 143, 144, 145], "oned_arr": 118, "ones": [5, 19, 34, 37, 38, 43, 50, 53, 62, 65, 66, 67, 70, 73, 93, 95, 96, 98, 99, 102, 112, 115, 118, 135, 143], "ones_lik": [6, 38, 40, 96, 115, 118, 125], "onevariablenet": 71, "ongo": 8, "onli": [0, 4, 7, 8, 11, 15, 16, 17, 18, 19, 23, 24, 25, 29, 31, 34, 35, 37, 38, 40, 41, 43, 44, 47, 48, 49, 50, 51, 52, 53, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 72, 73, 75, 76, 79, 80, 81, 82, 85, 86, 88, 96, 97, 98, 99, 100, 103, 105, 109, 111, 112, 115, 117, 118, 125, 126, 128, 130, 133, 135, 138], "onlin": [1, 47, 64, 70, 71, 77, 83, 85, 116, 117, 133], "onto": [7, 45, 109, 135, 141], "onu": 53, "op": 108, "opac": 44, "open": [8, 16, 25, 43, 61, 64, 73, 104, 115, 116], "openli": 64, "oper": [7, 8, 25, 34, 44, 47, 62, 63, 64, 66, 67, 73, 75, 77, 79, 83, 98, 115, 116, 120, 126], "operation": 66, "operatornam": [66, 85, 99], "opinion": [63, 141], "opportun": [44, 47, 53, 58, 64], "oppos": [19, 51, 101, 116], "opposit": [4, 8, 19, 37, 68, 97, 99], "opt_r": 81, "optic": 46, "optim": [1, 4, 5, 16, 34, 35, 38, 40, 41, 47, 51, 53, 65, 66, 67, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 82, 83, 85, 91, 93, 95, 98, 101, 102, 103, 105, 109, 141, 145], "optima": 92, "optimis": [77, 83], "optimum": [7, 34, 41, 67, 77, 82, 92, 98, 100], "option": [9, 11, 25, 34, 38, 40, 47, 50, 52, 56, 67, 70, 71, 90, 94, 95, 96, 105, 113, 118, 119, 132, 133, 138, 140], "optpar": [44, 99, 100], "optpara": 44, "optpars_i": 44, "optparslr": 34, "opvi": 73, "oracl": 48, "orang": 80, "orbit": 100, "orbit_gam": 132, "order": [5, 7, 19, 34, 41, 43, 44, 46, 47, 49, 52, 53, 56, 58, 62, 66, 67, 68, 71, 72, 73, 79, 88, 94, 96, 97, 98, 100, 115, 116, 119, 130, 132, 138, 143], "ordinari": [47, 51, 53, 65, 66, 75, 88, 96, 130, 132], "ordinarili": 109, "org": [1, 17, 40, 50, 69, 70, 76, 81, 93, 96, 99, 112, 130, 133, 136], "organ": [9, 63, 67, 114, 118, 143], "orient": [35, 50, 53, 63, 114, 125], "origin": [4, 16, 26, 33, 38, 42, 43, 44, 46, 47, 48, 50, 51, 53, 56, 63, 65, 66, 72, 73, 75, 77, 79, 88, 91, 93, 96, 109, 118, 125, 126, 133, 135, 145], "orthogon": [22, 45, 47, 53, 107, 109, 128], "orthonorm": [22, 31, 32, 47, 107], "oscil": [47, 51], "oslo": 56, "osu": [0, 78, 114, 119, 131, 133], "osx": 119, "other": [1, 4, 7, 8, 9, 10, 12, 13, 16, 17, 19, 21, 23, 25, 27, 30, 31, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 56, 63, 64, 65, 66, 67, 68, 69, 71, 73, 75, 77, 78, 79, 82, 83, 86, 88, 92, 93, 94, 97, 98, 99, 100, 102, 107, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 125, 126, 127, 129, 130, 132, 133, 134, 135, 136, 138, 140, 142, 143, 144], "otherwis": [7, 8, 25, 30, 38, 41, 42, 44, 47, 53, 71, 81, 86, 88, 92, 95, 103, 112, 116, 127, 135, 138, 144], "ouput": 68, "our": [0, 4, 7, 8, 9, 10, 11, 13, 16, 17, 19, 21, 22, 23, 25, 27, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 71, 73, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 89, 93, 94, 95, 96, 97, 98, 100, 103, 105, 109, 112, 118, 120, 125, 126, 127, 128, 129, 130, 132, 133, 134, 136, 138, 141, 143, 144], "ourselv": [46, 66, 67, 82, 99, 100, 112, 115, 135], "out": [1, 4, 5, 7, 9, 13, 16, 17, 19, 23, 29, 30, 31, 32, 33, 34, 37, 38, 39, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 59, 60, 61, 62, 63, 66, 68, 71, 72, 73, 76, 77, 83, 86, 88, 93, 94, 95, 98, 100, 103, 105, 109, 114, 115, 116, 118, 119, 124, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 143, 144], "out_featur": 71, "outcom": [8, 9, 11, 22, 23, 25, 30, 31, 43, 46, 53, 63, 88, 89, 100, 105, 112, 118, 135, 138, 140, 143], "outer": [0, 68], "outfil": 108, "outlier": [41, 55, 136], "outlin": [38, 41, 48, 99, 126, 135], "outperform": 47, "output": [0, 5, 9, 34, 41, 43, 45, 46, 47, 48, 58, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 85, 88, 89, 93, 96, 98, 100, 102, 103, 112, 115, 116, 117, 118, 143], "output_": [65, 100], "output_1": 100, "output_2": 100, "output_i": [65, 66, 100], "outputlayer1": 67, "outputs_i": [64, 99], "outsid": [3, 19, 46, 53, 82, 95, 117, 126, 145], "outward": 19, "over": [0, 4, 7, 16, 17, 18, 19, 22, 23, 31, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 55, 56, 63, 64, 65, 68, 71, 72, 73, 76, 77, 78, 82, 83, 85, 86, 88, 89, 93, 95, 96, 99, 102, 103, 106, 107, 108, 109, 112, 115, 117, 119, 124, 125, 126, 128, 129, 134, 135, 136, 143, 145], "overal": [9, 13, 31, 33, 37, 47, 48, 63, 73, 94, 96, 103, 114], "overall_titl": [37, 131, 132], "overarch": [64, 72], "overbrac": [9, 10, 23, 30], "overcom": 67, "overconfid": 103, "overestim": [66, 125], "overfit": [16, 29, 64, 65, 66, 67, 69, 71, 72, 73, 75, 94, 95, 97, 100], "overflow": 116, "overhead": 68, "overlai": 17, "overlaid": 111, "overlap": [7, 22, 44, 63, 66, 70, 76, 126, 141], "overli": [16, 38, 60], "overlin": [31, 42, 94, 125, 128, 136], "overlook": 63, "overrepres": 63, "overset": [13, 15, 19, 32, 86, 124], "overshoot": 99, "oversight": 63, "overview": [9, 16, 27, 28, 45, 56, 75, 89, 114, 119], "overview_text": [9, 114], "overweight": 63, "overwhelm": 53, "ow": 64, "own": [0, 4, 11, 22, 33, 37, 43, 56, 63, 64, 66, 69, 94, 109, 113, 115, 116, 121, 125, 143, 144], "oxford": [1, 56], "o\u02bchagan": 103, "p": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 13, 15, 16, 17, 23, 24, 25, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 63, 65, 66, 67, 70, 72, 73, 77, 78, 79, 82, 83, 85, 86, 88, 93, 95, 96, 98, 99, 100, 102, 107, 108, 109, 112, 114, 115, 124, 125, 126, 127, 128, 129, 130, 131, 134, 135, 136, 138, 140, 143, 144, 145], "p0": [50, 96, 125, 128], "p1": [40, 41, 131], "p2": 40, "p2cread": 108, "p2cwrite": 108, "p_": [7, 15, 19, 48, 51, 72, 88, 112, 131, 138, 143], "p_0": 131, "p_1": [4, 15, 16], "p_2": [4, 15], "p_3": 4, "p_4": 4, "p_accept": 126, "p_current": 126, "p_h": [9, 11, 12, 13, 15, 19, 25, 30], "p_i": [3, 4, 16, 44, 130], "p_j": 4, "p_n": 15, "p_phi": 131, "p_phi_0": 131, "p_phi_now": 131, "p_phi_vs_time_label": 131, "p_propos": 126, "p_star": 95, "p_x": [25, 53, 112], "p_y": [53, 67], "p_z": [7, 67], "pa": 7, "pace": [77, 141], "pacif": 1, "pack": 115, "packag": [17, 23, 38, 41, 43, 50, 64, 73, 77, 81, 83, 93, 96, 105, 108, 112, 115, 116, 119, 128, 129, 134, 135], "pad": [70, 78, 95, 132], "page": [0, 1, 17, 23, 41, 56, 70, 77, 83, 84, 87, 94, 112, 115, 116, 119, 124, 128, 130, 135, 136], "pai": [22, 63, 67, 72], "painfulli": [99, 117], "painstak": 64, "pair": [34, 40, 43, 47, 48, 51, 78, 82, 95, 98, 109, 115, 117, 125, 128], "pairplot": 143, "palett": 116, "panda": [34, 98, 116, 125], "panel": [7, 25, 37, 41, 43, 56, 65, 72, 95, 97, 103, 112, 115, 126, 129, 134, 138, 143], "pankaj": 1, "papanicola": 5, "paper": [1, 34, 43, 44, 46, 49, 51, 61, 72, 86, 94, 95, 98, 108, 125], "par": [7, 16, 34, 35, 44, 45, 46, 47, 53, 64, 66, 98, 99, 100, 102, 103, 135], "para": [34, 43, 44, 112, 135], "para_": [66, 98, 99], "para_0": [98, 100], "para_1": [44, 47, 98, 100, 135], "para_1f_1": [34, 98], "para_2": [44, 47, 98, 100, 135], "para_2f_2": 98, "para_3": 47, "para_i": [44, 45, 47, 99, 135], "para_j": 98, "para_n": 47, "paradigm": [8, 16, 38, 43, 47, 64, 95, 103], "paradox": 110, "parallel": [21, 35, 50, 53, 56, 73, 90, 93, 102, 105, 130, 145], "paralr": 34, "paralr_": 34, "paralr_0": 34, "paralr_1": 34, "paralr_1f_1": 34, "paralr_2": 34, "paralr_2f_2": 34, "paralr_i": 34, "paralr_j": 34, "param": [34, 50, 69, 76, 82, 96, 98, 99, 105, 125], "param_bound": 105, "param_max": 105, "param_min": 105, "param_resc": 105, "paramet": [1, 3, 4, 6, 8, 9, 10, 11, 13, 17, 18, 19, 20, 23, 24, 25, 27, 29, 30, 34, 35, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 81, 82, 85, 86, 90, 91, 92, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 118, 125, 126, 127, 128, 130, 131, 132, 133, 135, 136, 140, 141, 143, 144, 145], "parameter": [46, 72, 78, 82, 85, 102, 128], "parameter_estim": 145, "parameter_estimation_fitting_straight_line_i": [38, 41, 125], "parameter_estimation_fitting_straight_line_ii": 125, "parameter_estimation_gaussian_nois": 124, "parameter_estimation_gaussian_noise_compare_sampl": 145, "parameters_text": 114, "parametr": [8, 28, 44, 45, 47, 72, 73, 77, 78, 79, 82, 86, 101, 104, 115], "params_gradi": 99, "params_mod": 50, "params_rbf": 82, "paraphras": 102, "parenthes": 107, "pars_": [45, 99], "pars_0": 99, "pars_1": 47, "pars_2": 47, "pars_i": [7, 44, 45, 47, 135], "pars_j": [44, 47], "pars_n": [47, 99], "parsec": [7, 17], "parslr": 34, "parslr_1": 34, "parslr_2": 34, "part": [0, 16, 23, 27, 31, 32, 33, 34, 35, 41, 43, 45, 51, 56, 58, 59, 60, 62, 63, 64, 65, 71, 72, 73, 75, 77, 86, 90, 91, 94, 95, 98, 100, 106, 109, 115, 118, 124, 125, 130, 136, 138, 141], "parti": 21, "partial": [1, 3, 4, 7, 29, 34, 35, 39, 44, 53, 68, 88, 95, 97, 98, 99, 107, 109, 129, 130, 131, 134], "particl": [0, 1, 17, 19, 21, 23, 102, 105, 108, 115, 130, 138, 143], "particulali": 56, "particular": [0, 3, 4, 7, 8, 9, 16, 22, 24, 25, 29, 30, 31, 34, 38, 39, 41, 42, 44, 46, 47, 48, 50, 51, 52, 53, 56, 59, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 77, 83, 85, 86, 88, 92, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 108, 112, 114, 115, 120, 127, 129, 134, 135, 136, 144], "particularli": [23, 24, 27, 38, 43, 51, 56, 62, 66, 71, 75, 103, 112, 116, 135, 136, 143], "partit": [5, 34, 85, 86, 112, 141], "partli": [43, 47, 53, 78, 82], "pass": [17, 23, 50, 67, 68, 71, 72, 75, 76, 78, 88, 96, 100, 102, 105, 108, 109, 111, 115, 116, 118, 128, 131, 133, 135, 138, 143], "pass_fd": 108, "passeng": 64, "past": [8, 9, 16, 17, 21, 24, 46, 53, 99, 117, 124, 138], "patent": 135, "path": [1, 48, 62, 70, 77, 83, 86, 105, 112, 115, 130, 138, 143], "patient": [56, 63, 88, 119], "pattern": [1, 16, 49, 51, 62, 64, 67, 71, 76, 89, 138], "pauciora": 53, "pauli": 115, "paus": 19, "pb": 1, "pc": 116, "pca": [79, 106], "pcg64": 112, "pcolor": 40, "pct": [37, 40, 41], "pd": [34, 98, 115, 125], "pd_d": [34, 98], "pd_design_matrix": [34, 98], "pd_m": [34, 98], "pd_m_ol": [34, 98], "pd_r": [34, 98], "pd_x": [34, 98], "pd_xmeasur": [34, 98], "pd_xrealiti": [34, 98], "pdf": [0, 1, 3, 9, 10, 11, 12, 13, 16, 19, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 42, 44, 46, 49, 53, 55, 72, 74, 78, 82, 85, 86, 92, 96, 105, 108, 129, 130, 133, 134, 136, 138, 140, 141, 142, 143], "pdf_1": [0, 7], "pdf_2": [0, 7], "pdf_2_grid": [0, 7], "pdf_3": [0, 7], "pdf_3_grid": [0, 7], "pdf_4": [0, 7], "pdfy": 112, "peacock": 145, "peak": [7, 9, 12, 19, 33, 34, 35, 37, 39, 41, 49, 50, 51, 52, 53, 67, 90, 91, 95, 96, 112, 128, 129, 130, 134], "pen": [0, 23, 34, 98], "penal": 53, "penalti": [51, 52, 53, 66, 70], "pendleton": 1, "pendulum": 51, "peopl": [0, 4, 19, 22, 31, 53, 56, 62, 63, 64, 77, 98, 125, 133, 135], "per": [29, 41, 47, 53, 58, 67, 71, 77, 80, 95, 105, 108, 111, 115, 124, 131, 143], "perceiv": [63, 64], "percent": [17, 25, 49, 112], "percentag": [18, 19, 76, 108, 109, 130, 133], "percentil": [38, 94, 96], "perceptron": [67, 71, 73, 93], "peregrin": 115, "perfect": [34, 40, 41, 44, 48, 59, 65, 79, 86, 115, 125], "perfectli": [39, 44, 125, 129, 133, 134], "perfom": [65, 67], "perform": [4, 7, 8, 16, 25, 30, 31, 34, 38, 41, 43, 44, 45, 46, 47, 48, 50, 51, 53, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 88, 92, 95, 97, 98, 99, 100, 103, 107, 109, 112, 115, 116, 117, 118, 124, 125, 126, 128, 129, 134, 135, 138, 145], "perhap": [40, 62, 64], "perimet": 110, "period": [6, 34, 38, 44, 53, 77, 81, 83, 105, 127, 129, 134, 138, 144], "periodic_matern32": 77, "periodicexponenti": [77, 83], "periodicity_bound": 81, "perivolaropoulo": 51, "perm": [78, 82], "permeat": 72, "permiss": [44, 76, 103], "permit": [7, 43, 47, 53, 66], "permut": [78, 82, 88, 99], "persist": [43, 103], "person": [8, 9, 22, 30, 43, 63, 112], "perspect": [1, 8, 34, 47, 57, 59, 60, 61, 62, 77, 83, 86, 88, 89, 98, 100], "persuad": 5, "pertain": [25, 30], "pertin": 68, "perturb": [58, 102], "pervers": 19, "pessimist": 38, "peter": 109, "petrov": 47, "petunin": 46, "pf": [7, 138], "ph": [25, 30], "phase": [43, 45, 47, 50, 51, 52, 67, 71, 96, 114, 130, 131], "phase_space_label": 131, "phd": 56, "phenomena": [7, 51, 104], "phenomenolog": [34, 48, 98], "phenomenon": [7, 40, 62, 100], "phi": [7, 51, 103, 105, 114, 131, 132, 135, 141], "phi_": [85, 132], "phi_0": [131, 132], "phi_and_p_high": 131, "phi_and_p_low": 131, "phi_i": 132, "phi_now": 131, "phi_pt": 132, "phi_pts_eul": 132, "phi_pts_lf": 132, "phi_vs_time_label": 131, "phi_w": 114, "phil": [1, 56], "phillip": [5, 56, 133], "philosoph": [7, 19, 20, 25, 39, 129, 134], "philosophi": [8, 39, 110, 129, 134], "phivec": [136, 141], "photon": 60, "phrase": 45, "phtrue": 30, "phy": [1, 5, 44, 49, 78, 82, 86], "physic": [0, 1, 4, 7, 16, 17, 19, 23, 34, 43, 46, 47, 48, 50, 51, 53, 56, 57, 59, 64, 65, 67, 72, 79, 88, 92, 94, 98, 100, 102, 103, 104, 108, 109, 110, 112, 115, 127, 135, 136, 141, 143, 144], "physicist": [1, 8, 17, 23, 27, 29, 53, 56, 57, 59, 60, 62, 67, 102, 108], "physrep": 1, "physrevc": 1, "physrevlett": 1, "pi": [4, 7, 19, 24, 33, 34, 37, 38, 39, 40, 41, 42, 44, 49, 50, 52, 53, 67, 70, 72, 77, 78, 83, 86, 92, 94, 95, 96, 98, 100, 105, 111, 112, 114, 116, 117, 125, 126, 128, 129, 132, 134, 138], "pi_": 138, "pi_1": 138, "pi_2": 138, "pi_3": 138, "pi_i": [135, 138], "pi_j": 138, "pi_jt_": 138, "pi_n": 138, "pick": [13, 16, 19, 29, 51, 53, 65, 93, 108, 116, 131], "pictur": [38, 40, 41, 73, 102, 109, 125], "piec": [9, 19, 29, 39, 47, 100, 129, 130, 134], "pierr": [8, 34], "pillar": 73, "pioneer": [0, 8, 23], "pipe": 108, "pipelin": 64, "pipenv": 119, "pipes": 108, "pippin": 115, "pitt": 67, "pivot": 8, "pixel": [69, 75, 76, 102], "place": [8, 16, 19, 22, 32, 39, 42, 43, 48, 51, 60, 62, 67, 71, 73, 75, 79, 96, 115, 116, 124, 125, 126, 129, 133, 134, 135, 143], "plai": [5, 9, 11, 17, 23, 27, 30, 34, 35, 52, 53, 64, 66, 67, 73, 86, 98, 109, 114], "plain": [68, 72], "plan": [19, 61, 96, 136], "plane": [19, 65, 74], "planetari": 16, "plate": 51, "plateau": [66, 97, 105], "platform": [44, 63], "plato": 138, "platon": 62, "plausibl": [1, 42, 61, 72, 105], "player": [16, 143], "pleas": [30, 49, 70, 95, 133], "plenti": [67, 128], "plethora": 67, "plot": [0, 3, 6, 7, 9, 11, 19, 25, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 43, 49, 50, 51, 53, 65, 66, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 83, 86, 88, 92, 93, 94, 95, 96, 97, 98, 102, 109, 111, 112, 114, 115, 120, 124, 126, 127, 128, 129, 131, 134, 135, 138, 141, 143, 144, 145], "plot_autocorr": 133, "plot_conditional_distribut": 138, "plot_contour": 82, "plot_data": [34, 98], "plot_decision_boundari": 70, "plot_dens": 78, "plot_estim": 112, "plot_forest": 133, "plot_gaussian_contour": [78, 82], "plot_gpr_sampl": 81, "plot_hist": 17, "plot_imag": [69, 76], "plot_it": 116, "plot_limit": [77, 83], "plot_lin": 5, "plot_mcmc_model": 41, "plot_mcmc_trac": 41, "plot_num": 131, "plot_out": [9, 114], "plot_pair": 134, "plot_posterior": 133, "plot_process": [138, 143], "plot_propos": 126, "plot_result": 40, "plot_sample_dimens": [78, 82], "plot_sample_result": 33, "plot_sine_map": 117, "plot_start": [131, 132], "plot_stop": [131, 132], "plot_surfac": [37, 65, 112], "plot_titl": [40, 78, 125, 127, 144], "plot_trac": [133, 134], "plot_value_arrai": [69, 76], "plot_y_vs_x": 131, "plt": [0, 3, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 50, 65, 69, 70, 71, 73, 76, 77, 78, 80, 81, 82, 83, 88, 92, 93, 95, 96, 98, 105, 108, 109, 111, 112, 114, 115, 116, 117, 125, 126, 127, 129, 131, 132, 133, 134, 135, 138, 143, 144], "plu": [19, 26, 34, 37, 52, 56, 66, 67, 72, 90, 93, 94, 96, 109, 112, 119, 130, 138, 139, 142], "plug": [31, 40, 126], "plumle": 56, "plura": 53, "pm": [4, 7, 19, 29, 34, 35, 40, 41, 53, 73, 81, 93, 133, 134, 136, 138, 140], "pm1": [72, 74], "pm2": [72, 74], "pm3": 133, "pmatrix": [34, 35, 45, 52, 53, 67, 79, 85, 86, 135, 138], "pmc": 105, "pmf": [17, 23, 24, 33], "pmm": 104, "pn": 44, "png": [0, 3, 4, 6, 25, 53, 72, 73, 97, 115, 116, 131, 132], "po": [38, 44, 50, 99, 105, 125, 134], "pocomc_sampl": 105, "pod": [47, 107], "pofm": 48, "pofm1": 48, "point": [0, 4, 6, 7, 8, 9, 11, 16, 17, 19, 23, 25, 29, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 53, 61, 63, 65, 66, 69, 70, 71, 72, 73, 77, 78, 79, 80, 82, 83, 85, 86, 88, 90, 92, 94, 95, 96, 97, 98, 99, 102, 103, 105, 107, 108, 109, 114, 115, 116, 118, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 138, 144, 145], "point_alpha": 108, "pointer": [20, 72, 73, 93, 104], "pointestimates_fig": 112, "pointwis": [80, 99], "poisson": [19, 35, 43, 142], "poisson_plot": [33, 37], "poisson_pt": [33, 37, 127, 144], "poissonpropos": 133, "pol54a": [1, 62], "pol54b": [1, 62], "polar": 132, "poldeg": [34, 98], "polic": 15, "polit": 48, "polya": [1, 61], "polyfit": 95, "polym": 67, "polyni": 95, "polynomi": [5, 66, 79, 86, 88, 97], "polyv": [34, 95, 98], "pool": [50, 73, 75, 96, 105], "poor": [17, 19, 29, 34, 47, 53, 63, 66, 96, 102], "poorli": [43, 48, 66], "popen": 108, "popper": 62, "popul": [31, 32, 39, 63, 65, 73, 89, 112, 129, 134, 143], "popular": [47, 63, 64, 67, 95, 97, 99, 103, 112, 115, 116], "pos1": 65, "pos2": 65, "pos_": 44, "pos_i": 44, "pose": 63, "posit": [4, 6, 7, 8, 19, 25, 31, 34, 37, 38, 39, 41, 42, 44, 50, 51, 53, 61, 62, 63, 64, 65, 66, 71, 72, 77, 78, 82, 83, 85, 86, 88, 90, 96, 97, 99, 105, 107, 109, 112, 120, 124, 125, 126, 128, 129, 130, 134, 135, 138, 141, 143], "possibl": [4, 7, 8, 9, 13, 19, 25, 31, 32, 34, 38, 40, 43, 44, 45, 46, 48, 49, 53, 56, 59, 61, 62, 64, 65, 66, 67, 68, 75, 77, 83, 88, 94, 95, 98, 100, 102, 103, 105, 107, 112, 118, 126, 129, 134, 135, 136, 138, 141, 143], "possibli": [34, 40, 41, 46, 48, 64, 65, 67, 71, 72, 88, 98, 99, 116, 126, 128, 143], "post": [38, 72, 73, 93, 99, 126, 134], "postdoc": 56, "postenti": 130, "posterior": [1, 7, 9, 10, 12, 15, 19, 20, 23, 24, 25, 27, 29, 30, 37, 38, 39, 40, 41, 44, 46, 48, 49, 51, 52, 53, 59, 60, 72, 73, 74, 77, 79, 82, 83, 85, 86, 87, 90, 92, 93, 94, 95, 96, 103, 124, 126, 127, 128, 129, 130, 133, 134, 135, 136, 140, 144], "posterior1": 34, "posterior_calc": 42, "posterior_func": 126, "posterior_funct": 126, "posterior_pt": 42, "posteriorbma": 48, "posteriori": [34, 72, 133], "postiv": 63, "postul": 16, "potenti": [43, 44, 45, 47, 48, 51, 61, 63, 64, 66, 67, 71, 82, 99, 103, 119, 125, 130, 133], "potest": 53, "pott": 67, "pound": 116, "pow": 71, "powel": 105, "power": [7, 25, 33, 34, 46, 55, 56, 60, 63, 65, 66, 67, 71, 73, 76, 100, 102, 103, 105, 107, 112, 116, 118], "pp": [112, 138, 143], "ppc": [73, 93], "ppd": [16, 34], "ppd_definition_b": 0, "ppf": 112, "pr": [17, 23, 30, 40, 41, 42, 44, 49, 95, 105, 133], "practic": [7, 9, 15, 20, 27, 37, 39, 40, 43, 44, 46, 48, 51, 53, 58, 59, 61, 62, 63, 66, 71, 85, 86, 88, 94, 103, 107, 109, 127, 129, 130, 133, 134, 136, 138, 139, 141, 142, 143, 144], "practition": [59, 67, 88], "pradeep": 86, "pragmat": 100, "pratola": 56, "pre": [0, 43, 44, 45, 69, 73, 102], "preactiv": 102, "preced": [53, 67], "preceed": 116, "precent": 25, "precipic": 133, "precipit": 138, "precis": [5, 29, 34, 39, 40, 41, 43, 45, 46, 48, 51, 53, 63, 66, 67, 78, 79, 80, 82, 94, 96, 99, 100, 107, 108, 109, 115, 129, 131, 132, 134, 135, 136, 140, 143], "preconceiv": [9, 30], "precondit": 105, "pred": [73, 93], "pred_func": 70, "predefin": [71, 116], "predetermin": [96, 135], "predic": 125, "predict": [1, 4, 7, 20, 24, 25, 29, 44, 45, 46, 48, 51, 53, 58, 60, 62, 63, 64, 65, 66, 67, 70, 71, 72, 74, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 92, 94, 98, 99, 100, 103, 105, 109, 115, 127, 128, 135, 138, 140, 144], "predict_quantil": [77, 83], "predicted_label": [69, 76], "predicti": 44, "predictions_arrai": [69, 76], "predictor": [34, 64, 65, 85, 88, 98, 100, 115], "predispos": 63, "predominantli": 116, "preexec_fn": 108, "prefer": [3, 4, 34, 43, 53, 63, 65, 66, 71, 92, 117, 133], "preferenti": 53, "prejudic": 63, "preliminari": 31, "premis": [0, 7], "prepar": [25, 53, 69, 71, 108, 115, 119], "prepend": 88, "preprint": 94, "preprocess": [69, 73, 81, 93, 105], "prescrib": 33, "prescript": 132, "presenc": [8, 22, 38, 63], "present": [0, 8, 16, 22, 25, 34, 43, 48, 49, 53, 58, 62, 64, 65, 67, 73, 81, 92, 94, 98, 99, 105, 108, 115, 116, 117, 138, 143], "preserv": [44, 51, 130], "presid": 25, "presidenti": 25, "press": [1, 9, 11, 56, 64, 116], "pressur": 4, "presum": [48, 71], "presumpt": 48, "pretti": [33, 62, 73, 115, 119, 143], "prettypleas": [112, 138, 143], "preval": 88, "prevent": [63, 64, 69, 71, 72, 77, 108, 135], "preview": 116, "previou": [9, 16, 23, 30, 34, 37, 38, 39, 40, 41, 43, 44, 56, 60, 67, 68, 71, 75, 77, 92, 95, 98, 99, 100, 102, 106, 109, 116, 125, 126, 127, 129, 133, 134, 136, 138, 142, 144], "previous": [7, 48, 49, 71, 72, 77, 83], "prf": 0, "price": 72, "primari": [88, 94], "primarili": [67, 73], "prime": [40, 77, 83], "primer": [1, 43], "primit": 25, "princeton": 1, "princip": [35, 47, 53, 89, 106], "principl": [1, 7, 8, 20, 28, 34, 38, 39, 40, 43, 44, 47, 48, 53, 57, 59, 61, 62, 67, 73, 80, 88, 97, 99, 102, 106, 107, 115, 129, 134], "print": [1, 5, 6, 9, 17, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 50, 65, 69, 70, 71, 73, 74, 76, 77, 78, 81, 82, 83, 93, 95, 96, 98, 105, 108, 109, 111, 112, 115, 116, 117, 118, 120, 125, 126, 127, 129, 131, 132, 133, 134, 135, 143, 144], "print_frequentist_estim": [9, 30], "print_funct": 76, "print_likely_fair_prior_measur": [9, 30], "print_likely_unfair_prior_measur": [9, 30], "print_uniform_prior_measur": [9, 30], "printopt": [40, 41, 78, 82, 96], "prior": [0, 2, 3, 7, 8, 9, 10, 11, 15, 16, 19, 23, 25, 29, 30, 35, 37, 38, 41, 42, 44, 46, 47, 48, 51, 52, 55, 58, 59, 60, 64, 72, 73, 74, 77, 78, 82, 83, 85, 86, 87, 93, 94, 95, 96, 102, 103, 108, 124, 125, 133, 140], "prior_func": 105, "prior_rang": 95, "priori": [47, 48, 53, 60, 86, 133], "priorit": 103, "prioriti": [60, 64], "priors_text": 9, "priors_text_w": 9, "priorsamplesslop": 3, "privaci": 63, "privat": [63, 67, 110], "privileg": [22, 119], "prize": 67, "prng": 112, "pro": 63, "prob": [0, 8, 16, 17, 22, 23, 25, 31, 32, 38, 41, 46, 50, 65, 69, 88, 105, 112, 125, 126, 134, 138], "prob_": 138, "prob_head": 9, "prob_heads_w": 9, "probab": 34, "probabilist": [16, 22, 46, 55, 58, 59, 60, 62, 64, 80, 88, 89, 93, 134, 135], "probabilit": [112, 138], "probabilitii": 26, "probabilit\u00e9": 34, "probabl": [0, 1, 5, 7, 9, 10, 11, 12, 16, 19, 20, 21, 24, 27, 30, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 48, 49, 50, 51, 53, 55, 56, 58, 59, 60, 62, 64, 65, 67, 69, 72, 74, 78, 79, 82, 85, 86, 89, 90, 95, 96, 97, 98, 99, 100, 102, 103, 105, 106, 108, 125, 127, 129, 130, 133, 134, 135, 136, 138, 140, 144, 145], "problem": [4, 7, 8, 9, 11, 15, 16, 25, 28, 31, 34, 35, 38, 39, 40, 44, 45, 47, 48, 49, 51, 53, 56, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 79, 85, 88, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 102, 104, 105, 108, 112, 116, 119, 124, 125, 128, 129, 130, 131, 133, 136, 138, 141], "problemat": [39, 43, 48, 67, 102, 129, 134, 135, 136], "proc": 51, "proce": [19, 27, 34, 46, 53, 66, 98, 116], "procedur": [7, 8, 15, 38, 41, 44, 46, 47, 61, 63, 65, 66, 78, 82, 86, 97, 112, 116, 126, 135, 136], "proceed": 138, "process": [1, 8, 9, 16, 25, 30, 34, 43, 44, 45, 46, 47, 48, 59, 60, 62, 63, 64, 65, 66, 67, 69, 71, 73, 76, 79, 87, 89, 92, 93, 97, 98, 100, 102, 103, 105, 112, 118, 135, 142], "process_group": 108, "process_new_macros_for_config_fil": 0, "prod": [129, 134], "prod_": [4, 19, 34, 37, 38, 39, 40, 41, 48, 49, 88, 125, 129, 134], "prod_i": 72, "produc": [0, 5, 9, 11, 19, 25, 34, 38, 43, 44, 48, 51, 60, 63, 67, 88, 98, 100, 109, 112, 115, 116, 118, 126, 136, 138, 143], "product": [8, 13, 15, 16, 19, 20, 23, 31, 33, 34, 39, 41, 43, 44, 45, 47, 49, 52, 53, 65, 68, 75, 77, 83, 88, 98, 102, 105, 112, 119, 129, 134, 135, 136, 138], "production_step1": 73, "production_step2": 73, "prof": 95, "profici": 116, "program": [34, 62, 63, 64, 65, 67, 72, 89, 93, 99, 115, 116, 117, 118, 119, 134, 136], "programdata": 119, "programm": 64, "progress": [8, 50, 64, 68, 71, 105, 119, 134], "progress_callback": 108, "progressbar": 73, "prohibit": [104, 106], "project": [1, 37, 45, 47, 49, 63, 65, 109, 112, 116, 128, 135, 136, 145], "project_root_dir": 115, "promin": [67, 102, 110], "promis": [73, 97], "promot": [43, 116, 135], "prompt": [116, 119], "prone": [100, 117], "pronounc": [73, 93, 110], "proof": [3, 22, 31, 32, 33, 34, 62, 66, 67, 98, 126, 138], "propag": [0, 1, 3, 28, 43, 64, 70, 71, 75, 85, 88, 102, 131], "proper": [7, 43, 47, 64, 71, 99, 100, 107, 116], "properli": [4, 7, 43, 63, 71, 72, 88, 96, 112, 126, 129, 133, 134], "properti": [4, 7, 17, 25, 38, 44, 47, 48, 50, 53, 66, 67, 73, 75, 77, 78, 79, 80, 82, 83, 85, 97, 103, 109, 112, 126, 132, 135, 138, 143], "proport": [4, 7, 25, 29, 34, 39, 40, 66, 72, 93, 109, 115, 125, 128, 129, 130, 134, 136, 143], "proportion": [34, 43, 53, 63, 145], "propos": [8, 25, 38, 44, 51, 92, 96, 99, 102, 125, 126, 127, 128, 130, 135, 136, 138, 143, 144], "proposal_posit": 126, "proposal_width": [126, 141], "propose_loc": 92, "proposed_posit": 126, "proposit": [8, 25, 30, 62, 100], "propsal": [126, 135], "propto": [3, 4, 7, 13, 15, 25, 34, 35, 39, 40, 41, 44, 48, 51, 72, 85, 96, 128, 129, 130, 133, 134, 135, 138, 140, 141, 145], "protect": 119, "protocol": [47, 53, 61], "proton": [34, 79, 98, 115, 136], "prototyp": [16, 64, 77, 79, 91, 96, 140], "prove": [19, 33, 37, 53, 107, 109, 138], "proven": [12, 67, 100, 135], "provid": [3, 4, 7, 8, 9, 22, 24, 25, 28, 30, 34, 43, 44, 46, 47, 48, 51, 53, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 75, 77, 83, 86, 89, 91, 98, 100, 103, 114, 115, 117, 118, 128, 129, 133, 134, 135, 138, 143], "provis": 61, "provoc": 16, "proxi": [9, 30, 72, 114], "psd": [77, 83], "pseudo": [92, 98, 99, 141], "pseudoconverg": 44, "psi": [0, 17, 23, 45, 47, 125], "psi_": [45, 125], "psi_1": 45, "psi_2": 45, "psi_chain": 125, "psi_i": [45, 47], "psi_j": [45, 47], "psi_mean": 125, "psi_mean_al": 125, "psi_n": 45, "psub": 34, "psutil": 105, "psychologi": 64, "pt": 108, "pt_sampler_t0": 96, "ptemce": [50, 51, 90], "ptemse": 50, "ptmcmc": [50, 96], "ptsampler": 96, "public": [1, 63, 64], "publica": 63, "publicli": [44, 56], "publish": [1, 15, 44, 53, 91, 100, 115], "puk94": [1, 46], "pukelheim": 46, "pukelsheim": 1, "pull": [48, 51], "pulldown": [9, 116], "punish": 64, "pure": [16, 44, 48, 53, 61, 62, 129, 134, 135], "purport": 48, "purpos": [7, 44, 48, 49, 50, 66, 67, 71, 95, 100, 128, 138], "push": 133, "put": [0, 8, 19, 20, 23, 24, 27, 31, 32, 34, 39, 40, 47, 52, 53, 56, 66, 72, 85, 115, 116, 117, 118, 125, 129, 134, 141], "px": 5, "py": [0, 37, 38, 50, 81, 96, 105, 108, 115, 133, 134], "pylab": 115, "pymc": [64, 73, 93, 125, 128, 130, 142, 145], "pymc3": [93, 133], "pymc_docs_getting_started_upd": 140, "pymc_nam": 134, "pymcinference_library_vers": 133, "pypi": 43, "pyplot": [0, 3, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 50, 65, 69, 70, 71, 73, 76, 77, 78, 80, 81, 82, 83, 88, 92, 93, 95, 96, 98, 105, 108, 109, 111, 112, 114, 115, 116, 117, 125, 126, 127, 129, 131, 132, 133, 134, 135, 138, 143, 144], "pytensor": 71, "python": [0, 1, 5, 11, 19, 23, 26, 34, 39, 40, 43, 52, 56, 66, 69, 72, 73, 78, 85, 93, 94, 96, 98, 99, 107, 112, 113, 115, 118, 119, 121, 122, 129, 134, 135, 138, 140, 143, 145], "python3": [0, 50, 81, 96, 108, 119, 122, 134], "pytorch": [64, 111], "pytorch_thread": 105, "p\u00f3lya": 61, "q": [3, 4, 19, 35, 44, 46, 72, 78, 82, 85, 107, 126, 130, 131, 136, 138], "q_": 85, "q_0": 131, "q_i": [44, 130], "qbism": 106, "qcd": 44, "qfrsaikz4ric": 1, "qft": 102, "qmn15": [1, 45], "qoi": 48, "qquad": [4, 7, 35, 51, 52, 66, 78, 103, 105, 112, 130, 132, 141], "quad": [0, 3, 4, 5, 7, 11, 13, 15, 17, 19, 23, 24, 33, 34, 35, 37, 42, 46, 47, 53, 66, 85, 86, 105, 107, 112, 125, 127, 130, 135, 138, 140, 144], "quadrat": [19, 34, 38, 53, 72, 77, 78, 81, 82, 83, 85, 98, 100, 105], "quadratur": [51, 136], "qualifi": [63, 64], "qualit": [7, 62, 103, 112, 128], "qualiti": [34, 53, 60, 63, 72, 98], "quanta": 110, "quantif": [8, 45, 46, 47, 62, 85, 97, 104], "quantifi": [7, 8, 16, 22, 43, 46, 53, 60, 62, 65, 88, 95, 100, 102, 103, 112, 126], "quantil": [17, 38, 41, 43, 50, 77, 83, 94, 96, 105, 112, 125, 129, 134], "quantit": [7, 8, 16, 46, 58, 62, 71, 100, 103], "quantiti": [4, 7, 16, 17, 22, 23, 25, 31, 34, 41, 44, 45, 46, 47, 48, 51, 53, 64, 66, 67, 68, 72, 88, 94, 95, 98, 99, 100, 102, 103, 106, 108, 112, 115, 125, 126, 135], "quantum": [1, 16, 22, 23, 45, 47, 64, 67, 99, 102, 106, 138, 143], "quarteroni": 1, "que": 34, "queri": 116, "question": [7, 8, 11, 17, 25, 26, 27, 33, 39, 42, 49, 50, 52, 53, 56, 60, 61, 66, 68, 71, 73, 92, 93, 98, 109, 118, 124, 125, 129, 134, 138, 141, 143, 144], "questionnair": 63, "quick": [109, 116, 117, 128], "quickli": [40, 47, 66, 73, 75, 118], "quickstart": 69, "quiet": 67, "quirki": 38, "quit": [34, 38, 67, 68, 73, 93, 95, 117, 126], "quod": 53, "quot": [16, 19, 39, 51, 66, 95, 99, 116, 134], "r": [0, 1, 3, 5, 6, 7, 9, 11, 13, 15, 16, 17, 19, 29, 33, 34, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 65, 66, 67, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 93, 96, 98, 99, 100, 103, 105, 108, 109, 111, 112, 114, 115, 116, 117, 118, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 141, 143, 144, 145], "r2": [38, 66, 78], "r2_score": 115, "r_": [85, 132], "r_0": 132, "r_dot": 132, "r_dot_0": 132, "r_dot_half": 132, "r_dot_pt": 132, "r_dot_pts_eul": 132, "r_dot_pts_lf": 132, "r_hat": [133, 134], "r_i": [38, 95, 132], "r_list": 117, "r_pt": 132, "r_pts_euler": 132, "r_pts_lf": 132, "r_sq": 38, "race": 63, "racial": 63, "radford": [44, 130], "radfriend": 136, "radial": [80, 85, 103], "radii": 47, "radio": 53, "radioact": [37, 136], "radioactive_lighthouse_exercis": 124, "radioactive_lighthouse_exercise_kei": 35, "radiu": [46, 47, 49, 100, 115, 132, 136], "rai": [42, 124], "rain": [0, 8, 16, 17, 22, 23, 112, 138], "raini": 16, "raio": 7, "rais": [33, 50, 96, 105, 108, 111, 118], "rajesh": 1, "ran_uniform_arrai": 33, "rand": [6, 17, 25, 40, 50, 71, 77, 78, 82, 83, 96, 105, 109, 118, 125, 126, 128, 129, 131, 134], "randint": [33, 118], "randn": [17, 40, 41, 73, 92, 93, 109, 115, 125, 133], "random": [3, 6, 9, 16, 17, 19, 23, 24, 25, 26, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 50, 51, 53, 60, 63, 65, 66, 67, 70, 71, 73, 74, 77, 78, 79, 80, 81, 82, 83, 86, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 105, 109, 111, 115, 118, 124, 125, 127, 128, 129, 130, 131, 133, 134, 135, 142, 144], "random_st": [29, 70, 73, 74, 81, 93, 112, 138, 143], "randomcovariancematrix": 82, "randomli": [16, 32, 35, 40, 42, 44, 47, 49, 50, 65, 69, 71, 124, 125, 126, 130, 136], "randomst": [40, 80, 81, 125], "randomwalk": 143, "rang": [3, 5, 6, 7, 17, 25, 29, 30, 33, 34, 35, 37, 38, 41, 42, 43, 46, 47, 49, 50, 51, 58, 64, 65, 66, 69, 71, 76, 77, 78, 79, 82, 83, 85, 86, 88, 91, 95, 96, 98, 99, 102, 103, 104, 105, 108, 111, 112, 114, 116, 125, 126, 127, 129, 134, 135, 136, 138, 143, 144], "ranganath": [1, 72], "ranganathan": 86, "rangl": [4, 19, 37, 42, 45, 85, 128, 135, 141], "rangle_": 51, "rank": [34, 55, 98, 107, 109], "rapidli": [33, 64, 79, 119, 136], "rare": [33, 34, 63, 98, 103, 133], "rasmu": 108, "rasmussen": [1, 85, 86], "rasumu": 108, "rate": [1, 31, 37, 44, 47, 63, 66, 67, 68, 69, 70, 71, 88, 97, 99, 111, 126, 128, 130, 141, 143, 145], "rather": [4, 8, 22, 23, 25, 34, 37, 38, 39, 41, 43, 44, 46, 47, 52, 53, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 88, 95, 99, 100, 103, 109, 115, 116, 117, 125, 129, 133, 134, 141], "ratio": [5, 7, 8, 44, 50, 51, 52, 53, 78, 82, 85, 86, 96, 100, 102, 107, 112, 127, 133, 135, 136, 138, 144], "ratio_max": [78, 82], "ratio_min": [78, 82], "ration": [7, 8, 62], "rational": 61, "rationalquadrat": 81, "ravel": [37, 40, 41, 70, 80, 105], "ravin": 99, "raw": [75, 109], "razor": 53, "rbf": [77, 79, 80, 81, 83, 85, 92, 103, 105], "rbf_kernel": 105, "rbf_lengthscal": 82, "rbf_term": 105, "rbf_varianc": 82, "rbfco": 77, "rbfkernel": 82, "rbm": [47, 104], "rbrace": 48, "rc_context": 108, "rcparam": [5, 9, 37, 108, 114, 115, 131, 132], "rct1": 115, "rct2": 115, "rdbu": 70, "rdbu_r": 65, "rdot": 132, "rdylbu_r": 65, "re": [1, 3, 5, 8, 13, 16, 19, 22, 38, 40, 41, 42, 51, 63, 69, 71, 72, 78, 92, 95, 96, 116, 124, 125, 126, 128, 133, 141], "reach": [8, 16, 43, 44, 62, 63, 66, 67, 68, 88, 97, 99, 125, 133, 135, 138], "react": [25, 115], "reaction": 47, "read": [0, 11, 23, 32, 35, 59, 64, 67, 68, 72, 75, 86, 94, 95, 109, 116, 117, 118, 119, 120, 140], "read_fwf": 115, "readabl": 134, "reader": [43, 46, 59, 61, 79], "readi": [42, 61, 68, 69, 115], "readili": 41, "readm": 43, "readout": 114, "readout_format": 114, "readthedoc": [41, 134, 145], "real": [0, 7, 8, 9, 16, 23, 40, 47, 63, 67, 72, 73, 77, 82, 83, 88, 98, 99, 100, 107, 118, 128, 143], "realis": 138, "realist": [16, 34, 98, 135, 136, 138], "realiti": [8, 34, 48, 61, 62, 98, 100, 105, 110, 112], "realiz": [4, 7, 8, 22, 34, 41, 53, 65, 66, 67, 86, 98, 141, 143], "realli": [7, 13, 17, 18, 23, 31, 38, 39, 40, 42, 44, 67, 73, 85, 93, 96, 100, 102, 126, 129, 134, 135, 141], "realm": 62, "rearrang": [23, 31, 32], "reason": [0, 1, 7, 8, 11, 16, 19, 22, 25, 34, 40, 43, 53, 58, 61, 63, 71, 77, 79, 86, 96, 98, 99, 112, 118, 126, 128, 129, 134, 135, 136], "recal": [4, 9, 30, 31, 34, 38, 44, 48, 49, 52, 53, 63, 68, 82, 85, 88, 92, 107, 109, 125, 130], "recalcul": 124, "recalculate_data": 9, "recalculate_data_w": 9, "recapitul": 138, "recast": [51, 99], "receiv": [67, 82], "recent": [48, 49, 50, 63, 66, 69, 70, 71, 73, 93, 96, 99, 108], "recept": 67, "recess": 112, "recession": [7, 41], "recip": [16, 34, 69, 88, 95, 141], "recogn": [21, 39, 43, 46, 47, 53, 60, 62, 103, 109, 128, 129, 134], "recognis": [4, 88], "recognit": [53, 61, 63, 64, 67, 73, 75], "recommend": [38, 40, 41, 43, 56, 63, 64, 71, 75, 99, 112, 115, 116, 121, 124, 126, 133, 134], "reconstrain": [77, 83], "reconstuct": 5, "record": [4, 5, 8, 37, 42, 50, 53, 93, 96, 103, 105, 124, 127, 143, 144], "recov": [34, 103], "recreat": [44, 66, 109], "rectangl": 131, "rectifi": [67, 71, 75], "recurr": [68, 73, 118, 126, 135, 138], "recurs": 62, "red": [5, 9, 17, 23, 30, 33, 34, 37, 38, 39, 42, 49, 65, 69, 72, 75, 76, 77, 78, 81, 88, 93, 95, 98, 103, 105, 108, 109, 112, 116, 126, 127, 128, 129, 130, 132, 134, 136, 141, 143, 144, 145], "redefin": 92, "redirect": [73, 93], "redo": 41, "redrawn": 114, "redshift": 7, "reduc": [1, 22, 29, 34, 38, 39, 43, 44, 46, 47, 53, 60, 63, 66, 72, 75, 79, 88, 97, 98, 99, 102, 103, 104, 107, 109, 125, 128, 132], "reduct": [1, 44, 46, 47, 66, 106, 107, 125, 133], "redund": 107, "ref": [0, 42, 44, 45, 46, 47, 48, 145], "refactor": 108, "refer": [1, 2, 7, 8, 16, 17, 27, 34, 41, 43, 45, 46, 48, 52, 53, 56, 63, 66, 67, 72, 75, 76, 78, 81, 86, 88, 98, 100, 102, 103, 104, 107, 112, 116, 133, 135, 145], "refin": [5, 8, 46, 59, 67], "refit": 70, "reflect": [8, 25, 43, 46, 53, 63, 64, 103, 109, 115, 129, 134, 135, 138], "reformat": 69, "refresh": [56, 113], "regain": 34, "regard": [4, 8, 9, 25, 46, 51, 56, 58], "regardless": [8, 19, 77, 83, 135, 138], "regener": 9, "regenerate_data": 9, "regim": [48, 103], "region": [17, 19, 41, 44, 46, 48, 50, 51, 52, 53, 65, 66, 67, 72, 73, 75, 77, 78, 80, 82, 83, 93, 94, 95, 128, 130, 131, 135, 136, 141], "regist": [43, 119], "registri": 43, "regress": [1, 16, 27, 28, 38, 45, 47, 63, 67, 68, 71, 72, 73, 79, 86, 87, 89, 93, 95, 97, 99, 101, 115, 140], "regressor": [65, 82, 88], "regular": [60, 67, 70, 72, 73, 74, 77, 80, 83, 93, 133], "regularli": [71, 95], "reifi": 48, "reilli": 1, "reinforc": [32, 64], "reject": [4, 11, 19, 46, 53, 126, 127, 128, 130, 135, 136, 141, 144, 145], "rel": [8, 16, 31, 38, 43, 46, 47, 48, 49, 51, 53, 65, 88, 94, 96, 97, 100, 109, 116, 126, 135], "relat": [4, 7, 15, 17, 19, 23, 25, 34, 38, 40, 41, 42, 43, 46, 48, 53, 59, 61, 63, 64, 66, 67, 71, 77, 83, 89, 94, 96, 98, 100, 109, 110, 135], "relationship": [7, 34, 46, 53, 59, 62, 64, 86, 100, 102, 128], "relax": [47, 94], "releas": [43, 50, 56, 96], "relerr": [131, 132], "relev": [7, 9, 16, 25, 34, 38, 47, 53, 61, 63, 65, 66, 67, 72, 85, 88, 94, 95, 96, 98, 100, 112, 116, 119, 124, 128, 138, 143, 145], "reli": [22, 25, 46, 51, 53, 64, 71, 73, 93, 100, 118], "reliabl": [35, 38, 47, 51, 88, 96, 100, 103, 104, 117], "relu": [67, 69, 70, 71, 75, 76, 102, 111], "remain": [4, 16, 44, 47, 49, 53, 56, 66, 67, 103, 133, 135], "remaind": [25, 99], "remark": [20, 25, 43, 44, 47, 67, 103, 115, 128, 135, 143], "remedi": 8, "rememb": [4, 17, 22, 34, 46, 49, 65, 66, 74, 92, 107, 117, 118, 133, 136, 138, 143], "remind": 66, "remov": [37, 38, 46, 61, 63, 70, 78, 95, 107, 109, 126, 135], "ren": 1, "renaiss": 73, "renam": [116, 133], "render": [44, 45, 70, 116], "renewcommand": 0, "renorm": [12, 102], "reoffend": 63, "reorder": 88, "reorgan": 115, "rep": [1, 43], "reparameter": 133, "repeat": [29, 33, 34, 39, 41, 42, 43, 46, 50, 53, 66, 67, 77, 78, 80, 82, 90, 92, 94, 95, 96, 102, 104, 108, 109, 112, 117, 125, 127, 129, 133, 134, 135, 136, 141, 144], "repeatadli": 73, "repeatedli": [11, 15, 39, 44, 59, 129, 134], "repercuss": 63, "repetit": 112, "rephras": 7, "replac": [7, 16, 25, 44, 45, 46, 51, 52, 63, 68, 71, 72, 77, 80, 83, 85, 95, 104, 115, 124, 135], "repli": 110, "replic": 43, "replica": 51, "replot": 17, "report": [8, 43, 47, 53, 116, 129, 134], "repositori": [40, 43, 56, 64, 113, 119, 121, 122], "repres": [3, 4, 7, 8, 9, 16, 21, 22, 23, 25, 38, 39, 41, 44, 46, 48, 49, 51, 53, 59, 60, 63, 64, 65, 66, 67, 68, 71, 75, 76, 88, 94, 95, 96, 99, 102, 103, 105, 109, 112, 117, 118, 125, 126, 128, 129, 134, 135, 136, 138], "represent": [1, 4, 7, 19, 35, 47, 48, 66, 69, 70, 73, 75, 85, 100, 107, 117, 128, 135], "reproduc": [4, 13, 25, 30, 34, 44, 49, 53, 61, 63, 64, 65, 66, 68, 72, 91, 94, 96, 98, 100, 105, 109, 112, 115, 126, 136, 138, 143], "reproduct": [33, 34, 61, 66, 143], "repuls": 115, "request": [64, 77, 105, 138], "requir": [7, 8, 19, 33, 34, 37, 38, 40, 43, 44, 45, 46, 47, 49, 51, 53, 59, 60, 62, 64, 67, 71, 73, 75, 76, 85, 90, 96, 97, 98, 99, 104, 105, 106, 112, 115, 118, 119, 122, 124, 130, 135, 138, 141, 143], "requires_grad": 71, "rerun": [37, 70], "resampl": [1, 46, 66, 105, 130], "rescal": [44, 70, 105], "research": [0, 1, 8, 19, 28, 34, 48, 57, 59, 60, 61, 64, 72, 73, 99, 102, 103], "resembl": [48, 126], "reserv": [34, 68], "reset": [6, 9, 38, 50, 71, 96, 105, 125, 129, 134], "reset_button_w": 9, "reset_n": 9, "reshap": [3, 6, 17, 25, 30, 34, 38, 41, 50, 70, 73, 76, 77, 80, 81, 82, 83, 92, 93, 96, 98, 105, 109, 115, 125, 128, 129, 134], "resid": [45, 46, 118], "residenti": 16, "residu": [5, 29, 34, 38, 47, 51, 95, 96, 98, 99], "residual_": [34, 98], "residual_1": [34, 98], "residual_2": [34, 98], "residual_3": [34, 98], "residual_i": 34, "resist": 103, "resiz": [108, 118], "resolut": 131, "resolv": [46, 48], "reson": 47, "resort": 34, "resourc": [37, 43, 46, 116, 118], "respect": [4, 5, 7, 8, 16, 24, 25, 34, 38, 43, 44, 45, 46, 47, 48, 53, 63, 64, 65, 66, 67, 68, 71, 72, 75, 85, 88, 97, 98, 99, 102, 112, 115, 118, 126, 138], "respond": [8, 67], "respons": [34, 56, 63, 64, 65, 67, 71, 77, 85, 88, 98, 100, 110, 112, 116], "rest": [8, 46, 66, 73, 78, 82, 94, 95, 100, 136], "restart": [92, 116, 119], "restore_sign": 108, "restraint": 61, "restrict": [43, 46, 47, 52, 53, 58, 67, 82, 99, 116, 128, 143], "restructur": 118, "result": [3, 4, 6, 7, 8, 9, 11, 13, 15, 16, 19, 23, 25, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 44, 47, 48, 50, 51, 52, 53, 55, 58, 59, 61, 62, 63, 64, 65, 66, 68, 71, 72, 75, 77, 78, 82, 83, 85, 88, 90, 91, 92, 93, 94, 95, 96, 98, 103, 105, 108, 109, 111, 112, 115, 116, 118, 124, 125, 127, 128, 129, 134, 138, 140, 141, 143, 144], "retain": [109, 117], "retriev": [69, 73], "return": [0, 4, 5, 6, 7, 8, 9, 17, 25, 29, 30, 33, 34, 35, 37, 38, 40, 41, 42, 46, 49, 50, 52, 65, 69, 70, 71, 72, 73, 74, 77, 78, 82, 85, 86, 88, 92, 93, 94, 95, 96, 97, 98, 99, 105, 108, 109, 111, 112, 114, 115, 116, 117, 118, 120, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 138, 141, 143, 144], "return_cov": 82, "return_inferencedata": [133, 134], "return_std": [80, 81], "reusabl": 43, "rev": [1, 78, 82, 86], "reveal": [45, 53, 63, 102, 120, 138], "revers": [22, 23, 25, 44, 72, 119, 130, 132, 143], "reversibil": 44, "reversiblemarkovprocessexampl": 138, "reversiblemarkovprocessexample_cprob_fig": 138, "reversiblemarkovprocessexample_runs_fig": 138, "review": [34, 35, 41, 45, 49, 63], "revis": [5, 16, 38, 50, 56, 58, 61, 77, 78, 119, 125, 131, 133], "revisit": [25, 50, 59, 66], "revolut": 51, "revolv": 100, "reward": 64, "reweight": 136, "reword": 31, "rewrit": [25, 66, 67, 68, 72, 85, 88, 125], "rewritten": [66, 138], "rf": [17, 33, 37, 40, 42, 65, 78, 82, 108, 117, 125, 127, 131, 132, 143, 144], "rg": 102, "rhat": [125, 133], "rho": [44, 72, 78, 79, 86, 112, 126, 141], "rho_": [24, 52, 82, 112], "rich": [47, 64], "richard": [1, 44, 130, 135, 136], "richardson": 1, "ridg": [1, 88], "riemann": 128, "right": [0, 3, 4, 7, 9, 13, 15, 16, 17, 19, 22, 23, 24, 25, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 44, 47, 48, 49, 51, 52, 53, 56, 63, 64, 65, 66, 67, 68, 69, 72, 73, 76, 78, 82, 85, 88, 92, 94, 95, 96, 97, 98, 99, 100, 102, 103, 107, 108, 109, 112, 116, 119, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 138, 141, 143, 144], "rightarrow": [0, 3, 4, 7, 13, 15, 19, 22, 23, 33, 34, 35, 37, 44, 48, 67, 72, 85, 86, 98, 128, 130, 136, 140], "rightli": [8, 53], "rightmost": 56, "rigidli": 56, "rigor": [43, 58, 59, 62, 64, 100, 108, 126], "rigour": 100, "ring": 51, "rise": [8, 34, 53, 109], "risk": [8, 43, 44, 46, 59, 63, 66], "ritz": 47, "rivalri": 45, "rjf": 104, "rk23": 132, "rlhick": 133, "rm": [9, 11, 16, 19, 29, 33, 37, 42, 44, 48, 49, 63, 66, 67, 71, 78, 79, 86, 94, 95, 103, 112, 114, 132], "rmsprop": [67, 71], "rng": [30, 34, 80, 81, 98, 112], "rnn": 67, "roam": 141, "rob": 125, "rob21": [1, 102], "robert": [1, 102, 110, 126, 143], "roberto": 1, "robust": [1, 38, 43, 61, 63, 100, 103, 105, 133, 134, 145], "role": [43, 48, 53, 56, 64, 66, 67, 82, 86, 109, 112, 116], "roll": [4, 23, 65, 125], "rom": 47, "ron": 1, "ronald": 1, "rongzheng": 1, "rook": 79, "room": 116, "root": [24, 41, 56, 63, 64, 66, 71, 100, 112, 116, 118], "root_mean": 65, "rot": 115, "rotat": [46, 51, 109, 128], "rough": [18, 46], "roughli": [29, 33, 34, 39, 44, 51, 53, 63, 71, 107, 112, 126, 134], "round": [4, 105, 109, 115, 118], "routin": [50, 134], "row": [1, 25, 30, 32, 42, 67, 69, 78, 105, 109, 115, 116, 117, 126, 135, 138, 141], "roweth": 1, "royal": 1, "royalblu": 65, "rrapaj": 1, "rseed": [40, 125], "rsq": 38, "rst": [73, 93], "rstride": [37, 65], "rtol": [131, 132], "rub88": [1, 44], "rubin": [1, 128], "ruder": 99, "ruin": 8, "rule": [0, 1, 7, 13, 15, 16, 20, 23, 27, 29, 34, 37, 41, 51, 52, 53, 58, 61, 62, 63, 65, 71, 88, 99, 112, 128, 135, 138, 141, 143], "ruler": [7, 41], "rumelhart": 1, "rumelharthintonwilliams86": [1, 68], "run": [8, 9, 30, 34, 37, 38, 42, 43, 44, 46, 49, 50, 51, 56, 70, 71, 73, 76, 79, 83, 86, 93, 95, 96, 98, 99, 102, 105, 107, 108, 111, 112, 113, 115, 116, 117, 120, 125, 127, 132, 133, 134, 136, 138, 140, 141, 143, 144], "run_mcmc": [6, 38, 41, 50, 96, 105, 125, 129, 134], "run_model": 111, "rung": [130, 132], "runner": 77, "runtimeerror": 108, "runtimewarn": 38, "ruth": 1, "rutherford": 112, "rv": [9, 17, 29, 33, 37, 39, 42, 49, 65, 78, 82, 86, 108, 112, 126, 127, 129, 133, 134, 135, 144], "rvec": 51, "rvec_": 51, "rvec_i": 51, "rvert": [99, 103], "rw05": [1, 85], "rwidth": [127, 144], "ryh22": [1, 102], "r\u00e9duit": 34, "r\u00e9sum\u00e9": 63, "s1": 37, "s12918": 1, "s2": 37, "s41567": 1, "s43586": 1, "s_": 107, "s_eleph": 99, "s_i": 109, "s_j": [44, 109, 125, 133], "s_k": [107, 109], "s_n": 143, "s_shape": 109, "sa": 43, "saddl": [39, 53, 99, 129, 134], "safe": [50, 96], "safeti": [0, 63, 64], "sai": [0, 3, 4, 7, 8, 13, 16, 17, 19, 22, 23, 25, 30, 31, 32, 34, 37, 38, 39, 40, 42, 43, 44, 48, 49, 53, 56, 58, 62, 66, 68, 75, 86, 88, 95, 109, 116, 118, 119, 125, 126, 128, 129, 134, 138, 141], "said": [16, 58, 65, 138], "sake": [48, 88, 115], "salutari": 7, "sam": [115, 118], "same": [0, 4, 5, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 22, 23, 25, 30, 31, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 52, 53, 55, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 77, 79, 82, 83, 86, 92, 93, 94, 95, 96, 99, 102, 103, 105, 107, 108, 109, 111, 112, 115, 116, 117, 118, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 141, 143, 144, 145], "samp_label": 108, "sampl": [0, 1, 3, 6, 16, 19, 23, 29, 34, 37, 39, 40, 41, 42, 43, 45, 46, 47, 49, 51, 53, 59, 63, 66, 67, 69, 70, 72, 73, 79, 80, 81, 86, 88, 89, 92, 93, 94, 95, 96, 98, 102, 103, 104, 106, 108, 109, 111, 112, 118, 124, 125, 129, 130, 140, 143, 145], "sample_i": 81, "sample_mean": 65, "sample_means_fixed_sample_s": 33, "sample_nod": [73, 93], "sample_posterior_predict": [73, 93], "sample_proba": [73, 93], "sample_s": 33, "sample_sort": 96, "sample_stat": 133, "sample_std": 65, "sampler": [1, 6, 7, 38, 41, 44, 51, 59, 73, 74, 93, 94, 125, 126, 128, 129, 130, 135, 136, 142], "sampler_object": 41, "samples_md": 105, "samples_md_poco": 105, "samples_save_dir": 105, "samples_spars": 6, "samples_unflatten": [50, 125], "samples_wmd": 105, "samples_wmd_poco": 105, "samplescor": [78, 82], "samplesuncor": [78, 82], "samplig": 136, "sampling_tim": 133, "samwis": 115, "sandbox": 86, "saniti": 118, "santayana": 46, "sarah": [1, 56], "satisfi": [3, 4, 7, 29, 31, 46, 51, 53, 95, 112, 130, 138, 141], "satur": [49, 52, 90, 96], "save": [6, 7, 19, 42, 44, 66, 69, 96, 105, 108, 115, 118, 120, 124, 129, 134], "save_fig": 115, "save_model": 69, "savefig": [6, 73, 108, 115, 116, 131, 132], "savefig_kwarg": 108, "saw": [49, 82], "sbn": 125, "scalabl": 73, "scalar": [44, 47, 50, 65, 71, 85, 86, 96, 107, 109, 111, 125, 128], "scale": [13, 17, 19, 33, 34, 37, 38, 40, 41, 42, 43, 44, 47, 50, 51, 65, 67, 69, 71, 72, 77, 78, 79, 80, 81, 82, 83, 86, 95, 96, 99, 100, 103, 105, 108, 109, 111, 112, 125, 127, 129, 133, 134, 135, 141, 144, 145], "scale_": 105, "scaled_sum": 29, "scaler": 105, "scan": 88, "scandinavian_entropi": 4, "scatter": [34, 38, 39, 41, 42, 45, 47, 65, 70, 71, 72, 73, 78, 80, 81, 82, 93, 98, 109, 115, 133, 134, 136], "scatter_joint_bnn_plot": 72, "scatterplot": 65, "scb": 112, "sccord": 112, "scenario": [4, 7, 43, 44, 48, 53, 64, 66, 67, 72, 103, 141, 143], "schack": 110, "sched_getaffin": 105, "schedul": 99, "schemat": [47, 79, 102, 128, 141], "schematic_rbm": 47, "scheme": [46, 65, 101, 135], "school": [8, 22, 39, 53, 56, 63, 77, 83, 129, 134], "schoot": [1, 43], "schroding": [23, 47, 79], "schr\u00f6dinger": 45, "schwab": 1, "sch\u00f6n": 1, "sci": 1, "scienc": [0, 1, 8, 16, 43, 47, 48, 53, 56, 57, 58, 60, 61, 62, 63, 66, 67, 99, 102, 116, 127, 135, 144], "scientif": [7, 8, 15, 16, 25, 40, 43, 45, 46, 48, 53, 56, 58, 60, 61, 62, 64, 65, 67, 99, 100, 103, 108, 110, 116, 119, 122, 143], "scientist": [1, 8, 53, 63, 64, 112], "scikit": [1, 64, 66, 81, 86, 93, 115, 118, 119], "scikitlearn": 115, "scipi": [0, 5, 6, 7, 9, 13, 19, 23, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 65, 69, 78, 82, 92, 95, 96, 105, 108, 109, 116, 118, 119, 125, 126, 127, 129, 131, 132, 133, 134, 135, 136, 144], "scope": [8, 100], "score": [67, 69, 70, 75, 115, 133], "scorn": 58, "scott": 118, "scratch": [44, 69], "screen": [31, 44, 56, 63, 131], "script": [0, 43, 111, 136, 138, 143], "scroll": [17, 112, 116], "sd": [127, 133, 134, 144], "se": [1, 16, 47, 58, 78, 82, 125, 128], "seaborn": [5, 9, 17, 33, 37, 38, 39, 40, 41, 42, 49, 50, 70, 73, 77, 78, 92, 93, 95, 96, 115, 117, 125, 126, 127, 129, 134], "seali": [0, 23], "search": [1, 46, 56, 67, 99, 112, 116, 138, 143], "searchsort": [37, 40, 41], "sebastian": 99, "sec": [0, 41, 43, 105], "second": [7, 8, 16, 17, 19, 22, 23, 25, 31, 32, 34, 35, 38, 39, 41, 43, 44, 46, 48, 49, 52, 53, 64, 66, 67, 68, 69, 71, 72, 73, 85, 96, 98, 99, 100, 107, 108, 112, 115, 116, 118, 126, 128, 129, 132, 133, 134, 138, 141], "secondari": 94, "secondli": 68, "section": [8, 9, 14, 23, 26, 30, 34, 35, 37, 42, 43, 48, 56, 58, 61, 65, 77, 81, 83, 86, 90, 91, 94, 96, 98, 100, 107, 114, 115, 119, 127, 137, 139, 144], "sector": [1, 64, 67], "sedol": 73, "see": [0, 3, 4, 5, 7, 9, 11, 13, 15, 16, 19, 23, 25, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 56, 59, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 92, 93, 94, 95, 96, 97, 99, 100, 101, 103, 109, 112, 113, 115, 116, 118, 119, 121, 122, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138, 141, 144], "seed": [6, 9, 17, 25, 30, 38, 39, 40, 65, 66, 70, 78, 82, 92, 93, 95, 96, 105, 112, 115, 125, 126, 129, 134, 138, 141, 143], "seek": [9, 10, 16, 19, 23, 30, 34, 44, 45, 47, 49, 51, 55, 56, 62, 67, 85, 97, 98, 99, 103, 129, 130, 134, 135], "seem": [0, 5, 19, 22, 25, 31, 38, 39, 44, 48, 49, 53, 62, 73, 75, 77, 83, 129, 133, 134, 136, 138, 142], "seen": [7, 8, 34, 53, 62, 63, 68, 72, 75, 78, 82, 86, 88, 98, 109, 116, 126, 128, 130, 135, 136, 138, 141], "sekstromforssen22": [1, 44], "selct": 112, "seldomli": 8, "select": [1, 9, 16, 43, 47, 52, 54, 55, 56, 59, 64, 65, 66, 72, 77, 78, 80, 82, 83, 86, 89, 90, 91, 92, 96, 98, 111, 115, 116, 119, 131, 139, 143], "selection_mini": 90, "self": [9, 50, 59, 64, 71, 79, 96, 105, 108, 131, 132, 138, 143], "semi": [34, 77, 83, 92, 109], "semicolon": 120, "semidefinit": [82, 86], "semilogi": [95, 109, 131, 132], "semilogx": 144, "sen": 34, "send": 67, "sens": [4, 7, 8, 16, 25, 34, 35, 38, 40, 41, 47, 52, 59, 62, 63, 66, 73, 93, 96, 98, 112, 125, 126, 128, 133, 138], "sensibl": [4, 25, 75], "sensit": [0, 5, 8, 35, 38, 40, 43, 44, 46, 47, 49, 51, 66, 94, 95, 97, 104], "sentenc": [63, 67], "sentiment": 63, "sep": 115, "separ": [8, 34, 43, 44, 47, 50, 51, 53, 63, 64, 65, 73, 77, 83, 86, 93, 96, 98, 116, 117, 124, 125, 128], "septemb": 1, "sequenc": [1, 15, 30, 44, 67, 72, 75, 88, 92, 108, 112, 118, 120, 125, 138, 141, 143], "sequenti": [15, 25, 30, 67, 69, 70, 71, 76, 103, 111, 116, 118], "seri": [1, 8, 16, 33, 34, 37, 38, 39, 49, 55, 56, 64, 91, 94, 100, 115, 125, 129, 134, 136, 144], "serif": 115, "seriou": [8, 63, 64, 116], "serv": [44, 75, 86, 88, 103, 105, 115, 140], "server": [56, 113], "servic": 64, "set": [0, 1, 3, 4, 5, 7, 8, 11, 15, 16, 17, 19, 21, 22, 23, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 76, 78, 79, 80, 82, 85, 86, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 108, 109, 111, 112, 113, 115, 116, 117, 119, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 138, 141, 142, 143, 144, 145], "set_alpha": 9, "set_aspect": [40, 50, 65, 78, 82, 109, 117, 131, 132], "set_axis_off": 109, "set_axisbelow": 40, "set_color": [69, 76], "set_context": [5, 9, 38, 39, 42, 70, 73, 77, 78, 92, 93, 125, 126, 129, 134], "set_data": 73, "set_limit": [78, 82], "set_printopt": 109, "set_size_inch": 17, "set_styl": [73, 78, 92, 125], "set_titl": [3, 6, 9, 17, 29, 33, 34, 37, 38, 40, 41, 42, 49, 50, 65, 77, 78, 81, 82, 83, 98, 108, 109, 111, 114, 116, 117, 125, 127, 131, 132, 143, 144], "set_tt_rng": [73, 93], "set_vis": 108, "set_xlabel": [0, 3, 5, 6, 7, 9, 17, 25, 30, 33, 34, 37, 39, 40, 41, 42, 49, 65, 70, 73, 78, 81, 82, 88, 93, 95, 96, 98, 108, 109, 111, 112, 114, 115, 116, 117, 125, 127, 131, 132, 134, 135, 143, 144], "set_xlim": [6, 29, 33, 37, 42, 49, 50, 70, 77, 78, 95, 96, 108, 111, 112, 127, 131, 132, 144], "set_xtick": [78, 82], "set_ylabel": [0, 3, 5, 6, 7, 17, 25, 30, 33, 34, 37, 39, 40, 41, 49, 50, 65, 70, 73, 78, 81, 82, 88, 93, 95, 96, 98, 108, 111, 112, 114, 115, 116, 117, 125, 127, 131, 132, 134, 135, 143, 144], "set_ylim": [3, 6, 37, 42, 49, 50, 70, 81, 95, 96, 108, 111, 112, 127, 131, 132, 143, 144], "set_ytick": [9, 42], "set_zlabel": [65, 112], "set_zlim": 65, "settl": [8, 138], "setup": [9, 25, 30, 34, 48, 50, 51, 71, 98, 108, 114, 119, 125, 128, 129, 134], "setup_mod": 50, "setup_polynomial_design_matrix": [34, 98], "setup_rc_param": [105, 108], "setup_text": [9, 114], "seven": 63, "sever": [4, 7, 8, 9, 16, 17, 19, 29, 33, 38, 40, 42, 44, 46, 48, 53, 56, 63, 64, 65, 66, 67, 72, 73, 75, 76, 85, 88, 92, 95, 96, 97, 99, 102, 109, 110, 111, 112, 115, 116, 119, 122, 132, 135, 138, 145], "sexual": 63, "sg92": [1, 44], "sgd": [67, 99], "shade": [17, 37, 53, 108, 112], "shall": [46, 92, 105], "shallow": 19, "shannon": [4, 62], "shape": [6, 13, 25, 33, 34, 37, 41, 43, 50, 53, 65, 67, 69, 70, 73, 76, 77, 78, 80, 82, 83, 88, 92, 93, 94, 95, 96, 105, 108, 109, 112, 120, 125, 127, 128, 129, 130, 131, 133, 134, 135, 136, 138, 140, 141, 144], "share": [7, 43, 50, 56, 61, 72, 73, 81, 93, 96, 108, 115, 134, 138], "sharei": [3, 6, 25, 30, 40, 65, 78, 81, 82, 88, 112, 125, 143], "sharex": [3, 6, 25, 30, 40, 41, 81], "sharp": [19, 53, 65], "sharpli": [19, 34, 51, 67], "shave": 7, "she": [62, 88], "shed": 53, "sheet": [51, 118], "shef": 77, "sheffield": [77, 83, 85], "shell": [47, 108, 115, 136], "shift": [3, 5, 16, 39, 44, 72, 79, 105, 109, 116, 118, 120, 125, 126, 129, 134, 141], "shifti": 110, "shine": [40, 51], "ship": 76, "shire": 115, "sho": 1, "shop": 119, "shore": 4, "short": [7, 22, 23, 31, 32, 40, 44, 51, 56, 63, 67, 69, 72, 96, 108, 110, 118, 134, 138, 143], "shortcut": 118, "shorten": [0, 43], "shorter": [44, 126], "shorthand": [7, 25, 30, 66, 99, 115], "shortli": 8, "shoud": 30, "should": [4, 7, 8, 9, 10, 15, 16, 19, 21, 22, 23, 25, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 43, 44, 45, 46, 48, 51, 53, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 77, 78, 82, 83, 85, 86, 88, 93, 94, 95, 97, 98, 99, 100, 104, 105, 108, 109, 111, 112, 116, 118, 119, 125, 127, 129, 133, 134, 135, 136, 138, 141, 143, 144], "shouldn": [29, 119, 124], "show": [4, 7, 9, 11, 13, 16, 17, 24, 25, 30, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 49, 50, 51, 62, 65, 66, 67, 69, 70, 71, 72, 73, 76, 77, 79, 82, 83, 85, 86, 90, 93, 94, 96, 97, 98, 103, 105, 106, 107, 109, 112, 114, 115, 116, 117, 119, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 141, 143], "show_titl": [17, 38, 41, 50, 82, 94, 96, 105, 125, 129, 134], "shown": [4, 7, 9, 17, 19, 25, 34, 37, 38, 44, 47, 51, 65, 66, 67, 72, 73, 77, 81, 83, 95, 99, 103, 109, 112, 115, 116, 117, 118, 126, 133, 138, 143, 145], "shrink": [17, 37, 46, 76, 108, 124], "shrinkag": 66, "shuch": 112, "shuffl": [65, 99], "side": [3, 7, 8, 10, 16, 19, 22, 23, 25, 31, 34, 39, 44, 47, 53, 65, 72, 107, 112, 124, 127, 129, 131, 132, 134, 135, 138, 141, 143], "sig": [41, 50], "sig0": [38, 95], "sig_vm": 41, "siga": 7, "sigd": [0, 7], "sigf": 7, "sigh": [0, 7], "sight": 53, "sigma": [1, 3, 4, 7, 9, 17, 19, 24, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 44, 50, 52, 53, 66, 70, 72, 73, 78, 79, 82, 85, 86, 92, 93, 94, 95, 96, 97, 102, 107, 108, 109, 111, 112, 125, 126, 128, 129, 130, 133, 134, 135, 136, 140, 141, 143, 144], "sigma0": [38, 95], "sigma1": [50, 112], "sigma11_sq": 34, "sigma1inv": 50, "sigma2": [17, 34, 50, 108, 112], "sigma2inv": 50, "sigma_": [7, 24, 29, 34, 45, 46, 52, 66, 82, 85, 86, 90, 96, 98, 105, 107, 112, 140, 143], "sigma_0": [34, 38, 39, 52, 81, 95, 129, 134], "sigma_0_bound": 81, "sigma_1": [34, 38, 48, 72, 86, 112], "sigma_2": [72, 86, 112], "sigma_a": 7, "sigma_b": 38, "sigma_contour": 41, "sigma_error": [34, 98], "sigma_est": [39, 129, 134], "sigma_exp": 96, "sigma_f": [7, 82, 85], "sigma_f_opt": 82, "sigma_fn": 70, "sigma_h": [7, 105], "sigma_i": [7, 29, 34, 35, 38, 48, 53, 65, 78, 82, 86, 96, 97, 100, 103, 128], "sigma_interval__": 134, "sigma_j": 82, "sigma_k": 4, "sigma_mat": 49, "sigma_mat_inv": 49, "sigma_max": 108, "sigma_mean_prior": 133, "sigma_n": [47, 86, 135], "sigma_now": 108, "sigma_nu": 82, "sigma_prior": 133, "sigma_sampl": 92, "sigma_sd_prior": 133, "sigma_t": [7, 50, 96], "sigma_tild": 33, "sigma_tru": [35, 39, 129, 134], "sigma_v": [7, 41, 105, 108], "sigma_w": 72, "sigma_x": [7, 35, 53, 78, 86], "sigma_z": [7, 67, 82], "sigmacor": [78, 82], "sigmai": 34, "sigmamat": 109, "sigmamv": 82, "sigmap": 50, "sigmapinv": 50, "sigmar": 34, "sigmauncor": [78, 82], "sigmavec": [52, 79, 86, 107, 136], "sigmoid": [1, 67, 68, 70, 71, 73, 88, 93, 111], "sigmoid_functions_fig": 88, "sign": [4, 43, 51, 53, 65, 66, 88, 103, 116, 119, 125, 130, 143], "signal": [1, 7, 25, 38, 44, 51, 53, 65, 70, 72, 73, 82, 85, 88, 90, 91, 96, 136], "signatur": [44, 51], "signific": [4, 50, 51, 53, 56, 99, 109, 118, 136], "significantli": [29, 45, 53, 66, 71, 97, 99, 103, 107, 118, 135, 136], "sigp": 50, "sigv": [0, 7], "silenc": [67, 115], "silicon": 119, "silver": 16, "sim": [3, 29, 34, 38, 40, 41, 44, 45, 49, 51, 72, 74, 77, 79, 82, 83, 85, 86, 95, 98, 103, 105, 108, 112, 125, 126, 127, 135, 136, 140, 141, 144], "similar": [39, 40, 43, 44, 46, 51, 53, 65, 67, 71, 73, 75, 80, 88, 96, 97, 99, 116, 124, 128, 130], "similarli": [15, 53, 72, 82, 115, 141], "simon": [8, 34], "simp": [37, 138], "simpl": [0, 1, 4, 5, 7, 20, 25, 32, 34, 38, 39, 40, 41, 44, 46, 47, 48, 49, 50, 53, 63, 64, 65, 66, 69, 71, 72, 73, 75, 76, 80, 88, 93, 95, 96, 98, 99, 102, 103, 112, 115, 116, 120, 125, 126, 129, 131, 132, 133, 135, 136, 145], "simpler": [7, 52, 53, 71, 103, 112, 114, 135], "simplest": [7, 15, 47, 53, 67, 69, 75, 85, 88, 112, 116, 143], "simpli": [7, 9, 13, 17, 24, 25, 34, 38, 39, 40, 41, 43, 48, 53, 56, 63, 64, 65, 67, 71, 95, 102, 103, 105, 109, 112, 115, 118, 124, 126, 128, 129, 131, 134, 135, 136, 143], "simplic": [7, 34, 38, 44, 48, 67, 71, 86, 88, 100, 103, 138], "simplif": [100, 109], "simplifi": [24, 34, 42, 44, 49, 52, 53, 65, 95, 99, 128, 135, 136], "simpson": [37, 51, 136], "simul": [1, 11, 25, 30, 43, 44, 45, 51, 58, 67, 104, 106, 125, 128, 130, 135, 136, 138, 143], "simultan": [25, 47, 62, 66, 103], "sin": [34, 71, 77, 80, 81, 83, 92, 95, 100, 109, 114, 116, 117, 118, 120, 131, 132], "sinc": [4, 6, 7, 8, 13, 16, 19, 25, 33, 34, 35, 41, 44, 48, 53, 64, 66, 71, 72, 77, 78, 83, 85, 95, 96, 98, 99, 100, 103, 105, 107, 112, 115, 116, 124, 125, 126, 133, 135, 138, 143], "sine": [34, 114, 116, 117, 118], "sine_and_exp": 116, "sine_and_exp_transpar": 116, "sine_map": 117, "singer": 1, "singl": [4, 7, 30, 34, 37, 38, 39, 40, 43, 46, 47, 48, 49, 63, 65, 66, 67, 70, 71, 72, 73, 74, 75, 82, 85, 88, 95, 96, 98, 99, 100, 112, 115, 116, 117, 118, 125, 126, 129, 134, 136, 143], "single_cauchy_likelihood": 38, "single_conservative_likelihood": 38, "single_gaussian_likelihood": 38, "single_neuron": 70, "single_neuron_binary_classifi": 70, "single_prior": 81, "singular": [5, 47, 66, 106, 109], "singularli": 107, "sinh": 71, "sir": 1, "sit": 34, "site": [50, 64, 81, 96, 108, 133, 134, 136], "situat": [4, 7, 8, 16, 33, 34, 38, 39, 40, 44, 46, 48, 51, 52, 53, 63, 66, 71, 77, 88, 90, 98, 99, 112, 126, 129, 134, 135, 136, 141, 143], "sivia": [1, 2, 7, 9, 27, 37, 38, 39, 42, 53, 56, 90, 95, 96, 129, 134], "six": [3, 4, 47, 136], "sixth": 138, "size": [3, 4, 5, 7, 9, 17, 29, 34, 35, 37, 39, 40, 42, 43, 44, 46, 47, 49, 50, 66, 67, 69, 70, 73, 74, 75, 76, 77, 79, 80, 82, 83, 86, 92, 93, 95, 96, 97, 98, 99, 100, 102, 105, 108, 109, 112, 114, 115, 119, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 141, 143, 144, 145], "sk": 96, "skate": 133, "skater": 133, "skeleton": 116, "skew": [18, 35, 53, 63, 135], "ski": 138, "skill": [1, 4, 37, 56, 64], "skimag": 109, "skin": 1, "skip": [0, 35, 79, 109, 115, 124, 127, 141, 144], "skirt": [39, 129, 134], "skl": 115, "sklearn": [50, 70, 73, 74, 80, 81, 82, 93, 105, 109, 115], "sky": [0, 1, 22, 95, 138], "slab": 73, "slant": [53, 128], "slate": 71, "slice": [118, 131, 133, 134, 138], "slide": 75, "slider": [9, 11, 114, 116], "slider_bord": 114, "slight": [43, 71], "slightli": [5, 7, 34, 38, 40, 60, 66, 133, 143], "slope": [3, 6, 23, 34, 35, 37, 38, 40, 41, 53, 86, 99, 125], "slope_limit": 40, "slope_max": 41, "slope_prior": [3, 6], "slope_rang": [40, 41], "slope_sampl": 41, "slopesamples_fig": 3, "sloppi": [23, 109], "slow": [64, 73, 99, 108, 115, 117, 133], "slowli": [66, 68, 73, 79, 99, 136], "small": [0, 5, 7, 8, 9, 17, 19, 23, 29, 34, 38, 39, 44, 46, 47, 48, 51, 53, 63, 66, 67, 68, 71, 72, 73, 75, 77, 78, 80, 82, 83, 85, 86, 97, 98, 99, 100, 103, 109, 118, 119, 126, 128, 129, 133, 134, 135, 136], "small_list_a": 117, "smaller": [4, 7, 29, 31, 33, 37, 44, 45, 46, 47, 53, 63, 66, 68, 96, 97, 99, 131, 132, 135, 143], "smallest": [41, 107, 109, 112, 115], "smartphon": 116, "smhi": 16, "smith": 1, "sml": 1, "smlbook": 1, "smooth": [4, 5, 9, 30, 45, 47, 78, 79, 82, 85, 86], "smoother": [47, 133], "sn": [5, 9, 17, 33, 37, 38, 39, 42, 50, 70, 73, 77, 78, 92, 93, 95, 96, 115, 126, 129, 134], "snapshot": [45, 47, 108], "snippet": [92, 96, 128], "snow": 138, "so": [3, 4, 5, 7, 8, 9, 11, 13, 15, 16, 17, 19, 22, 23, 25, 26, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 82, 83, 85, 86, 88, 89, 92, 93, 94, 95, 96, 97, 98, 102, 103, 105, 107, 108, 109, 112, 114, 115, 116, 118, 119, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 141, 143, 144], "social": [8, 48, 63, 64], "societ": [63, 64], "societi": [1, 63], "soft": [43, 88], "softmax": [67, 69, 71, 75, 76], "softplu": [72, 102], "softwar": [43, 51, 63, 64, 73, 76, 77, 83, 89, 93, 99, 119, 125, 128], "sol": 105, "sold": 8, "sole": [8, 43, 49, 51, 56], "solid": [7, 37, 42, 44, 49, 64, 79, 86, 88, 114, 132], "solut": [4, 44, 45, 47, 48, 68, 79, 99, 102, 105, 109, 118, 119, 130, 131, 132, 136], "solv": [3, 7, 31, 34, 39, 44, 45, 46, 47, 61, 64, 65, 66, 67, 69, 79, 85, 96, 97, 98, 99, 105, 107, 116, 129, 131, 134, 138, 143], "solvabl": 135, "solve_ivp": [131, 132], "solve_od": [131, 132], "solve_ode_eul": 132, "solve_ode_leapfrog": 132, "solver": [47, 70, 130], "some": [4, 5, 7, 8, 9, 10, 16, 19, 21, 22, 23, 24, 25, 26, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 109, 110, 112, 115, 116, 117, 118, 119, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138, 141, 143, 144], "someon": [8, 48, 56], "someth": [3, 8, 16, 19, 21, 39, 42, 62, 63, 66, 71, 73, 99, 116, 119, 129, 130, 134], "sometim": [7, 8, 16, 18, 23, 34, 39, 43, 47, 48, 53, 60, 64, 67, 72, 85, 98, 103, 104, 108, 112, 116, 126, 129, 134, 135, 138], "somewhat": [8, 16, 19, 23, 34, 51, 53, 98, 99], "somewher": [34, 126], "son": 1, "soon": 53, "sophist": [46, 48, 95, 115, 126, 135], "sort": [19, 37, 40, 41, 53, 65, 67, 73, 78, 82, 96, 109, 116], "sorted_": [37, 40], "sorted_lnprob": 41, "sound": [63, 64, 116], "sourc": [0, 17, 33, 42, 43, 51, 56, 64, 66, 76, 87, 104, 115, 116, 117, 119, 124, 143], "sp": [69, 78, 92, 109, 138, 143], "space": [8, 17, 19, 21, 23, 33, 37, 38, 40, 44, 45, 46, 47, 51, 52, 53, 59, 62, 64, 65, 67, 71, 72, 73, 77, 78, 79, 82, 83, 85, 86, 93, 95, 96, 99, 103, 108, 112, 116, 125, 126, 128, 130, 131, 132, 133, 135, 136, 138, 141, 143], "spacetim": 16, "span": [34, 47, 48, 66, 98, 109, 115], "spars": 71, "sparse_categorical_crossentropi": [69, 76], "sparsiti": 73, "spatial": [51, 67, 75, 102, 105, 109, 131], "speak": [8, 56, 59, 79, 112], "speci": 62, "special": [8, 16, 17, 23, 34, 38, 39, 47, 48, 53, 63, 65, 68, 73, 86, 88, 96, 112, 115, 128, 129, 130, 133, 134, 135, 136], "specif": [4, 7, 23, 25, 34, 38, 41, 43, 45, 46, 48, 50, 53, 58, 59, 61, 62, 63, 64, 65, 66, 67, 71, 72, 74, 75, 76, 78, 82, 86, 88, 96, 100, 103, 105, 111, 112, 115, 118, 126, 135, 138, 143], "specifi": [3, 4, 5, 7, 9, 10, 17, 22, 23, 25, 34, 37, 38, 39, 40, 41, 42, 43, 46, 48, 49, 50, 51, 53, 55, 58, 59, 67, 69, 73, 78, 79, 80, 82, 85, 86, 88, 91, 94, 95, 102, 103, 105, 111, 112, 114, 118, 119, 125, 129, 131, 132, 133, 134, 135, 136, 140, 143], "specifii": 79, "speckl": 138, "spectacular": 48, "spectroscopi": 96, "spectrum": [47, 90, 96, 107], "speech": [64, 67], "speed": [47, 68, 71, 73, 93, 116, 118], "spell": [61, 116], "spend": [43, 62, 136], "spent": [7, 60], "sphere": 105, "spheric": 130, "spike": 73, "spin": [67, 102, 112], "spirit": [40, 46, 53, 58], "spite": 64, "split": [6, 43, 50, 64, 66, 67, 85, 93, 110, 125, 128, 143], "spot": [53, 63], "spread": [4, 66, 79, 112, 124, 128, 141], "springer": 1, "sqrt": [0, 4, 7, 9, 19, 24, 29, 30, 33, 34, 37, 38, 39, 40, 41, 44, 46, 48, 49, 50, 52, 53, 66, 67, 71, 78, 79, 82, 86, 95, 96, 99, 105, 108, 111, 112, 116, 118, 120, 125, 126, 128, 129, 131, 133, 134, 135, 136, 141, 144], "squar": [4, 17, 19, 23, 24, 26, 38, 41, 44, 46, 51, 52, 65, 66, 67, 71, 72, 75, 77, 78, 83, 86, 88, 94, 95, 96, 97, 99, 100, 107, 109, 112, 115, 116, 117, 118, 136], "square_cube_list": 117, "square_loss": 38, "squared_loss": 38, "squeez": [80, 81], "sr": [129, 134], "ss06": [1, 2, 27, 35, 53, 56], "st": 63, "stabil": [6, 16, 38, 61, 72, 73, 85, 93, 105, 128, 129, 134], "stabl": [1, 37, 44, 65, 81, 93, 99, 115, 125], "stack": [0, 69, 73, 75, 76, 93, 116], "stacklevel": [50, 96], "stackoverflow": [73, 93, 120], "stackrel": [19, 33, 37], "staffwww": 77, "stage": [9, 11, 23, 34, 40, 44, 47, 63, 64, 125], "stai": [126, 127, 128, 136, 138, 144], "stan": [1, 40, 44, 72, 73, 135], "stanc": 8, "stand": [9, 11, 21, 38, 40, 64, 66, 115, 125, 130, 133], "standalon": 134, "standard": [3, 4, 15, 16, 19, 20, 24, 25, 29, 32, 33, 34, 35, 37, 39, 40, 41, 43, 44, 46, 48, 50, 53, 62, 63, 64, 65, 66, 67, 71, 72, 73, 74, 77, 78, 80, 81, 83, 85, 93, 94, 95, 98, 99, 103, 105, 108, 109, 111, 112, 115, 117, 120, 126, 127, 128, 129, 133, 134, 135, 140, 141, 143, 144], "standardize_data": 65, "standardscal": 105, "stanford": 75, "stapl": 16, "star": [48, 129, 134, 145], "start": [5, 6, 7, 9, 15, 16, 19, 25, 26, 30, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 55, 65, 66, 67, 68, 71, 78, 79, 80, 81, 82, 86, 92, 93, 94, 95, 96, 97, 99, 100, 102, 105, 107, 108, 111, 112, 115, 116, 117, 118, 119, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 138, 141, 143, 144], "start_index": [131, 132], "start_new_sess": 108, "start_po": 126, "start_posit": 126, "start_stop_indic": [131, 132], "start_tim": 105, "starter": [7, 119], "starting_guess": [6, 38, 41, 96, 105, 129, 134], "startupinfo": 108, "startval": 133, "stat": [1, 5, 6, 9, 13, 19, 23, 29, 30, 33, 34, 37, 39, 42, 43, 49, 65, 69, 78, 82, 92, 96, 105, 108, 125, 126, 127, 129, 133, 134, 135, 136, 144], "state": [0, 4, 6, 7, 8, 9, 11, 21, 22, 25, 31, 32, 38, 44, 45, 46, 47, 50, 53, 56, 61, 66, 67, 71, 73, 85, 88, 105, 106, 109, 112, 115, 125, 129, 130, 133, 134, 141, 143], "statement": [0, 8, 16, 17, 19, 20, 22, 31, 33, 34, 43, 46, 53, 56, 62, 64, 65, 98, 100, 112, 116, 117, 122, 140, 141], "static": [115, 116, 141], "stationar": [43, 44, 47, 125, 128, 143], "stationari": [43, 44, 45, 47, 71, 77, 79, 82, 83, 125, 128, 133, 135, 143], "statisc": 103, "statist": [1, 3, 4, 7, 9, 17, 20, 23, 24, 25, 26, 27, 29, 30, 34, 35, 37, 39, 44, 45, 48, 51, 55, 56, 59, 60, 62, 64, 66, 67, 72, 73, 88, 89, 92, 94, 97, 98, 102, 103, 106, 109, 115, 124, 127, 129, 133, 134, 136, 138, 140, 141, 143, 144], "statistician": [0, 1, 43, 56, 103, 112, 141], "stats_random_numb": 112, "stats_titl": 42, "statu": [34, 81, 88, 105], "std": [7, 17, 33, 38, 41, 50, 65, 67, 71, 73, 78, 81, 82, 93, 108, 111, 112, 115, 118, 125, 127, 133, 143, 144], "std_predict": 80, "std_train_data": 65, "stddev": 111, "stderr": 108, "stdin": 108, "stdmv": 82, "stdout": 108, "stdperiod": [77, 83], "steadi": 141, "steadili": [66, 97], "stealthili": 63, "steep": 133, "steer": [64, 69], "stein": 136, "stem": [47, 53, 63, 64, 103], "step": [4, 6, 7, 9, 15, 16, 22, 24, 25, 30, 34, 35, 37, 38, 42, 44, 46, 49, 53, 60, 65, 67, 68, 69, 70, 72, 76, 79, 88, 90, 92, 96, 97, 99, 105, 107, 112, 114, 115, 116, 117, 118, 119, 120, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 143, 144, 145], "step1": 133, "step2": 133, "step_fn": 70, "step_method": 133, "step_siz": 128, "stepfil": 126, "stepsiz": [50, 125, 128], "stereotyp": 63, "stern": 1, "stick": [8, 23, 44, 61, 116, 126, 136], "still": [3, 8, 31, 34, 41, 43, 45, 46, 47, 51, 64, 65, 66, 67, 73, 75, 85, 93, 100, 109, 114, 117, 124, 130, 132, 136], "stimuli": 67, "stirl": [4, 37], "stochast": [1, 34, 43, 48, 59, 67, 68, 71, 72, 73, 78, 82, 85, 86, 88, 97, 100, 101, 105, 112, 135, 142, 145], "stochasticprocess": [138, 143], "stochasticprocessexampl": 143, "stoke": 67, "stone": [8, 88], "stoner": 1, "stongli": [78, 82], "stop": [9, 19, 22, 80, 81, 116, 119, 130, 141], "stop_index": [131, 132], "stopiter": 108, "storag": 118, "store": [0, 34, 38, 45, 50, 69, 98, 99, 107, 115, 118, 119, 126], "stori": [95, 133], "storylin": 11, "str": [6, 69, 78, 82, 117], "straight": [23, 34, 35, 38, 53, 65, 70, 78, 94, 97, 98, 99, 100, 128, 135, 136], "straightforward": [4, 7, 25, 33, 34, 38, 39, 43, 46, 47, 53, 67, 85, 100, 129, 134, 135], "straightforwardli": 38, "strainghtforward": 46, "strang": [25, 53], "strategi": [7, 31, 39, 43, 46, 47, 48, 51, 66, 71, 102, 128, 129, 130, 134], "street": 110, "strength": [7, 43, 46, 47, 51, 53, 62, 64, 80, 95, 96, 100, 102, 112, 115, 128, 136], "strerror": 108, "stress": [46, 66, 100, 102, 116, 138], "stretch": [109, 128], "strftime": 108, "strict": 19, "strictli": 67, "string": [21, 42, 77, 83, 105, 117, 120], "stringent": 135, "strive": 8, "stroke": 88, "strong": [7, 38, 43, 48, 51, 65, 67, 86, 103, 128], "strongli": [7, 43, 53, 63, 64, 65, 75, 78, 82, 115], "strprior": 6, "structur": [7, 11, 16, 34, 45, 46, 47, 51, 64, 65, 66, 67, 71, 75, 77, 79, 83, 102, 115, 118, 133, 135], "sts412": 1, "stuck": [31, 42, 51, 96, 109, 130, 135], "student": [0, 18, 19, 23, 32, 38, 41, 44, 56, 62, 103, 106, 112, 116], "student_t_animation_": 108, "student_t_animation_31aug2025": 108, "studi": [7, 16, 19, 40, 41, 43, 45, 46, 48, 53, 56, 62, 63, 64, 67, 89, 92, 97, 103, 126, 138, 143], "stumbl": 133, "sty": 0, "style": [0, 9, 42, 76, 96, 116, 131], "sub": [51, 62, 67, 73, 92, 118], "subclass": 76, "subdirectori": [0, 105, 119], "subfield": [64, 104], "subgradi": 1, "subject": [4, 8, 22, 38, 39, 43, 46, 61, 62, 72, 100, 112, 129, 134, 138, 143], "subplot": [0, 3, 6, 7, 17, 25, 29, 30, 33, 34, 38, 39, 40, 41, 44, 49, 50, 65, 69, 70, 73, 76, 77, 78, 81, 82, 83, 88, 93, 95, 98, 111, 112, 115, 116, 117, 120, 125, 126, 134, 135, 143, 144], "subplot2grid": 134, "subplot_kw": 112, "subplots_adjust": 33, "subprocess": 108, "subprocess_creation_flag": 108, "subroutin": 115, "subscript": [5, 24, 85, 132], "subsect": [20, 43, 48, 56, 116], "subsequ": [7, 25, 43, 45, 46, 56, 67, 71, 111, 138, 143], "subset": [44, 45, 46, 47, 48, 63, 66, 67, 74, 86, 89, 99, 112, 118, 126, 130, 136, 138, 143], "subshel": 115, "subspac": [1, 45, 47, 109], "substanti": [43, 63], "substitut": [4, 7, 13, 19, 47, 53, 71, 132], "subsum": 16, "subtask": 90, "subtl": [48, 63], "subtleti": [39, 129, 134], "subtract": [22, 42, 52, 66, 71, 97, 107, 118, 141], "succe": 16, "succeed": [72, 127, 144], "succes": 44, "success": [9, 11, 19, 30, 33, 37, 39, 65, 86, 88, 103, 105, 119, 127, 133, 136, 141, 144], "successfulli": [105, 124], "succinctli": [34, 98], "suffer": [47, 66, 68], "suffici": [5, 19, 38, 43, 47, 51, 70, 71, 73, 93, 133, 135, 140], "suggest": [42, 51, 56, 63, 66, 99, 109, 116, 119, 125, 126, 128, 135], "suit": [46, 67, 71, 105], "suitabl": [43, 45, 53, 71, 103], "sum": [5, 9, 13, 15, 19, 20, 23, 26, 30, 31, 34, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 53, 65, 66, 67, 68, 69, 71, 72, 77, 78, 79, 83, 90, 92, 95, 96, 98, 99, 102, 103, 105, 107, 108, 109, 112, 116, 117, 118, 125, 128, 129, 133, 134, 135, 138, 141, 143], "sum21": [1, 63], "sum_": [4, 13, 16, 19, 24, 29, 33, 34, 35, 38, 39, 40, 41, 44, 45, 47, 48, 49, 51, 52, 53, 65, 66, 67, 68, 72, 78, 82, 85, 88, 94, 95, 96, 97, 98, 99, 100, 107, 109, 112, 125, 126, 128, 129, 133, 134, 135, 136, 138, 141, 143], "sum_0": 37, "sum_h": 85, "sum_i": [3, 4, 22, 25, 31, 32, 66, 72, 82, 136, 138], "sum_j": [22, 31, 32, 88, 109, 138], "sum_k": [15, 68, 109], "sum_n": 72, "sum_norm_squar": 29, "sum_of_squar": 117, "sum_xsq_val": 29, "summar": [4, 7, 9, 23, 24, 25, 30, 34, 43, 44, 46, 60, 66, 103, 112, 124, 141], "summari": [3, 4, 9, 17, 18, 27, 30, 38, 43, 44, 47, 51, 52, 56, 66, 68, 69, 70, 75, 76, 77, 83, 92, 94, 95, 102, 112, 113, 133, 134], "summaris": 46, "summat": [38, 44, 109, 126], "summer": [56, 77, 83], "sumpter": [1, 63], "sun": [8, 100], "sunil": [103, 105], "super": [71, 116], "superconductor": 112, "superfici": 75, "superflu": 47, "superior": [47, 117], "supermodel": 48, "supernova": 40, "superpos": [17, 33], "superposit": 1, "superscript": [67, 85], "supervis": [64, 66, 69, 88, 100, 115], "supplement": [62, 63, 88, 94, 101], "supplementari": [27, 38], "suppli": 67, "support": [1, 35, 43, 47, 51, 56, 63, 66, 73, 93, 95], "suppos": [4, 7, 9, 13, 15, 16, 19, 29, 31, 33, 37, 41, 48, 50, 52, 65, 67, 86, 88, 112, 116, 117, 128, 136, 138, 141], "supposedli": [64, 96], "suppress": [13, 19, 40, 48, 73, 78, 82, 86, 88, 93, 109, 114], "suptitl": [17, 33, 37, 42, 81, 126, 131, 132], "sure": [16, 17, 18, 24, 25, 29, 34, 37, 39, 82, 85, 92, 98, 107, 109, 114, 128, 129, 133, 134], "surf": 112, "surfac": [34, 37, 65, 97, 98, 99, 112, 115, 130], "surmis": 104, "surpris": [7, 17, 30, 35, 39, 41, 51], "surprisingli": [129, 134], "surrog": [92, 104], "surround": [0, 43], "survei": 48, "susan": 98, "suspect": 38, "suspici": [9, 30], "suspicion": [9, 30, 38], "svd": [47, 79, 106], "svd_shape": 109, "svensson": [1, 44, 56], "svg": 109, "svgd": 136, "svisak": [44, 112, 143], "swap": 51, "swedish": 112, "swift": 64, "switch": [16, 33, 56, 73, 86, 93, 96, 107, 108, 109, 116, 120], "sword": 47, "sy": [38, 41, 50, 93, 105, 112, 125, 138, 143], "syllog": 62, "symbol": [9, 11, 34, 53, 72, 73, 85, 93, 98], "symmet": 130, "symmetr": [17, 18, 19, 35, 38, 40, 41, 44, 52, 53, 71, 72, 78, 82, 85, 109, 118, 125, 126, 130, 135, 136, 138], "symmetri": [16, 18, 23, 25, 43, 55, 71, 107, 130], "sympi": 37, "symplect": [44, 130], "synonym": 58, "syntax": [73, 93, 107, 116, 118], "syntaxerror": 116, "synthet": [17, 63, 80], "system": [1, 4, 8, 16, 46, 47, 51, 64, 67, 68, 88, 100, 102, 103, 105, 130, 138, 143], "systemat": [7, 48, 51, 60, 62, 63, 72, 97, 99, 102], "t": [1, 5, 7, 8, 9, 11, 13, 15, 16, 18, 19, 22, 23, 25, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 44, 45, 48, 49, 50, 51, 53, 56, 58, 61, 63, 64, 65, 66, 68, 70, 72, 73, 74, 77, 78, 81, 82, 83, 85, 86, 88, 93, 94, 95, 96, 97, 98, 100, 102, 103, 105, 106, 107, 109, 112, 114, 115, 116, 118, 119, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 141, 143, 144], "t0": 105, "t1_dist": 17, "t1_label": 17, "t2_dist": 17, "t2_label": 17, "t3_dist": 17, "t3_label": 17, "t_": [114, 138], "t_0": 105, "t_1": 143, "t_2": 143, "t_color": 108, "t_df": 108, "t_dist": 108, "t_dist_max": 108, "t_dist_pt": 108, "t_end": [131, 132], "t_eval": [131, 132], "t_i": [68, 143], "t_j": 68, "t_k": 143, "t_label": 108, "t_loc": 108, "t_max": 114, "t_max_w": 114, "t_min": 114, "t_min_w": 114, "t_n": 138, "t_nois": 105, "t_ob": 105, "t_old": 143, "t_pt": [114, 116, 131, 132], "t_scale": 108, "t_start": [131, 132], "t_test": 74, "t_train": 74, "t_x": 138, "t_y": 138, "tab": [5, 9, 11, 39, 56, 79, 80, 86, 109, 116, 118, 120, 129, 134, 141], "tab0": [9, 114], "tab1": [9, 114], "tab2": [9, 114], "tab3": [9, 114], "tab_height": [9, 114], "tabl": [1, 4, 20, 24, 32, 42, 49, 51, 53, 56, 63, 64, 79, 94, 95, 96, 115], "tablet": 116, "tabul": [115, 138], "tabular": 115, "tadess": 1, "tag": [0, 43, 73, 93, 105], "tail": [8, 9, 11, 12, 15, 16, 17, 18, 19, 25, 33, 38, 39, 42, 43, 44, 51, 52, 53, 108, 112, 134, 135, 143], "tak": 91, "take": [0, 4, 5, 6, 9, 11, 19, 22, 29, 31, 33, 34, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 51, 52, 53, 56, 58, 60, 62, 63, 66, 67, 71, 72, 74, 75, 76, 78, 79, 81, 82, 86, 88, 91, 96, 102, 105, 109, 110, 111, 112, 113, 115, 116, 118, 119, 126, 127, 128, 129, 130, 133, 134, 135, 136, 138, 141, 143, 144], "taken": [4, 25, 29, 34, 37, 42, 47, 49, 56, 59, 60, 72, 78, 79, 86, 102, 103, 105, 118, 133], "taku": 73, "talent": [38, 39, 50, 56, 77, 95, 125, 126, 129, 134], "talk": [5, 9, 31, 38, 39, 40, 41, 42, 49, 50, 60, 70, 73, 77, 78, 86, 92, 93, 95, 104, 115, 116, 125, 126, 129, 133, 134], "tall": [7, 22, 31, 32, 100], "tan": [3, 34, 42, 49, 94, 98, 116], "tangent": [67, 102], "tangl": 19, "tanh": [67, 70, 71, 73, 88, 93, 111], "target": [44, 45, 46, 51, 64, 65, 67, 68, 70, 71, 72, 88, 105, 115, 118, 125, 128, 130, 136], "task": [7, 16, 17, 34, 37, 38, 42, 47, 49, 53, 62, 64, 65, 66, 67, 71, 72, 92, 93, 94, 95, 96, 100, 109, 112, 116, 117, 118, 124, 135, 140], "tau": [44, 51, 126, 141], "tau_": 44, "tau_1": 51, "tau_2": 51, "tau_3": 51, "taught": [56, 59, 75, 109], "taylor": [1, 19, 34, 35, 49, 53, 91, 94, 131], "td": 42, "teach": 62, "teacher": 67, "tear": 1, "tech": [1, 67], "technic": 63, "techniqu": [1, 34, 51, 55, 64, 65, 66, 73, 94, 112, 130, 140], "technologi": [56, 63, 64, 99, 135], "techtarget": 89, "tediou": 7, "telescop": 62, "tell": [7, 9, 10, 11, 16, 17, 19, 22, 23, 25, 30, 31, 37, 49, 53, 58, 62, 66, 73, 79, 86, 93, 126, 128, 131, 136], "temp": [50, 96, 108], "temper": [50, 53, 90, 130, 145], "temperatur": [4, 44, 50, 51, 96, 112, 130], "tempering_ptemce": 51, "tempering_ptemcee_vs_zeu": 145, "tempor": 8, "temporarili": 23, "temps_hi": [50, 96], "temps_lo": [50, 96], "tempt": [40, 41, 100], "ten": [66, 72, 74, 92, 132, 135, 143], "tend": [9, 11, 19, 33, 42, 53, 64, 66, 68, 76, 99, 100, 112], "tendenc": [43, 63, 115, 135], "tension": [63, 66], "tensor": [73, 75, 76, 93, 111], "tensorflow": [1, 64, 66, 70, 71, 72, 73], "tensorflow_vers": 76, "term": [4, 7, 9, 15, 16, 19, 21, 25, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 58, 62, 63, 64, 65, 66, 67, 71, 72, 73, 85, 88, 89, 91, 98, 99, 100, 102, 103, 105, 107, 109, 112, 115, 116, 118, 125, 126, 129, 130, 134, 138, 145], "termin": [34, 100, 105, 116, 143], "terminologi": [53, 63], "terribl": 31, "territori": 53, "test": [0, 5, 19, 22, 31, 32, 33, 34, 38, 43, 47, 49, 50, 51, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 82, 86, 93, 95, 96, 103, 109, 112, 116, 125, 127, 135, 138, 142, 143, 144], "test_acc": [69, 76], "test_f": 116, "test_imag": 76, "test_label": 76, "test_loss": [69, 76], "test_poisson_pt": 33, "test_siz": [73, 74], "test_valu": [73, 93], "testimoni": 8, "testinput": [64, 65, 66], "testinputs_i": 65, "testoutput": [64, 65, 66], "testval": [73, 93], "tex": 121, "text": [0, 1, 4, 7, 9, 10, 11, 12, 13, 15, 16, 19, 21, 23, 24, 25, 30, 31, 34, 35, 37, 38, 41, 42, 43, 44, 46, 47, 48, 51, 52, 53, 56, 57, 58, 60, 63, 65, 66, 67, 82, 90, 92, 95, 98, 99, 102, 108, 109, 112, 114, 116, 125, 128, 130, 135, 136, 138, 140, 141, 145], "text_i": [17, 108], "text_mod": 108, "text_represent": 0, "text_x": [17, 108], "text_x_mid": [17, 108], "textbf": [17, 78, 133], "textbook": [25, 46, 56, 66], "textbox0": [9, 114], "textbox1": [9, 114], "textiowrapp": 108, "textit": [35, 51], "textrm": [9, 17, 23, 30, 40, 41, 42, 49, 71, 95, 125, 133], "texttt": 103, "textur": 48, "tf": [69, 70, 76], "tf_cpp_min_log_level": 69, "th": [0, 3, 9, 11, 29, 33, 34, 35, 40, 42, 48, 49, 50, 66, 67, 68, 88, 94, 96, 99, 103, 112, 125, 136, 138, 140], "th0": 38, "th0_mcmc": 38, "th0neg": 38, "th0po": 38, "th1": [6, 38], "th1_mcmc": 38, "th1neg": 38, "th1po": 38, "than": [4, 7, 8, 9, 12, 17, 19, 22, 23, 25, 29, 30, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 60, 62, 63, 65, 66, 67, 71, 72, 73, 77, 78, 79, 82, 83, 88, 93, 95, 96, 97, 98, 99, 100, 102, 103, 105, 107, 109, 110, 112, 115, 116, 117, 118, 125, 126, 128, 129, 133, 134, 135, 136, 140, 141, 143], "thank": [56, 115, 119], "theano": [93, 140], "theanof": [73, 93], "theanorc": 73, "thei": [0, 7, 8, 9, 15, 16, 17, 18, 19, 21, 22, 23, 30, 31, 32, 34, 35, 43, 44, 45, 46, 47, 48, 51, 52, 59, 60, 61, 62, 63, 64, 66, 67, 68, 72, 73, 75, 76, 77, 78, 83, 86, 91, 98, 99, 100, 102, 103, 107, 108, 109, 111, 112, 115, 116, 118, 125, 126, 128, 130, 133, 135, 138, 141], "them": [4, 7, 16, 19, 22, 23, 25, 29, 31, 34, 37, 38, 39, 40, 43, 44, 45, 47, 48, 50, 52, 53, 58, 59, 63, 64, 66, 67, 68, 69, 70, 73, 75, 76, 77, 78, 82, 83, 92, 93, 95, 96, 103, 105, 109, 112, 115, 116, 118, 119, 120, 124, 126, 129, 130, 134, 138], "theme": [47, 72], "themselv": [25, 43, 47, 53, 62, 100, 115], "theorem": [7, 8, 9, 10, 13, 16, 20, 24, 26, 27, 30, 31, 32, 34, 35, 37, 39, 42, 43, 44, 49, 51, 52, 53, 58, 62, 67, 72, 85, 111, 124, 129, 130, 133, 134, 135, 136, 138, 140], "theoret": [0, 3, 7, 17, 23, 25, 29, 38, 39, 40, 41, 43, 49, 51, 55, 59, 62, 100, 102, 103, 105, 106, 125, 129, 134, 136], "theori": [1, 4, 7, 8, 16, 19, 21, 24, 29, 33, 34, 40, 41, 43, 44, 46, 49, 51, 53, 56, 58, 59, 60, 61, 62, 64, 65, 67, 72, 79, 88, 89, 91, 94, 100, 102, 103, 106, 108, 110, 112, 125, 129, 134, 136, 139, 142, 143], "theorist": 53, "thereaft": 115, "therebi": [45, 46, 47, 64, 65, 82, 88, 103, 115], "therefor": [4, 7, 8, 21, 23, 25, 29, 31, 34, 39, 41, 43, 45, 46, 48, 52, 53, 58, 62, 64, 65, 66, 67, 72, 78, 85, 86, 88, 96, 98, 99, 100, 112, 115, 118, 135, 138], "thermodynam": [51, 53, 126, 130], "thesi": 1, "theta": [0, 3, 6, 7, 9, 19, 30, 34, 38, 40, 41, 42, 44, 48, 49, 53, 65, 66, 72, 77, 78, 81, 83, 85, 92, 95, 97, 98, 105, 109, 112, 125, 129, 133, 134, 136], "theta0": [38, 125], "theta1": [38, 125], "theta2": 38, "theta3": 38, "theta_": [7, 50, 85, 95, 109, 125, 135, 136], "theta_0": [3, 38, 40, 41, 50, 53, 98, 125, 128, 135], "theta_1": [3, 38, 40, 41, 50, 98, 125, 135, 136], "theta_2": 136, "theta_and_phi": 105, "theta_dist": 42, "theta_hat": 95, "theta_i": [53, 66, 95, 136, 141], "theta_j": [29, 53, 95, 109, 133], "theta_k": [42, 48, 109, 141], "theta_max": 95, "theta_min": 95, "theta_ml": [38, 41], "theta_n": 136, "theta_ol": [34, 65, 98], "theta_tru": [34, 40, 49, 98, 125], "thetavec": [9, 10, 23, 30, 51, 52, 79, 86, 107, 109, 128, 130, 136], "thetavec_": [51, 107, 109, 136, 141], "thetavec_0": 141, "thetavec_1": 136, "thetavec_2": 136, "thetavec_a": 136, "thetavec_b": 136, "thetavec_i": 136, "thetavec_j": 107, "thetavec_k": [107, 141], "thetavechat": 107, "thetavechat_": 107, "thetavechat_j": 107, "thi": [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 88, 90, 91, 93, 94, 96, 97, 98, 99, 100, 102, 103, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 144, 145], "thick": 51, "thicker": 51, "thim": 56, "thin": [50, 51, 96, 134], "thing": [0, 5, 8, 9, 10, 11, 16, 17, 19, 22, 29, 30, 31, 33, 43, 51, 53, 58, 62, 71, 73, 86, 93, 116, 130], "think": [4, 8, 11, 15, 16, 25, 31, 33, 34, 40, 48, 53, 62, 63, 64, 66, 67, 69, 73, 77, 83, 86, 95, 98, 102, 112, 124, 126, 127, 136, 138, 143, 144], "third": [0, 1, 4, 7, 16, 17, 25, 32, 34, 46, 56, 64, 71, 73, 75, 78, 82, 93, 115, 126, 132, 138], "thirteenth": 53, "thisplot": [69, 76], "thoma": [8, 73, 93, 126], "thorough": [29, 46, 61], "those": [7, 8, 9, 17, 23, 25, 30, 34, 37, 43, 44, 46, 48, 51, 56, 59, 60, 62, 63, 66, 67, 71, 74, 78, 85, 94, 97, 99, 103, 109, 112, 129, 134], "though": [0, 5, 12, 22, 39, 62, 64, 72, 103, 129, 134, 141], "thought": [7, 8, 52, 53, 66, 85, 107], "thousand": [45, 64, 67, 72], "thread": [50, 96, 105], "three": [0, 1, 3, 6, 7, 8, 9, 11, 16, 17, 18, 23, 29, 32, 34, 35, 37, 41, 43, 44, 47, 48, 51, 53, 56, 61, 65, 66, 67, 68, 71, 72, 74, 75, 77, 83, 88, 93, 95, 96, 100, 102, 103, 107, 108, 109, 112, 115, 116, 118, 126, 133, 138], "threlkeld": 1, "threshold": [43, 53, 67, 75, 88, 109, 143], "through": [0, 4, 7, 9, 14, 16, 17, 22, 23, 25, 27, 30, 33, 34, 35, 38, 41, 42, 43, 46, 47, 48, 49, 53, 56, 58, 67, 68, 69, 71, 75, 76, 77, 78, 79, 82, 83, 85, 86, 88, 89, 90, 95, 96, 98, 102, 103, 107, 116, 119, 125, 126, 127, 128, 130, 132, 136, 140, 144], "throughout": [16, 23, 44, 48, 56, 58, 62, 95, 115], "throw": [4, 41, 44, 109, 133], "thu": [7, 11, 23, 34, 38, 41, 44, 47, 48, 52, 53, 58, 63, 64, 66, 67, 68, 73, 99, 103, 109, 112, 128, 131], "thumb": 29, "thursdai": 8, "thusfar": 16, "th\u00e9ori": 34, "tibshirani": 1, "tick": [9, 42, 43], "tick_param": 33, "tight": [9, 73, 93, 108, 131, 132], "tight_layout": [5, 7, 17, 29, 33, 37, 39, 40, 41, 42, 49, 50, 65, 69, 73, 76, 77, 78, 81, 82, 83, 93, 95, 108, 109, 111, 117, 125, 126, 127, 131, 132, 134, 144], "tighter": [46, 103], "tikhonov": 80, "tild": [7, 34, 44, 45, 52, 65, 66, 79, 86, 88, 97], "tildecovparslr": 34, "tile": [82, 96], "time": [4, 7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 41, 42, 44, 45, 47, 49, 50, 51, 52, 53, 56, 63, 65, 66, 67, 69, 73, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 92, 93, 94, 96, 98, 99, 100, 102, 103, 104, 105, 107, 108, 109, 112, 114, 115, 117, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 136, 138, 143, 144, 145], "timeit": [73, 117], "times_overview_text": 114, "times_overview_text_w": 114, "times_text": 114, "timestep": [44, 118], "titl": [0, 19, 56, 71, 73, 76, 77, 80, 81, 83, 93, 116, 126, 129, 131, 133, 134], "title_fmt": 96, "title_kwarg": [17, 38, 50, 96, 105, 125, 129, 134], "title_loc": 112, "title_str": [17, 33, 42], "tmax": [50, 96], "tmp": [37, 38, 77, 82, 115, 133], "tmp2": [78, 82], "tn": [63, 64], "to_numer": 115, "to_numpi": [34, 98], "toal": 18, "toc": 56, "todai": [16, 49, 64, 108, 110, 112, 138], "togeth": [19, 25, 27, 31, 38, 39, 40, 41, 48, 49, 66, 69, 72, 73, 74, 77, 82, 83, 86, 95, 96, 115, 125, 129, 134, 141], "toggl": [56, 105], "toi": [39, 47, 73, 90, 91, 93, 129, 134], "token": 53, "tol": [5, 50, 70], "told": [4, 16, 22, 31, 130], "toler": 5, "tolist": 118, "tomorrow": [8, 16, 17, 23, 112, 138], "tone": 58, "tonight": 21, "too": [19, 29, 31, 43, 44, 53, 62, 63, 71, 79, 94, 99, 126, 128, 130, 136, 141], "took": [115, 133, 134], "tool": [1, 7, 22, 34, 40, 41, 48, 56, 58, 59, 63, 64, 73, 95, 98, 99, 102, 107, 115, 116, 125], "toolbar": 116, "tooltip": 9, "top": [0, 1, 4, 9, 19, 25, 33, 42, 44, 51, 53, 56, 73, 77, 83, 94, 95, 109, 114, 116, 126, 131, 138, 143], "topic": [8, 43, 55, 64, 88, 89, 94, 129, 134, 143], "topologi": [67, 136], "tor": 56, "torch": [71, 111], "torchvis": 71, "torqu": 51, "torsion": 51, "toss": [8, 12, 13, 15, 19, 23, 143], "toss_coin_text": 9, "tot_val": 29, "total": [6, 19, 25, 31, 32, 34, 37, 38, 41, 44, 46, 48, 50, 63, 67, 68, 69, 71, 75, 76, 88, 93, 99, 102, 105, 109, 112, 115, 116, 125, 129, 130, 133, 134], "total_count": 37, "total_draw": 33, "total_huber_loss": 38, "total_length": 133, "total_s": [73, 93], "total_sampl": 50, "totalenergi": 115, "touch": [16, 94], "tough": 136, "tour": 116, "toward": [16, 53, 58, 62, 68, 72, 78, 88, 100, 125, 133], "tower": [103, 105], "tp": [63, 64], "tr": 42, "trace": [38, 41, 43, 44, 47, 50, 71, 73, 96, 120, 125, 126, 127, 128, 133, 136, 141, 144], "trace1": 41, "trace2": 41, "trace_2_sampl": 133, "trace_arrai": 133, "trace_inferencedata": 133, "trace_mh": 133, "trace_nut": [133, 134], "trace_titl": [127, 144], "trace_two_param": 133, "trace_unord": 96, "traceabl": 60, "traceback": [50, 69, 70, 73, 93, 96, 108], "traceplot": 73, "track": [22, 45, 53], "tractabl": [7, 34], "traction": 64, "trade": [92, 130], "tradeoff": 97, "tradit": [8, 64, 73, 101], "tradition": [62, 103], "train": [47, 60, 62, 64, 67, 68, 70, 71, 73, 74, 75, 78, 79, 80, 81, 82, 86, 88, 89, 91, 93, 95, 97, 99, 100, 102, 105, 111], "train_data": 65, "train_imag": 76, "train_label": 76, "train_test_split": [73, 74, 93, 115], "trainabl": [67, 69, 76], "training_err": 95, "training_indic": 80, "trainingdata": [64, 65, 66], "trainingdata_n": 66, "trajectori": [44, 45, 47, 50], "tran": [34, 72, 73], "tranform": 128, "transact": 119, "transax": [7, 25, 30, 95], "transfer": 73, "transform": [3, 4, 7, 25, 30, 48, 53, 65, 67, 69, 72, 88, 95, 109, 128, 131, 135], "transit": [37, 38, 47, 67, 95, 126, 135, 136, 138, 141, 143], "translat": [4, 17, 19, 20, 22, 37, 42, 43, 46, 53, 102, 103, 112, 128, 130], "translation": 85, "transmiss": [65, 88], "transmit": 67, "transpar": [8, 43, 61, 63, 66, 73, 92, 93, 94, 116], "transpos": [107, 109, 118, 120, 138], "trapezoid": [96, 128], "trapz": [25, 30, 33, 96], "travel": [100, 130, 143], "travers": [66, 67, 118], "treat": [16, 28, 38, 43, 47, 99, 102, 105, 130], "treatment": [28, 46, 53, 89, 96, 101, 102, 106], "tree": [67, 73], "tremend": [47, 56], "trend": [33, 43, 63, 72, 79, 103, 141], "trevor": 66, "tri": [16, 133], "trial": [9, 19, 21, 29, 45, 47, 64], "triangular": 33, "tribal": 73, "trick": [72, 73, 77, 83, 93, 126, 135], "tricki": 51, "trickier": 136, "trig": 116, "trigger": [67, 138], "trigonometr": [71, 100, 116], "trivia": [0, 23], "trivial": [8, 16, 33, 40, 65, 112, 136], "tro08": [1, 27, 51], "trotta": [1, 27, 51, 95], "troubl": [5, 63, 68, 130, 141], "troublesom": 53, "truck": [64, 76], "true": [3, 5, 6, 7, 9, 11, 12, 15, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 46, 48, 50, 53, 58, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 76, 77, 78, 80, 81, 82, 83, 85, 88, 90, 92, 93, 94, 95, 96, 98, 100, 103, 105, 108, 109, 111, 112, 114, 116, 117, 118, 124, 125, 126, 128, 129, 132, 133, 134, 135, 138, 140, 143], "true_func": 95, "true_height": 105, "true_label": [69, 76], "true_model": 48, "true_param": [34, 98], "truli": [34, 39, 43, 48, 56, 63, 129, 134], "truncat": [7, 16, 34, 53, 100, 107, 109], "trunk": 99, "trust": [9, 30, 43, 70], "trustworthi": 63, "truth": [8, 21, 25, 53, 64, 82, 96, 100, 103, 129, 134], "truths_corn": 96, "try": [4, 8, 9, 11, 13, 15, 16, 17, 19, 23, 30, 31, 33, 34, 35, 37, 39, 40, 41, 48, 51, 53, 65, 66, 70, 76, 77, 79, 83, 86, 88, 90, 92, 94, 95, 96, 98, 103, 105, 108, 109, 114, 116, 117, 118, 124, 125, 126, 128, 129, 131, 132, 133, 134, 135, 136, 140, 141, 144], "tumor": 88, "tune": [44, 47, 66, 67, 71, 97, 99, 102, 125, 128, 130, 133, 134, 135, 136, 141, 145], "tungsten": 51, "tuning_step": 133, "tupl": [111, 117, 118], "turn": [1, 4, 7, 9, 17, 19, 34, 39, 42, 44, 52, 63, 64, 68, 73, 93, 95, 96, 98, 100, 106, 109, 112, 115, 116, 126, 129, 130, 132, 133, 134, 135, 136, 141], "tutori": [1, 37, 39, 42, 56, 69, 71, 73, 76, 78, 82, 118, 129, 134], "tweak": [42, 71, 97, 108], "twentieth": 62, "twice": [31, 107, 125, 126], "twiecki": [73, 93], "twist": 51, "two": [0, 1, 3, 4, 8, 9, 11, 13, 15, 16, 17, 19, 22, 24, 25, 26, 29, 37, 38, 39, 40, 43, 44, 45, 47, 49, 51, 52, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 83, 85, 86, 92, 93, 94, 95, 96, 98, 99, 100, 102, 103, 107, 112, 115, 116, 117, 118, 119, 122, 124, 125, 126, 127, 128, 129, 130, 133, 134, 135, 136, 140, 143, 144, 145], "two_param_model": 133, "tx": 109, "txt": [78, 82, 115], "ty": 109, "type": [0, 11, 16, 34, 43, 45, 47, 50, 51, 60, 69, 71, 73, 75, 76, 77, 83, 85, 89, 93, 94, 95, 96, 98, 100, 103, 105, 114, 115, 116, 117, 119, 130, 136, 143], "typeerror": 65, "typic": [4, 23, 34, 38, 43, 44, 47, 48, 49, 51, 60, 63, 67, 71, 75, 76, 82, 85, 88, 98, 99, 100, 103, 107, 108, 109, 127, 130, 133, 136, 141, 144], "u": [1, 4, 6, 7, 8, 9, 10, 16, 17, 19, 22, 23, 25, 30, 31, 34, 37, 38, 39, 41, 44, 45, 46, 48, 49, 50, 51, 53, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 77, 78, 79, 81, 82, 83, 85, 86, 88, 93, 95, 96, 97, 98, 99, 100, 103, 107, 109, 112, 115, 116, 118, 119, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 141, 143, 144], "u_": [86, 107, 109], "u_0": 86, "u_1": [51, 86, 112], "u_deriv": 132, "u_i": [53, 135], "u_n": 112, "u_pt": 132, "u_shap": 109, "ua": 115, "ucf": 132, "ucf_deriv": 132, "ucf_pt": 132, "ud": 31, "udat": 73, "ueff": 132, "ueff_deriv": 132, "ueff_pt": 132, "ui": 120, "ui_box": [9, 114], "uid": 108, "uint8": [69, 76], "uk": [1, 50, 56, 77, 125, 126], "ul": [9, 114], "ultim": [23, 31, 48, 97, 99], "umask": 108, "un": 43, "unabl": 70, "unaccept": 44, "unaffect": 109, "unambigu": 61, "unawar": [16, 63], "unbalanc": 66, "unbias": [39, 125, 129, 134, 143], "unbow": 62, "unc": 115, "uncertain": [7, 8, 16, 34, 72, 73, 98, 108, 112, 143], "uncertainti": [0, 1, 4, 8, 16, 17, 23, 25, 34, 41, 43, 44, 45, 46, 47, 48, 49, 51, 53, 56, 79, 80, 85, 100, 103, 104, 105, 108, 124, 125, 128, 136], "unchalleng": 79, "unchang": [68, 75, 130], "unchart": 53, "uncheck": 119, "uncolor": 136, "uncom": 105, "uncontrain": 52, "uncontrol": 63, "uncorrel": [35, 41, 50, 72, 78, 79, 82, 103, 105, 112, 128, 130, 141], "uncov": 43, "under": [3, 4, 7, 8, 9, 10, 16, 18, 19, 29, 44, 45, 48, 51, 53, 56, 64, 66, 71, 76, 86, 95, 96, 97, 103, 111, 114, 116, 119, 125, 138, 141, 145], "underappreci": 73, "underbrac": [4, 9, 10, 23, 30, 52], "underestim": [41, 100, 125], "underfit": [71, 95, 97], "undergird": 48, "undergo": 64, "underground": 62, "underli": [7, 29, 34, 43, 44, 45, 47, 48, 49, 60, 63, 65, 66, 67, 77, 79, 83, 90, 94, 98, 103, 125, 128], "underrepresent": 63, "underscor": 116, "underset": [52, 66, 85, 92, 99], "underst": 25, "understand": [8, 11, 17, 42, 43, 45, 47, 49, 53, 58, 60, 62, 64, 65, 66, 67, 71, 75, 99, 102, 103, 107, 109, 124, 127, 138, 143, 144], "understood": [23, 34, 43, 48, 58, 63, 64, 67, 73, 102, 105, 112, 135, 138], "undetect": 64, "undoubtedli": 62, "undul": 47, "unduli": 48, "unemploy": 25, "unequ": 117, "unessenti": 106, "unexpect": [40, 53, 128], "unexpected": 53, "unfair": [9, 15, 25, 30, 63], "unfairli": 46, "unfortun": [8, 44, 68, 72, 73, 100], "uni": [80, 81], "uni_dist": 33, "uni_dist_pt": 33, "uni_gauss_pt": 33, "uni_max": 33, "uni_min": 33, "unicode_liter": 76, "unif": 61, "uniform": [3, 4, 5, 6, 7, 9, 11, 12, 19, 25, 29, 30, 33, 35, 37, 38, 40, 41, 42, 43, 44, 49, 50, 51, 53, 71, 79, 81, 92, 95, 96, 98, 103, 105, 125, 126, 127, 131, 134, 136, 138, 141, 143, 144, 145], "uniform_1": [127, 144], "uniform_2": [127, 144], "uniformli": [6, 33, 35, 42, 47, 71, 77, 82, 83, 112, 124, 135, 136, 145], "uniformpropos": 133, "uniformsampl": 3, "unifrompdf": 112, "unimod": [18, 19, 46], "uninform": [11, 37, 49], "uninterest": 112, "union": [22, 48, 66, 112], "uniqu": [7, 18, 25, 44, 100, 102, 112, 135, 138], "unit": [23, 34, 40, 42, 44, 60, 67, 68, 69, 71, 73, 93, 96, 112, 115, 135], "uniti": [16, 37, 53, 78, 95, 112], "unitless": [103, 108], "univari": [43, 44, 82, 85, 100, 112, 133, 138, 143], "univers": [1, 7, 8, 47, 48, 56, 64, 67, 75, 79, 109, 112], "universal_newlin": 108, "unknown": [19, 22, 31, 34, 37, 43, 46, 53, 66, 85, 96, 98, 103, 106, 111, 133, 140], "unknowwn": 68, "unlabel": 67, "unless": [4, 16, 46, 47, 52, 53, 71, 76, 99, 106, 115, 125, 126, 133, 135, 138, 141], "unlik": [23, 33, 37, 40, 53, 75, 116, 124, 135], "unlock": 73, "unlov": 45, "unnecessarili": [67, 129, 134], "unnorm": [13, 35, 42, 44, 53, 126, 141], "unobserv": 34, "unpack": [48, 78, 82], "unreason": [53, 102], "unrol": 76, "unround": 115, "unsatisfi": 62, "unscal": 95, "unseen": 88, "unshift": [125, 126], "unsort": 41, "unspecifi": 69, "unsqueez": 71, "unstabl": [65, 68, 79, 86], "unstack": 69, "unsupervis": [64, 67, 73], "unsur": 42, "until": [19, 63, 67, 68, 71, 88, 97, 99, 103, 126, 127, 133, 135, 136, 141, 144], "unverifi": 61, "unwant": 25, "up": [0, 4, 8, 11, 12, 16, 19, 23, 26, 33, 35, 38, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 56, 60, 62, 63, 64, 65, 69, 71, 72, 73, 82, 93, 98, 99, 100, 102, 103, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 120, 125, 126, 127, 128, 129, 133, 136, 140, 141, 142, 144], "updat": [1, 5, 11, 12, 13, 15, 23, 25, 27, 33, 34, 37, 43, 44, 48, 49, 56, 58, 59, 62, 66, 67, 68, 69, 70, 71, 72, 73, 77, 78, 83, 92, 93, 99, 103, 114, 116, 126, 128, 130, 131, 132, 135, 138, 143], "update_n": 9, "update_plot": [9, 114], "update_prob_head": 9, "update_t_max": 114, "uphil": [97, 133], "uphold": 61, "upon": [16, 19, 21, 38, 43, 47, 48, 58], "upper": [9, 17, 33, 42, 49, 51, 53, 56, 72, 81, 105, 108, 119, 132, 134], "uq": [47, 104], "url": 1, "us": [0, 1, 3, 5, 6, 8, 9, 10, 11, 13, 15, 16, 17, 18, 20, 23, 24, 25, 26, 29, 30, 32, 33, 34, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 76, 77, 78, 79, 80, 81, 82, 86, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 118, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 143, 144, 145], "usag": [0, 71, 115], "usecol": 115, "usefulli": 48, "uselatex": 108, "user": [11, 38, 41, 44, 50, 63, 81, 86, 93, 99, 108, 111, 116, 119, 125, 133, 135, 143], "user_nam": 118, "userwarn": [50, 105, 134], "usetex": 105, "usr": [50, 81, 96, 108, 134], "usual": [0, 2, 4, 7, 19, 22, 24, 25, 29, 32, 34, 38, 43, 45, 46, 47, 48, 49, 52, 53, 60, 64, 65, 66, 67, 71, 72, 73, 82, 85, 88, 93, 97, 98, 99, 100, 107, 109, 112, 115, 116, 126, 128, 130, 135], "util": [44, 64, 67, 77, 82, 99, 100, 103, 108, 112, 138, 143], "utmost": 64, "uvec": 86, "v": [7, 17, 33, 35, 38, 41, 47, 52, 78, 82, 96, 99, 100, 103, 105, 107, 109, 116, 117, 120, 131, 133, 134, 136], "v0": [0, 7, 41, 105], "v1": [96, 109, 114], "v12": 1, "v2": [43, 109], "v3": 96, "v5": [133, 134], "v_": [7, 41, 47, 48, 107, 109], "v_0": [7, 45, 79, 103, 105], "v_1": 48, "v_1v_2": 48, "v_2": 48, "v_d": 135, "v_i": 45, "v_shape": 109, "v_t": 100, "v_tran": 109, "va": [17, 33, 95, 131, 132], "vaiidat": 66, "vain": 53, "val": [64, 66], "val_accuraci": 76, "val_loss": 76, "vale": 4, "valid": [0, 29, 43, 44, 47, 51, 58, 59, 63, 64, 67, 77, 78, 82, 83, 85, 97, 99, 103, 105, 135, 136], "validation_data": 76, "vallei": 99, "valu": [3, 4, 5, 7, 9, 10, 11, 13, 16, 17, 22, 25, 27, 30, 33, 34, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 82, 83, 85, 86, 88, 89, 92, 94, 95, 98, 99, 100, 102, 103, 105, 106, 108, 109, 111, 115, 116, 117, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 138, 141, 143, 144, 145], "valuabl": [107, 116, 118], "valueconstraintsprior": 78, "valueerror": [37, 105, 111, 129, 134], "van": [1, 43, 66], "van16": [1, 66], "vander": [34, 98], "vandermond": [34, 98], "vanderpla": [1, 66, 80], "vandschootdk": [1, 43], "vanish": [68, 71, 102], "vannucci": 1, "var": [7, 17, 24, 44, 45, 46, 66, 77, 83, 96, 112, 118, 125, 133, 135], "var2": 17, "var_chain": 125, "var_lnl": 96, "var_nam": 134, "var_theta": 125, "varabl": 46, "varepsilon": [7, 40, 44, 48, 85, 96, 99], "varepsilon_": 48, "varepsilon_i": [40, 41, 49, 125], "vari": [19, 35, 37, 43, 45, 47, 51, 64, 65, 79, 95, 100, 103, 108, 111, 136], "variabl": [3, 4, 11, 16, 19, 22, 23, 24, 25, 26, 31, 32, 34, 37, 38, 39, 43, 44, 52, 53, 59, 61, 63, 64, 65, 66, 67, 72, 73, 78, 80, 82, 86, 88, 91, 93, 98, 99, 100, 103, 108, 109, 115, 116, 117, 118, 125, 127, 129, 130, 133, 134, 135, 138, 140, 143, 144, 145], "varianc": [1, 7, 17, 19, 24, 29, 33, 34, 37, 38, 39, 41, 43, 46, 48, 50, 65, 67, 71, 72, 77, 78, 79, 80, 82, 83, 85, 86, 88, 92, 95, 96, 97, 98, 99, 103, 105, 106, 108, 109, 111, 115, 125, 127, 128, 129, 130, 133, 134, 135, 136, 140, 144], "variance3": 78, "variant": [23, 67, 95, 132, 135], "variat": [1, 4, 34, 38, 44, 45, 46, 47, 51, 64, 65, 66, 79, 97, 99, 100, 103, 109, 115, 125, 128, 133, 135, 136], "varieti": [38, 55, 67, 118, 133], "variou": [0, 16, 18, 25, 31, 33, 46, 47, 56, 58, 64, 70, 71, 73, 74, 88, 94, 99, 100, 113, 115, 142], "varphi": 7, "varz": 82, "vast": [45, 63], "vastli": 75, "vbox": [5, 9, 114], "vdot": [34, 52, 98, 109, 138, 143], "ve": [11, 17, 27, 29, 31, 38, 40, 52, 77, 78, 83, 109, 127, 128, 130, 133, 136, 144], "vec": [23, 85, 96], "vecor": 98, "vector": [5, 7, 9, 10, 23, 30, 34, 35, 38, 40, 41, 44, 45, 47, 49, 50, 52, 53, 65, 66, 68, 70, 72, 73, 75, 76, 77, 78, 82, 83, 85, 86, 88, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 105, 107, 109, 111, 112, 115, 117, 118, 120, 125, 128, 129, 130, 131, 132, 134, 135, 136, 138, 143], "vee": [73, 93], "veen": 1, "vega": 136, "vehicl": 64, "vehtari": [1, 51], "veloc": [7, 41, 100, 103, 105], "venn": 8, "ventur": 64, "venv": 119, "verbos": [34, 65, 69, 70, 76, 98], "verdict": [8, 62], "veri": [4, 7, 8, 9, 16, 25, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 53, 56, 62, 64, 65, 66, 67, 71, 72, 73, 75, 76, 78, 79, 82, 85, 86, 94, 96, 97, 98, 99, 100, 112, 115, 117, 125, 126, 129, 130, 133, 134, 135, 136, 138, 141, 143, 145], "verif": 43, "verifi": [3, 7, 13, 19, 34, 37, 39, 42, 43, 53, 63, 69, 109, 112, 118, 119, 124, 132, 134, 135, 138], "vernon": [1, 56], "versa": [112, 138], "version": [16, 19, 23, 24, 28, 35, 37, 38, 39, 40, 41, 43, 44, 45, 47, 49, 50, 51, 62, 64, 66, 67, 69, 70, 73, 76, 85, 88, 93, 99, 103, 105, 108, 109, 115, 116, 119, 121, 125, 126, 127, 128, 130, 133, 134, 135, 136, 144], "versu": [38, 52, 63, 78, 82], "vert": [30, 34, 45, 66, 88, 109, 112, 138, 141, 143], "vert_1": 66, "vert_2": 66, "vertic": [4, 9, 17, 37, 53, 94, 126], "verticalalign": [9, 42], "vgb10": [1, 46], "vgb14": [1, 46], "via": [4, 7, 27, 34, 41, 43, 44, 45, 46, 47, 48, 64, 66, 67, 68, 71, 72, 75, 88, 90, 91, 95, 98, 100, 105, 107, 112, 117, 119, 120, 124, 125, 133, 135, 136, 138], "viabl": 63, "vice": [112, 138], "vicin": 51, "video": [63, 67, 108], "vien": 56, "view": [9, 23, 25, 30, 38, 39, 40, 43, 53, 56, 61, 64, 66, 67, 72, 76, 110, 115, 118, 129, 134, 138], "view_init": 65, "viewpoint": [45, 101, 112], "vincent": 80, "violat": [8, 19], "virtu": [7, 57, 59], "virtual": [68, 119], "viru": 119, "visibl": 7, "vision": [64, 71], "visit": [126, 135], "visual": [7, 19, 26, 34, 37, 38, 39, 41, 43, 44, 47, 51, 53, 64, 65, 67, 70, 71, 73, 75, 77, 83, 86, 88, 98, 108, 109, 115, 125, 126, 128, 134, 138, 143], "vlg": [1, 46], "vline": [39, 41, 134], "vm": 41, "vmatrix": 3, "vmax": 65, "vmeasur": 41, "vmin": 65, "vocabulari": [17, 32, 40], "volum": [1, 4, 6, 34, 35, 41, 44, 46, 51, 62, 98, 100, 115, 129, 130, 131, 134, 135, 136], "volume_theta": [129, 134], "von": 99, "von_neumann": 99, "vote": 65, "vp": 78, "vp_mat": 49, "vp_mat_inv": 49, "vp_tran": 109, "vsigma": 41, "vstack": 17, "vt": 109, "vulner": 63, "vw15": [1, 66], "vysochanskii": 46, "w": [1, 4, 35, 37, 44, 67, 68, 70, 72, 74, 88, 95, 96, 102, 109, 115, 125, 133], "w_": [67, 68, 88], "w_0": [65, 67, 70, 72, 74, 88], "w_1": [65, 67, 70, 72, 74, 88], "w_1_2": [73, 93], "w_1x": 88, "w_2": [65, 67, 72, 74, 88], "w_2_out": [73, 93], "w_i": [72, 135], "w_in_1": [73, 93], "w_j": 88, "w_jx_j": 67, "w_p": [67, 88], "w_pad": 33, "w_std": 111, "wa": [0, 4, 7, 8, 15, 19, 21, 23, 25, 34, 39, 40, 44, 46, 47, 48, 49, 50, 51, 53, 56, 61, 62, 63, 66, 67, 71, 72, 73, 74, 77, 79, 81, 88, 93, 95, 96, 97, 99, 100, 102, 103, 105, 111, 112, 115, 119, 125, 126, 127, 129, 132, 133, 134, 135, 136, 138, 143, 144], "wahlstr\u00f6m": 1, "wai": [0, 4, 5, 7, 8, 9, 12, 13, 16, 17, 19, 22, 23, 25, 29, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 51, 53, 59, 62, 63, 64, 65, 67, 68, 69, 71, 73, 75, 78, 80, 82, 86, 88, 95, 97, 99, 100, 102, 109, 112, 114, 115, 116, 124, 126, 127, 135, 136, 138, 143, 144], "waic": 51, "wak": [1, 115], "walk": [15, 35, 44, 50, 125, 130, 135, 142], "walker": [6, 35, 38, 41, 50, 51, 96, 105, 124, 125, 128, 129, 134, 141, 145], "wall": [38, 41, 50, 93, 125, 126], "wang": [1, 115], "want": [0, 7, 9, 11, 12, 13, 16, 18, 19, 22, 30, 31, 34, 35, 37, 39, 40, 41, 42, 43, 44, 48, 50, 51, 56, 58, 59, 63, 68, 69, 71, 72, 73, 77, 78, 79, 81, 82, 83, 86, 90, 92, 94, 96, 98, 99, 108, 113, 116, 117, 118, 119, 122, 124, 125, 126, 128, 129, 131, 133, 134, 136, 138, 141], "wantonli": 61, "ware": 43, "warm": [38, 41, 50, 98, 109, 125, 127, 128, 136, 141, 144], "warm_up_step": [127, 144], "warmup": [38, 41, 50, 125], "warn": [7, 50, 53, 69, 73, 77, 83, 92, 93, 96, 105, 115, 125, 126], "warnup": 38, "warrant": 66, "warranti": 76, "wash": 51, "washington": [51, 80], "wasn": 133, "wasserman": 53, "wast": [48, 52, 66, 75, 136], "wave": [7, 17, 23, 45, 46, 47, 114, 116], "wavelength": 103, "we": [0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 77, 78, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 112, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 142, 143, 144], "weak": [7, 43, 46, 47, 52, 53, 78, 82, 99, 128], "weaker": 82, "weakli": [40, 43, 52, 78, 82, 102], "wear": [1, 135], "weather": [16, 67], "web": [17, 116], "webpag": 49, "websit": [63, 87], "webster": 100, "week": [56, 92], "weigh": [38, 53], "weight": [1, 19, 25, 33, 34, 38, 40, 44, 48, 53, 60, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 85, 93, 95, 102, 103, 105, 111, 125, 128, 133, 135, 136], "weight_0": [64, 65], "weight_1": 65, "weight_2": 65, "weight_std": 111, "weights_1_2": [73, 93], "weights_2_out": [73, 93], "weights_in_1": [73, 93], "weiguang": [1, 44, 56], "welcom": 8, "well": [0, 3, 7, 8, 12, 19, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 51, 53, 58, 59, 63, 64, 66, 67, 71, 72, 73, 77, 80, 83, 85, 88, 93, 95, 96, 97, 99, 100, 102, 105, 109, 115, 116, 119, 125, 126, 128, 129, 130, 133, 134, 135, 136, 140, 143], "went": 62, "were": [4, 7, 16, 18, 23, 25, 31, 32, 34, 38, 41, 43, 44, 47, 48, 50, 51, 53, 63, 71, 73, 75, 76, 88, 96, 111, 115, 124, 126, 134, 138], "wesolowski": [56, 108], "wessel": [1, 66], "what": [0, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 42, 43, 47, 49, 50, 52, 53, 56, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 74, 75, 77, 78, 82, 83, 85, 86, 88, 90, 92, 94, 96, 100, 107, 108, 109, 112, 113, 114, 116, 117, 119, 124, 125, 126, 127, 130, 132, 133, 136, 138, 140, 143, 144, 145], "whatev": [21, 22, 37, 42, 64, 114], "when": [4, 7, 8, 15, 16, 17, 22, 23, 25, 27, 29, 30, 31, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 76, 77, 82, 83, 85, 86, 88, 92, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 109, 112, 115, 116, 118, 125, 126, 127, 129, 130, 131, 133, 134, 135, 136, 138, 141, 143, 144, 145], "whenev": [63, 80, 105, 112], "where": [3, 4, 5, 7, 8, 9, 10, 13, 16, 17, 19, 23, 25, 29, 30, 32, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 79, 81, 82, 83, 85, 86, 88, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 105, 107, 108, 109, 112, 115, 116, 117, 119, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 141, 143, 144, 145], "wherea": [8, 31, 34, 43, 53, 65, 66, 117, 118], "wherebi": 16, "wherein": [48, 62, 67], "whether": [16, 17, 22, 29, 32, 34, 37, 38, 40, 43, 49, 51, 53, 58, 63, 88, 94, 99, 112, 116, 126, 130, 135, 136, 141], "which": [0, 4, 5, 7, 8, 9, 12, 16, 17, 18, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 85, 86, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 114, 115, 116, 117, 118, 119, 122, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 142, 143, 145], "while": [0, 4, 7, 19, 22, 23, 25, 32, 34, 38, 44, 46, 47, 48, 51, 53, 58, 63, 65, 66, 67, 68, 71, 73, 76, 78, 79, 81, 85, 86, 88, 89, 91, 99, 100, 107, 112, 114, 116, 117, 118, 119, 126, 128, 129, 133, 134, 135, 136, 141, 143, 145], "whilst": [77, 83], "whistl": 116, "white": [63, 77, 82, 83, 85, 86, 102, 125], "who": [16, 43, 46, 48, 53, 56, 61, 62, 63, 64, 117], "whoever": 25, "whole": [70, 73, 75, 93, 117, 118], "whose": [17, 31, 34, 35, 53, 58, 65, 66, 85, 100, 108, 112, 136, 138], "why": [1, 5, 8, 9, 12, 15, 19, 23, 25, 26, 30, 31, 32, 34, 39, 40, 42, 44, 48, 65, 66, 70, 71, 73, 76, 77, 78, 79, 82, 88, 93, 95, 98, 102, 108, 109, 115, 116, 118, 126, 129, 133, 134, 135, 138, 143], "wide": [34, 35, 43, 48, 51, 53, 64, 68, 71, 75, 85, 102, 104, 118, 136], "widehat": [44, 52, 136], "wider": [38, 73], "widespread": [130, 135, 136], "widetild": [34, 79, 86], "widget": [5, 9, 11, 30, 108, 120], "width": [9, 17, 25, 29, 33, 34, 37, 38, 42, 43, 50, 52, 53, 65, 67, 71, 75, 76, 82, 89, 90, 96, 108, 111, 114, 115, 124, 125, 126, 128, 135, 136, 141, 145], "wiecki": [73, 93, 126], "wieringen": [1, 66], "wierstra": 1, "wiggl": 99, "wigner": 102, "wiki": 99, "wikimedia": 43, "wikipedia": [19, 49, 52, 77, 89, 99, 103, 110], "wild": 49, "wildli": 37, "wilei": 1, "willemsen": 1, "william": [0, 1, 7, 23, 53, 85, 86], "willing": 8, "win": [16, 25, 77, 130], "window": [93, 105, 116, 119, 125], "wine": 7, "winner": 62, "wisdom": [48, 66], "wise": [61, 67, 71, 72, 73, 77, 78, 82, 83, 109, 118], "wish": [9, 30, 43, 44, 61, 77, 78, 82, 83, 88, 112, 115], "with_errorbar": [34, 98], "within": [3, 6, 7, 16, 19, 38, 39, 43, 44, 46, 47, 48, 51, 53, 58, 60, 62, 63, 64, 66, 71, 79, 88, 94, 95, 96, 98, 99, 102, 105, 112, 115, 119, 125, 126, 128, 129, 130, 133, 134, 135, 138, 143], "without": [1, 8, 34, 40, 44, 45, 46, 47, 49, 53, 56, 59, 61, 62, 64, 67, 69, 76, 79, 80, 82, 85, 86, 88, 89, 92, 93, 95, 96, 100, 102, 103, 109, 112, 116, 117, 125, 133, 138, 141, 145], "wm": 133, "wmap": 40, "wno": [73, 93], "women": [63, 112], "won": [38, 63, 73, 107, 114, 115, 126, 129, 130, 134], "wooff": [1, 46], "word": [21, 22, 31, 38, 40, 41, 42, 46, 49, 53, 58, 66, 75, 77, 78, 82, 83, 109, 112, 115, 117, 124, 125, 126, 138, 143], "work": [1, 3, 5, 7, 9, 12, 13, 14, 17, 19, 23, 27, 29, 32, 33, 34, 37, 38, 43, 44, 48, 49, 50, 51, 53, 56, 61, 63, 65, 67, 68, 71, 72, 73, 79, 80, 82, 86, 88, 90, 92, 93, 95, 96, 97, 98, 102, 103, 105, 109, 110, 112, 115, 116, 117, 118, 119, 124, 125, 126, 129, 130, 133, 134, 135, 136, 141], "worker": [63, 105], "workflow": [27, 28, 47, 57, 60, 116, 140], "workhors": 142, "world": [8, 16, 21, 40, 47, 63, 73, 77, 98, 116, 117], "worldwid": 115, "worri": [40, 43, 53], "wors": [65, 66, 75], "worsen": 63, "worst": 47, "worth": [23, 51, 61, 95, 97, 99], "worthwhil": 23, "would": [0, 3, 4, 7, 8, 15, 16, 17, 19, 21, 23, 25, 29, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 51, 53, 56, 63, 65, 66, 67, 68, 70, 71, 72, 73, 75, 85, 88, 92, 93, 95, 98, 99, 100, 102, 107, 112, 115, 116, 126, 127, 129, 130, 133, 134, 135, 136, 138, 143, 144], "wreck": 63, "write": [9, 16, 19, 23, 24, 25, 30, 32, 34, 40, 41, 42, 47, 48, 49, 52, 56, 58, 64, 65, 66, 67, 68, 71, 73, 76, 77, 78, 82, 83, 85, 86, 93, 98, 105, 107, 108, 109, 112, 115, 116, 126, 135], "writer": 108, "writervideo": 108, "written": [0, 3, 4, 5, 7, 22, 34, 44, 45, 48, 51, 53, 63, 64, 68, 73, 77, 78, 82, 83, 85, 86, 93, 98, 105, 115, 118, 132, 135, 138, 140], "wrong": [7, 12, 16, 19, 29, 34, 35, 44, 48, 59, 63, 67, 76, 97, 98, 100, 128, 141], "wrote": [22, 23, 59, 62, 141], "wrt": [33, 71], "wt": 47, "wvar": 33, "www": [1, 51, 69, 76, 119], "x": [0, 1, 3, 4, 5, 6, 9, 13, 17, 19, 22, 23, 24, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 85, 86, 88, 92, 93, 94, 95, 96, 98, 99, 102, 103, 105, 107, 108, 109, 111, 112, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 138, 141, 143, 144, 145], "x0": [40, 41, 42, 92, 96, 135], "x0_max": [42, 70], "x0_min": [42, 70], "x0_pt": 42, "x0_true": [35, 42, 124], "x1": [23, 65, 70, 78, 92, 93, 96, 105, 112], "x1_max": 70, "x1_min": 70, "x1_orig": 65, "x1sq": 78, "x1x2": [65, 112], "x1x2_grid": 65, "x2": [23, 40, 65, 70, 78, 93, 105, 112], "x27": [70, 133], "x2_orig": 65, "x2givenx0_fig": 138, "x2sq": 78, "x_": [3, 4, 7, 34, 41, 42, 44, 65, 78, 82, 85, 94, 96, 98, 102, 126, 138, 141, 143], "x_0": [3, 4, 7, 17, 19, 23, 35, 37, 53, 65, 70, 88, 90, 96, 103, 124, 138, 143, 145], "x_1": [0, 7, 17, 19, 23, 33, 34, 39, 48, 52, 65, 67, 70, 72, 74, 78, 79, 82, 86, 88, 90, 96, 98, 105, 109, 112, 129, 134, 138, 140, 143, 145], "x_2": [0, 7, 17, 19, 23, 33, 34, 52, 65, 67, 70, 72, 74, 78, 79, 82, 86, 88, 98, 109, 112, 138, 140, 143], "x_3": [34, 67, 86, 143], "x_arang": 117, "x_arr": 41, "x_beta": 17, "x_co": 71, "x_col": 82, "x_cosh": 71, "x_cv": 95, "x_d": [33, 78], "x_data": 65, "x_data_pt": 49, "x_dist": [17, 42, 108], "x_exp": 71, "x_fit": 95, "x_gamma": 108, "x_i": [3, 4, 22, 24, 25, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 44, 48, 49, 53, 65, 67, 72, 82, 86, 95, 98, 103, 105, 109, 112, 125, 128, 129, 134, 135, 138, 143], "x_ip": 24, "x_j": [4, 7, 19, 48, 82, 88, 96, 103, 128, 138, 143], "x_k": [4, 35, 37, 39, 42, 82, 96, 124, 129, 134, 143], "x_l": 67, "x_label": 42, "x_list": 117, "x_log": 71, "x_m": [7, 39, 129, 134, 138], "x_max": [33, 37, 41, 42, 49, 95, 108, 125], "x_max_index": [9, 17, 30, 108], "x_mean": 41, "x_min": [33, 37, 41, 42, 95], "x_n": [19, 33, 48, 52, 67, 82, 105, 109, 112, 135, 138, 143], "x_new": 82, "x_norm": [17, 108], "x_norm_val": 29, "x_p": 88, "x_posterior": 41, "x_pt": [5, 33, 37, 40, 42, 49, 78, 116, 117], "x_pts_all": 49, "x_rang": 117, "x_row": 82, "x_row_til": 82, "x_sampl": 92, "x_sin": 71, "x_sinh": 71, "x_sort": 96, "x_sqrt": 71, "x_squar": 71, "x_t": [17, 44, 108, 126, 141, 143], "x_tensor": 111, "x_test": [69, 71, 73, 74, 93], "x_train": [65, 69, 71, 73, 74, 80, 81, 93, 95], "x_true": 81, "x_valu": 37, "x_with_fixedh": 41, "xarrai": [115, 133], "xavier": 71, "xaxi": 108, "xbar": [109, 141], "xbin": 41, "xdata": [34, 41, 65, 98], "xfit": [38, 41], "xi": [77, 83, 92, 129, 134], "xilin": 1, "xing": 1, "xk": 96, "xk_pt": 37, "xlabel": [7, 38, 69, 71, 73, 76, 77, 78, 80, 81, 82, 93, 95, 96, 105, 116, 126], "xlim": [73, 78, 82, 93, 111, 133], "xlinspac": 3, "xmax": [34, 41, 42, 96, 98], "xmeasur": [34, 98], "xmgivenx0_fig": 138, "xmin": [34, 41, 42, 96, 98], "xmode": 112, "xnew": [77, 83], "xp": [24, 77, 78, 82, 83], "xposterior": 41, "xposterior_fixedh": 41, "xposterior_pdfh": 41, "xrealiti": [34, 98], "xrightarrow": [44, 102], "xsq": 78, "xstar": 65, "xt": [78, 82], "xtick": [69, 76], "xtrue": 77, "xu": [1, 115], "xv": 50, "xvec": [23, 78, 79, 86, 128], "xvec_1": [79, 86], "xvec_2": [79, 86], "xx": [109, 112], "xx0": 70, "xx1": 70, "xx_j": 7, "xy": [7, 9, 17, 24, 35, 37, 42, 78, 108, 109, 112, 126], "xycoord": [9, 42], "xytext": [17, 108, 126], "y": [0, 3, 4, 5, 6, 9, 13, 17, 22, 23, 24, 25, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 48, 50, 52, 53, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 85, 88, 92, 93, 94, 95, 96, 97, 98, 102, 103, 105, 107, 108, 109, 111, 112, 116, 117, 125, 127, 128, 131, 132, 134, 135, 138, 140, 143, 144, 145], "y0": [42, 143], "y0_true": [35, 42, 124], "y1": [82, 112], "y2": [40, 82, 112], "y_": [0, 3, 29, 34, 40, 82, 88, 98, 102, 107, 109, 125, 138, 140, 141], "y_0": [7, 35, 42, 53, 124, 138, 141, 143, 145], "y_1": [7, 9, 32, 34, 48, 52, 67, 79, 82, 88, 98, 112, 138, 141], "y_2": [7, 9, 32, 34, 52, 67, 79, 82, 88, 98, 112], "y_3": 9, "y_cv": 95, "y_d": 82, "y_data_pt": 49, "y_determinist": 143, "y_fit": 95, "y_i": [3, 7, 29, 34, 38, 40, 41, 48, 49, 51, 52, 65, 66, 67, 68, 82, 95, 97, 98, 107, 109, 125, 135, 143], "y_j": [7, 22, 31, 32, 66, 67, 82, 88, 128], "y_k": 82, "y_logit": 88, "y_m": [7, 38, 40, 41, 49, 95, 125], "y_max": [9, 143], "y_mean": [81, 143], "y_model": [40, 41, 49, 125], "y_n": [48, 52, 138], "y_ob": [133, 134], "y_obs_dim_0": 133, "y_obs_dim_0pandasindexpandasindex": 133, "y_perceptron": 88, "y_pt": [33, 37, 49, 116], "y_reconstruct": 5, "y_run": 143, "y_sampl": [81, 92], "y_sort": 65, "y_std": 81, "y_stochast": 143, "y_t": 141, "y_tanh": 88, "y_test": [69, 71, 73, 93], "y_train": [65, 69, 71, 73, 80, 81, 93, 95], "y_train_noisi": 80, "y_true": [5, 81], "y_vec": 49, "y_x": 82, "yaida": 1, "yau": 1, "yaxi": 108, "ybar": 109, "ybin": 41, "ydata": [34, 41, 98], "ye": [22, 34, 35, 64, 88, 138], "year": [25, 56, 62, 63, 77, 102], "yellow": 136, "yerr": [41, 96, 105], "yerror": [34, 98], "yet": [8, 16, 31, 34, 43, 49, 98, 103, 109, 138], "yexp": 0, "yfit": [38, 41], "yfunc": 77, "yhat_hard_grid": 65, "yhat_knn_grid": 65, "yhat_soft_grid": 65, "yhi95": [77, 83], "yhii": [77, 83], "yi": [78, 82, 112, 129, 134], "yield": [7, 22, 23, 25, 31, 32, 34, 38, 46, 47, 52, 53, 65, 66, 67, 86, 98, 102, 103, 108, 115], "ylabel": [7, 38, 71, 73, 76, 77, 78, 80, 81, 82, 83, 93, 95, 96, 105, 125, 126], "ylim": [69, 73, 76, 78, 81, 82, 93, 111, 125, 126, 133], "ylo95": [77, 83], "yloi": [77, 83], "ymean": [77, 83], "ymeani": [77, 83], "ymin": 96, "yml": [0, 70, 93, 119, 122], "ynew": [77, 83], "yoram": 1, "york": [50, 56, 125, 126], "yoshioka": 73, "you": [0, 3, 4, 5, 7, 8, 9, 11, 12, 15, 16, 17, 18, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 59, 62, 63, 64, 65, 66, 67, 69, 71, 73, 74, 76, 77, 79, 81, 83, 86, 88, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 107, 108, 109, 112, 113, 115, 116, 117, 118, 119, 121, 122, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 138, 143, 144], "young": [63, 64], "your": [0, 7, 8, 11, 12, 15, 16, 17, 19, 22, 31, 32, 34, 35, 37, 39, 40, 42, 49, 56, 62, 63, 64, 65, 66, 67, 69, 71, 73, 74, 76, 77, 85, 90, 93, 94, 95, 97, 108, 109, 112, 113, 116, 121, 122, 124, 125, 126, 127, 128, 129, 133, 134, 135, 140, 143, 144], "yourself": [7, 16, 22, 30, 31, 37, 90, 96, 116], "yp": 78, "yt": [78, 82], "yth": 0, "ytick": [69, 76], "ytrue": 77, "yvar": [77, 83], "yvari": [77, 83], "yvec": [109, 128], "z": [5, 33, 34, 37, 44, 46, 50, 51, 64, 65, 67, 68, 70, 71, 72, 77, 78, 79, 82, 83, 85, 88, 92, 96, 98, 102, 103, 109, 112, 115, 130, 133, 141], "z_": [68, 88, 102], "z_0": 7, "z_1": [46, 88], "z_2": [46, 88], "z_grid": [37, 65], "z_i": [38, 46], "z_j": [46, 67, 88], "z_k": 68, "z_m": [46, 72], "z_n": 85, "z_p": [53, 95], "z_q": 53, "z_w": 72, "zdir": 65, "zdist": 82, "zeiler": 1, "zeiler12": [1, 99], "zenodo": 43, "zero": [3, 6, 7, 9, 19, 23, 24, 25, 29, 33, 34, 37, 38, 40, 42, 48, 49, 50, 53, 56, 65, 66, 67, 68, 71, 72, 75, 77, 78, 82, 83, 85, 86, 88, 95, 96, 97, 98, 99, 102, 103, 107, 108, 109, 111, 112, 113, 115, 116, 125, 126, 127, 128, 130, 132, 136, 138, 140, 141, 143, 144], "zero_grad": 71, "zeros_lik": [0, 7, 25, 30, 41, 65, 96, 112], "zeta": [47, 103], "zeta_i": 47, "zeus_multimod": 145, "zhang": 1, "zip": [33, 38, 65, 77, 83, 96, 105, 109, 112], "zm_h": 115, "zoom": 42, "zorder": [34, 81, 98], "zrang": 82, "\u00b2": 105, "\u00e9": 1, "\u03bc": [38, 111], "\u03c3": 111}, "titles": ["<span class=\"section-number\">32. </span>Guide to Jupyter Book markdown", "<span class=\"section-number\">31. </span>Bibliography", "<span class=\"section-number\">10. </span>Assigning probabilities", "<span class=\"section-number\">10.1. </span>Assigning probabilities (I): Indifferences and translation groups", "<span class=\"section-number\">10.2. </span>Assigning probabilities (II): The principle of maximum entropy", "<span class=\"section-number\">10.3. </span>\ud83d\udce5 Maximum Entropy for reconstructing a function from its moments", "\ud83d\udce5 Demonstration: Prior PDFs for straight lines", "<span class=\"section-number\">7.1. </span>Advantages of the Bayesian approach", "<span class=\"section-number\">4.8. </span>*Aside: Bayesian epistemology", "<span class=\"section-number\">6.7. </span>\ud83d\udce5 Demonstration: Coin tossing", "<span class=\"section-number\">6. </span>Updating via Bayes\u2019 rule", "<span class=\"section-number\">6.1. </span>Coin tossing: Frequentists and Bayesaians", "<span class=\"section-number\">6.2. </span>When do priors matter? When don\u2019t they matter?", "<span class=\"section-number\">6.3. </span>Computing the posterior analytically", "<span class=\"section-number\">6.4. </span>Degree of belief/credibility intervals vs frequentist 1-sigma intervals", "<span class=\"section-number\">6.5. </span>Take-aways and follow-up questions from coin flipping:", "<span class=\"section-number\">4.9. </span>Data, models, and predictions", "<span class=\"section-number\">5.1. </span>\ud83d\udce5 Exploring PDFs", "Follow-up questions and answers to the <em>Exploring PDFs</em> section.", "<span class=\"section-number\">5.2. </span>Gaussians: A couple of frequentist connections", "<span class=\"section-number\">4. </span>Inference and PDFs", "<span class=\"section-number\">4.1. </span>Statements", "<span class=\"section-number\">4.2. </span>Manipulating probabilities: Bayesian rules of probability as principles of logic", "<span class=\"section-number\">4.3. </span>Probability density functions", "<span class=\"section-number\">4.4. </span>Looking ahead", "<span class=\"section-number\">4.7. </span>More on Bayes\u2019 theorem", "<span class=\"section-number\">5. </span>Bayesian posteriors", "<span class=\"section-number\">3. </span>Bayesian methods for scientific modeling", "<span class=\"section-number\">7. </span>Bayes in practice", "<span class=\"section-number\">5.4. </span>\ud83d\udce5 Demonstration: Sum of normal variables squared", "<span class=\"section-number\">6.6. </span>\ud83d\udce5 Demonstration:  Bayesian Coin Tossing", "<span class=\"section-number\">4.6. </span>Exercise: Standard medical example using Bayes", "<span class=\"section-number\">4.5. </span>Exercise: Checking the sum and product rules", "\ud83d\udce5 Visualization of the Central Limit Theorem", "<span class=\"section-number\">7.3. </span>Bayesian Linear Regression (BLR)", "<span class=\"section-number\">5.3. </span>Interpreting 2D posteriors", "<span class=\"section-number\">9. </span>More Bayesian parameter estimation", "<span class=\"section-number\">9.2. </span>\ud83d\udce5 Amplitude of a signal in the presence of background", "<span class=\"section-number\">9.5. </span>\ud83d\udce5 Dealing with outliers", "\ud83d\udce5 Parameter estimation example: Gaussian noise and averages I", "<span class=\"section-number\">9.3. </span>Parameter estimation example: fitting a straight line", "<span class=\"section-number\">9.4. </span>\ud83d\udce5 Parameter estimation example: fitting a straight line II", "<span class=\"section-number\">9.1. </span>\ud83d\udce5 Radioactive lighthouse problem", "<span class=\"section-number\">7.2. </span>Bayesian research workflow", "<span class=\"section-number\">17.1. </span>Advanced Markov chain Monte Carlo sampling", "<span class=\"section-number\">27.1. </span>Bayes goes fast: Emulators", "<span class=\"section-number\">11. </span>Bayes goes linear: History matching", "<span class=\"section-number\">27.2. </span>Emulators", "<span class=\"section-number\">12.2. </span>Model mixing", "Evidence calculation for EFT expansions", "Demo: Multimodal distributions with two samplers", "Computing the Bayesian evidence", "Evidence for an expansion", "<span class=\"section-number\">12.1. </span>Model Selection", "<span class=\"section-number\">12. </span>Multi-model inference with Bayes", "<span class=\"section-number\">8. </span>Overview of Part II: Advanced Bayesian methods", "About this Jupyter Book", "<span class=\"section-number\">2. </span>Introduction", "<span class=\"section-number\">2.1. </span>Physicist\u2019s perspective", "<span class=\"section-number\">2.2. </span>Bayesian workflow", "<span class=\"section-number\">2.3. </span>Machine learning", "<span class=\"section-number\">2.4. </span>Virtues", "<span class=\"section-number\">1. </span>Invitation to inductive inference", "<span class=\"section-number\">22.9. </span>Data bias and fairness in machine learning", "<span class=\"section-number\">22. </span>Machine learning: Overview and notation", "<span class=\"section-number\">21.5. </span>Machine Learning: First Examples", "<span class=\"section-number\">22.8. </span>Model validation", "<span class=\"section-number\">22.5. </span>Artifical neural networks", "<span class=\"section-number\">22.10. </span>*Neural networks: Backpropagation", "<span class=\"section-number\">22.6. </span>Demonstration: Neural network classifier", "<span class=\"section-number\">21.6. </span>Exercise: Logistic Regression and neural networks", "<span class=\"section-number\">22.7. </span>Feed-forward neural network for a function in PyTorch", "<span class=\"section-number\">24. </span>Bayesian neural networks", "<span class=\"section-number\">24.4. </span>Demonstration: Variational Inference and Bayesian Neural Networks", "<span class=\"section-number\">24.5. </span>Exercise: Bayesian neural networks", "<span class=\"section-number\">25. </span>*Convolutional Neural Networks", "<span class=\"section-number\">25.6. </span>Demonstration: Image recognition with Convolutional Neural Networks", "Exercise: Gaussian Process models with GPy", "Gaussian processes demonstration", "Lecture 20", "Gaussian Processes regression: basic introductory example", "Illustration of prior and posterior Gaussian process for different kernels", "Demonstration: Gaussian processes", "Exercise: Gaussian processes using <code class=\"docutils literal notranslate\"><span class=\"pre\">GPy</span></code>", "<span class=\"section-number\">20.6. </span>GPy demo notebooks", "<span class=\"section-number\">20.4. </span>Gaussian processes", "<span class=\"section-number\">20. </span>Overview of Gaussian process", "<span class=\"section-number\">20.5. </span>Scikit-learn demo notebooks", "<span class=\"section-number\">21. </span>Logistic Regression", "<span class=\"section-number\">19. </span>Machine Learning", "Overview of Mini-project IIb: How many lines?", "Overview of TALENT mini-projects", "Mini-project IIIa: Bayesian Optimization", "Mini-project IIIb: Bayesian Neural Networks", "Mini-project I: Parameter estimation for a toy model of an EFT", "Mini-project IIa: Model selection basics", "Mini-project IIb: How many lines are there?", "<span class=\"section-number\">34. </span>Gradient-descent optimization", "<span class=\"section-number\">37. </span>Linear models", "<span class=\"section-number\">38. </span>Mathematical optimization", "<span class=\"section-number\">36. </span>Overview of modeling", "<span class=\"section-number\">35. </span>Overview of scientific modeling material", "<span class=\"section-number\">23. </span>ANNs in the large-width limit", "<span class=\"section-number\">13. </span>Bayesian approach to model discrepancy", "<span class=\"section-number\">27. </span>Emulators", "<span class=\"section-number\">13.4. </span>\ud83d\udce5 Model discrepancy example: The ball-drop experiment", "<span class=\"section-number\">26. </span>Overview of other topics", "<span class=\"section-number\">29. </span>PCA, SVD, and all that", "<span class=\"section-number\">28. </span>Student t distribution as a mixture of Gaussians", "<span class=\"section-number\">29.5. </span>\ud83d\udce5 Linear algebra games including SVD for PCA", "<span class=\"section-number\">30. </span>Quantum Bayesianism (QBism)", "<span class=\"section-number\">23.3. </span>\ud83d\udce5 Distributions of Randomly-Initialized ANNs", "<span class=\"section-number\">33. </span>Statistics concepts and notation", "<span class=\"section-number\">39. </span>Overview of getting started materials", "<span class=\"section-number\">41.7. </span>\ud83d\udce5 Making a simple widget-based UI", "<span class=\"section-number\">41.6. </span>\ud83d\udce5 Demonstration: Reading Data and fitting", "<span class=\"section-number\">40. </span>\ud83d\udce5 Exercise: Jupyter Notebooks and Python", "<span class=\"section-number\">41.4. </span>\ud83d\udce5 Exercise: Python lists and iterations", "<span class=\"section-number\">41.5. </span>\ud83d\udce5 Exercise: Linear algebra operations with NumPy", "<span class=\"section-number\">42.1. </span>Using Anaconda", "<span class=\"section-number\">41. </span>More on Python and using Jupyter notebooks", "<span class=\"section-number\">42. </span>Setting up to use this Jupyter book", "<span class=\"section-number\">42.2. </span>Using GitHub", "<span class=\"section-number\">17. </span>Advanced Markov Chain Monte Carlo", "<span class=\"section-number\">16.4. </span>Assignment: 2D radioactive lighthouse location using MCMC", "<span class=\"section-number\">17.2. </span>Overview: MCMC Diagnostics", "<span class=\"section-number\">15.11. </span>Exercise: Random walk", "<span class=\"section-number\">15.7. </span>Metropolis-Hasting MCMC sampling of a Poisson distribution", "<span class=\"section-number\">17.4. </span>Lecture 12", "<span class=\"section-number\">15.10. </span>Parameter estimation example: Gaussian noise and averages II", "<span class=\"section-number\">18.1. </span>Hamiltonian Monte Carlo (HMC) overview and visualization", "Liouville Theorem Visualization", "Solving orbital equations with different algorithms", "<span class=\"section-number\">18.3. </span>PyMC Introduction", "<span class=\"section-number\">18.4. </span>Comparing samplers for a simple problem", "<span class=\"section-number\">16.2. </span>Markov chain Monte Carlo sampling", "<span class=\"section-number\">16.3. </span>MCMC Intro from BUQEYE", "<span class=\"section-number\">16. </span>Overview of Markov Chain Monte Carlo", "<span class=\"section-number\">16.1. </span>Markov chains", "<span class=\"section-number\">18. </span>HMC and other samplers", "Overview of Intro to PyMC notebook", "<span class=\"section-number\">15.9. </span>Recaps", "<span class=\"section-number\">14. </span>Overview of Part III: Sampling", "<span class=\"section-number\">15. </span>Stochastic processes", "<span class=\"section-number\">15.8. </span>Demonstration: Metropolis-Hasting MCMC sampling of a Poisson distribution", "<span class=\"section-number\">18.2. </span>The Zeus Ensemble Slice Sampler"], "titleterms": {"": [7, 44, 46, 53, 58, 65, 93, 114, 118], "0": [86, 93], "05": 93, "06068": 141, "1": [0, 7, 14, 31, 32, 33, 34, 38, 41, 65, 66, 67, 74, 77, 79, 83, 85, 86, 92, 93, 98, 100, 111, 112, 114, 125, 126, 138, 143], "10": [33, 138], "100": 93, "1000": 93, "11": [125, 138], "12": [128, 136, 138], "13": 138, "14": 138, "15": [138, 143], "16": [135, 138], "17": 135, "1710": 141, "18": 135, "1d": [17, 118], "2": [5, 29, 31, 32, 34, 38, 41, 67, 74, 77, 83, 92, 93, 100, 111, 112, 114, 126, 136, 138, 143], "20": 79, "2025": 119, "21": 65, "22": [66, 67], "2d": [35, 118, 124], "3": [5, 7, 16, 31, 32, 38, 41, 67, 74, 77, 83, 92, 93, 98, 100, 112, 114, 126, 138, 143], "30000": 93, "32": 0, "33": 112, "36": 100, "37": 98, "3d": 75, "4": [5, 7, 16, 31, 32, 38, 41, 65, 67, 71, 77, 83, 92, 93, 100, 112, 114, 138], "5": [5, 7, 16, 31, 32, 65, 66, 77, 93, 112, 114, 126, 138], "50": 33, "6": [7, 16, 31, 66, 112, 114, 138], "60000": 93, "7": [7, 16, 31, 66, 114, 138], "8": [31, 66, 138], "9": [31, 66, 128, 138], "A": [7, 19, 38, 48, 53, 70, 74, 77, 83, 85, 88, 92, 96, 115, 138, 141], "But": [39, 129, 134], "For": 141, "In": [34, 133, 141], "No": [78, 82], "One": [8, 40, 53], "The": [0, 4, 7, 16, 19, 25, 34, 38, 40, 41, 43, 44, 46, 49, 53, 63, 65, 66, 72, 75, 77, 78, 82, 83, 85, 88, 95, 98, 103, 105, 112, 116, 125, 135, 138, 145], "To": [17, 19, 93, 115], "With": 105, "_": 85, "ab": 45, "about": [19, 39, 56, 60, 71, 120, 128, 129, 134], "abov": 141, "acceler": 71, "accept": [125, 133, 141], "accumul": 109, "accuraci": 69, "acknowledg": [56, 73], "activ": [67, 68, 88], "ad": [33, 118], "adagrad": 99, "adam": 99, "adapt": 99, "add": [76, 114], "addendum": 34, "addit": 94, "adjust": 53, "admonit": 0, "advanc": [44, 55, 116, 123], "advantag": 7, "advi": 73, "agre": 141, "ahead": 24, "ai": 63, "aka": [17, 78, 82], "al": [79, 86, 125], "aleator": 72, "algebra": [49, 52, 85, 109, 118], "algorithm": [46, 63, 64, 67, 68, 88, 92, 99, 125, 126, 130, 132, 135, 136, 141], "all": [19, 31, 32, 107, 114, 134], "amplitud": 37, "an": [23, 52, 56, 94, 141, 143], "anaconda": 119, "analogi": 141, "analys": 19, "analysi": [96, 98, 100, 124], "analyt": 13, "analyz": [37, 133], "ani": [114, 141], "ann": [102, 111], "anoth": [5, 17], "answer": [0, 3, 11, 12, 15, 16, 18, 19, 22, 23, 24, 31, 32, 34, 35, 47, 95, 96, 141], "appli": [23, 109, 124, 129, 134], "applic": [51, 79, 107], "approach": [7, 38, 39, 41, 85, 103, 125, 129, 134], "approxim": [7, 35], "ar": [35, 79, 96, 118, 141], "architectur": [67, 75], "argument": 4, "arrai": [116, 117, 118], "art": 135, "artif": 67, "artifici": 67, "arxiv": 141, "asid": [8, 86, 109, 116, 117], "ask": 71, "aspect": 64, "aspir": 61, "assess": [29, 125, 128], "assign": [2, 3, 4, 124], "assum": 141, "assumpt": 48, "atom": 141, "attribut": 63, "autocorrel": [44, 125, 133, 141], "autom": 63, "avail": 133, "averag": [39, 48, 118, 129], "awai": [15, 25], "axiom": 25, "b": [32, 53, 141], "back": [68, 69], "background": [34, 35, 37, 86, 134], "backprop": 72, "backpropag": [68, 71], "bad": 38, "balanc": [126, 138, 141], "ball": [103, 105], "base": [52, 76, 114, 118, 141], "basi": [34, 81, 98], "basic": [53, 71, 72, 80, 88, 95, 109, 133, 136], "batch": [73, 99], "bay": [10, 22, 23, 25, 28, 31, 45, 46, 51, 54, 72, 124], "bayesaian": 11, "bayesian": [0, 7, 8, 9, 16, 17, 19, 22, 26, 27, 30, 31, 32, 34, 36, 38, 39, 41, 43, 48, 51, 53, 55, 59, 61, 72, 73, 74, 92, 93, 95, 103, 110, 129, 134, 135], "bayesopt": 92, "bda3": 125, "befor": 96, "behavior": [33, 52], "belief": [9, 14, 30], "benchmark": 5, "beta": [13, 17], "between": [50, 141], "beyond": 61, "bia": [30, 63, 66], "bias": 63, "bibliographi": [0, 1], "binari": [65, 70, 88], "bind": [34, 98, 115], "bivari": [78, 92, 112], "blr": 34, "bma": 48, "bmm": 48, "boh": 103, "boldsymbol": [29, 85], "bonu": [94, 95], "book": [0, 56, 119, 120, 121], "bound": 72, "boundari": 65, "breakout": 41, "bridg": 73, "brief": [24, 43, 44, 56, 59, 75, 86, 115], "bring": 68, "build": [69, 75, 92], "buqey": 136, "c": [32, 85], "calcul": [35, 49, 51, 53], "call": 141, "callback": 114, "can": [19, 141], "cancel": 141, "carlo": [44, 123, 130, 135, 136, 137], "case": [4, 5, 13, 19, 41, 78, 143], "cauchi": 38, "cell": [0, 116], "central": [19, 33, 85, 112], "certain": 52, "chain": [44, 50, 68, 123, 125, 135, 136, 137, 138], "challeng": [68, 99, 135], "chang": [7, 52, 119], "characterist": [18, 22], "chart": 141, "chatgpt": [71, 111], "cheat": 120, "check": [7, 32, 43, 50, 52, 132, 136], "checklist": [0, 43], "checkpoint": [0, 3, 15, 16, 19, 22, 23, 24, 34, 47], "chi": [29, 53], "choic": 93, "choos": 85, "cifar10": 76, "class": [0, 11, 17, 19, 35, 88, 105, 131, 133], "classif": [64, 65, 70, 74, 88], "classifi": [65, 69, 70, 73, 88, 93], "close": 48, "clt": 19, "cluster": 64, "cnn": [75, 76], "code": [0, 9, 65, 68, 69, 71, 111, 112, 116, 136], "coin": [9, 11, 15, 19, 25, 30], "collect": 141, "color": 0, "colorblind": 112, "combin": [77, 83], "command": 122, "comment": 94, "common": [4, 71, 134], "compa": 63, "compact": 88, "compar": [33, 35, 134], "comparison": [7, 29, 53, 117], "compil": 76, "complex": [66, 71, 73, 93], "compon": 109, "comprehens": 117, "compress": 109, "comput": [13, 51, 71, 77, 83], "concaten": 118, "concept": 112, "conda": 119, "condit": [112, 136, 138, 141, 143], "confid": [18, 19], "conjug": [13, 49], "connect": 19, "consequ": 19, "conserv": [38, 132], "continu": [4, 34, 45, 99, 112], "continuum": 25, "contrast": [19, 48], "control": 114, "converg": [44, 50, 125, 128], "convers": 118, "convert": 34, "convolut": [67, 75, 76], "cookbook": 81, "core": [78, 82], "correct": 38, "correl": [7, 35, 53, 79, 112, 128], "cost": [65, 68, 88], "could": 40, "coupl": 19, "cours": 109, "covari": [77, 78, 82, 83, 85, 109, 112], "cow": 62, "creat": [70, 76, 114, 117, 118, 119], "credibl": [14, 19, 112], "criteria": 51, "crocodil": 62, "cross": [66, 88, 95], "current": 73, "curv": [66, 97], "custom": 71, "d": [33, 141], "data": [16, 34, 37, 38, 40, 41, 49, 52, 63, 64, 65, 69, 73, 74, 76, 77, 83, 93, 96, 109, 115, 118, 119, 124, 125, 134], "dataset": [75, 76, 80, 81], "deal": 38, "debug": 116, "decis": 65, "decomposit": 107, "deep": [67, 73, 88], "default": 71, "defin": [5, 42, 105], "definit": [34, 68, 98, 112, 143], "degre": [9, 14, 30], "delta": [7, 136], "demo": [50, 84, 87], "demolit": 62, "demonstr": [6, 9, 29, 30, 69, 73, 76, 78, 82, 115, 144], "dens": 76, "densiti": [17, 23, 112, 141], "depend": [53, 78, 82, 100], "derbi": 62, "deriv": [4, 68, 141], "descent": [97, 99], "design": [34, 98, 138], "detail": [71, 126, 136, 138, 141], "determin": [30, 43, 79, 88, 118], "develop": [69, 70], "deviat": 118, "diagnost": [44, 125, 133], "diagon": 107, "differ": [0, 5, 53, 81, 96, 132], "dimens": 136, "dimension": [64, 78, 82, 118], "dirac": 7, "discrep": [100, 103, 105], "discret": [3, 99, 112, 135, 138], "discuss": [8, 34, 38, 53, 112, 129, 134, 143], "displai": 114, "dissect": 109, "distanc": 7, "distribut": [4, 16, 17, 33, 34, 37, 43, 50, 71, 78, 82, 85, 86, 108, 111, 112, 127, 128, 135, 138, 141, 144], "diverg": 72, "do": [12, 19, 33, 40, 49, 69, 86, 92, 93, 95, 105, 109, 125, 127, 128, 141], "doe": [35, 52], "dof": 29, "don": [12, 75], "donut": 136, "dot": [81, 118], "download": 76, "dr": 53, "draw": [33, 86, 117], "drawn": 33, "drop": [34, 98, 103, 105], "duke": 109, "e": 141, "each": [19, 33, 53, 71, 114], "edwin": 62, "effect": 5, "eft": [49, 94], "eigendecomposit": 109, "eigenvalu": 118, "eigenvector": [45, 118], "elabor": 114, "eleg": 85, "element": 118, "elementwis": 118, "elicit": 43, "ellips": 35, "emce": [96, 105, 134, 135], "emul": [45, 47, 79, 104], "energi": [34, 52, 98, 115, 132], "ensembl": 145, "entropi": [4, 5, 88], "env": 119, "environ": 119, "epistem": 72, "epistemologi": 8, "equal": 13, "equat": [0, 34, 68, 98, 109, 132], "equilibrium": 141, "errat": 38, "error": [7, 34, 41, 63, 65, 66, 125], "estim": [0, 7, 16, 18, 36, 39, 40, 41, 53, 77, 83, 94, 96, 112, 129, 134, 135], "et": [79, 86, 125], "ethic": [63, 64], "evalu": [69, 76], "event": 112, "everi": 128, "everyth": 17, "evid": [49, 51, 52, 53, 72, 95], "evolut": 108, "exampl": [3, 23, 25, 31, 33, 34, 35, 38, 39, 40, 41, 51, 63, 65, 70, 71, 75, 77, 78, 80, 82, 92, 100, 105, 112, 118, 129, 133, 136, 141, 143], "exchang": 141, "exercis": [0, 7, 11, 16, 19, 31, 32, 34, 40, 65, 66, 67, 70, 74, 77, 79, 83, 98, 100, 107, 109, 112, 116, 117, 118, 126, 133, 135, 138, 143], "exp": 81, "expans": [49, 52], "expect": [24, 67, 112], "experi": [52, 105], "experiment": [43, 105], "explan": 71, "explicit": 114, "explor": [17, 18, 35, 69, 95, 96, 116], "exponenti": [4, 143], "express": [71, 88, 116, 124], "extend": 88, "extern": 0, "f": 136, "factor": 51, "failur": 5, "fair": [25, 63], "falsifi": 19, "fast": 45, "favorit": 96, "featur": [56, 88, 116], "feed": [67, 71, 111], "feedback": 67, "fft": 33, "fig": 125, "figur": [0, 37, 114, 116, 124, 128], "file": 0, "fill": 141, "final": 68, "find": [109, 118], "first": [13, 33, 65, 68, 114, 115, 134], "fit": [40, 41, 95, 115, 125], "fix": [33, 41], "flat": 13, "flip": [9, 15, 19, 138], "flop": 138, "fold": 66, "follow": [15, 18, 31, 37, 70, 77, 128], "foreman": 128, "form": [34, 109], "formal": 43, "formul": [38, 105], "forward": [67, 71, 111], "four": [43, 59], "fourier": 33, "fourth": 33, "framework": 103, "free": 80, "frequentist": [8, 11, 14, 19, 38, 53, 129, 134], "friend": 25, "from": [5, 15, 33, 71, 74, 77, 79, 83, 86, 96, 109, 118, 119, 122, 128, 133, 135, 136, 141], "frontmatt": 0, "full": [41, 75], "function": [5, 7, 13, 17, 23, 34, 40, 43, 63, 65, 68, 70, 71, 77, 78, 81, 82, 83, 85, 88, 98, 112, 114, 116, 131, 136], "further": 118, "g": 141, "galact": 7, "game": [86, 109], "gaussian": [4, 7, 17, 19, 33, 34, 35, 39, 49, 53, 77, 78, 80, 81, 82, 83, 85, 86, 108, 112, 129, 134, 143], "gelman": [44, 125, 133], "gener": [34, 64, 73, 80, 81, 93, 96, 105, 112, 114, 124, 134, 135], "get": [56, 77, 83, 113, 116, 136, 140], "github": [119, 122], "given": [77, 83], "global": 99, "goal": [94, 96, 124], "goe": [45, 46], "good": [38, 120], "gothenburg": 138, "gp": [78, 79, 82, 85, 86], "gpu": 71, "gpy": [77, 83, 84], "gpyopt": 92, "gradient": [71, 97, 99], "graphic": 116, "gregori": 136, "group": [3, 63], "growth": 143, "guid": [0, 56, 120], "guidelin": 63, "h_0": 41, "ha": [73, 93, 125], "hamiltonian": [44, 130], "handl": [41, 64], "happen": 141, "harmon": 19, "hast": [126, 127, 135, 136, 144], "have": 52, "hbar": [78, 82], "height": 105, "help": [7, 56, 116], "helper": [17, 81], "here": 96, "hick": 133, "hidden": 0, "higdon": 79, "high": [82, 136], "higher": [52, 141], "highli": 79, "hint": [19, 32, 34, 67], "histogram": 108, "histori": 46, "hmc": [130, 139], "hogg": 128, "how": [7, 40, 52, 71, 86, 90, 94, 96, 125, 141], "huber": 38, "hybrid": 7, "hydrogen": 141, "hyperparamet": 85, "hypothesi": 53, "i": [3, 7, 13, 17, 19, 25, 33, 39, 60, 79, 94, 138, 141], "icon": 56, "idea": 53, "ii": [4, 7, 13, 41, 55, 129], "iia": 95, "iib": [90, 96], "iii": [7, 142], "iiia": 92, "iiib": 93, "illustr": [44, 81], "imag": [75, 76, 109], "implement": [40, 66, 133, 135], "implicit": 63, "import": [5, 38, 44, 50, 73, 76, 77, 83, 92, 95, 96, 109, 112, 114, 115, 124, 126, 133], "improv": 40, "includ": [63, 109], "independ": [53, 100, 112], "index": [109, 118], "indiffer": 3, "induct": 62, "infer": [0, 7, 20, 41, 43, 48, 54, 61, 62, 72, 73, 74, 85, 93, 100, 135], "inferencedata": 133, "infinit": 78, "info": 86, "inform": [51, 71], "infti": 52, "ingredi": [25, 64], "initi": [71, 111], "initio": 45, "input": [77, 83, 111, 114], "insert": 0, "instal": [71, 119, 122], "integr": [33, 49, 96, 128, 135], "interactive_output": 114, "interfac": [9, 114], "interlud": 128, "interpret": 35, "interv": [9, 14, 18, 19, 30], "intial": 71, "intro": [136, 140], "introduct": [17, 57, 69, 86, 112, 133, 143], "introductori": 80, "intuit": [78, 128, 141], "invari": 3, "invers": [34, 118], "invit": 62, "ipython": 114, "ipywidget": 114, "ir": 44, "issu": 56, "iter": [46, 93, 117], "its": 5, "jayn": 62, "joint": [23, 112], "jupyt": [0, 6, 9, 56, 115, 116, 119, 120, 121, 122], "justifi": 19, "k": [65, 66, 78, 82], "kernel": [78, 81, 82, 85, 119], "knn": [65, 66], "know": [86, 120, 125], "known": 96, "koh": 103, "kraken": 114, "kullback": 72, "l": 68, "l1": 4, "label": 0, "langl": 136, "laplac": 53, "larg": [66, 102], "lasso": 66, "law": 135, "layer": [75, 76], "layout": 114, "learn": [60, 63, 64, 65, 66, 67, 68, 70, 71, 73, 74, 87, 88, 89, 93, 94, 96, 97, 119, 124], "learningfromdata": 122, "least": [34, 98], "lectur": [79, 128], "leibler": 72, "length": 118, "let": [73, 93], "lighthous": [35, 42, 124], "like": 5, "likelihood": [13, 34, 35, 38, 41, 43, 50, 88, 95], "limit": [19, 25, 33, 44, 52, 63, 67, 102, 138], "line": [3, 6, 40, 41, 90, 96, 117, 122, 125], "linear": [34, 46, 49, 52, 65, 67, 85, 98, 100, 109, 118], "liouvil": 131, "liquid": [34, 98], "list": [117, 118], "ll": 37, "local": 99, "locat": [3, 124], "log": [4, 19, 126], "logic": 22, "logist": [70, 74, 88], "look": [5, 24, 73, 93, 140], "lorentzian": 126, "loss": 38, "lower": 72, "m": 48, "machin": [60, 63, 64, 65, 73, 89], "mackei": 128, "macro": 0, "main": [9, 64], "major": 118, "make": [69, 71, 76, 86, 108, 114, 128, 131, 141], "mani": [38, 85, 90, 96], "manipul": [22, 109, 118], "margin": [7, 23, 25, 34, 41, 112, 128], "mark": 0, "markdown": [0, 116], "markov": [44, 123, 135, 136, 137, 138], "mass": [112, 115], "match": [46, 108], "materi": [56, 101, 113], "mathbf": [77, 83], "mathcal": [48, 86], "mathemat": [67, 71, 99, 116], "matplotlib": [17, 116], "matric": [109, 118], "matrix": [34, 67, 85, 98, 107, 109, 118, 138], "matter": 12, "mat\u00e9rn": 81, "maxent": 4, "maxim": 4, "maximum": [4, 5, 41, 88, 95, 118], "mc": 136, "mcmc": [44, 74, 96, 124, 125, 126, 127, 128, 135, 136, 141, 144], "mean": [4, 33, 35, 44, 82, 85, 112, 125], "measur": 112, "mechan": 19, "median": 112, "medic": [22, 31], "meet": 115, "melendez": 86, "memori": 138, "menu": [56, 116], "method": [27, 44, 45, 46, 53, 55, 71, 114, 135], "metropoli": [126, 127, 135, 136, 138, 141, 144], "mh": [50, 125, 136, 141], "mini": [73, 90, 91, 92, 93, 94, 95, 96, 99], "minim": [5, 88, 99, 114], "minimum": 118, "misclassif": 65, "mix": 48, "mixtur": 108, "mnist": 75, "mode": 112, "model": [3, 6, 7, 16, 27, 29, 34, 38, 40, 41, 43, 45, 48, 49, 53, 54, 64, 66, 67, 68, 69, 72, 73, 76, 77, 78, 82, 83, 85, 93, 94, 95, 98, 100, 101, 103, 105, 125, 133, 143], "modul": [38, 77, 83, 92, 95, 115, 126], "moment": [5, 24, 112], "monkei": 4, "mont": [44, 123, 130, 135, 136, 137], "moor": 34, "moral": 61, "more": [25, 36, 52, 66, 88, 100, 114, 120, 136], "move": 141, "movi": 108, "multi": [48, 54], "multilay": 68, "multimod": 50, "multipl": [48, 117, 118], "multivari": [34, 53, 78, 82, 86, 92, 112], "n": [5, 33, 52, 85, 86, 93, 118, 141], "n_a": 141, "n_b": 141, "n_sampl": 93, "naiv": 136, "name": 6, "ndarrai": 118, "nearest": 65, "need": [5, 37], "neighbor": 65, "net": 70, "network": [67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 93], "neural": [67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 93], "neuron": [67, 75], "new": 85, "newcommand": 29, "next": [46, 73], "nn": [66, 75], "nois": [35, 39, 80, 93, 129], "noisi": [67, 80], "non": [85, 100], "norm": 4, "normal": [4, 17, 25, 29, 34, 53, 65, 71, 78, 82, 85, 86, 98], "notat": [64, 67, 85, 88, 100, 112, 143], "note": [0, 29, 49, 136], "notebook": [19, 79, 84, 87, 115, 116, 119, 120, 122, 133, 140], "now": [50, 71, 105, 134, 141], "nuclear": [34, 45, 98, 115], "nuisanc": [7, 38, 41], "number": [7, 112], "numer": [33, 118, 135], "numpi": [116, 117, 118], "object": [85, 133], "observ": [105, 114], "obtain": [85, 138], "occam": 7, "odd": 95, "omega": [78, 82], "one": [33, 71], "onli": [33, 114, 141], "onlin": [56, 120], "open": [48, 56], "oper": [71, 117, 118], "optic": 138, "optim": [88, 92, 97, 99, 100], "option": [92, 114, 126], "orbit": 132, "order": [45, 95, 118], "ordinari": [34, 98], "organ": 115, "origin": [111, 134], "oscil": 19, "other": [106, 139, 141], "our": 115, "out": 141, "outlier": 38, "output": [68, 111, 114], "over": [66, 141], "overfit": 63, "overgener": 63, "overview": [55, 64, 86, 90, 91, 100, 101, 106, 113, 125, 130, 137, 140, 142], "own": [52, 70, 92], "p": [19, 141], "pair": 79, "panda": 115, "paper": 79, "par": 29, "parallel": [51, 96], "paramet": [0, 7, 16, 36, 38, 39, 40, 41, 53, 77, 83, 88, 93, 94, 96, 117, 129, 134], "parametr": [7, 85, 100], "part": [55, 83, 126, 142], "pass": 114, "pca": [107, 109], "pdf": [4, 6, 7, 17, 18, 20, 23, 37, 41, 112, 124, 126, 135], "pendulum": 131, "penros": 34, "penultim": 13, "perceptron": [65, 68, 88], "perform": 96, "permut": 3, "perspect": 58, "philosoph": 8, "physic": [60, 105, 130], "physicist": 58, "pi": 135, "pick": 132, "plausibl": 62, "plot": [5, 17, 42, 78, 82, 105, 108, 116, 117, 125, 132, 133], "plu": [92, 95], "pocomc": 105, "point": [18, 33, 112, 141], "poisson": [4, 33, 37, 127, 136, 141, 144], "polya": 62, "polynomi": [34, 95, 98], "popul": 22, "possibl": [0, 11, 22, 51], "posterior": [13, 16, 17, 26, 34, 35, 42, 43, 50, 81, 105, 125, 141], "potenti": [5, 132], "power": 135, "practic": [22, 28, 34, 72, 98], "predict": [16, 34, 43, 52, 69, 73, 76, 85, 93], "preliminari": [107, 108, 109], "prelud": 34, "prepar": [37, 76], "presenc": 37, "princip": 109, "principl": [4, 22, 63], "prior": [6, 12, 13, 34, 39, 40, 43, 49, 50, 53, 79, 81, 105, 129, 134], "probabilist": [72, 73], "probabl": [2, 3, 4, 8, 17, 22, 23, 25, 31, 32, 73, 88, 93, 112, 126, 141, 143], "problem": [22, 42, 70, 74, 96, 134, 135], "proce": 94, "process": [77, 78, 80, 81, 82, 83, 85, 86, 138, 143], "product": [7, 22, 25, 32, 81, 118], "prof": 53, "program": 73, "project": [17, 90, 91, 92, 93, 94, 95, 96], "prompt": 111, "proof": [13, 19], "propag": [7, 41, 67, 68, 69], "properti": [34, 118, 141], "propos": 141, "prove": 34, "pseudo": [34, 112, 136], "pt": [50, 96], "ptemce": 96, "pukelsheim": 46, "pump": 138, "put": 96, "pymc": [133, 134, 140], "pymc3": [72, 73, 135], "pymultinest": 135, "pystan": 135, "python": [6, 9, 17, 38, 50, 64, 109, 116, 117, 120, 124], "pytorch": 71, "q": 141, "qbism": 110, "quadradt": 81, "quadrat": 35, "quadratur": 135, "qualiti": 61, "quantum": 110, "question": [0, 3, 4, 5, 12, 15, 16, 18, 19, 22, 23, 24, 31, 32, 34, 35, 41, 47, 70, 83, 85, 88, 95, 126, 127, 136], "quick": [17, 112], "quot": 133, "r2": 65, "radial": 81, "radioact": [42, 124], "random": [7, 85, 112, 126, 136, 138, 141, 143], "randomli": 111, "rang": [53, 117], "rangl": 136, "rank": 118, "rate": [125, 133], "rather": 33, "ratio": [95, 141], "ration": 81, "razor": 7, "rbf": [78, 82], "read": 115, "real": 115, "reason": 62, "recal": [13, 136, 141], "recap": [49, 79, 141], "recognit": 76, "reconstruct": 5, "recurr": 67, "reduc": 45, "reduct": [45, 64, 75, 109], "refer": [0, 31, 32, 85, 110], "referenc": 0, "region": [71, 112, 126], "regress": [34, 64, 65, 66, 70, 74, 77, 78, 80, 82, 83, 85, 88, 98, 100], "regular": [66, 75, 88], "relat": 141, "releas": 114, "remark": [0, 8, 66], "remind": 115, "remnant": 138, "remov": 118, "report": 63, "reproduc": 43, "request": 96, "requir": 63, "resampl": 44, "research": 43, "reshap": 118, "result": [5, 35, 43, 49, 133], "return": 79, "revers": 138, "review": [17, 44, 78], "revisit": [7, 125], "rewrit": 34, "rewritten": 88, "ridg": 66, "rightarrow": 52, "rmsprop": 99, "rob": 133, "root": 7, "routin": 118, "row": 118, "rubin": [44, 125, 133], "rule": [10, 19, 22, 25, 31, 32, 46, 67, 68, 124, 136], "run": [77, 119, 124, 128], "sampl": [7, 17, 18, 33, 35, 38, 44, 50, 74, 77, 78, 82, 83, 105, 126, 127, 128, 133, 134, 135, 136, 138, 141, 142, 144], "sampler": [50, 96, 105, 133, 134, 139, 145], "save": 116, "scalar": 118, "scale": [3, 73, 75, 93], "scandinavian": 4, "scienc": [7, 64, 100], "scientif": [27, 101], "scientist": 61, "scikit": [70, 74, 87], "scipi": [17, 112], "score": [65, 66], "second": [33, 114], "sect": 128, "section": [0, 18, 95, 136], "select": [34, 53, 63, 79, 95, 118], "sens": 86, "sensit": 34, "set": [6, 9, 48, 68, 74, 75, 77, 83, 105, 114, 121, 134], "setup": [105, 133], "shape": 118, "sheet": 120, "shell": [78, 82], "shortcut": 116, "should": [96, 120], "sigma": [14, 46], "sigmoid": 65, "signal": [35, 37, 67], "signific": 19, "simpl": [67, 70, 74, 114, 134, 138, 143], "sine": 81, "singl": [33, 41], "singular": 107, "sivia": 35, "size": [33, 118], "slant": 35, "slice": 145, "societi": 64, "soft": 65, "softmax": 88, "solut": [0, 7, 16, 34, 40, 65, 66, 67, 96, 98, 100, 112, 135, 138, 143], "solv": [109, 132], "some": [17, 108], "sort": 118, "sound": [0, 43], "space": 48, "spars": 118, "sparsiti": 102, "special": [19, 60, 118, 143], "specif": [73, 93], "specifi": 71, "spectral": 96, "speed": 117, "split": 118, "spot": 34, "squar": [7, 29, 34, 53, 81, 98], "standard": [7, 17, 22, 31, 38, 88, 118, 125], "start": [56, 77, 83, 113, 140], "stat": [17, 112], "state": [19, 135, 138], "statement": [21, 96, 109], "stationari": [85, 138, 141], "statist": [0, 19, 43, 46, 49, 53, 100, 105, 112, 118, 135], "step": [19, 41, 43, 59, 71, 73], "stochast": [99, 138, 143], "stori": 53, "straight": [3, 6, 40, 41, 125], "strategi": 96, "string": 116, "structur": 136, "student": [17, 108], "studi": 66, "style": 105, "sub": 70, "subtask": [94, 96], "suggest": [71, 94], "sum": [7, 22, 25, 29, 32, 33, 85], "summari": [7, 8, 24, 41, 85, 115, 141], "supervis": 67, "surfac": [73, 93], "svd": [107, 109], "switch": 71, "symmetr": [107, 141], "symmetri": 3, "system": 63, "systemat": [41, 75], "t": [12, 17, 75, 108], "tab": 114, "tabl": 35, "take": [7, 15, 25], "taken": 109, "tale": 48, "talent": 91, "target": [80, 85], "task": [70, 74, 77, 126], "tell": 71, "temper": [51, 96], "tensor": 71, "tensorflow": [69, 76], "term": [68, 141], "terminologi": 67, "test": [29, 44, 53, 92], "test_siz": 93, "text": 29, "than": 33, "theano": 73, "thei": 12, "them": 0, "theorem": [19, 22, 23, 25, 33, 131], "theori": [25, 45, 105], "thermodynam": [96, 141], "theta": 29, "thetavec": 141, "thetavec_i": 141, "thi": [25, 40, 52, 56, 71, 86, 92, 95, 120, 121, 125, 141], "thing": [40, 49, 95, 109, 111, 127], "think": [19, 141], "third": [33, 114], "those": 141, "three": [46, 64], "through": 117, "time": [128, 141], "tip": 0, "togeth": 68, "toi": [49, 94], "top": [35, 76], "topic": 106, "toss": [9, 11, 25, 30], "total": 141, "trace": 118, "tradeoff": 66, "train": [63, 65, 66, 69, 72, 76], "transform": [33, 34, 75], "translat": 3, "trend": 73, "trick": 85, "true": 49, "try": [5, 50, 111, 115], "two": [7, 33, 34, 35, 48, 50, 53, 88, 138], "type": [63, 64, 67, 112, 118], "ubiqu": 19, "ui": [9, 114], "uncertainti": [7, 72, 73, 93], "uncorrel": 4, "underfit": [63, 66], "uniform": [13, 34, 112, 135], "univari": [92, 125], "up": [6, 9, 15, 18, 31, 34, 37, 68, 70, 75, 77, 114, 121, 134], "updat": [9, 10, 30, 119], "uphil": 141, "url": 0, "us": [4, 7, 19, 22, 31, 41, 48, 49, 70, 71, 74, 75, 83, 85, 96, 109, 119, 120, 121, 122, 124, 126, 141], "user": [9, 114], "util": [71, 131], "v": [14, 118], "valid": [65, 66, 95], "valu": [19, 24, 73, 93, 96, 107, 112, 114, 118], "variabl": [7, 29, 33, 35, 71, 85, 112], "varianc": [4, 44, 66, 112, 118], "variat": [50, 72, 73, 74, 93], "vector": 67, "verbatim": 133, "verif": 71, "verifi": [18, 76, 141], "versu": [100, 117, 118], "via": 10, "view": [8, 34], "virtu": 61, "visual": [17, 23, 33, 130, 131, 135, 136], "volum": 75, "walk": [126, 136, 138, 141, 143], "wamb": 43, "want": 114, "warm": 34, "warmup": [34, 98], "warn": 0, "we": [5, 37, 52, 86, 125, 136, 141], "weather": 138, "websit": [71, 86], "weight": [67, 88], "well": [75, 79], "went": 141, "were": 141, "what": [5, 19, 35, 39, 46, 60, 73, 79, 93, 95, 118, 120, 128, 129, 134, 141], "when": [12, 19, 119], "why": [4, 67, 136, 141], "wide": 67, "widget": [114, 116], "width": 102, "winter": 138, "without": 105, "workflow": [34, 43, 59], "would": 141, "x": [7, 77, 83], "x_0": 42, "x_a": 141, "x_b": 141, "y": 7, "yet": 5, "you": [19, 49, 56, 114, 120, 128, 141], "your": [52, 70, 92, 96, 119], "yourself": 115, "z": 7, "z_j": 68, "zero": 118, "zeu": [50, 134, 145]}})