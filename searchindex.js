Search.setIndex({"alltitles": {"": [[0, "exercise:ppd_definition_b"], [16, "exercise:ppd_definition"], [16, "exercise:pdf_normalization"], [16, "exercise:rain"], [16, "exercise:monty_hall"], [16, "exercise:coin_ppd"], [34, "exercise:ols_example_1_b"], [34, "exercise:ols_example_2_b"], [34, "exercise:ols_example_3_b"], [34, "exercise:ols_example_4_b"], [34, "exercise:ols_example_5_b"], [48, "id1"], [101, "exercise:ols_example_1"], [101, "exercise:ols_example_2"], [101, "exercise:ols_example_3"], [102, "exercise:ols_example_4"], [102, "exercise:ols_example_5"], [161, "exercise:StochasticProcess:first-example"], [161, "exercise:conditional-probabilities-stochastic-process"], [161, "exercise:construct-stochastic-process"]], " (A reversible Markov chain)": [[156, "exercise:MarkovChains:reversible-chain"]], " (A reversible Markov process)": [[156, "example:reversible-markov-process"]], " (A simple Markov process)": [[156, "example:simple-markov-process"]], " (An exponential growth model)": [[161, "example:exponential-growth-models"]], " (Bayes\u2019 rule/theorem)": [[25, "property:bayes_rule"]], " (Binary classification)": [[65, "example:MLexamples:binary-classification"]], " (Bivariate pdf)": [[130, "exercise:Statistics:bivariate-pdf"]], " (Checklist for statistically sound Bayesian inference)": [[0, "remark:BayesianWorkflow:buqeye-checklist_b"], [43, "remark:BayesianWorkflow:buqeye-checklist"]], " (Conditional discrete probability mass function)": [[130, "exercise:Statistics:conditional-discrete-pmf"]], " (Conditional distributions)": [[156, "exercise:MarkovChains:conditional-distributions"]], " (Conditional expectation)": [[130, "exercise:Statistics:conditional-expectation"]], " (Conditional probabilities of a stochastic process)": [[161, "example:conditional-stochastic-process"]], " (Conditional probability for continuous variables)": [[130, "exercise:Statistics:conditional-probability-continuous"]], " (Conditional probability)": [[130, "definition:conditional-probability"]], " (Conditional probability-distribution)": [[130, "definition:conditional-probability-distribution"]], " (Correlated errors)": [[7, "exercise:BayesianAdvantage:correlated-errors"]], " (Covariance and correlation)": [[130, "definition:covariance-correlation"]], " (Detailed balance)": [[156, "exercise:detailed-balance"]], " (Eigenvector continuation in ab initio nuclear theory)": [[45, "example-0"]], " (Expectation value)": [[130, "definition:expectation-value"]], " (Expected signal)": [[67, "exercise:NeuralNet:expected-signal"]], " (Flip-flop)": [[156, "exercise:flip-flop"]], " (Gaussian process)": [[161, "definition:gaussian-process"]], " (Gaussian product of errors)": [[7, "exercise:BayesianAdvantages:gaussian-product-of-errors"]], " (Gaussian sum of errors)": [[7, "exercise:BayesianAdvantages:gaussian-sum-of-errors"]], " (Generalized normal equation)": [[34, "exercise:BayesianLinearRegression:GeneralizedNormalEquation"]], " (Global minimization)": [[104, "definition:MathematicalOptimization:global-minimization"]], " (Gothenburg winter weather)": [[156, "exercise:MarkovChains:gothenburg-winter-weather"]], " (Gradient descent optimization)": [[105, "algorithm:MathematicalOptimization:gradient-descent"]], " (Illustration of S/IR)": [[44, "example-3"]], " (Implement k-fold cross validation)": [[66, "exercise:ModelValidation:kfold-cross-validation"]], " (Independence)": [[130, "property:independence"]], " (Independent and dependent)": [[114, "exercise:OverviewModeling:independent-dependent"]], " (Independent events)": [[130, "definition:independent-events"]], " (Inferring galactic distances)": [[7, "example:BayesianAdvantage:inferring-galactic-distances"], [7, "exercise:BayesianAdvantages:inferring-galactic-distances-ex"]], " (Inferring galactic distances\u2014revisited)": [[7, "example:BayesianAdvantage:inferring-galactic-distances-revisited"]], " (Is it reversible?)": [[156, "exercise:is-it-reversible"]], " (Joint probability distribution)": [[130, "definition:joint-probability-distribution"]], " (Large training error)": [[66, "exercise:ModelValidation:large-training-error"]], " (Limiting distribution)": [[156, "definition:limiting-distribution"], [156, "exercise:limiting-distribution"]], " (Linear models)": [[112, "example:OverviewModeling:linear-models"]], " (Linear or non-linear)": [[114, "exercise:OverviewModeling:linear-nonlinear"]], " (Linear or non-linear; more examples)": [[114, "exercise:OverviewModeling:linear-nonlinear-examples"]], " (Linear signals)": [[67, "exercise:NeuralNet:linear-signal"]], " (Liquid-drop model for nuclear binding energies)": [[34, "example:LinearModels:liquid-drop-model_b"], [99, "example:LinearModels:liquid-drop-model"]], " (Local minimization)": [[104, "definition:MathematicalOptimization:local-minimization"]], " (Marginal density functions)": [[130, "property:marginal-density-functions"]], " (Markov chains)": [[156, "definition:markov-chains"]], " (Metropolis sampling of a uniform distribution)": [[153, "exercise:metropolis-sampling-uniform"]], " (Misclassification cost function)": [[65, "exercise:MLexamples:misclassification-cost-function"]], " (Model discrepancy)": [[114, "exercise:OverviewModeling:model-discrepancy"]], " (Monte Carlo estimation of \\pi)": [[153, "example-0"]], " (Non-linear models)": [[112, "example:OverviewModeling:nonlinear-models"]], " (Optical pumping)": [[156, "exercise:optical-pumping"]], " (Ordinary least squares (the normal equation))": [[34, "theorem:BayesianLinearRegression:normal-equation_b"], [100, "theorem:LinearModels:normal-equation"]], " (Polynomial basis functions)": [[34, "example:polynomial-linear-model_b"], [99, "example:polynomial-linear-model"]], " (Power-law distributions)": [[153, "exercise:power-law-distribution-sampling"]], " (Practicing the sum and product rule with population characteristics)": [[22, "exercise:Inferenceandpdfs:sumandproductrule"]], " (Prior and posterior predictive checking)": [[43, "remark:BayesianWorkflow:predictive-checking"]], " (Probability density function)": [[130, "definition:probability-density-function"]], " (Probability mass function)": [[130, "definition:probability-mass-function"]], " (Probability measure)": [[130, "definition:probability-measure"]], " (Product rule)": [[25, "property:product_rule"]], " (Prove the Gaussian likelihood)": [[34, "exercise:BayesianLinearRegression:likelihood_pars_b"]], " (R2 score)": [[65, "exercise:MLexamples:R2-score"]], " (Random and colorblind)": [[130, "exercise:Statistics:colorblind"]], " (Random variable and distribution function)": [[130, "definition:random-variable"]], " (Regression analysis)": [[110, "definition:OverviewModeling:regression-analysis"]], " (Remnant memory)": [[156, "exercise:MarkovChains:memory"]], " (Reversibility)": [[156, "exercise:MarkovChains:reversibility"]], " (Scipy.stats)": [[130, "exercise:Statistics:scipy-stats"]], " (Sigmoid decision boundary)": [[65, "exercise:MLexamples:sigmoid-decision-boundary"]], " (Simple random walk)": [[156, "exercise:MarkovChains:simple-random-walk"], [161, "example:simple-random-walk"]], " (Stationary Gothenburg winter weather)": [[156, "exercise:stationary-gothenburg-winter-weather"]], " (Stationary distribution of \u201cA simple Markov process\u201d)": [[156, "example:stationary-simple-markov-process"]], " (Stationary distribution)": [[156, "definition:stationary-distribution"], [156, "exercise:MarkovChains:stationary-distribution"]], " (Stationary processes)": [[156, "definition:stationary-processes"]], " (Stationary two-state distribution)": [[156, "exercise:stationary-2x2"]], " (Statistical inference)": [[110, "definition:OverviewModeling:statistical-inference"]], " (Stochastic matrix)": [[156, "exercise:MarkovChains:stochastic-matrix"]], " (Study of model bias and variance)": [[66, "exercise:ModelValidation:study-model-bias-variance"]], " (Sum of two Gaussian  PDFs)": [[7, "exercise:BayesianAdvantage:complete-the square"]], " (Sum rule)": [[25, "property:sum_rule"]], " (Taking the square root of a number)": [[7, "example:BayesianAdvantage:taking-square-root"]], " (The Gelman-Rubin diagnostic)": [[44, "algorithm:AdvancedMCMC:gelman-rubin"]], " (The Hamiltonian Monte Carlo method)": [[44, "algorithm:AdvancedMCMC:HMC"]], " (The Metropolis algorithm for a discrete distribution)": [[153, "exercise:MCMC:discrete-metropolis"]], " (The Metropolis design for obtaining a discrete limiting distribution)": [[156, "remark:MCMC:Metropolis-discrete"]], " (The Metropolis-Hastings algorithm)": [[153, "algorithm-1"]], " (The Sampling/Importance Resampling method)": [[44, "algorithm:AdvancedMCMC:SIR"]], " (The WAMBS checklist)": [[43, "remark:BayesianWorkflow:wambs-checklist"]], " (The bias-variance tradeoff)": [[66, "theorem:ModelValidation:bias-variance"]], " (The design matrix for polynomial models)": [[34, "example:design-matrix-polynomial-models_b"], [100, "example:design-matrix-polynomial-models"]], " (The history-matching algorithm)": [[46, "algorithm:BayesLinear:History-Matching"]], " (The square root of a number)": [[7, "exercise:BayesianAdvantages:square-root-of-a-number"]], " (The standard random variable)": [[7, "exercise:BayesianAdvantages:standard-random-variable"]], " (Using Bayesian rules of probability on a standard medical problem)": [[22, "exercise:Inferenceandpdfs:medicalexample"]], " (Validation errors)": [[65, "exercise:MLexamples:validation-errors"]], " (Variance)": [[130, "definition:variance"]], " (Warm-up Bayesian linear regression (data errors))": [[34, "exercise:BayesianLinearRegression:warmup_errors"]], " (Warm-up Bayesian linear regression (prior sensitivity))": [[34, "exercise:BayesianLinearRegression:warmup_priors"]], " (Warm-up Bayesian linear regression)": [[34, "exercise:BayesianLinearRegression:warmup"]], " (Weights and signal propagation of a simple neural network)": [[67, "exercise:NeuralNet:simple-network"]], " (Weights and signal propagation of a wide neural network)": [[67, "exercise:NeuralNet:wide-network"]], " (Z = X + Y)": [[7, "example:BayesianAdvantage:Z=X+Y"]], " (k-fold cross-validation)": [[66, "algorithm:ModelValidation:cross-validation"]], " (k=1 NN training error)": [[66, "exercise:ModelValidation:kNN-training-error"]], " (kNN for regression)": [[65, "exercise:MLexamples:kNN-regression"]], " (kNN model complexity)": [[66, "exercise:ModelValidation:kNN-model-complexity"]], " (\u201cIn practice\u201d Bayesian linear regression)": [[34, "exercise:BayesianLinearRegression:in_practice"]], "(Pseudo) random number generator": [[130, "pseudo-random-number-generator"]], "*Aside: Bayesian epistemology": [[8, null]], "*Convolutional Neural Networks": [[75, null]], "*Marking a section in a different color": [[0, "marking-a-section-in-a-different-color"]], "*Neural networks: Backpropagation": [[68, null]], "1 Getting started: The Covariance Function": [[77, "getting-started-the-covariance-function"]], "1. A univariate example with GPyOpt": [[92, "a-univariate-example-with-gpyopt"]], "1. Import ipywidgets and Ipython.display": [[132, "import-ipywidgets-and-ipython-display"], [132, "id1"], [132, "id7"]], "1. n_samples = 1000, noise = 0.2, test_size = 0.5, iterations n = 30000": [[93, "n-samples-1000-noise-0-2-test-size-0-5-iterations-n-30000"]], "1D vs 2D Array": [[136, "d-vs-2d-array"]], "2 Sampling from a Gaussian Process": [[77, "sampling-from-a-gaussian-process"]], "2. Build your own BayesOpt algorithm (optional or for your project)": [[92, "build-your-own-bayesopt-algorithm-optional-or-for-your-project"]], "2. Create a function with all inputs that makes the output figure(s).": [[132, "create-a-function-with-all-inputs-that-makes-the-output-figure-s"], [132, "id8"]], "2. Create a function with all inputs to generate the output figure(s).": [[132, "create-a-function-with-all-inputs-to-generate-the-output-figure-s"]], "2. n_samples = 1000, noise = 0.2, test_size = 0.5, iterations n = 60000": [[93, "n-samples-1000-noise-0-2-test-size-0-5-iterations-n-60000"]], "3 A Gaussian Process Regression Model": [[77, "a-gaussian-process-regression-model"]], "3. Make a widget for each value you want to control.": [[132, "make-a-widget-for-each-value-you-want-to-control"], [132, "id2"], [132, "id9"]], "3. Test on bivariate example (Do this for a plus)": [[92, "test-on-bivariate-example-do-this-for-a-plus"]], "3. n_samples = 1000, noise = 0.05, test_size = 0.5, iterations n = 60000": [[93, "n-samples-1000-noise-0-05-test-size-0-5-iterations-n-60000"]], "3D volumes of neurons": [[75, "d-volumes-of-neurons"]], "4 A Running Example": [[77, "a-running-example"]], "4.  Make any explicit callback functions and add .observe methods.": [[132, "make-any-explicit-callback-functions-and-add-observe-methods"], [132, "id3"], [132, "id10"]], "4. Multivariate test examples (optional)": [[92, "multivariate-test-examples-optional"]], "4. n_samples = 1000, noise = 0.5, test_size = 0.5, iterations n = 60000": [[93, "n-samples-1000-noise-0-5-test-size-0-5-iterations-n-60000"]], "5. Set up the interactive_output function.": [[132, "set-up-the-interactive-output-function"], [132, "id4"], [132, "id11"]], "5. n_samples = 100, noise = 0.2, test_size = 0.5, iterations n = 60000": [[93, "n-samples-100-noise-0-2-test-size-0-5-iterations-n-60000"]], "6. Make the layout of the widgets.": [[132, "make-the-layout-of-the-widgets"], [132, "id5"], [132, "id12"]], "7. Release the Kraken!": [[132, "release-the-kraken"], [132, "id6"], [132, "id13"]], "<a name=\"Python\">Python/Jupyter set up</a>": [[6, "python-jupyter-set-up"]], "A Gaussian Process Regression Model": [[83, "a-gaussian-process-regression-model"]], "A binary classifier with two parameters": [[88, "a-binary-classifier-with-two-parameters"]], "A first summary": [[133, "a-first-summary"]], "A learning algorithm": [[88, "a-learning-algorithm"]], "A more compact expression": [[88, "a-more-compact-expression"]], "A new target prediction using a GP": [[85, null]], "A simple classification problem": [[70, "a-simple-classification-problem"], [74, "a-simple-classification-problem"]], "A spectral line problem": [[96, "a-spectral-line-problem"]], "A tale of two models: contrasting BMA with BMM}": [[48, "a-tale-of-two-models-contrasting-bma-with-bmm"]], "ANNs in the large-width limit": [[117, null]], "About this Jupyter Book": [[56, null]], "Acceptance Rate for the MH Algorithm": [[143, "acceptance-rate-for-the-mh-algorithm"]], "Acceptance rate": [[151, "acceptance-rate"]], "Acknowledgements": [[73, "acknowledgements"]], "Acknowledgments": [[56, "acknowledgments"]], "Activation outputs": [[68, null]], "Activation rule": [[67, null]], "Activation rules": [[67, "activation-rules"]], "Adagrad": [[107, "adagrad"]], "Adam": [[107, "adam"]], "Adaptive gradient descent algorithms": [[107, null]], "Add Dense layers on top": [[76, "add-dense-layers-on-top"]], "Addendum: Ordinary linear regression in practice": [[34, "addendum-ordinary-linear-regression-in-practice"]], "Adding n variables drawn from a distribution": [[33, "adding-n-variables-drawn-from-a-distribution"]], "Adding/removing elements": [[136, "adding-removing-elements"]], "Admonitions": [[0, "admonitions"]], "Advanced Markov Chain Monte Carlo": [[141, null]], "Advanced Markov chain Monte Carlo sampling": [[44, null]], "Advanced feature: Widgets for graphical exploration": [[134, "advanced-feature-widgets-for-graphical-exploration"]], "Advantages of the Bayesian approach": [[7, null]], "Aleatoric uncertainties": [[72, null]], "Algorithm pseudo-code:": [[154, null]], "Anaconda and github": [[137, "anaconda-and-github"]], "Anaconda environments": [[137, "anaconda-environments"]], "Analysis": [[142, "analysis"]], "Analyze sampling results": [[151, "analyze-sampling-results"]], "Another standard class of pdf:  Student t": [[17, "another-standard-class-of-pdf-student-t"]], "Answer": [[0, null], [3, null], [11, null], [12, null], [12, null], [12, null], [15, null], [16, null], [18, null], [18, null], [18, null], [18, null], [18, null], [19, null], [19, null], [23, null], [23, null], [23, null], [24, null], [24, null], [31, null], [31, null], [31, null], [31, null], [31, null], [31, null], [31, null], [31, null], [31, null], [31, null], [31, null], [32, null], [32, null], [32, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [35, null], [35, null], [47, null], [47, null]], "Answer (a)": [[32, null], [32, null]], "Answer (b)": [[32, null], [32, null]], "Answer (c)": [[32, null]], "Answer all the questions": [[31, "answer-all-the-questions"], [32, "answer-all-the-questions"]], "Answer these questions": [[95, "answer-these-questions"]], "Answers": [[35, null], [100, null]], "Application 1: GP emulator from Higdon et al. paper": [[79, "application-1-gp-emulator-from-higdon-et-al-paper"]], "Application of Information Criteria and Bayes factors": [[51, "application-of-information-criteria-and-bayes-factors"]], "Applications of SVD": [[125, "applications-of-svd"]], "Applying the Bayesian approach": [[147, "applying-the-bayesian-approach"], [152, "applying-the-bayesian-approach"]], "Architecture": [[67, null]], "Array Manipulation Routines": [[136, "array-manipulation-routines"]], "Array shape manipulations": [[136, "array-shape-manipulations"]], "Array to/from List conversion": [[136, "array-to-from-list-conversion"]], "Arrays vs Lists": [[136, "arrays-vs-lists"]], "Artifical neural networks": [[67, null]], "Artificial neurons": [[67, "artificial-neurons"]], "Aside: List comprehensions": [[135, "aside-list-comprehensions"]], "Aside: dissection of the Python statement to find the index for accumulation": [[127, "aside-dissection-of-the-python-statement-to-find-the-index-for-accumulation"]], "Aside: how do we make draws from a multivariate     Gaussian (normal) distribution if we know how to make draws from     \\mathcal{N}(0,1)?": [[86, null]], "Aspirational virtues for Bayesian inference and beyond": [[61, null]], "Assigning probabilities": [[2, null]], "Assigning probabilities (I): Indifferences and translation groups": [[3, null]], "Assigning probabilities (II): The principle of maximum entropy": [[4, null]], "Assignment: 2D radioactive lighthouse location using MCMC": [[142, null]], "Autocorrelation": [[44, "autocorrelation"], [159, "autocorrelation"]], "Autocorrelation Plots": [[143, "autocorrelation-plots"]], "Autocorrelation plots": [[151, "autocorrelation-plots"]], "Automation bias": [[63, null]], "Available samplers": [[151, "available-samplers"]], "Average, Variance, and Standard Deviation": [[136, "average-variance-and-standard-deviation"]], "Axioms of probability theory": [[25, "axioms-of-probability-theory"]], "BDA3: Gelman et al, Fig. 11.1": [[143, "bda3-gelman-et-al-fig-11-1"]], "Background info on GPs": [[86, "background-info-on-gps"]], "Background on linear models": [[34, "background-on-linear-models"]], "Basic Mathematical Operations": [[71, "basic-mathematical-operations"]], "Basic idea": [[53, "basic-idea"]], "Basic neural network": [[72, "basic-neural-network"]], "Basic setup of a model": [[151, "basic-setup-of-a-model"]], "Basic structure of MCMC algorithm": [[154, "basic-structure-of-mcmc-algorithm"]], "Basics and notation": [[88, "basics-and-notation"]], "Batch, stochastic and mini-batch gradient descent": [[106, null]], "Bayes by Backprop": [[72, "bayes-by-backprop"]], "Bayes goes fast: Emulators": [[45, null]], "Bayes goes linear: History matching": [[46, null]], "Bayes in practice": [[28, null]], "Bayes linear methods": [[46, "bayes-linear-methods"]], "Bayes linear statistics": [[46, null]], "Bayesian Approach to Outliers #1: A conservative formulation": [[38, "bayesian-approach-to-outliers-1-a-conservative-formulation"]], "Bayesian Approach to Outliers #2: Good-and-bad data": [[38, "bayesian-approach-to-outliers-2-good-and-bad-data"]], "Bayesian Approach to Outliers #3: The Cauchy formulation": [[38, "bayesian-approach-to-outliers-3-the-cauchy-formulation"]], "Bayesian Approach to Outliers #4: Many nuisance parameters": [[38, "bayesian-approach-to-outliers-4-many-nuisance-parameters"]], "Bayesian Linear Regression (BLR)": [[34, null]], "Bayesian Neural Networks in PyMC3": [[73, "bayesian-neural-networks-in-pymc3"]], "Bayesian approach to Gaussian parameter estimation": [[39, "bayesian-approach-to-gaussian-parameter-estimation"], [147, "bayesian-approach-to-gaussian-parameter-estimation"], [152, "bayesian-approach-to-gaussian-parameter-estimation"]], "Bayesian approach to model discrepancy": [[118, null]], "Bayesian approaches to erratic data": [[38, "bayesian-approaches-to-erratic-data"]], "Bayesian credible intervals and frequentist confidence intervals": [[19, "bayesian-credible-intervals-and-frequentist-confidence-intervals"]], "Bayesian evidence": [[95, "id1"]], "Bayesian evidence:": [[95, "bayesian-evidence"]], "Bayesian handling of nuisance parameters": [[41, "bayesian-handling-of-nuisance-parameters"]], "Bayesian inference for multiple models": [[48, "bayesian-inference-for-multiple-models"]], "Bayesian inference in the multi-model setting": [[48, "bayesian-inference-in-the-multi-model-setting"]], "Bayesian linear regression: warmup": [[34, "bayesian-linear-regression-warmup"]], "Bayesian methods for scientific modeling": [[27, null]], "Bayesian model averaging and the \\mathcal{M}-closed assumption": [[48, "bayesian-model-averaging-and-the-mathcal-m-closed-assumption"]], "Bayesian model selection": [[53, "bayesian-model-selection"]], "Bayesian neural networks": [[72, null]], "Bayesian neural networks in PyMC3": [[72, "bayesian-neural-networks-in-pymc3"]], "Bayesian neural networks in practice": [[72, "bayesian-neural-networks-in-practice"]], "Bayesian parameter estimation": [[16, "bayesian-parameter-estimation"]], "Bayesian posteriors": [[26, null]], "Bayesian probability": [[8, "bayesian-probability"]], "Bayesian research workflow": [[43, null]], "Bayesian updating": [[9, "bayesian-updating"], [30, "bayesian-updating"]], "Bayesian workflow": [[59, null]], "Bayes\u2019 theorem": [[22, "bayes-theorem"], [25, "bayes-theorem"]], "Bayes\u2019 theorem applied to PDFs": [[23, "bayes-theorem-applied-to-pdfs"]], "Behavior of the mean of a fixed-size sample": [[33, "behavior-of-the-mean-of-a-fixed-size-sample"]], "Benchmark case: questions": [[5, "benchmark-case-questions"]], "Bibliography": [[1, null]], "Bibliography references": [[0, "bibliography-references"]], "Binary classification": [[88, "binary-classification"]], "Bonus:  Do this section for a plus": [[95, "bonus-do-this-section-for-a-plus"]], "Bonus: additional subtasks": [[94, "bonus-additional-subtasks"]], "Breakout questions": [[41, "breakout-questions"]], "Bridging Deep Learning and Probabilistic Programming": [[73, "bridging-deep-learning-and-probabilistic-programming"]], "Brief guide to online Jupyter Book features": [[56, "brief-guide-to-online-jupyter-book-features"]], "Brief introduction to GPs from Melendez et al.": [[86, "brief-introduction-to-gps-from-melendez-et-al"]], "Brief review of the method": [[44, "brief-review-of-the-method"]], "Brief summary of expectation values and moments": [[24, null]], "Bringing it together, first back propagation equation": [[68, "bringing-it-together-first-back-propagation-equation"]], "Build the network": [[69, "build-the-network"]], "But what about the prior?": [[39, "but-what-about-the-prior"], [147, "but-what-about-the-prior"], [152, "but-what-about-the-prior"]], "CNNs in brief": [[75, "cnns-in-brief"]], "Calculating the evidence": [[51, "calculating-the-evidence"]], "Case 1: Fixed H_0": [[41, "case-1-fixed-h-0"]], "Case 2: Using the inferred pdf for H_0": [[41, "case-2-using-the-inferred-pdf-for-h-0"]], "Case I: uniform (flat) prior": [[13, "case-i-uniform-flat-prior"]], "Case II: conjugate prior": [[13, "case-ii-conjugate-prior"]], "Central moments: Variance and Covariance": [[130, "central-moments-variance-and-covariance"]], "Challenges for gradient descent": [[105, null]], "Challenges in MCMC sampling": [[153, "challenges-in-mcmc-sampling"]], "Changing to the 2025-book-env env kernel when running a Jupyter notebook": [[137, "changing-to-the-2025-book-env-env-kernel-when-running-a-jupyter-notebook"]], "Characteristics of PDFs": [[18, null]], "ChatGPT prompts for original code": [[129, "chatgpt-prompts-for-original-code"]], "Check for between chain variations": [[50, "check-for-between-chain-variations"]], "Check that with the delta functions we get the rule for \\langle f\\rangle.": [[154, null]], "Check the N\\rightarrow \\infty limit": [[52, null]], "Checklists": [[43, "checklists"]], "Checkpoint Question": [[19, null]], "Checkpoint question": [[0, null], [0, null], [3, null], [15, null], [16, null], [19, null], [22, null], [23, null], [23, null], [23, null], [24, null], [24, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [47, null], [47, null], [100, null]], "Checkpoint questions": [[0, "checkpoint-questions"]], "Choosing the GP model hyperparameters": [[85, "choosing-the-gp-model-hyperparameters"]], "Class exercises": [[11, null]], "Class probabilities: The Softmax function": [[88, "class-probabilities-the-softmax-function"]], "Class: state the rule used to justify each step": [[19, null]], "Classification algorithms": [[64, null]], "Clustering algorithms": [[64, null]], "Code": [[129, "code"]], "Code and Markdown cells": [[134, "code-and-markdown-cells"]], "Code example": [[130, "code-example"]], "Code examples: binary classifiers": [[65, "code-examples-binary-classifiers"]], "Coin tossing: Frequentists and Bayesaians": [[11, null]], "Combining Covariance Functions": [[77, "combining-covariance-functions"], [83, "combining-covariance-functions"]], "Combining Covariance Functions in GPy": [[77, "combining-covariance-functions-in-gpy"], [83, "combining-covariance-functions-in-gpy"]], "Comments and suggestions": [[94, "comments-and-suggestions"]], "Common Initialization Methods": [[71, "common-initialization-methods"]], "Common set up and generating data for all samplers": [[152, "common-set-up-and-generating-data-for-all-samplers"]], "Compare Gaussian noise sampling to lighthouse calculation": [[35, "compare-gaussian-noise-sampling-to-lighthouse-calculation"]], "Compare a sum of D Poisson draws with mean 1 to a single Poisson distribution with mean D": [[33, "compare-a-sum-of-d-poisson-draws-with-mean-1-to-a-single-poisson-distribution-with-mean-d"]], "Comparing samplers for a simple problem": [[152, null]], "Comparison with parameter estimation": [[53, "comparison-with-parameter-estimation"]], "Compile and train the model": [[76, "compile-and-train-the-model"]], "Complex Expressions": [[71, "complex-expressions"]], "Computational possibilities for evidence": [[51, "computational-possibilities-for-evidence"]], "Computing the Bayesian evidence": [[51, null]], "Computing the Covariance Function given the Input Data, \\mathbf{X}": [[77, "computing-the-covariance-function-given-the-input-data-mathbf-x"], [83, "computing-the-covariance-function-given-the-input-data-mathbf-x"]], "Computing the posterior analytically": [[13, null]], "Concatenate arrays": [[136, "concatenate-arrays"]], "Confidence intervals": [[18, null]], "Consequences:": [[19, "consequences"]], "Continuing \u2026": [[34, "continuing"]], "Continuous case": [[4, "continuous-case"]], "Contrast Bayesian and significance analyses for coin flipping": [[19, "contrast-bayesian-and-significance-analyses-for-coin-flipping"]], "Convergence tests for MCMC sampling": [[44, "convergence-tests-for-mcmc-sampling"]], "Converting linear models to matrix form": [[34, "converting-linear-models-to-matrix-form"]], "Convolutional Neural Network": [[67, "convolutional-neural-network"]], "Convolutional Neural Network (CNN)": [[76, "convolutional-neural-network-cnn"]], "Correlated posteriors": [[35, "correlated-posteriors"]], "Correlations": [[53, "correlations"]], "Covariance Function Parameter Estimation": [[77, "covariance-function-parameter-estimation"], [83, "covariance-function-parameter-estimation"]], "Covariance Functions in GPy": [[77, "covariance-functions-in-gpy"], [83, "covariance-functions-in-gpy"]], "Covariance functions, aka kernels": [[78, "covariance-functions-aka-kernels"], [82, "covariance-functions-aka-kernels"]], "Covariance, PCA and SVD": [[127, "covariance-pca-and-svd"]], "Create Arrays": [[136, "create-arrays"]], "Create special ndarray": [[136, "create-special-ndarray"]], "Create the convolutional base": [[76, "create-the-convolutional-base"]], "Creating a Sparse Matrix": [[136, "creating-a-sparse-matrix"]], "Creating a conda environment": [[137, "creating-a-conda-environment"]], "Creating a list, range, numpy array": [[135, "creating-a-list-range-numpy-array"]], "Credible regions": [[130, "credible-regions"]], "Cross validation": [[95, "cross-validation"]], "Cross-validation": [[66, "cross-validation"]], "Current trends in Machine Learning": [[73, "current-trends-in-machine-learning"]], "Customizing Initialization in PyTorch": [[71, "customizing-initialization-in-pytorch"]], "Data bias and fairness in machine learning": [[63, null]], "Data bias types in machine learning, including examples": [[63, "data-bias-types-in-machine-learning-including-examples"]], "Data handling, machine learning  and ethical aspects": [[64, "data-handling-machine-learning-and-ethical-aspects"]], "Data normalization": [[65, null], [65, "data-normalization"]], "Data reduction": [[127, "data-reduction"]], "Data sets from scikit-learn": [[74, "data-sets-from-scikit-learn"]], "Data, models, and predictions": [[16, null]], "Dataset and Gaussian process generation": [[81, "dataset-and-gaussian-process-generation"]], "Dataset generation": [[80, "dataset-generation"]], "Debugging aside \u2026": [[134, "debugging-aside"], [134, "id1"]], "Deep Learning": [[73, "deep-learning"]], "Define and plot the posterior for x_0": [[42, "define-and-plot-the-posterior-for-x-0"]], "Define model discrepancy class": [[123, "define-model-discrepancy-class"]], "Define physics model": [[123, "define-physics-model"]], "Define priors": [[123, "define-priors"]], "Define the functions we will need": [[5, "define-the-functions-we-will-need"]], "Definition and examples": [[34, "definition-and-examples"]], "Definition of a stochastic process": [[161, "definition-of-a-stochastic-process"]], "Definition of linear models": [[99, null]], "Definitions": [[68, "definitions"]], "Degree of belief intervals": [[9, "degree-of-belief-intervals"], [30, "degree-of-belief-intervals"]], "Degree of belief/credibility intervals vs frequentist 1-sigma intervals": [[14, null]], "Demo: Multimodal distributions with two samplers": [[50, null]], "Demolition derbies, cows, and crocodiles": [[62, "demolition-derbies-cows-and-crocodiles"]], "Demonstration: Gaussian processes": [[82, null]], "Demonstration: Image recognition with Convolutional Neural Networks": [[76, null]], "Demonstration: Metropolis-Hasting MCMC sampling of a Poisson distribution": [[162, null]], "Demonstration: Neural network classifier": [[69, null]], "Demonstration: Variational Inference and Bayesian Neural Networks": [[73, null]], "Derivation of common pdfs using MaxEnt": [[4, "derivation-of-common-pdfs-using-maxent"]], "Derivative of the cost function": [[68, "derivative-of-the-cost-function"]], "Derivatives and the chain rule": [[68, "derivatives-and-the-chain-rule"]], "Derivatives in terms of z_j^L": [[68, "derivatives-in-terms-of-z-j-l"]], "Deriving the back propagation code for a multilayer perceptron model": [[68, "deriving-the-back-propagation-code-for-a-multilayer-perceptron-model"]], "Detailed Explanation of Each Step:": [[71, "detailed-explanation-of-each-step"]], "Determinant": [[136, "determinant"]], "Determination of weights": [[88, "determination-of-weights"]], "Determining the bias of a coin": [[30, "determining-the-bias-of-a-coin"]], "Determining the likelihood function": [[43, "determining-the-likelihood-function"]], "Developing a code for doing neural networks with back propagation": [[69, "developing-a-code-for-doing-neural-networks-with-back-propagation"]], "Diagnostics": [[151, "diagnostics"]], "Diagonalization of symmetric matrix": [[125, "diagonalization-of-symmetric-matrix"]], "Dimensionality reduction algorithms": [[64, null]], "Dirac delta functions": [[7, null]], "Discrete or continuous optimization": [[104, null]], "Discrete permutation invariance": [[3, "discrete-permutation-invariance"]], "Discuss": [[8, null], [34, null], [53, null], [130, null], [130, null], [130, null], [161, null]], "Discussion": [[38, "discussion"], [147, "discussion"], [152, "discussion"]], "Doing Fourier transforms by numerical integration (rather than FFT)": [[33, "doing-fourier-transforms-by-numerical-integration-rather-than-fft"]], "Dot product versus elementwise multiplication": [[136, "dot-product-versus-elementwise-multiplication"]], "Dot-product kernel": [[81, "dot-product-kernel"]], "Download and prepare the CIFAR10 dataset": [[76, "download-and-prepare-the-cifar10-dataset"]], "Edwin Jaynes and plausible reasoning": [[62, null]], "Eigendecomposition of the covariance matrix": [[127, "eigendecomposition-of-the-covariance-matrix"]], "Eigenvalues and eigenvectors": [[136, "eigenvalues-and-eigenvectors"]], "Eigenvector continuation": [[45, "eigenvector-continuation"]], "Elegant linear algebra tricks to obtain \\boldsymbol{C}_{N+1}^{-1}": [[85, "elegant-linear-algebra-tricks-to-obtain-boldsymbol-c-n-1-1"]], "Emulators": [[47, null], [122, null]], "Epistemic uncertainties": [[72, null]], "Equation references": [[0, "equation-references"]], "Error propagation (I): Nuisance parameters and marginalization": [[7, "error-propagation-i-nuisance-parameters-and-marginalization"]], "Error propagation (II): Changing variables": [[7, "error-propagation-ii-changing-variables"]], "Error propagation (III): A useful approximation": [[7, "error-propagation-iii-a-useful-approximation"]], "Ethical principles": [[63, null]], "Ethics guidelines": [[63, "ethics-guidelines"]], "Evaluate the model": [[76, "evaluate-the-model"]], "Evidence Lower Bound": [[72, "evidence-lower-bound"]], "Evidence calculation": [[49, "evidence-calculation"]], "Evidence calculation for EFT expansions": [[49, null]], "Evidence calculations": [[53, "evidence-calculations"]], "Evidence for an expansion": [[52, null]], "Evidence using conjugate prior": [[49, "evidence-using-conjugate-prior"]], "Evidence using linear algebra and Gaussian integrals": [[49, "evidence-using-linear-algebra-and-gaussian-integrals"]], "Evidence with linear algebra": [[52, "evidence-with-linear-algebra"]], "Example of a Complex Expression": [[71, "example-of-a-complex-expression"]], "Example of parallel tempering": [[51, "example-of-parallel-tempering"]], "Example with noise-free target": [[80, "example-with-noise-free-target"]], "Example with noisy targets": [[80, "example-with-noisy-targets"]], "Example: CNN architecture": [[75, "example-cnn-architecture"]], "Example: GP models for regression": [[78, "example-gp-models-for-regression"], [82, "example-gp-models-for-regression"]], "Example: Is this a fair coin?": [[25, "example-is-this-a-fair-coin"]], "Example: Random walk": [[161, "example-random-walk"]], "Example: Straight-line model": [[3, "example-straight-line-model"]], "Example: The Compas algorithm": [[63, "example-the-compas-algorithm"]], "Example: The MNIST dataset": [[75, "example-the-mnist-dataset"]], "Example: good data / bad data": [[38, "example-good-data-bad-data"]], "Examples": [[154, null]], "Examples from Rob Hicks": [[151, "examples-from-rob-hicks"]], "Examples of classifier functions used in logistic regression and neural networks": [[70, "examples-of-classifier-functions-used-in-logistic-regression-and-neural-networks"]], "Examples of information criteria": [[51, "examples-of-information-criteria"]], "Exercise": [[19, null], [19, null], [70, "exercise"]], "Exercise 1": [[77, "exercise-1"], [83, "exercise-1"]], "Exercise 2": [[77, "exercise-2"], [83, "exercise-2"]], "Exercise 3": [[77, "exercise-3"], [83, "exercise-3"]], "Exercise 4": [[77, "exercise-4"], [83, "exercise-4"]], "Exercise 5": [[77, "exercise-5"]], "Exercise: Bayesian neural networks": [[74, null]], "Exercise: Checking the sum and product rules": [[32, null]], "Exercise: Create a neural net binary classifier": [[70, "exercise-create-a-neural-net-binary-classifier"]], "Exercise: Develop your own logistic regression binary classifier": [[70, "exercise-develop-your-own-logistic-regression-binary-classifier"]], "Exercise: Gaussian Process models with GPy": [[77, null]], "Exercise: Gaussian processes using GPy": [[83, null]], "Exercise: Logistic Regression and neural networks": [[70, null]], "Exercise: Random walk": [[144, null]], "Exercise: Standard medical example using Bayes": [[31, null]], "Exercises": [[16, "exercises"], [40, "exercises"], [65, "exercises"], [66, "exercises"], [67, "exercises"], [114, null], [130, "exercises"], [153, "exercises"], [156, "exercises"]], "Exercises and solutions": [[0, "exercises-and-solutions"]], "Exercises: covariance matrix manipulations in Python (taken from the Duke course)": [[127, "exercises-covariance-matrix-manipulations-in-python-taken-from-the-duke-course"]], "Exp-Sine-Squared kernel": [[81, "exp-sine-squared-kernel"]], "Expectation values and moments": [[130, "expectation-values-and-moments"]], "Experimentation (of the statistical model)": [[43, "experimentation-of-the-statistical-model"]], "Explorations:  Things to do and Questions to answer": [[95, "explorations-things-to-do-and-questions-to-answer"]], "Explore the data": [[69, "explore-the-data"]], "Explore!": [[35, null]], "Expressions": [[142, "expressions"]], "Extending to more classes": [[88, "extending-to-more-classes"]], "Extending to more features": [[88, "extending-to-more-features"]], "External URL references": [[0, "external-url-references"]], "Fairness and error functions": [[63, "fairness-and-error-functions"]], "Feed-forward neural network for a function in PyTorch": [[71, null]], "Feed-forward neural networks": [[67, "feed-forward-neural-networks"]], "Feedback networks": [[67, "feedback-networks"]], "Figures to analyze!": [[37, "figures-to-analyze"]], "Figures to make every time you run MCMC (following Hogg and Foreman-Mackey sect. 9)": [[146, "figures-to-make-every-time-you-run-mcmc-following-hogg-and-foreman-mackey-sect-9"]], "Fill in the chart based on the Metropolis algorithm we are using and verify that the ratio of p(X_B|X_A) to p(X_A|X_B) agrees with the answer derived above.": [[159, null]], "Final back-propagating equation": [[68, "final-back-propagating-equation"]], "Final outputs": [[68, null]], "Find the Maximum and Minimum Values": [[136, "find-the-maximum-and-minimum-values"]], "First example: each sample is only one point": [[33, "first-example-each-sample-is-only-one-point"]], "First pass: only minimal controls": [[132, "first-pass-only-minimal-controls"]], "First sample with emcee": [[152, "first-sample-with-emcee"]], "First the likelihood": [[13, "first-the-likelihood"]], "Fitting a straight line - revisited": [[143, "fitting-a-straight-line-revisited"]], "Follow-up question on 2.": [[31, null]], "Follow-up question on 5.": [[31, null]], "Follow-up questions and answers to the Exploring PDFs section.": [[18, null]], "Follow-up questions to the medical example": [[31, "follow-up-questions-to-the-medical-example"]], "Follow-up task": [[77, "follow-up-task"]], "Follow-ups": [[37, "follow-ups"]], "Formalizing prior distributions": [[43, "formalizing-prior-distributions"]], "Four-step Bayesian workflow in brief": [[43, null], [59, null]], "Fourth example: each sample is 50 points": [[33, "fourth-example-each-sample-is-50-points"]], "Framework": [[120, null]], "Frequentist Correction for Outliers: Huber Loss": [[38, "frequentist-correction-for-outliers-huber-loss"]], "Frequentist approach to Gaussian parameter estimation": [[147, "frequentist-approach-to-gaussian-parameter-estimation"], [152, "frequentist-approach-to-gaussian-parameter-estimation"]], "Frequentist hypothesis testing": [[53, "frequentist-hypothesis-testing"]], "Frequentist probability": [[8, "frequentist-probability"]], "Frontmatter for markdown files": [[0, "frontmatter-for-markdown-files"]], "Functions": [[134, "functions"]], "Further examples with numpy": [[136, null]], "GP models for regression": [[85, "gp-models-for-regression"]], "GPy demo notebooks": [[84, null]], "Games with Gaussian process websites": [[86, "games-with-gaussian-process-websites"]], "Gaussian Processes regression: basic introductory example": [[80, null]], "Gaussian distribution": [[130, "gaussian-distribution"]], "Gaussian processes": [[85, null]], "Gaussian processes as high-dimensional Gaussian distributions": [[82, "gaussian-processes-as-high-dimensional-gaussian-distributions"]], "Gaussian processes as infinite-dimensional Gaussian distributions": [[78, "gaussian-processes-as-infinite-dimensional-gaussian-distributions"]], "Gaussian processes demonstration": [[78, null]], "Gaussians: A couple of frequentist connections": [[19, null]], "Gelman Rubin Diagnostic": [[143, "gelman-rubin-diagnostic"]], "Gelman Rubin Diagnostic (quoted verbatim from the Hicks notebook)": [[151, "gelman-rubin-diagnostic-quoted-verbatim-from-the-hicks-notebook"]], "General problems in Bayesian inference": [[153, "general-problems-in-bayesian-inference"]], "Generate data": [[96, "generate-data"]], "Generate figures": [[142, "generate-figures"]], "Generate \u201cexperimental\u201d observations for height": [[123, "generate-experimental-observations-for-height"]], "Generating data": [[73, "generating-data"], [93, "generating-data"]], "Generating the data": [[142, "generating-the-data"]], "Generative models": [[64, null]], "Getting help": [[134, "getting-help"]], "Getting started: The Covariance Function": [[83, "getting-started-the-covariance-function"]], "Good online cheat-sheets:": [[138, "good-online-cheat-sheets"]], "Gradient Computations": [[71, "gradient-computations"]], "Gradient-descent optimization": [[97, null], [105, null]], "Group Attribution Biases": [[63, null]], "Guide to Jupyter Book markdown": [[0, null]], "Guides in this Jupyter Book": [[138, "guides-in-this-jupyter-book"]], "HMC algorithm": [[148, "hmc-algorithm"]], "HMC and other samplers": [[157, null]], "HMC physics": [[148, "hmc-physics"]], "Hamiltonian Monte Carlo": [[44, "hamiltonian-monte-carlo"]], "Hamiltonian Monte Carlo (HMC) overview and visualization": [[148, null]], "Helper function": [[81, "helper-function"]], "Hidden code cell": [[0, "hidden-code-cell"]], "Hint": [[19, null], [32, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null], [34, null]], "Hint (a)": [[32, null]], "Hint (b)": [[32, null]], "Hint-1": [[34, null]], "Hint-2": [[34, null]], "Hints": [[34, null], [67, null]], "Histograms matching a t distribution": [[126, "histograms-matching-a-t-distribution"]], "How are N_A and N_B related to the total N and the posteriors p(X_A|D,I) and p(X_B|D,I)?": [[159, null]], "How do we know this chain has converged to the posterior?": [[143, "how-do-we-know-this-chain-has-converged-to-the-posterior"]], "How the Bayesian approach helps in science": [[7, null]], "Hybrid Uncertainty:": [[7, null]], "Hypothesis testing with the chi-squared statistic": [[53, "hypothesis-testing-with-the-chi-squared-statistic"]], "Icons and menus": [[56, null]], "Illustration of prior and posterior Gaussian process for different kernels": [[81, null]], "Implementation": [[40, "implementation"]], "Implicit Biases": [[63, null]], "Import Python modules": [[38, "import-python-modules"]], "Import TensorFlow": [[76, "import-tensorflow"]], "Import functions": [[5, "import-functions"]], "Import modules": [[77, "import-modules"], [83, "import-modules"], [92, "import-modules"], [133, "import-modules"]], "Import of modules": [[95, "import-of-modules"], [144, "import-of-modules"]], "Import statements": [[96, "import-statements"]], "Import theano and pymc3": [[73, "import-theano-and-pymc3"]], "Important definitions": [[130, "important-definitions"]], "Important distributions": [[130, "important-distributions"]], "Imports": [[151, "imports"]], "In terms of p(X_A|X_B), p(X_B|X_A), N_A, and N_B, what is the condition that the exchanges between A and B cancel out? (For now assume a symmetric proposal distribution q.)": [[159, null]], "In-class exercise": [[151, "in-class-exercise"]], "Inference and PDFs": [[20, null]], "Inference using Gaussian processes": [[85, "inference-using-gaussian-processes"]], "Inference with parametric models": [[7, "inference-with-parametric-models"]], "InferenceData object": [[151, "inferencedata-object"]], "Information from ChatGPT about backpropagation": [[71, "information-from-chatgpt-about-backpropagation"]], "Information from ChatGPT about how to switch to normal distributions to intialize": [[71, "information-from-chatgpt-about-how-to-switch-to-normal-distributions-to-intialize"]], "Information from ChatGPT about tensor operations": [[71, "information-from-chatgpt-about-tensor-operations"], [71, "id1"]], "Information from ChatGPT about the default initialization": [[71, "information-from-chatgpt-about-the-default-initialization"]], "Ingredients of Bayes\u2019 theorem": [[25, null]], "Inserting figures and references to them": [[0, "inserting-figures-and-references-to-them"]], "Installation of LearningFromData Jupyter notebooks from GitHub by command line": [[140, "installation-of-learningfromdata-jupyter-notebooks-from-github-by-command-line"]], "Installation of PyTorch": [[71, "installation-of-pytorch"]], "Installing Anaconda": [[137, "installing-anaconda"]], "Integration": [[146, "integration"]], "Integration and marginalization by sampling: intuition": [[146, "integration-and-marginalization-by-sampling-intuition"]], "Interpreting 2D posteriors": [[35, null]], "Introduction": [[57, null], [161, "introduction"]], "Introduction to tensorflow": [[69, "introduction-to-tensorflow"]], "Intuition by sampling and plotting multivariate Gaussians": [[78, "intuition-by-sampling-and-plotting-multivariate-gaussians"]], "Intuition for detailed balance and the MH algorithm": [[159, "intuition-for-detailed-balance-and-the-mh-algorithm"]], "Inverse": [[136, "inverse"]], "Invitation to inductive inference": [[62, null]], "Iterating through a list of parameters to draw multiple lines on a plot": [[135, "iterating-through-a-list-of-parameters-to-draw-multiple-lines-on-a-plot"]], "Iteration versus array operation": [[135, "iteration-versus-array-operation"]], "Iterative history matching": [[46, "iterative-history-matching"]], "Joint PDFs, marginal PDFs, and an example of marginalization": [[23, "joint-pdfs-marginal-pdfs-and-an-example-of-marginalization"]], "KOH and BOH discrepancy models": [[119, null]], "Kernel cookbook": [[81, "kernel-cookbook"]], "Labeling and referencing a section": [[0, "labeling-and-referencing-a-section"]], "Laplace\u2019s method": [[53, "laplaces-method"]], "Large-width limit": [[117, "large-width-limit"]], "Layers used to build CNNs": [[75, "layers-used-to-build-cnns"]], "Learning algorithm": [[67, null], [67, "learning-algorithm"]], "Learning challenges": [[68, "learning-challenges"]], "Learning curves": [[66, "learning-curves"], [97, "learning-curves"]], "Learning goals:": [[94, "learning-goals"], [96, "learning-goals"], [142, "learning-goals"]], "Lecture 12": [[146, null]], "Lecture 20": [[79, null]], "Lets look at what the classifier has learned": [[73, "lets-look-at-what-the-classifier-has-learned"]], "Let\u2019s look at what the classifier has learned": [[93, "lets-look-at-what-the-classifier-has-learned"]], "Likelihood": [[50, "likelihood"]], "Likelihoods (or posteriors) with two variables with quadratic approximation": [[35, "likelihoods-or-posteriors-with-two-variables-with-quadratic-approximation"]], "Limit of Poisson distribution is Gaussian": [[33, "limit-of-poisson-distribution-is-gaussian"]], "Limitations of supervised learning with deep networks": [[67, "limitations-of-supervised-learning-with-deep-networks"]], "Limitations of training data": [[63, "limitations-of-training-data"]], "Linear algebra and numerical operations": [[136, "linear-algebra-and-numerical-operations"]], "Linear classification": [[65, "linear-classification"]], "Linear classifier(s)": [[65, "linear-classifier-s"]], "Linear models": [[98, null]], "Linear regression": [[65, "linear-regression"]], "Linear versus non-linear models": [[112, null]], "Liouville Theorem Visualization": [[149, null]], "Location invariance": [[3, "location-invariance"]], "Log normal distribution": [[4, "log-normal-distribution"]], "Logistic Regression": [[88, null]], "Logistic regression using scikit-learn": [[70, "logistic-regression-using-scikit-learn"]], "Looking ahead": [[24, null]], "Looking at PyMC getting started notebook": [[158, "looking-at-pymc-getting-started-notebook"]], "MCMC Intro from BUQEYE": [[154, null]], "MCMC Sampling Interlude: Assessing Convergence": [[146, "mcmc-sampling-interlude-assessing-convergence"]], "MCMC diagnostics: assessing convergence": [[143, "mcmc-diagnostics-assessing-convergence"]], "MCMC random walk and sampling example": [[159, "mcmc-random-walk-and-sampling-example"]], "MH Sampling and convergence": [[50, "mh-sampling-and-convergence"]], "Machine Learning": [[89, null]], "Machine Learning: First Examples": [[65, null]], "Machine learning": [[60, null]], "Machine learning in science and society": [[64, "machine-learning-in-science-and-society"]], "Machine learning: Overview and notation": [[64, null]], "Macros": [[0, "macros"]], "Main code for coin-flipping UI": [[9, "main-code-for-coin-flipping-ui"]], "Make Liouville theorem visualization": [[149, "make-liouville-theorem-visualization"]], "Make predictions": [[76, "make-predictions"]], "Make predictions and evaluate accuracy": [[69, "make-predictions-and-evaluate-accuracy"]], "Make some plots": [[126, "make-some-plots"]], "Making a movie of the evolution of the distribution": [[126, "making-a-movie-of-the-evolution-of-the-distribution"]], "Making predictions": [[76, "making-predictions"]], "Manipulating probabilities: Bayesian rules of probability as principles of logic": [[22, null]], "Many new target predictions using a GP": [[85, null]], "Marginal posterior distributions": [[34, "marginal-posterior-distributions"]], "Marginalization": [[41, "marginalization"], [146, "marginalization"]], "Marginalization using samples": [[7, null]], "Markov Chain Monte Carlo (MCMC)": [[154, "markov-chain-monte-carlo-mcmc"]], "Markov chain Monte Carlo sampling": [[153, null]], "Markov chains": [[156, null]], "Materials to help you get started": [[56, "materials-to-help-you-get-started"]], "Mathematical functions with numpy": [[134, "mathematical-functions-with-numpy"]], "Mathematical model": [[67, "mathematical-model"]], "Mathematical optimization": [[104, null]], "Matplotlib plotting helper functions": [[17, "matplotlib-plotting-helper-functions"]], "Matrix  Operations": [[136, "matrix-operations"]], "Matrix-vector notation": [[67, "matrix-vector-notation"]], "Mat\u00e9rn kernel": [[81, "matern-kernel"]], "Maximum likelihood": [[88, "maximum-likelihood"]], "Maximum likelihood fits": [[95, "maximum-likelihood-fits"]], "Mean and covariance function": [[82, "mean-and-covariance-function"]], "Mean and the Exponential pdf": [[4, "mean-and-the-exponential-pdf"]], "Mean, median, mode": [[130, "mean-median-mode"]], "Meet the Pandas": [[133, "meet-the-pandas"]], "Metropolis Poisson example (Gregory, section 12.2)": [[154, "metropolis-poisson-example-gregory-section-12-2"]], "Metropolis condition": [[154, null]], "Metropolis design": [[156, "metropolis-design"]], "Metropolis-Hasting MCMC sampling of a Poisson distribution": [[145, null]], "Mini-batch ADVI": [[73, "mini-batch-advi"]], "Mini-project I: Parameter estimation for a toy model of an EFT": [[94, null]], "Mini-project IIIa: Bayesian Optimization": [[92, null]], "Mini-project IIIb: Bayesian Neural Networks": [[93, null]], "Mini-project IIa: Model selection basics": [[95, null]], "Mini-project IIb: How many lines are there?": [[96, null]], "Minimize the effective potential and plot results for benchmark case": [[5, "minimize-the-effective-potential-and-plot-results-for-benchmark-case"]], "Minimizing the cross entropy": [[88, "minimizing-the-cross-entropy"]], "Model Selection": [[53, null]], "Model checking:": [[7, null]], "Model comparison:": [[7, null]], "Model mixing": [[48, null]], "Model specification": [[73, "model-specification"], [93, "model-specification"]], "Model validation": [[66, null], [66, "id7"]], "Model-order reduction": [[45, null]], "Models in science": [[110, null]], "Monte Carlo integration": [[153, "monte-carlo-integration"]], "Monte Carlo integration in statistics": [[153, "monte-carlo-integration-in-statistics"]], "Moral qualities of the scientist": [[61, null]], "More Bayesian parameter estimation": [[36, null]], "More details on naive MC": [[154, null]], "More on Bayes\u2019 theorem": [[25, null]], "More on Python and using Jupyter notebooks": [[138, null]], "More on Ridge Regression": [[66, "more-on-ridge-regression"]], "Multi-model inference with Bayes": [[54, null]], "Multivariate Gaussian distribution": [[130, "multivariate-gaussian-distribution"]], "Multivariate normal distributions": [[82, "multivariate-normal-distributions"]], "N dimensional arrays": [[136, "n-dimensional-arrays"]], "N=2 moments": [[5, "n-2-moments"]], "N=3 moments": [[5, "n-3-moments"]], "N=4 moments": [[5, "n-4-moments"]], "N=5 moments": [[5, "n-5-moments"]], "Network training": [[72, "network-training"]], "Neural network architecture": [[67, "neural-network-architecture"]], "Neural network types": [[67, "neural-network-types"]], "Next steps": [[73, "next-steps"]], "No-core shell model \\hbar\\omega dependence": [[78, "no-core-shell-model-hbar-omega-dependence"], [82, "no-core-shell-model-hbar-omega-dependence"]], "Noisy networks": [[67, null]], "Non-parametric approach: Mean and covariance functions": [[85, "non-parametric-approach-mean-and-covariance-functions"]], "Normalization and marginalization": [[25, null]], "Normalization and marginalization in the continuum limit": [[25, null]], "Normalization of a multivariate Gaussian": [[53, "normalization-of-a-multivariate-gaussian"]], "Notation": [[64, "notation"], [85, null], [88, null], [109, null], [130, "notation"], [161, "notation"]], "Note on \\chi^2/\\text{dof} for model assessment and comparison  \\newcommand{\\pars}{\\boldsymbol{\\theta}}": [[29, "note-on-chi-2-text-dof-for-model-assessment-and-comparison-newcommand-pars-boldsymbol-theta"]], "Note on donuts in high dimensions": [[154, null]], "Notebook:": [[19, "notebook"]], "Notes": [[0, "notes"], [49, "notes"]], "Now ask ChatGPT to use this code to learn a specified function in a specified region": [[71, "now-ask-chatgpt-to-use-this-code-to-learn-a-specified-function-in-a-specified-region"]], "Now do the sampling and plot the posteriors": [[123, "now-do-the-sampling-and-plot-the-posteriors"]], "Now sample with PyMC": [[152, "now-sample-with-pymc"]], "Now sample with zeus": [[152, "now-sample-with-zeus"]], "Now try it with zeus!": [[50, "now-try-it-with-zeus"]], "Numerical integration": [[153, "numerical-integration"]], "Occam\u2019s razor": [[7, null]], "Odds-ratios": [[95, "odds-ratios"]], "One adjustable parameter each": [[53, "one-adjustable-parameter-each"]], "One adjustable parameter each; different prior ranges": [[53, "one-adjustable-parameter-each-different-prior-ranges"]], "One solution (how could these functions be improved?)": [[40, "one-solution-how-could-these-functions-be-improved"]], "One solution (how could this solution be improved?)": [[40, "one-solution-how-could-this-solution-be-improved"]], "One view": [[8, null]], "Open an issue": [[56, null]], "Operating on matrices with special properties": [[136, null]], "Optimization and Deep learning": [[88, "optimization-and-deep-learning"]], "Optional task: log probabilities": [[144, "optional-task-log-probabilities"]], "Ordinary linear regression in practice": [[102, null]], "Ordinary linear regression: warmup": [[101, null]], "Organizing our data": [[133, "organizing-our-data"]], "Original background": [[152, "original-background"]], "Output Distribution of Randomly-Initialized feed-forward ANN (1 Input \u2192 1 Output)": [[129, "output-distribution-of-randomly-initialized-feed-forward-ann-1-input-1-output"]], "Output Distribution of Randomly-Initialized feed-forward ANN (2 Inputs \u2192 1 Output)": [[129, "output-distribution-of-randomly-initialized-feed-forward-ann-2-inputs-1-output"]], "Over- and underfitting": [[66, "over-and-underfitting"]], "Overfitting and underfitting the data": [[63, null]], "Overgeneralization Bias": [[63, null]], "Overview of Gaussian process": [[86, null]], "Overview of Intro to PyMC notebook": [[158, null]], "Overview of Markov Chain Monte Carlo": [[155, null]], "Overview of Mini-project IIb: How many lines?": [[90, null]], "Overview of Part II: Advanced Bayesian methods": [[55, null]], "Overview of Part III: Sampling": [[160, null]], "Overview of TALENT mini-projects": [[91, null]], "Overview of getting started materials": [[131, null]], "Overview of modeling": [[108, null]], "Overview of other topics": [[124, null]], "Overview of scientific modeling material": [[116, null]], "Overview: MCMC Diagnostics": [[143, null]], "PCA (from Duke course)": [[127, "pca-from-duke-course"]], "PCA, SVD, and all that": [[125, null]], "PDFs for applying Bayes\u2019 rule": [[142, "pdfs-for-applying-bayes-rule"]], "PT Sampler": [[50, "pt-sampler"]], "Parallel tempering": [[51, "parallel-tempering"]], "Parameter Estimation:": [[0, null], [7, null]], "Parameter choices": [[93, "parameter-choices"]], "Parameter estimation example: Gaussian noise and averages II": [[147, null]], "Parameter estimation example: fitting a straight line": [[40, null]], "Parameter estimation with your favorite MCMC sampler (emcee here!)": [[96, "parameter-estimation-with-your-favorite-mcmc-sampler-emcee-here"]], "Parameters known before the analysis (explore different values for these as requested)": [[96, "parameters-known-before-the-analysis-explore-different-values-for-these-as-requested"]], "Parameters that should be learned from the data": [[96, "parameters-that-should-be-learned-from-the-data"]], "Parametric approach": [[85, "parametric-approach"]], "Parametric versus non-parametric models": [[111, null]], "Part 1": [[83, "part-1"]], "Part 1: Random walk in [-5,5] region": [[144, "part-1-random-walk-in-5-5-region"]], "Part 2": [[83, "part-2"]], "Part 2: MCMC sampling of a Lorentzian pdf using the random walk Metropolis algorithm": [[144, "part-2-mcmc-sampling-of-a-lorentzian-pdf-using-the-random-walk-metropolis-algorithm"]], "Part 3": [[83, "part-3"]], "Part 3: Detailed balance and the Metropolis-Hastings algorithm": [[144, "part-3-detailed-balance-and-the-metropolis-hastings-algorithm"]], "Pendulum class and utility functions": [[149, "pendulum-class-and-utility-functions"]], "Perform thermodynamic integration from PT sampler": [[96, "perform-thermodynamic-integration-from-pt-sampler"]], "Philosophical remarks on probabilities": [[8, "philosophical-remarks-on-probabilities"]], "Physicist\u2019s perspective": [[58, null]], "Pick a potential": [[150, "pick-a-potential"]], "Plot orbit and check energy conservation": [[150, "plot-orbit-and-check-energy-conservation"]], "Plotting with Matplotlib": [[134, "plotting-with-matplotlib"]], "Point estimates": [[18, null]], "Point estimates and credible regions": [[130, "point-estimates-and-credible-regions"]], "Poisson distribution": [[4, "poisson-distribution"], [37, "poisson-distribution"]], "Polya and Jaynes": [[62, "polya-and-jaynes"]], "Polya and plausible inference": [[62, null]], "Possible answers": [[0, null], [11, null], [22, null]], "Posterior": [[50, "posterior"]], "Posterior with a Gaussian prior": [[34, "posterior-with-a-gaussian-prior"]], "Posterior with a uniform prior": [[34, "posterior-with-a-uniform-prior"]], "Predict based on your own experience: How does this behavior change if we have more data (higher energy) or more certain data?": [[52, null]], "Preliminaries": [[126, "preliminaries"]], "Preliminary exercise: manipulations using the index form of matrices": [[127, "preliminary-exercise-manipulations-using-the-index-form-of-matrices"]], "Preliminary exercises": [[125, "preliminary-exercises"]], "Prelude: ordinary linear regression": [[34, "prelude-ordinary-linear-regression"]], "Preparing data and the pdfs we\u2019ll need": [[37, "preparing-data-and-the-pdfs-well-need"]], "Principal components": [[127, "principal-components"]], "Prior": [[50, "prior"]], "Prior PDFs for straight line model": [[6, "prior-pdfs-for-straight-line-model"]], "Prior elicitation.": [[43, "prior-elicitation"]], "Probabilistic Programming at scale": [[73, "probabilistic-programming-at-scale"]], "Probabilistic model": [[72, "probabilistic-model"]], "Probability density functions": [[23, null]], "Probability surface": [[73, "probability-surface"], [93, "probability-surface"]], "Product rule": [[22, "product-rule"]], "Projected posterior plots": [[17, "projected-posterior-plots"]], "Proof of penultimate equality": [[13, null]], "Proof of the CLT in a special case:": [[19, "proof-of-the-clt-in-a-special-case"]], "Pukelsheim\u2019s three-sigma rule": [[46, "pukelsheims-three-sigma-rule"], [46, null]], "PyMC Introduction": [[151, null]], "PyMC implementation": [[151, "pymc-implementation"]], "PyMC3:": [[153, null]], "PyMultiNest:": [[153, null]], "PyStan:": [[153, null]], "PyTorch Default Initialization": [[71, "pytorch-default-initialization"]], "Python expressions and strings": [[134, "python-expressions-and-strings"]], "Python for machine learning": [[64, null]], "Python imports": [[50, "python-imports"], [127, "python-imports"], [142, "python-imports"]], "Python/Jupyter set up": [[9, "python-jupyter-set-up"]], "QBism references": [[128, "qbism-references"]], "Quadrature methods": [[153, "quadrature-methods"]], "Quantum Bayesianism (QBism)": [[128, null]], "Question": [[4, null], [12, null], [35, null], [83, "question"], [85, null], [88, null], [88, null], [95, "question"], [154, null]], "Question 1": [[31, null], [32, null]], "Question 2": [[31, null], [32, null]], "Question 3": [[31, null], [32, null]], "Question 4": [[31, null], [32, null]], "Question 5": [[31, null], [32, null]], "Question 6": [[31, null]], "Question 7": [[31, null]], "Question 8": [[31, null]], "Question 9": [[31, null]], "Questions": [[144, "questions"]], "Questions / tasks": [[144, "questions-tasks"], [144, "id2"]], "Questions and things to do": [[145, "questions-and-things-to-do"]], "Questions for the class": [[35, null]], "Questions:": [[144, "id1"]], "Quick introduction to  scipy.stats": [[17, "quick-introduction-to-scipy-stats"], [130, "quick-introduction-to-scipy-stats"]], "Quick review: To a Bayesian, everything is a PDF (probability density function)": [[17, "quick-review-to-a-bayesian-everything-is-a-pdf-probability-density-function"]], "RMSprop": [[107, "rmsprop"]], "Radial Basis Function kernel": [[81, "radial-basis-function-kernel"]], "Random Walk Metropolis-Hasting (MH)": [[154, "random-walk-metropolis-hasting-mh"]], "Random variables: probability distribution and density": [[130, "random-variables-probability-distribution-and-density"]], "Rank": [[136, "rank"]], "Rational Quadradtic kernel": [[81, "rational-quadradtic-kernel"]], "Recall Beta function": [[13, null]], "Recall Metropolis algorithm for p(\\thetavec | D, I) (or any other posterior).": [[159, null]], "Recall the basic structure of Metropolis-Hastings": [[154, null]], "Recap of GPs": [[79, "recap-of-gps"]], "Recap of Poisson MCMC example": [[159, "recap-of-poisson-mcmc-example"]], "Recaps": [[159, null]], "Recurrent neural networks": [[67, "recurrent-neural-networks"]], "Reduced-order methods": [[45, "reduced-order-methods"]], "Reference: Bayesian rules of probability": [[31, "reference-bayesian-rules-of-probability"], [32, "reference-bayesian-rules-of-probability"]], "References:": [[85, "references"]], "Regression algorithms": [[64, null]], "Regression analysis with linear models": [[100, null]], "Regression analysis: optimization versus inference": [[113, null]], "Regular NNs don\u2019t scale well to full images": [[75, "regular-nns-dont-scale-well-to-full-images"]], "Regularization": [[88, "regularization"]], "Regularization: Ridge and Lasso": [[66, "regularization-ridge-and-lasso"]], "Remarks": [[0, "remarks"]], "Remarks on bias and variance": [[66, "remarks-on-bias-and-variance"]], "Reporting Biases": [[63, null]], "Reproducibility": [[43, "reproducibility"]], "Requirements for AI systems": [[63, null]], "Reshape": [[136, "reshape"]], "Results": [[43, "results"]], "Reversibility": [[156, "reversibility"]], "Review of bivariate normal case": [[78, "review-of-bivariate-normal-case"]], "Rewriting the likelihood": [[34, "rewriting-the-likelihood"]], "Row-major order": [[136, null]], "Run MCMC": [[142, "run-mcmc"]], "S/IR limitations": [[44, "s-ir-limitations"]], "SVD applied to images for compression": [[127, "svd-applied-to-images-for-compression"]], "SVD basics": [[127, "svd-basics"]], "Sampling": [[18, null], [38, "sampling"], [151, "sampling"]], "Sampling / Importance Resampling": [[44, "sampling-importance-resampling"]], "Sampling a distribution": [[156, null]], "Sampling and plotting multivariate Gaussians": [[82, "sampling-and-plotting-multivariate-gaussians"]], "Sampling from a Gaussian Process": [[83, "sampling-from-a-gaussian-process"]], "Sampling from a PDF": [[153, "sampling-from-a-pdf"]], "Sampling of 1d pdfs in Python": [[17, "sampling-of-1d-pdfs-in-python"]], "Saving a figure": [[134, "saving-a-figure"]], "Scalar operations": [[136, "scalar-operations"]], "Scale invariance": [[3, "scale-invariance"]], "Scikit-learn demo notebooks": [[87, null]], "Second example: each sample is two points": [[33, "second-example-each-sample-is-two-points"]], "Second pass: More elaborate controls and options": [[132, "second-pass-more-elaborate-controls-and-options"]], "Select element(s)": [[136, "select-element-s"]], "Selected exercises from notebook": [[79, "selected-exercises-from-notebook"]], "Selection bias": [[63, null]], "Set plot style": [[123, "set-plot-style"]], "Setting Covariance Function Parameters": [[77, "setting-covariance-function-parameters"], [83, "setting-covariance-function-parameters"]], "Setting it up": [[75, "setting-it-up"]], "Setting up the back-propagation algorithm": [[68, "setting-up-the-back-propagation-algorithm"]], "Setting up to use this Jupyter book": [[139, null]], "Setup sampling with emcee and pocomc samplers": [[123, "setup-sampling-with-emcee-and-pocomc-samplers"]], "Shape, size, length and data type": [[136, "shape-size-length-and-data-type"]], "Singular value decomposition (SVD)": [[125, "singular-value-decomposition-svd"]], "Sivia example on \u201csignal on top of background\u201d": [[35, "sivia-example-on-signal-on-top-of-background"]], "Solution strategy:": [[96, "solution-strategy"]], "Solution to": [[34, "solution:BayesianLinearRegression:likelihood_pars"], [34, "solution:ols_example_1_b"], [34, "solution:ols_example_3_b"]], "Solution to Exercise 15.1": [[161, "solution:StochasticProcess:first-example"]], "Solution to Exercise 15.2": [[161, "solution:conditional-probabilities-stochastic-process"]], "Solution to Exercise 15.3": [[161, "solution:construct-stochastic-process"]], "Solution to Exercise 16.1 (Stochastic matrix)": [[156, "solution:MarkovChains:stochastic-matrix"]], "Solution to Exercise 16.10 (Flip-flop)": [[156, "solution:flip-flop"]], "Solution to Exercise 16.11 (Gothenburg winter weather)": [[156, "solution:MarkovChains:gothenburg-winter-weather"]], "Solution to Exercise 16.12 (Stationary Gothenburg winter weather)": [[156, "solution:stationary-gothenburg-winter-weather"]], "Solution to Exercise 16.13 (Is it reversible?)": [[156, "solution:is-it-reversible"]], "Solution to Exercise 16.14 (Optical pumping)": [[156, "solution:optical-pumping"]], "Solution to Exercise 16.15 (Detailed balance)": [[156, "solution:detailed-balance"]], "Solution to Exercise 16.16 (Metropolis sampling of a uniform distribution)": [[153, "solution:metropolis-sampling-uniform"]], "Solution to Exercise 16.17 (Power-law distributions)": [[153, "solution:power-law-distribution-sampling"]], "Solution to Exercise 16.18 (The Metropolis algorithm for a discrete distribution)": [[153, "solution:MCMC:discrete-metropolis"]], "Solution to Exercise 16.2 (Simple random walk)": [[156, "solution:MarkovChains:simple-random-walk"]], "Solution to Exercise 16.3 (Remnant memory)": [[156, "solution:MarkovChains:memory"]], "Solution to Exercise 16.4 (Conditional distributions)": [[156, "solution:MarkovChains:conditional-distributions"]], "Solution to Exercise 16.5 (Stationary distribution)": [[156, "solution:MarkovChains:stationary-distribution"]], "Solution to Exercise 16.6 (Reversibility)": [[156, "solution:MarkovChains:reversibility"]], "Solution to Exercise 16.7 (A reversible Markov chain)": [[156, "solution:MarkovChains:reversible-chain"]], "Solution to Exercise 16.8 (Stationary two-state distribution)": [[156, "solution:stationary-2x2"]], "Solution to Exercise 16.9 (Limiting distribution)": [[156, "solution:limiting-distribution"]], "Solution to Exercise 21.1 (Sigmoid decision boundary)": [[65, "solution:MLexamples:sigmoid-decision-boundary"]], "Solution to Exercise 21.4 (kNN for regression)": [[65, "solution:MLexamples:kNN-regression"]], "Solution to Exercise 21.5 (R2 score)": [[65, "solution:MLexamples:R2-score"]], "Solution to Exercise 22.1 (Weights and signal propagation of a simple neural network)": [[67, "solution:NeuralNet:simple-network"]], "Solution to Exercise 22.2 (Weights and signal propagation of a wide neural network)": [[67, "solution:NeuralNet:wide-network"]], "Solution to Exercise 22.3 (Linear signals)": [[67, "solution:NeuralNet:linear-signal"]], "Solution to Exercise 22.4 (Expected signal)": [[67, "solution:NeuralNet:expected-signal"]], "Solution to Exercise 22.5 (k=1 NN training error)": [[66, "solution:ModelValidation:kNN-training-error"]], "Solution to Exercise 22.6 (kNN model complexity)": [[66, "solution:ModelValidation:kNN-model-complexity"]], "Solution to Exercise 22.7 (Study of model bias and variance)": [[66, "solution:ModelValidation:study-model-bias-variance"]], "Solution to Exercise 22.8 (Implement k-fold cross validation)": [[66, "solution:ModelValidation:kfold-cross-validation"]], "Solution to Exercise 22.9 (Large training error)": [[66, "solution:ModelValidation:large-training-error"]], "Solution to Exercise 32.1": [[0, "solution:ppd_definition_b"]], "Solution to Exercise 33.1 (Random and colorblind)": [[130, "solution:Statistics:colorblind"]], "Solution to Exercise 33.2 (Conditional discrete probability mass function)": [[130, "solution:Statistics:conditional-discrete-pmf"]], "Solution to Exercise 33.3 (Conditional probability for continuous variables)": [[130, "solution:Statistics:conditional-probability-continuous"]], "Solution to Exercise 33.4 (Conditional expectation)": [[130, "solution:Statistics:conditional-expectation"]], "Solution to Exercise 33.5 (Scipy.stats)": [[130, "colution:Statistics:scipy-stats"]], "Solution to Exercise 33.6 (Bivariate pdf)": [[130, "solution:Statistics:bivariate-pdf"]], "Solution to Exercise 36.1 (Independent and dependent)": [[115, "solution:OverviewModeling:independent-dependent"]], "Solution to Exercise 36.2 (Linear or non-linear)": [[115, "solution:OverviewModeling:linear-nonlinear"]], "Solution to Exercise 36.3 (Linear or non-linear; more examples)": [[115, "solution:OverviewModeling:linear-nonlinear-examples"]], "Solution to Exercise 36.4 (Model discrepancy)": [[115, "solution:OverviewModeling:model-discrepancy"]], "Solution to Exercise 37.1": [[103, "solution:ols_example_1"]], "Solution to Exercise 37.3": [[103, "solution:ols_example_3"]], "Solution to Exercise 4.3": [[16, "solution:ppd_definition"]], "Solution to Exercise 4.4": [[16, "solution:pdf_normalization"]], "Solution to Exercise 4.5": [[16, "solution:rain"]], "Solution to Exercise 4.6": [[16, "solution:monty_hall"]], "Solution to Exercise 4.7": [[16, "solution:coin_ppd"]], "Solution to Exercise 7.1 (Correlated errors)": [[7, "solution:BayesianAdvantage:correlated-errors"]], "Solution to Exercise 7.3 (Inferring galactic distances)": [[7, "solution:BayesianAdvantages:inferring-galactic-distances-ex"]], "Solution to Exercise 7.4 (The standard random variable)": [[7, "solution:BayesianAdvantages:standard-random-variable"]], "Solution to Exercise 7.5 (The square root of a number)": [[7, "solution:BayesianAdvantages:square-root-of-a-number"]], "Solution to Exercise 7.6 (Gaussian sum of errors)": [[7, "solution:BayesianAdvantages:gaussian-sum-of-errors"]], "Solution to Exercise 7.7 (Gaussian product of errors)": [[7, "solution:BayesianAdvantages:gaussian-product-of-errors"]], "Solutions": [[7, "solutions"], [16, "solutions"], [65, "solutions"], [66, "solutions"], [67, "solutions"], [103, null], [115, null], [130, "solutions"], [153, "solutions"], [156, "solutions"], [161, "solutions"]], "Solutions to selected exercises": [[34, "solutions-to-selected-exercises"]], "Solving matrix equations with SVD": [[127, "solving-matrix-equations-with-svd"]], "Solving orbital equations with different algorithms": [[150, null]], "Some standard pdfs: the normal (aka Gaussian) and beta distributions": [[17, "some-standard-pdfs-the-normal-aka-gaussian-and-beta-distributions"]], "Sorting": [[136, "sorting"]], "Sparsity": [[117, "sparsity"]], "Special case: Gaussian process": [[161, "special-case-gaussian-process"]], "Speed comparisons": [[135, "speed-comparisons"]], "Splitting arrays": [[136, "splitting-arrays"]], "Spot the error!": [[34, null]], "Standard Error of the Mean": [[143, "standard-error-of-the-mean"]], "Standard Likelihood Approach": [[38, "standard-likelihood-approach"]], "Standard activation functions": [[88, "standard-activation-functions"]], "State-of-the-art MCMC implementations": [[153, "state-of-the-art-mcmc-implementations"]], "Statements": [[21, null]], "Stationary and limiting distributions": [[156, "stationary-and-limiting-distributions"]], "Stationary kernels": [[85, "stationary-kernels"]], "Stationary processes": [[156, "stationary-processes"]], "Statistical Operations": [[136, "statistical-operations"]], "Statistical formulation": [[123, "statistical-formulation"]], "Statistics concepts and notation": [[130, null]], "Step 1: Maximum likelihood estimate": [[41, "step-1-maximum-likelihood-estimate"]], "Step 2: Single-parameter model": [[41, "step-2-single-parameter-model"]], "Step 3: Full Bayesian approach": [[41, "step-3-full-bayesian-approach"]], "Step 4: Error propagation": [[41, "step-4-error-propagation"]], "Stochastic processes": [[161, null]], "Student t distribution as a mixture of Gaussians": [[126, null]], "Sub-task": [[70, "sub-task"]], "Sub-tasks and follow-up questions": [[70, "sub-tasks-and-follow-up-questions"]], "Subtasks (put your answers here):": [[96, "subtasks-put-your-answers-here"]], "Suggestions for how to proceed:": [[94, "suggestions-for-how-to-proceed"]], "Sum of normally distributed random variables.": [[85, null]], "Sum rule": [[22, "sum-rule"]], "Summary": [[7, null], [8, "summary"], [41, "summary"], [85, null]], "Summary points from arXiv:1710.06068": [[159, null]], "Symmetry invariance": [[3, "symmetry-invariance"]], "Systematic error example": [[41, "systematic-error-example"]], "Systematic reduction": [[75, "systematic-reduction"]], "Systemic biases": [[63, null]], "Table of results": [[35, null]], "Take aways: Coin tossing": [[25, "take-aways-coin-tossing"]], "Take-aways and follow-up questions from coin flipping:": [[15, null]], "Task 1: Logistic regression using scikit-learn": [[74, "task-1-logistic-regression-using-scikit-learn"]], "Task 2: Bayesian logistic regression using MCMC sampling": [[74, "task-2-bayesian-logistic-regression-using-mcmc-sampling"]], "Task 3: Bayesian logistic regression using Variational Inference": [[74, "task-3-bayesian-logistic-regression-using-variational-inference"]], "Telling ChatGPT 4 to make a network for a function of one variable": [[71, "telling-chatgpt-4-to-make-a-network-for-a-function-of-one-variable"]], "Terminology": [[67, "terminology"]], "Test the sum of normal variables squared": [[29, "test-the-sum-of-normal-variables-squared"]], "The Central Limit Theorem": [[19, "the-central-limit-theorem"]], "The Data": [[40, "the-data"], [143, "the-data"]], "The Data and the question": [[41, "the-data-and-the-question"]], "The Data and the true result": [[49, "the-data-and-the-true-result"]], "The Gaussian is to statistics what the harmonic oscillator is to mechanics": [[19, "the-gaussian-is-to-statistics-what-the-harmonic-oscillator-is-to-mechanics"]], "The Gelman-Rubin test": [[44, "the-gelman-rubin-test"]], "The Jupyter Notebook menu and shortcuts": [[134, "the-jupyter-notebook-menu-and-shortcuts"]], "The Kullback-Leibler divergence": [[72, "the-kullback-leibler-divergence"]], "The Metropolis-Hastings algorithm": [[153, "the-metropolis-hastings-algorithm"]], "The Model": [[38, "the-model"], [40, "the-model"], [41, "the-model"], [95, "the-model"], [143, "the-model"]], "The Prior": [[40, "the-prior"]], "The RBF kernel (a.k.a Gaussian)": [[78, "the-rbf-kernel-a-k-a-gaussian"], [82, "the-rbf-kernel-a-k-a-gaussian"]], "The Story of Dr. A and Prof. B": [[53, "the-story-of-dr-a-and-prof-b"]], "The Zeus Ensemble Slice Sampler": [[163, null]], "The ball-drop model": [[121, null]], "The bias-variance tradeoff": [[66, "the-bias-variance-tradeoff"]], "The continuum limit": [[25, "the-continuum-limit"]], "The cost function rewritten as cross entropy": [[88, "the-cost-function-rewritten-as-cross-entropy"]], "The covariance matrix as the central object": [[85, "the-covariance-matrix-as-the-central-object"]], "The entropy of Scandinavians": [[4, "the-entropy-of-scandinavians"]], "The friends of Bayes\u2019 theorem": [[25, "the-friends-of-bayes-theorem"]], "The likelihood": [[34, "the-likelihood"]], "The logistic function": [[88, "the-logistic-function"]], "The monkey argument": [[4, "the-monkey-argument"]], "The near ubiquity of Gaussians": [[19, "the-near-ubiquity-of-gaussians"]], "The normal distribution": [[4, null]], "The normal equation": [[34, "the-normal-equation"], [100, "the-normal-equation"]], "The perceptron": [[88, "the-perceptron"]], "The perceptron classifier": [[65, "the-perceptron-classifier"]], "The posterior": [[34, "the-posterior"]], "The posterior predictive": [[34, "the-posterior-predictive"]], "The posterior predictive distribution": [[16, "the-posterior-predictive-distribution"]], "The prior": [[34, "the-prior"]], "The probability measure": [[130, "the-probability-measure"]], "The pseudo-inverse (or Moore-Penrose inverse)": [[34, null]], "The soft classifier": [[65, "the-soft-classifier"]], "The statistical model (recap)": [[49, "the-statistical-model-recap"]], "The tip class": [[0, "the-tip-class"]], "The toy model": [[49, "the-toy-model"]], "The uniform distribution": [[130, "the-uniform-distribution"]], "Theory": [[123, "theory"]], "Things for you to do:": [[49, "things-for-you-to-do"]], "Things to do and Questions to answer": [[95, "things-to-do-and-questions-to-answer"]], "Things to do:": [[40, "things-to-do"], [127, "things-to-do"]], "Things to try:": [[129, "things-to-try"]], "Third example: each sample is 10 points": [[33, "third-example-each-sample-is-10-points"]], "Third pass:  a more elaborate user interface with tabs": [[132, "third-pass-a-more-elaborate-user-interface-with-tabs"]], "This makes sense:": [[86, null]], "Three main ingredients of machine learning": [[64, null]], "To do": [[93, "to-do"]], "To our real data: nuclear binding energies. Brief reminder on masses and binding energies": [[133, "to-our-real-data-nuclear-binding-energies-brief-reminder-on-masses-and-binding-energies"]], "To think about \u2026": [[19, null]], "Trace": [[136, "trace"]], "Train and evaluate the model:": [[69, "train-and-evaluate-the-model"]], "Training and validation scores": [[66, null]], "Training scores": [[65, "training-scores"]], "Transformation property of multivariate normal distributions": [[34, null]], "Transforming images": [[75, "transforming-images"]], "Try it yourself with the Jupyter notebook": [[133, null]], "Trying a different function": [[5, "trying-a-different-function"]], "Two dependent parameters": [[53, "two-dependent-parameters"]], "Two independent parameters": [[53, "two-independent-parameters"]], "Two views on the likelihood": [[34, null]], "Types of Machine Learning": [[64, "types-of-machine-learning"]], "Types of probability": [[130, "types-of-probability"]], "Uncertainty in predicted value": [[73, "uncertainty-in-predicted-value"], [93, "uncertainty-in-predicted-value"]], "Uncorrelated assignments": [[4, null]], "Univariate Approaches": [[143, "univariate-approaches"]], "Updating via Bayes\u2019 rule": [[10, null]], "Updating your conda environment for Learning from Data": [[137, "updating-your-conda-environment-for-learning-from-data"]], "User-interface for coin-flipping": [[9, "user-interface-for-coin-flipping"]], "Using Anaconda": [[137, null]], "Using Bayesian model mixing to open the model space": [[48, "using-bayesian-model-mixing-to-open-the-model-space"]], "Using GitHub": [[140, null]], "Using SVD for PCA": [[127, "using-svd-for-pca"]], "Using parallel tempering: ptemcee": [[96, "using-parallel-tempering-ptemcee"]], "Utilizing GPU Acceleration": [[71, "utilizing-gpu-acceleration"]], "Variance and the Gaussian pdf": [[4, "variance-and-the-gaussian-pdf"]], "Variance of the mean": [[44, "variance-of-the-mean"]], "Variational Inference: Bayesian Neural Networks": [[93, "variational-inference-bayesian-neural-networks"]], "Variational Inference: Scaling model complexity": [[73, "variational-inference-scaling-model-complexity"], [93, "variational-inference-scaling-model-complexity"]], "Variational inference for Bayesian neural networks": [[72, "variational-inference-for-bayesian-neural-networks"]], "Verification of PyTorch installation (suggested in PyTorch website)": [[71, "verification-of-pytorch-installation-suggested-in-pytorch-website"]], "Verify the data": [[76, "verify-the-data"]], "Verifying sampling": [[18, null]], "Virtues": [[61, null]], "Visualization of MCMC sampling": [[154, "visualization-of-mcmc-sampling"]], "Visualization of PDFs": [[17, "visualization-of-pdfs"]], "Visualizations of MCMC": [[153, "visualizations-of-mcmc"]], "Visualizing PDFs": [[23, "visualizing-pdfs"]], "Warnings": [[0, "warnings"]], "What are arrays?": [[136, "what-are-arrays"]], "What does it mean that the ellipses are slanted?": [[35, null]], "What failure looks like": [[5, "what-failure-looks-like"]], "What if the only moves accepted were those that went uphill (i.e., to higher probability density)? What would happen to N_A and N_B over time? Is this stationary?": [[159, null]], "What is p(\\thetavec_i|D,I)?": [[159, null]], "What is special about machine learning in physics?": [[60, null]], "What is the ratio of p(X_B|X_A) to p(X_A|X_B) in terms of p(X_A|D,I) and p(X_B|D,I)?": [[159, null]], "What is well determined?": [[79, null]], "What next?": [[46, "what-next"]], "What order polynomial?": [[95, "what-order-polynomial"]], "What pairs are highly correlated?": [[79, null]], "What returns the prior?": [[79, null]], "What to do about sampling from correlated distributions?": [[146, "what-to-do-about-sampling-from-correlated-distributions"]], "What you should know about Python and using Jupyter notebooks": [[138, "what-you-should-know-about-python-and-using-jupyter-notebooks"]], "When do priors matter? When don\u2019t they matter?": [[12, null]], "Why MCMC?": [[154, "why-mcmc"]], "Why deep neural networks?": [[67, "why-deep-neural-networks"]], "Why do you think that this property is called detailed balance? Can you make an analogy with thermodynamic equilibrium for e.g. a collection of hydrogen atoms?": [[159, null]], "Why maximize the entropy?": [[4, "why-maximize-the-entropy"]], "With model discrepancy": [[123, "with-model-discrepancy"]], "Without model discrepancy": [[123, "without-model-discrepancy"]], "Workflow for Bayesian linear regression": [[34, "workflow-for-bayesian-linear-regression"]], "Yet another function": [[5, "yet-another-function"]], "Zero-based indexing": [[136, null]], "emcee": [[96, "emcee"]], "emcee:": [[153, null]], "k nearest neighbors classification": [[65, "k-nearest-neighbors-classification"]], "kNN classifier": [[65, "knn-classifier"]], "l1-norm": [[4, "l1-norm"]], "numpy arrays": [[134, "numpy-arrays"]], "p or \\log p?": [[19, null]], "p-values: when all you can do is falsify": [[19, "p-values-when-all-you-can-do-is-falsify"]], "\ud83d\udce5 Amplitude of a signal in the presence of background": [[37, null]], "\ud83d\udce5 Dealing with outliers": [[38, null]], "\ud83d\udce5 Demonstration:  Bayesian Coin Tossing": [[30, null]], "\ud83d\udce5 Demonstration: Coin tossing (with widget)": [[9, null]], "\ud83d\udce5 Demonstration: Prior PDFs for straight lines": [[6, null]], "\ud83d\udce5 Demonstration: Reading Data and fitting": [[133, null]], "\ud83d\udce5 Demonstration: Sum of normal variables squared": [[29, null]], "\ud83d\udce5 Distributions of Randomly-Initialized ANNs": [[129, null]], "\ud83d\udce5 Exercise: Jupyter Notebooks and Python": [[134, null]], "\ud83d\udce5 Exercise: Linear algebra operations with NumPy": [[136, null]], "\ud83d\udce5 Exercise: Python lists and iterations": [[135, null]], "\ud83d\udce5 Exploring PDFs": [[17, null]], "\ud83d\udce5 Linear algebra games including SVD for PCA": [[127, null]], "\ud83d\udce5 Making a simple widget-based UI": [[132, null]], "\ud83d\udce5 Maximum Entropy for reconstructing a function from its moments": [[5, null]], "\ud83d\udce5 Model discrepancy example: The ball-drop experiment": [[123, null]], "\ud83d\udce5 Parameter estimation example: Gaussian noise and averages I": [[39, null]], "\ud83d\udce5 Parameter estimation example: fitting a straight line II": [[41, null]], "\ud83d\udce5 Radioactive lighthouse problem": [[42, null]], "\ud83d\udce5 Visualization of the Central Limit Theorem": [[33, null]]}, "docnames": ["LearningFromData-content/Backmatter/JB_tests", "LearningFromData-content/Backmatter/bibliography", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/Assigning", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/IgnorancePDF", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt2", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt_Function_Reconstruction", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/demo-straight_lines", "LearningFromData-content/BayesianStatistics/BayesianBasics/BayesianAdvantages", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_epistemology", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_updating_coinflip_interactive", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-01-coin-tossing-frequentists-and-bayesaians", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-02-when-do-priors-matter-when-don-t-they-matter", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-03-computing-the-posterior-analytically", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-04-degree-of-belief-credibility-intervals-vs-frequentist-1-sigm", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-05-take-aways-and-follow-up-questions-from-coin-flipping", "LearningFromData-content/BayesianStatistics/BayesianBasics/DataModelsPredictions", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs_followups", "LearningFromData-content/BayesianStatistics/BayesianBasics/Gaussians", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-01-statements", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-02-manipulating-probabilities-bayesian-rules-of-probability-as", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-03-probability-density-functions", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-04-summary", "LearningFromData-content/BayesianStatistics/BayesianBasics/MoreBayesTheorem", "LearningFromData-content/BayesianStatistics/BayesianBasics/Posteriors", "LearningFromData-content/BayesianStatistics/BayesianBasics/RootBayesianBasics", "LearningFromData-content/BayesianStatistics/BayesianBasics/UsingBayes", "LearningFromData-content/BayesianStatistics/BayesianBasics/chi_squared_tests", "LearningFromData-content/BayesianStatistics/BayesianBasics/demo-BayesianBasics", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_medical_example_by_Bayes", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_sum_product_rule", "LearningFromData-content/BayesianStatistics/BayesianBasics/visualization_of_CLT", "LearningFromData-content/BayesianStatistics/BayesianLinearRegression/BayesianLinearRegression_rjf", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/Interpreting2Dposteriors", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/ParameterEstimation", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/amplitude_in_presence_of_background", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/dealing_with_outliers", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_Gaussian_noise", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_I", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_II", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/radioactive_lighthouse_exercise", "LearningFromData-content/BayesianStatistics/BayesianWorkflow/BayesianWorkflow", "LearningFromData-content/BayesianStatistics/ComputationalBayes/AdvancedMCMC", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesFast", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesLinear", "LearningFromData-content/BayesianStatistics/ComputationalBayes/extra_RBM_emulators", "LearningFromData-content/BayesianStatistics/ModelMixing/model_mixing", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/Evidence_for_model_EFT_coefficients", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/MCMC-parallel-tempering_ptemcee_vs_zeus", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/computing_evidence", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/two_model_evidence", "LearningFromData-content/BayesianStatistics/ModelSelection/ModelSelection", "LearningFromData-content/BayesianStatistics/Multimodel_inference", "LearningFromData-content/BayesianStatistics/RootAdvancedMethods", "LearningFromData-content/Intro/About", "LearningFromData-content/Intro/Introduction", "LearningFromData-content/Intro/Introduction/sec-01-physicist-s-perspective", "LearningFromData-content/Intro/Introduction/sec-02-bayesian-workflow", "LearningFromData-content/Intro/Introduction/sec-03-machine-learning", "LearningFromData-content/Intro/Introduction/sec-04-virtues", "LearningFromData-content/Intro/Invitation", "LearningFromData-content/MachineLearning/ANN/DataBiasFairness", "LearningFromData-content/MachineLearning/ANN/MachineLearning", "LearningFromData-content/MachineLearning/ANN/MachineLearningExamples", "LearningFromData-content/MachineLearning/ANN/ModelValidation", "LearningFromData-content/MachineLearning/ANN/NeuralNet", "LearningFromData-content/MachineLearning/ANN/NeuralNet/NeuralNetBackProp", "LearningFromData-content/MachineLearning/ANN/NeuralNet/demo-NeuralNet", "LearningFromData-content/MachineLearning/ANN/NeuralNet/exercises_LogReg_NeuralNet", "LearningFromData-content/MachineLearning/ANN/Neural_Network_for_simple_function_in_PyTorch", "LearningFromData-content/MachineLearning/BNN/bnn", "LearningFromData-content/MachineLearning/BNN/demo-bnn", "LearningFromData-content/MachineLearning/BNN/exercises_BNN", "LearningFromData-content/MachineLearning/CNN/cnn", "LearningFromData-content/MachineLearning/CNN/demo-cnn", "LearningFromData-content/MachineLearning/GP/BUQ/Gaussian_processes_exercises", "LearningFromData-content/MachineLearning/GP/BUQ/demo-GaussianProcesses", "LearningFromData-content/MachineLearning/GP/BUQ/lecture_20", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_noisy_targets", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_prior_posterior", "LearningFromData-content/MachineLearning/GP/CF/demo-GaussianProcesses", "LearningFromData-content/MachineLearning/GP/CF/exercise_GP_GPy", "LearningFromData-content/MachineLearning/GP/GPy_demos", "LearningFromData-content/MachineLearning/GP/GaussianProcesses", "LearningFromData-content/MachineLearning/GP/RootGP", "LearningFromData-content/MachineLearning/GP/Sklearn_demos", "LearningFromData-content/MachineLearning/LogReg/LogReg", "LearningFromData-content/MachineLearning/RootML", "LearningFromData-content/Mini-projects/Mini-project_IIb_overview", "LearningFromData-content/Mini-projects/RootMiniProjects", "LearningFromData-content/Mini-projects/mini-project_IIIa_bayesian_optimization", "LearningFromData-content/Mini-projects/mini-project_IIIb_Bayesian_neural_networks_from_demo", "LearningFromData-content/Mini-projects/mini-project_I_toy_model_of_EFT", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIa", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIb_How_many_lines_ptemcee", "LearningFromData-content/ModelingOptimization/GradientDescent", "LearningFromData-content/ModelingOptimization/LinearModels", "LearningFromData-content/ModelingOptimization/LinearModels/sec-01-definition-of-linear-models", "LearningFromData-content/ModelingOptimization/LinearModels/sec-02-regression-analysis-with-linear-models", "LearningFromData-content/ModelingOptimization/LinearModels/sec-03-ordinary-linear-regression-warmup", "LearningFromData-content/ModelingOptimization/LinearModels/sec-04-ordinary-linear-regression-in-practice", "LearningFromData-content/ModelingOptimization/LinearModels/sec-05-solutions", "LearningFromData-content/ModelingOptimization/MathematicalOptimization", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-01-gradient-descent-optimization", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-02-batch-stochastic-and-mini-batch-gradient-descent", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-03-adaptive-gradient-descent-algorithms", "LearningFromData-content/ModelingOptimization/OverviewModeling", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-01-notation", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-02-models-in-science", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-03-parametric-versus-non-parametric-models", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-04-linear-versus-non-linear-models", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-05-regression-analysis-optimization-versus-inference", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-06-exercises", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-07-solutions", "LearningFromData-content/ModelingOptimization/RootScientificModeling", "LearningFromData-content/OtherTopics/ANNFT", "LearningFromData-content/OtherTopics/DiscrepancyModels", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-01-koh-and-boh-discrepancy-models", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-02-framework", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-03-the-ball-drop-model", "LearningFromData-content/OtherTopics/Emulators", "LearningFromData-content/OtherTopics/MD_balldrop_v1", "LearningFromData-content/OtherTopics/RootOtherTopics", "LearningFromData-content/OtherTopics/SVD", "LearningFromData-content/OtherTopics/Student_t_distribution_from_Gaussians", "LearningFromData-content/OtherTopics/linear_algebra_games_including_SVD", "LearningFromData-content/OtherTopics/qbism", "LearningFromData-content/OtherTopics/random_initialized_ANN_vs_width", "LearningFromData-content/Reference/Statistics", "LearningFromData-content/Setup/RootGettingStarted", "LearningFromData-content/Setup/Simple_widgets_v1", "LearningFromData-content/Setup/demo-Intro", "LearningFromData-content/Setup/exercise_Intro_01_Jupyter_Python", "LearningFromData-content/Setup/exercise_Intro_02_Jupyter_Python", "LearningFromData-content/Setup/exercise_Intro_03_Numpy", "LearningFromData-content/Setup/installing_anaconda", "LearningFromData-content/Setup/more_python_and_jupyter", "LearningFromData-content/Setup/setting_up", "LearningFromData-content/Setup/using_github", "LearningFromData-content/StochasticProcesses/Advanced_MCMC", "LearningFromData-content/StochasticProcesses/BUQ/Assignment_extending_radioactive_lighthouse", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-diagnostics", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-random-walk-and-sampling", "LearningFromData-content/StochasticProcesses/BUQ/Metropolis_Poisson_example", "LearningFromData-content/StochasticProcesses/BUQ/intuition_sampling", "LearningFromData-content/StochasticProcesses/BUQ/parameter_estimation_Gaussian_noise-2", "LearningFromData-content/StochasticProcesses/BUQ2/HMC_intro_BUQ", "LearningFromData-content/StochasticProcesses/BUQ2/Liouville_theorem_visualization", "LearningFromData-content/StochasticProcesses/BUQ2/Orbital_eqs_with_different_algorithms", "LearningFromData-content/StochasticProcesses/BUQ2/PyMC_intro_updated", "LearningFromData-content/StochasticProcesses/BUQ2/parameter_estimation_Gaussian_noise_compare_samplers", "LearningFromData-content/StochasticProcesses/MCMC", "LearningFromData-content/StochasticProcesses/MCMC_intro_BUQ", "LearningFromData-content/StochasticProcesses/MCMC_overview", "LearningFromData-content/StochasticProcesses/MarkovChains", "LearningFromData-content/StochasticProcesses/Other_samplers", "LearningFromData-content/StochasticProcesses/OverviewIntroPyMC", "LearningFromData-content/StochasticProcesses/Recap_BUQ", "LearningFromData-content/StochasticProcesses/RootMCMC", "LearningFromData-content/StochasticProcesses/StochasticProcesses", "LearningFromData-content/StochasticProcesses/demo-MCMC", "LearningFromData-content/StochasticProcesses/zeus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["LearningFromData-content/Backmatter/JB_tests.md", "LearningFromData-content/Backmatter/bibliography.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/Assigning.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/IgnorancePDF.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt2.md", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/MaxEnt_Function_Reconstruction.ipynb", "LearningFromData-content/BayesianStatistics/AssigningProbabilities/demo-straight_lines.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/BayesianAdvantages.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_epistemology.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Bayesian_updating_coinflip_interactive.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-01-coin-tossing-frequentists-and-bayesaians.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-02-when-do-priors-matter-when-don-t-they-matter.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-03-computing-the-posterior-analytically.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-04-degree-of-belief-credibility-intervals-vs-frequentist-1-sigm.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/CoinTossing/sec-05-take-aways-and-follow-up-questions-from-coin-flipping.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/DataModelsPredictions.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/Exploring_pdfs_followups.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Gaussians.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-01-statements.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-02-manipulating-probabilities-bayesian-rules-of-probability-as.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-03-probability-density-functions.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-04-summary.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/MoreBayesTheorem.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/Posteriors.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/RootBayesianBasics.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/UsingBayes.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/chi_squared_tests.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/demo-BayesianBasics.ipynb", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_medical_example_by_Bayes.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/exercise_sum_product_rule.md", "LearningFromData-content/BayesianStatistics/BayesianBasics/visualization_of_CLT.ipynb", "LearningFromData-content/BayesianStatistics/BayesianLinearRegression/BayesianLinearRegression_rjf.md", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/Interpreting2Dposteriors.md", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/ParameterEstimation.md", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/amplitude_in_presence_of_background.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/dealing_with_outliers.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_Gaussian_noise.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_I.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_II.ipynb", "LearningFromData-content/BayesianStatistics/BayesianParameterEstimation/radioactive_lighthouse_exercise.ipynb", "LearningFromData-content/BayesianStatistics/BayesianWorkflow/BayesianWorkflow.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/AdvancedMCMC.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesFast.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/BayesLinear.md", "LearningFromData-content/BayesianStatistics/ComputationalBayes/extra_RBM_emulators.md", "LearningFromData-content/BayesianStatistics/ModelMixing/model_mixing.md", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/Evidence_for_model_EFT_coefficients.ipynb", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/MCMC-parallel-tempering_ptemcee_vs_zeus.ipynb", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/computing_evidence.md", "LearningFromData-content/BayesianStatistics/ModelSelection/BUQ/two_model_evidence.md", "LearningFromData-content/BayesianStatistics/ModelSelection/ModelSelection.md", "LearningFromData-content/BayesianStatistics/Multimodel_inference.md", "LearningFromData-content/BayesianStatistics/RootAdvancedMethods.md", "LearningFromData-content/Intro/About.md", "LearningFromData-content/Intro/Introduction.md", "LearningFromData-content/Intro/Introduction/sec-01-physicist-s-perspective.md", "LearningFromData-content/Intro/Introduction/sec-02-bayesian-workflow.md", "LearningFromData-content/Intro/Introduction/sec-03-machine-learning.md", "LearningFromData-content/Intro/Introduction/sec-04-virtues.md", "LearningFromData-content/Intro/Invitation.md", "LearningFromData-content/MachineLearning/ANN/DataBiasFairness.md", "LearningFromData-content/MachineLearning/ANN/MachineLearning.md", "LearningFromData-content/MachineLearning/ANN/MachineLearningExamples.md", "LearningFromData-content/MachineLearning/ANN/ModelValidation.md", "LearningFromData-content/MachineLearning/ANN/NeuralNet.md", "LearningFromData-content/MachineLearning/ANN/NeuralNet/NeuralNetBackProp.md", "LearningFromData-content/MachineLearning/ANN/NeuralNet/demo-NeuralNet.ipynb", "LearningFromData-content/MachineLearning/ANN/NeuralNet/exercises_LogReg_NeuralNet.ipynb", "LearningFromData-content/MachineLearning/ANN/Neural_Network_for_simple_function_in_PyTorch.ipynb", "LearningFromData-content/MachineLearning/BNN/bnn.md", "LearningFromData-content/MachineLearning/BNN/demo-bnn.ipynb", "LearningFromData-content/MachineLearning/BNN/exercises_BNN.ipynb", "LearningFromData-content/MachineLearning/CNN/cnn.md", "LearningFromData-content/MachineLearning/CNN/demo-cnn.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/Gaussian_processes_exercises.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/demo-GaussianProcesses.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/lecture_20.md", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_noisy_targets.ipynb", "LearningFromData-content/MachineLearning/GP/BUQ/plot_gpr_prior_posterior.ipynb", "LearningFromData-content/MachineLearning/GP/CF/demo-GaussianProcesses.ipynb", "LearningFromData-content/MachineLearning/GP/CF/exercise_GP_GPy.ipynb", "LearningFromData-content/MachineLearning/GP/GPy_demos.md", "LearningFromData-content/MachineLearning/GP/GaussianProcesses.md", "LearningFromData-content/MachineLearning/GP/RootGP.md", "LearningFromData-content/MachineLearning/GP/Sklearn_demos.md", "LearningFromData-content/MachineLearning/LogReg/LogReg.md", "LearningFromData-content/MachineLearning/RootML.md", "LearningFromData-content/Mini-projects/Mini-project_IIb_overview.md", "LearningFromData-content/Mini-projects/RootMiniProjects.md", "LearningFromData-content/Mini-projects/mini-project_IIIa_bayesian_optimization.ipynb", "LearningFromData-content/Mini-projects/mini-project_IIIb_Bayesian_neural_networks_from_demo.ipynb", "LearningFromData-content/Mini-projects/mini-project_I_toy_model_of_EFT.ipynb", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIa.ipynb", "LearningFromData-content/Mini-projects/model-selection_mini-project-IIb_How_many_lines_ptemcee.ipynb", "LearningFromData-content/ModelingOptimization/GradientDescent.md", "LearningFromData-content/ModelingOptimization/LinearModels.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-01-definition-of-linear-models.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-02-regression-analysis-with-linear-models.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-03-ordinary-linear-regression-warmup.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-04-ordinary-linear-regression-in-practice.md", "LearningFromData-content/ModelingOptimization/LinearModels/sec-05-solutions.md", "LearningFromData-content/ModelingOptimization/MathematicalOptimization.md", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-01-gradient-descent-optimization.md", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-02-batch-stochastic-and-mini-batch-gradient-descent.md", "LearningFromData-content/ModelingOptimization/MathematicalOptimization/sec-03-adaptive-gradient-descent-algorithms.md", "LearningFromData-content/ModelingOptimization/OverviewModeling.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-01-notation.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-02-models-in-science.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-03-parametric-versus-non-parametric-models.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-04-linear-versus-non-linear-models.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-05-regression-analysis-optimization-versus-inference.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-06-exercises.md", "LearningFromData-content/ModelingOptimization/OverviewModeling/sec-07-solutions.md", "LearningFromData-content/ModelingOptimization/RootScientificModeling.md", "LearningFromData-content/OtherTopics/ANNFT.md", "LearningFromData-content/OtherTopics/DiscrepancyModels.md", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-01-koh-and-boh-discrepancy-models.md", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-02-framework.md", "LearningFromData-content/OtherTopics/DiscrepancyModels/sec-03-the-ball-drop-model.md", "LearningFromData-content/OtherTopics/Emulators.md", "LearningFromData-content/OtherTopics/MD_balldrop_v1.ipynb", "LearningFromData-content/OtherTopics/RootOtherTopics.md", "LearningFromData-content/OtherTopics/SVD.md", "LearningFromData-content/OtherTopics/Student_t_distribution_from_Gaussians.ipynb", "LearningFromData-content/OtherTopics/linear_algebra_games_including_SVD.ipynb", "LearningFromData-content/OtherTopics/qbism.md", "LearningFromData-content/OtherTopics/random_initialized_ANN_vs_width.ipynb", "LearningFromData-content/Reference/Statistics.md", "LearningFromData-content/Setup/RootGettingStarted.md", "LearningFromData-content/Setup/Simple_widgets_v1.ipynb", "LearningFromData-content/Setup/demo-Intro.ipynb", "LearningFromData-content/Setup/exercise_Intro_01_Jupyter_Python.ipynb", "LearningFromData-content/Setup/exercise_Intro_02_Jupyter_Python.ipynb", "LearningFromData-content/Setup/exercise_Intro_03_Numpy.ipynb", "LearningFromData-content/Setup/installing_anaconda.md", "LearningFromData-content/Setup/more_python_and_jupyter.md", "LearningFromData-content/Setup/setting_up.md", "LearningFromData-content/Setup/using_github.md", "LearningFromData-content/StochasticProcesses/Advanced_MCMC.md", "LearningFromData-content/StochasticProcesses/BUQ/Assignment_extending_radioactive_lighthouse.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-diagnostics.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/MCMC-random-walk-and-sampling.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/Metropolis_Poisson_example.ipynb", "LearningFromData-content/StochasticProcesses/BUQ/intuition_sampling.md", "LearningFromData-content/StochasticProcesses/BUQ/parameter_estimation_Gaussian_noise-2.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/HMC_intro_BUQ.md", "LearningFromData-content/StochasticProcesses/BUQ2/Liouville_theorem_visualization.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/Orbital_eqs_with_different_algorithms.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/PyMC_intro_updated.ipynb", "LearningFromData-content/StochasticProcesses/BUQ2/parameter_estimation_Gaussian_noise_compare_samplers.ipynb", "LearningFromData-content/StochasticProcesses/MCMC.md", "LearningFromData-content/StochasticProcesses/MCMC_intro_BUQ.md", "LearningFromData-content/StochasticProcesses/MCMC_overview.md", "LearningFromData-content/StochasticProcesses/MarkovChains.md", "LearningFromData-content/StochasticProcesses/Other_samplers.md", "LearningFromData-content/StochasticProcesses/OverviewIntroPyMC.md", "LearningFromData-content/StochasticProcesses/Recap_BUQ.md", "LearningFromData-content/StochasticProcesses/RootMCMC.md", "LearningFromData-content/StochasticProcesses/StochasticProcesses.md", "LearningFromData-content/StochasticProcesses/demo-MCMC.ipynb", "LearningFromData-content/StochasticProcesses/zeus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 3, 4, 8, 9, 11, 12, 15, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 56, 57, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 92, 94, 95, 96, 97, 98, 100, 101, 102, 110, 114, 115, 117, 119, 120, 121, 123, 125, 126, 127, 128, 129, 130, 133, 134, 135, 137, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 159, 161, 162], "0": [0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 21, 22, 24, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 88, 92, 94, 95, 96, 97, 99, 100, 102, 104, 107, 114, 120, 121, 123, 125, 126, 127, 129, 130, 132, 133, 134, 135, 136, 137, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 159, 161, 162, 163], "00": [1, 39, 50, 66, 69, 77, 78, 83, 93, 95, 123, 127, 130, 145, 147, 150, 151, 152, 161, 162], "000": [31, 32, 43, 44, 75, 76, 133, 145, 151, 156, 159, 161, 162], "0000": 71, "000000": 133, "00000000e": [78, 127], "00001": 1, "000054": 133, "00008": 1, "00009": 133, "0001": [31, 70], "00011": 133, "00012": 133, "0003725": 151, "00046": 133, "00049": 133, "0005": 78, "0005735": 39, "00088142": 39, "000e": [123, 127], "001": [1, 77, 82, 83, 107, 130, 150, 151], "00107510802066753": 1, "00124": 151, "00145017e": 151, "0015": 49, "001mb": 77, "002": [127, 133, 152], "00297317": 39, "0029802": 39, "003": [127, 151], "003100": 133, "003287052672065272": 77, "003620": 133, "0036e": 71, "0037e": 71, "0038": 76, "0038e": 71, "00390438e": 78, "00398911": 39, "004": [5, 130, 151, 161], "00400084": 39, "00429143": [147, 152], "0042e": 71, "0043": 31, "004752": 78, "005": [44, 78, 82, 143, 146, 151, 162], "0051e": 71, "00524490e": 151, "00560623": [147, 152], "00568668": 39, "0059": 129, "006": 127, "0070": 129, "00727646693": 133, "00730944": 151, "007315": 133, "0074e": 71, "007825": 133, "00788": 72, "00796648": 39, "00806543": 39, "0084806e": 76, "00854895": 39, "008664": 133, "0086649156": 133, "009": [1, 127], "00910918": 151, "0094": 76, "00941": 92, "00978733": 39, "009e": 123, "00arviz_vers": 151, "00j": 78, "01": [3, 7, 17, 33, 34, 37, 42, 49, 65, 66, 67, 69, 70, 71, 73, 76, 77, 78, 81, 83, 92, 93, 95, 123, 130, 151, 152, 161, 162], "01012718": 39, "01082473": 127, "010902": 133, "011": 127, "0111021": 127, "01120706": 39, "01125": 1, "012": 162, "013": [32, 127, 161], "01335268": 39, "01354311": 151, "0135e": 71, "0136": 151, "01382247": 39, "01395875": 151, "013e": 123, "014": [31, 127], "014004": 1, "014101": 133, "015": 161, "01572298": 151, "016": 143, "01652757": 39, "01677131": 151, "017": [1, 161], "01715": 1, "01716473": 39, "01740941": 39, "01795589": 39, "01818182": 127, "018232": 133, "01855247": 39, "019": 127, "01e": 81, "01it": 152, "02": [1, 37, 38, 42, 44, 76, 77, 78, 80, 82, 95, 123, 126, 151, 152, 161, 162], "020": [1, 151, 162], "02010975": 39, "021": [127, 161], "02124813": 39, "02186284": 39, "022": 1, "022227": 39, "02227172": [147, 152], "023": [31, 127], "024": [127, 162], "025": 133, "02507": 1, "0256e": 71, "02599999": 39, "026218253x": 1, "02673241": 39, "027": 38, "02753": 151, "028": 38, "02827408": [147, 152], "02834467": 127, "02941762": 39, "029733": 133, "02it": 152, "03": [1, 4, 71, 76, 78, 95, 123, 151, 152, 162], "030002": 133, "030003": [1, 133], "0303": 82, "03085711": 39, "0317509": 127, "03224": 133, "032501": 1, "03261455": 39, "03298378": 39, "03342118": 151, "0334508": 39, "03368687": 39, "03381043e": 78, "034": 143, "034047": 133, "03431": 1, "0343265": 70, "034328": [78, 82], "03493433": [147, 152], "03494359": 39, "035002": 1, "0353601": 39, "035909": 133, "037": 130, "0370": 1, "03703898": 39, "038": 151, "0387364": 39, "0388246": 39, "03956759": 127, "03970741": 127, "03998411": 130, "03it": 152, "04": [33, 38, 39, 50, 71, 76, 77, 78, 95, 123, 130, 143, 151, 152, 162], "04008915": 39, "04011": 1, "04037143": 39, "0408143": 127, "041": 38, "04183091": 39, "04221375": 39, "04278640498515118": 5, "04279159257882259": 5, "043": 161, "04359686": 39, "04366899": 39, "04385474": 151, "044001": 86, "0441": 126, "04425957": 127, "044334": 133, "04444209": 39, "04457474": 39, "04499441": 39, "045": 29, "04527": 1, "0453": 71, "04548788": [147, 152], "04618286": [147, 152], "0462994": 39, "04651135e": 151, "0465673": 39, "04663941": 127, "047": 161, "04789471": 39, "0479379": 39, "0480108": 127, "0484": 1, "048920": 133, "049": [38, 127], "04906169": 39, "0490804": 39, "04909075": 39, "04912": 1, "04921829": 39, "04938272": 153, "04945222": 151, "049462": 133, "04it": 152, "04t13": 151, "05": [9, 17, 19, 42, 46, 49, 50, 65, 71, 76, 77, 78, 81, 82, 83, 94, 95, 96, 123, 126, 130, 151, 152, 162], "05031709": 39, "05080775": 39, "051": [38, 127], "05117344": 39, "05132077": 39, "05156034": 39, "052e": 123, "053": [4, 127], "05340954": 39, "054": [127, 133], "05418781": 133, "05424": 1, "0546241": 39, "05495304": 39, "055": 127, "05528": 1, "055676": 133, "056": 9, "05635552": 39, "05667659": 39, "057121": 39, "05741082": 39, "058": 19, "0587121": 49, "059": 127, "05931904": 39, "05965165": 127, "05arrai": 151, "05it": 152, "06": [69, 71, 73, 78, 81, 82, 83, 93, 95, 151, 152, 162], "06032751": 39, "060349": 133, "06056664": [147, 152], "0607502": 39, "061": 127, "061679": 133, "0617284": 153, "06298492": 130, "063": 127, "063443": 133, "063724": 133, "06423057": 39, "065026": 133, "06578332": 39, "06581816": 39, "065e": 123, "066": 4, "06608534": 39, "06662586": 127, "067": [81, 127], "06796626": 127, "06798079e": 65, "068": 133, "06802716": 133, "06836875": 151, "0684": 49, "06897162": 39, "06898597": 39, "06942093": 151, "069584": 133, "06996554": 39, "07": [4, 69, 71, 77, 78, 82, 95, 130, 151, 152, 162], "070": 4, "070043": 133, "07090": 1, "07125243": 39, "0713": 133, "0719842": 127, "072": 127, "0722519": 39, "07248480e": 151, "07272727": 127, "07312806": 39, "074": 151, "074001": 49, "07432055": 39, "07454014": 127, "0761167e": 76, "07638048": 39, "077": 151, "07734007": 39, "07782113": 39, "078": 9, "07825379": 151, "07883168": 127, "079": 152, "07932044": 130, "07941624": 152, "07it": 152, "08": [69, 71, 78, 93, 95, 147, 152, 162], "0803": 1, "08075099": 39, "0809271": 39, "081": 127, "08155996": 39, "08176782": 39, "082875": 133, "0831827": 127, "08340777": 127, "083527": 133, "08352721390288316": 133, "08420815": 39, "08457563": 39, "08601": 1, "08613684": 78, "08646441": 39, "087887": 133, "087e": 123, "0883": 76, "08846454": 151, "0894": 71, "08958761": [147, 152], "08968641": 39, "08972912": 39, "08989298859694": 42, "08it": 152, "09": [29, 31, 69, 82, 151, 152], "090": 143, "09059632e": 151, "09169": 1, "0925": 71, "09314945": 130, "094": 127, "09499611": 39, "09542509": 39, "09574677": 39, "09645482": 127, "09744091": 127, "09777527": 78, "09811225": 39, "09836551": 39, "09881469": 127, "09899633": 39, "099": 151, "09914922": [147, 152], "09922139": 130, "09964576e": 127, "09it": 152, "0_": 151, "0_1": 1, "0arrai": 151, "0e": [66, 149, 150], "0f": [6, 41, 69, 76, 134], "0inference_librari": 151, "0l": 67, "0m": [77, 83], "0px": 132, "0th": 76, "1": [1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 15, 16, 17, 19, 21, 22, 23, 24, 25, 27, 29, 30, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 59, 61, 63, 64, 68, 69, 70, 71, 72, 73, 75, 76, 78, 80, 81, 82, 88, 90, 94, 95, 96, 97, 99, 100, 101, 102, 105, 106, 107, 110, 112, 113, 114, 117, 120, 121, 123, 125, 126, 127, 133, 134, 135, 136, 137, 142, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 158, 159, 162, 163], "10": [0, 1, 3, 4, 6, 7, 9, 17, 25, 29, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 65, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 93, 95, 96, 102, 107, 123, 125, 127, 129, 130, 132, 133, 134, 136, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 159, 161, 162], "100": [0, 3, 4, 6, 7, 9, 16, 17, 29, 33, 34, 35, 37, 38, 40, 41, 42, 45, 50, 51, 65, 66, 67, 69, 70, 71, 73, 76, 78, 79, 81, 82, 86, 96, 123, 125, 126, 127, 130, 133, 136, 137, 143, 144, 145, 147, 149, 150, 151, 152, 153, 154, 158, 159, 161, 162], "1000": [6, 9, 17, 25, 29, 30, 33, 34, 38, 39, 40, 41, 42, 50, 65, 71, 73, 78, 82, 95, 96, 102, 127, 130, 133, 134, 137, 143, 144, 145, 146, 147, 151, 152, 159, 162], "10000": [6, 9, 17, 31, 33, 38, 41, 42, 70, 82, 130, 144, 151, 161], "100000": [6, 17, 33, 41, 82, 130, 151, 162], "1000000": 17, "100009": 151, "10000coordin": 151, "1000xarrai": 151, "10025514": 39, "100480": 69, "1007": 1, "100_000": 151, "100coordin": 151, "100j": [73, 93], "101": [129, 135, 152, 161], "1010002": 39, "10107499": 127, "10118794": 39, "10131681": 39, "1016": 1, "10165": 1, "1017": 1, "101770": 69, "102": 152, "102001": 1, "1022": 126, "10223673": 39, "1023": 126, "1024": [50, 76, 96, 126], "10246085": 127, "10255671": 151, "1026": 126, "1027": 126, "1028": 126, "1029": 126, "103": 152, "1030": 126, "1031": 126, "1032": 126, "1033": 126, "1034": 126, "1035": 126, "1036": 126, "10363908": 39, "1037": 126, "1037466": 78, "1038": 1, "104": [1, 152], "10405339": 39, "10417433": 39, "104411": 133, "10473305": 39, "105": [1, 9, 152], "10513283": 127, "10581": 86, "1058809": [1, 44], "106": 152, "10622272": 39, "106431": 133, "1066": 127, "107": [127, 151, 152], "10717545": 39, "1072684": 127, "10734329": 39, "10735333": 39, "10770823": [147, 152], "108": [133, 152], "1080": 1, "10803082": 39, "10854853": [147, 152], "1086": 1, "10861676": 39, "1088": 1, "109": 152, "1092931": 1, "1093": 126, "10930687": 151, "1094027": 39, "10944442": 39, "1095": 126, "1096": 126, "1097": 126, "10972845": 39, "1098": 126, "1099": 126, "10_000": 151, "10it": 152, "11": [25, 30, 34, 37, 38, 39, 40, 42, 46, 50, 67, 73, 77, 78, 79, 81, 86, 93, 95, 96, 100, 102, 105, 123, 126, 133, 134, 136, 144, 146, 147, 148, 151, 152, 153, 154, 161, 162], "110": [133, 152], "1100": [71, 126], "1101": 126, "1102": 126, "1103": 1, "11060505": 39, "11096561": 78, "111": [70, 152], "1110567": 39, "1111": 1, "11114458": 127, "1112": 133, "11133727": 39, "112": 161, "11236849": 39, "11237104": 39, "11248774": 39, "11273195": 130, "113": 152, "1132": 71, "1137": 1, "1139": 63, "11394172": 34, "114": 152, "11438298": 39, "115": [19, 156], "1157018": 39, "11584111": 39, "116": [9, 41, 127], "117": 152, "117430": 133, "1176": [50, 152], "1181334": 39, "118318": 133, "11858913": 39, "1186": 1, "119": [127, 143], "11900865": 39, "1194224": 39, "1196": 1, "11981094": 39, "11it": 152, "12": [0, 1, 5, 6, 7, 9, 16, 17, 25, 30, 33, 34, 37, 38, 39, 41, 44, 49, 50, 52, 53, 65, 66, 67, 72, 73, 75, 76, 77, 78, 79, 82, 83, 86, 93, 94, 96, 123, 126, 127, 130, 132, 133, 136, 143, 144, 145, 147, 150, 151, 152, 153, 162], "120": [75, 126, 129], "1200": [1, 41, 71], "1201": 88, "12015895": 39, "12027389e": 127, "121": 1, "1212": 1, "1214": 1, "12141771": 39, "12174943": 130, "12182127": 39, "122": 76, "12214158": 39, "122282": 133, "1223": 130, "12232832": 39, "1226768": 130, "12269799": 151, "12271848": 39, "123": 144, "1234": 17, "12341216": 39, "12369125": [147, 152], "124": [1, 42, 130, 133, 152], "12438004": 151, "1249115293": 151, "125": 1, "1253235": 39, "12535626": 127, "126": 130, "12634831": 151, "12683902": 39, "1269": 41, "127812": 133, "12783421": 151, "1279": 41, "128": [42, 69, 75], "12837699": 39, "12878515": [147, 152], "1290": 69, "12910158": 39, "12911235": 39, "12948391": 39, "12999178": 39, "12it": 152, "13": [0, 1, 5, 32, 34, 37, 39, 51, 53, 56, 66, 67, 76, 77, 78, 81, 83, 95, 120, 121, 127, 129, 133, 146, 151, 152, 153, 161, 162], "1300": 71, "1304781454370705": 123, "13090956": 127, "130k": 130, "13135": 133, "13162939": 39, "13165914": 127, "13219435": 5, "13221278": 39, "13223132": 39, "13224778": 39, "13268873": 151, "1327083": [147, 152], "133": 50, "13376944": 39, "134": [41, 95], "1340482": 39, "13437312": 39, "13444589": 123, "13454402": 130, "134e": 123, "135": 126, "13513688": [147, 152], "13515942": 127, "13557886317328113": 77, "136": [41, 126, 127, 152], "1361": 1, "13622942": 5, "1365": 1, "1369": 63, "137": [126, 152], "13705024641296903": 83, "1375": 71, "13770121": 39, "13782807": 39, "138": 126, "13802808": 34, "13868364": 39, "139": [63, 126], "13e": 95, "13it": 152, "14": [1, 5, 9, 19, 25, 30, 37, 38, 42, 44, 53, 69, 70, 72, 78, 82, 95, 126, 127, 133, 146, 150, 151, 152], "140": [0, 7], "1400": 71, "14010988": 39, "14039544": 39, "14048406": 39, "14085185": 127, "14091435": 127, "140px": 132, "141": 127, "1411": 40, "1412": 1, "14164054": 39, "14189485": 70, "14201814": 39, "14225137": 39, "14250318": 39, "1426": 71, "14276186": 78, "14381452": [147, 152], "144": [9, 30], "14472371": 39, "1448929119131699": 83, "1449": 71, "144993": 133, "145": 156, "1454651347": 151, "14548": 1, "14676526": 39, "14690038": 39, "14720375": 127, "1475": 71, "1477": 152, "14854434": 39, "149": 152, "15": [1, 5, 7, 17, 19, 25, 33, 35, 37, 38, 40, 41, 42, 50, 53, 65, 76, 78, 82, 93, 95, 126, 127, 130, 133, 146, 149, 151, 152], "150": [33, 38, 123, 143], "1500": 71, "15000": [38, 144], "15001628": 39, "15007104": 127, "1505": 1, "1506": 1, "1509": 1, "150px": 9, "152": 127, "15259914": 39, "153036": 133, "153e": 123, "15431": 1, "15479436": 39, "155": 152, "15528789": 39, "15573901": 127, "156": [95, 133], "15626385": 39, "1563": 76, "157": 133, "1570": 76, "1575e": 71, "158": 133, "1581": 152, "15817785": 127, "159": 133, "1592e": 71, "1593": 1, "15it": 152, "16": [5, 17, 25, 33, 37, 38, 40, 41, 42, 50, 75, 78, 82, 94, 95, 96, 123, 127, 129, 130, 132, 133, 135, 143, 146, 147, 149, 151, 152, 161, 162], "160": 133, "1600": [71, 123, 127], "16000": [145, 162], "16001109": 39, "16003707": 39, "1601": 1, "1603": 72, "16033857": 39, "16056499": 39, "160kb": 151, "161": 152, "16128569": 39, "1614": 1, "16143998": 39, "1623": 1, "162999": 133, "16363636": 127, "16384": 75, "16466507": 39, "167": 30, "16707517": 39, "1674": 1, "16760465": 39, "16890192684613": 42, "16938243": 39, "1698281": 39, "16983114": 39, "16986926": 39, "16998901": 39, "16b": 151, "16it": [50, 152], "16j": 78, "17": [1, 7, 32, 44, 50, 69, 78, 82, 95, 97, 105, 127, 133, 136, 146, 151, 152, 156, 162], "1700": 71, "1711": 1, "17137202": 39, "17195713": 39, "172": 95, "172872": 151, "173": 152, "17390257": 39, "175": 152, "17516773": 39, "175300": 133, "17608015": 39, "177": 152, "17718772": 39, "17753281": 39, "17792215": 151, "17801963736677": 123, "1788": 152, "179": 152, "17994348": 127, "17e": 95, "17it": 152, "18": [1, 5, 9, 32, 33, 45, 46, 65, 71, 78, 81, 93, 95, 130, 132, 136, 137, 151, 152, 156, 162, 163], "180": [93, 151], "1800": 71, "1800880e": 76, "1805": 110, "1809": 110, "181": 152, "18103874": 39, "1810401e": 76, "183": 152, "1833e": 71, "184": 152, "1841262e": 69, "184519": 133, "18496": 76, "185": [81, 152], "1850492": 70, "18515642": 39, "1851e": 71, "1853": 46, "18553562": 39, "18557541": 39, "18576771": 127, "186": 152, "18656139": 39, "1867": [46, 152], "18697965": 39, "187": 152, "1870": 77, "18755985": 127, "188": 152, "18843153": 152, "189": 152, "1892932": 39, "189367": 133, "189496": 133, "1896": 77, "189622": 133, "18986165": 39, "18th": 8, "19": [1, 5, 38, 46, 65, 66, 71, 82, 95, 96, 117, 133, 151, 152, 161, 162], "190": 152, "1900": 71, "1902": 92, "1904": 86, "19069973": 39, "19091548": 39, "191": 152, "1911528": 39, "191963": 133, "192": 152, "19268607": 39, "19381518": 39, "19381718": 151, "19382179": 39, "1939": 53, "194": 152, "1943": 67, "1948": 4, "195": 1, "1950": [153, 154], "19501328": [147, 152], "1953": [126, 144], "1954": [1, 62, 126], "19540886": [147, 152], "1955": 126, "1956": 126, "19562109": 126, "1957": 126, "196": 152, "1960": 4, "1961": 1, "1963": 4, "19686978": 39, "1970": 144, "19783084": 39, "1979": [85, 108], "1980": [46, 153, 154], "19829972": 39, "1983": 46, "1984": [4, 5], "1986": 1, "1987": 1, "1988": [1, 4, 53, 63], "1989": 1, "19891788": 39, "1992": 1, "1994": [1, 46], "1997": 144, "19975956": 39, "19it": 152, "19th": [8, 110], "1_": 67, "1_000": [80, 81, 135, 151, 152], "1_1": 67, "1_2": 67, "1_3": 67, "1_j": 67, "1_l": 67, "1a": 79, "1arrai": 151, "1b": 79, "1cm": 133, "1d": [26, 76, 123], "1darrai": 123, "1e": [41, 50, 78, 80, 81, 82, 123, 143], "1e15": 81, "1e2": 80, "1e30": 123, "1e5": 123, "1f": [17, 33, 37, 38, 40, 41, 42, 82, 96, 126, 130, 132, 135, 143, 145, 149, 150, 162], "1mgaussian_nois": [77, 83], "1mgp_regress": [77, 83], "1mlengthscal": [77, 83], "1mmat52": [77, 83], "1mmul": [77, 83], "1mrbf": [77, 83], "1msum": [77, 83], "1mvarianc": [77, 83], "1n": [52, 133], "1sampling_tim": 151, "1st": [15, 73, 93, 134], "1x": 133, "1xarrai": 151, "2": [0, 1, 3, 4, 6, 7, 9, 13, 15, 16, 17, 18, 19, 23, 24, 25, 26, 27, 30, 33, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 59, 63, 65, 66, 68, 69, 70, 71, 72, 73, 76, 78, 79, 80, 81, 82, 85, 86, 88, 90, 94, 95, 96, 97, 99, 100, 101, 102, 103, 107, 112, 113, 114, 117, 120, 121, 123, 125, 126, 127, 133, 134, 135, 136, 137, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 158, 159, 162, 163], "20": [0, 7, 16, 17, 19, 29, 32, 33, 35, 38, 40, 41, 44, 50, 51, 53, 65, 70, 71, 74, 77, 78, 83, 85, 95, 96, 118, 123, 126, 132, 133, 143, 145, 150, 151, 152, 153, 156, 161, 162], "200": [9, 12, 33, 34, 38, 40, 41, 70, 71, 75, 78, 82, 102, 123, 129, 132, 143, 144, 150, 159], "2000": [41, 44, 50, 65, 71, 123, 143, 146, 159], "20000": [123, 129, 143, 161], "2003": [1, 56], "2004": 51, "20045251": 39, "2005": [1, 56], "2006": [1, 53, 56], "2007": 1, "2008": 1, "2009": 1, "200_000": 151, "201": 42, "2010": 1, "2011": 1, "2012": [1, 77, 128], "2013": [0, 1, 56, 128], "20134291": 127, "2014": 1, "2015": 1, "2016": [1, 72, 73, 78, 82, 93, 133], "2017": [1, 133, 148, 154], "2018": [1, 73, 78, 82, 93], "20183018": 39, "2019": [1, 5, 38, 39, 50, 53, 56, 73, 74, 76, 77, 78, 86, 91, 95, 143, 144, 147, 149, 152], "20199118": [147, 152], "2020": [6, 73], "20205486": 39, "2021": [1, 5, 63, 151], "2022": [1, 44, 65], "2023": 151, "2024": 78, "20246085e": 151, "2025": [50, 67, 81, 96, 123, 126, 151, 152], "20273021": 39, "2030": 77, "20303737": [147, 152], "2035808": [147, 152], "204": 133, "20433313": 133, "20437739": 39, "2048": 123, "2048px": 0, "205231": 133, "20659521": 127, "2066079": 39, "206915": 39, "207": 152, "2075e": 71, "207888": 133, "208": 1, "20845633": 39, "2088896239": 38, "209": 127, "20900359": 39, "20909668": 39, "20920005": 39, "209789": 133, "20_000": 151, "20it": 152, "20px": 42, "20th": 8, "21": [1, 16, 38, 41, 43, 50, 67, 79, 82, 86, 96, 137, 144, 151, 152, 156], "2104": [1, 126], "21048638": 130, "2106": 1, "2110": 1, "21112476": 39, "2112": 1, "2113378": 126, "21208711": 39, "2121": 1, "21219653": 151, "213": [9, 127], "2130": 41, "2135339": 39, "21397852": 127, "214": [38, 44, 152], "2140": 1, "21440984": 65, "21441925": 151, "214466": 39, "2153": 1, "2159": 1, "21590044e": 151, "216": [1, 126], "217": 126, "21726515": [147, 152], "21746553": 39, "2179409": 39, "218": [126, 152], "21808832": 39, "21987438": 39, "21997231": 34, "21e": 95, "21it": 152, "22": [1, 34, 38, 45, 46, 71, 78, 79, 82, 86, 95, 130, 151, 152], "220": 126, "2203": 1, "221": [126, 151], "2210": 1, "22102504": 49, "221180": 133, "2212": 1, "22135108": 151, "221761357079009": 77, "222": [1, 9, 126, 127], "22214117": 39, "222400": 133, "22243362": 39, "2228": 41, "22294075": 127, "223": [126, 151], "22372221": 39, "224": [41, 126], "2241e": 71, "2245077": 39, "2246093": 1, "22483838": 39, "22492971": 39, "225": [127, 151], "22515585": 39, "22519727": 127, "227": 32, "22863013": [147, 152], "22869221": 127, "22895559": 39, "229": 152, "22it": 152, "23": [63, 67, 82, 95, 96, 127, 136, 151, 152, 153, 156], "230": 31, "23009474": 39, "2305582": 39, "23066907": 5, "2320": 127, "23219625": 39, "23225307": 39, "232435": 133, "23249456": 39, "23269017": 39, "23289919": 39, "233": 152, "23333913": 39, "234": [50, 96, 143], "2344157": 39, "235": [50, 96], "23616403": 39, "2366e": 71, "237": [50, 96], "2373327": 39, "2387931": 39, "23896348": 151, "23921293": 127, "23931144": 39, "23955002e": 151, "23965277e": 151, "24": [1, 5, 40, 65, 72, 78, 82, 127, 132, 133, 151, 152, 162], "240": [32, 152], "2404": 5, "24050555": 39, "24073709": 39, "240kb": 151, "24193267": 39, "24266944": 39, "243": 143, "24349463": 127, "24407436": 39, "24433723": 39, "24454398": [147, 152], "245": 30, "24503505": 127, "2453781259": 151, "24542285": 39, "24560206": 39, "24610704": [147, 152], "24865585": 151, "24879916": 39, "24912743": 127, "24957254": 127, "24987188": 127, "24it": 152, "25": [8, 16, 33, 35, 38, 40, 41, 46, 49, 69, 73, 76, 77, 78, 92, 93, 94, 127, 133, 136, 144, 151, 152, 161, 162], "250": [9, 34, 73, 93, 102], "2500": [0, 7, 143], "25003038": 39, "250154": 133, "250636": 133, "251879": 133, "252": [38, 152], "252436": 133, "25284171": 39, "25286816": 39, "253": 30, "253775": 133, "25403512": 127, "25408328": 151, "255": [69, 76], "255001": 133, "25502": 151, "25558087": 37, "256": 42, "2562": 41, "25647226": [147, 152], "2566277": [147, 152], "257": 34, "258": [50, 96, 133], "25839": 5, "259": [50, 96], "259134": 151, "2593743975": 37, "25956201": 151, "25arrai": 151, "25it": 152, "26": [41, 46, 95, 133, 137, 151, 152], "260": 38, "26006752": 49, "26006763": 49, "26006766": 49, "26006767": 49, "26006806": 49, "26008336": 49, "26026098": 49, "2607": 76, "261": [50, 96], "26158619": 49, "26193455": 127, "262": [50, 96], "26223973e": 151, "26246745": 39, "26271037": 39, "262e": 151, "263": [102, 127, 152], "2632": 1, "264": [50, 96, 133], "26430767": 151, "264421": 133, "265": 133, "2650": 71, "265234": 151, "26551159": [147, 152], "2656424": 39, "266": 133, "26607016": [147, 152], "26666667": 153, "2667284": 39, "267": 32, "267439": 151, "2680305": [147, 152], "2684253": 1, "26846902": 39, "26882432": 102, "269": 133, "2693": 1, "26972154": 127, "27": [4, 38, 45, 47, 50, 65, 72, 78, 82, 95, 135, 151, 152, 161], "270": 133, "27146251": 39, "272": [127, 152], "27244608": 127, "27375593": 39, "274": [127, 152], "27440288": 39, "27478507": 39, "275": 50, "275082": 49, "276": [30, 151], "27648644e": 151, "2764993": 39, "276e": 123, "27758988": 151, "27760809": 39, "278": 152, "27852808": 39, "279": 81, "27982588": 151, "27991444": [147, 152], "28": [50, 69, 75, 77, 83, 143, 144, 148, 151, 153, 154], "280179": 133, "28060553": 39, "28066508": 39, "28174985": 151, "281930": 133, "282259": 133, "28267571": 39, "28299553": 39, "283": 133, "28331452": 151, "284": 146, "28474811": 39, "28558733": 39, "286": 152, "28807817": 39, "28883234": 39, "289": 33, "2890": 133, "2890942": [147, 152], "28968131": 151, "28it": 152, "28x28": 69, "29": [1, 37, 38, 49, 66, 77, 78, 85, 94, 95, 127, 151, 152, 162], "29090909": 127, "291": [151, 152], "2911889": 39, "2919282": 49, "29209002": 127, "2931": 133, "29322588": 39, "29354962": 39, "29371761": 39, "29415949": 39, "29490632e": 151, "2949430162": 151, "295": 133, "2950": 71, "2951e": 71, "29564967": 39, "296247": 133, "29641219": 151, "296414": 133, "2966": 1, "2968": 133, "2970796": 39, "2979": 71, "298": 152, "2980": 133, "298273": 133, "298375": 133, "29865557": 39, "2990": 133, "29905": 151, "2996015": 39, "299748": 133, "2_": [35, 52, 66, 67, 96, 107], "2_000": [151, 152], "2_1": 67, "2_2": 67, "2_3": 67, "2_n": 107, "2b": 95, "2d": [26, 33, 37, 40, 75, 77, 78, 79, 82], "2draw": 151, "2e": [66, 95], "2e_i": 38, "2f": [38, 39, 41, 42, 49, 77, 83, 95, 96, 123, 130, 134, 144, 145, 147, 150, 152, 161, 162], "2k": 51, "2kb": 151, "2l": [19, 34, 35], "2m": [46, 90, 96], "2n": 44, "2nd": [1, 15, 23, 34, 37, 73, 79, 93, 102, 136, 148, 159], "2p": 19, "2px": 42, "2r": 150, "2sigma": 41, "2w": 35, "2x": [5, 34, 101], "2x2": 4, "2x3": 136, "2z": 7, "3": [0, 1, 3, 4, 6, 9, 15, 17, 19, 22, 23, 25, 30, 33, 34, 35, 37, 39, 40, 42, 45, 46, 47, 49, 50, 51, 53, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 85, 94, 95, 96, 99, 100, 101, 102, 113, 120, 123, 126, 127, 129, 133, 134, 135, 136, 137, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 162], "30": [0, 7, 9, 30, 37, 38, 40, 50, 76, 82, 83, 95, 96, 126, 127, 130, 134, 143, 151, 152, 162], "300": [40, 71, 149], "30000": 73, "30006940e": 151, "30017032": 39, "30052148": 78, "3006664": 39, "301": [5, 9, 30], "30163826": 39, "30196005": 39, "30218997": [147, 152], "3025": 5, "30253554": 39, "3027": 71, "303": 1, "30321769": 127, "30392866": 127, "30471708": 130, "3049": 1, "30496125": 151, "3050791": 39, "30526704": 39, "3053064": 39, "30544652": 102, "306": 1, "30620607": 39, "3072": 75, "307e": 123, "30833925": 39, "30847308": [147, 152], "3088": 127, "309": [1, 126, 152], "30970591": 39, "30979757": 123, "30981676": 39, "30it": 152, "31": [35, 37, 38, 67, 78, 95, 126, 130, 151, 152, 156], "310": 126, "31027229": 39, "310e": 123, "311": [126, 152], "312": [1, 126], "31216994": [147, 152], "31223869": 39, "31251261": 39, "3128273": 39, "313": 76, "31317516465288": 42, "31354772": 39, "314": 1, "31475378": [147, 152], "31497241": 151, "31515939": 39, "31563495": 39, "31594001": 39, "316": 81, "31627214": 39, "31640294": 151, "31663724": 39, "3166589": 39, "31694": 49, "31713": 133, "318": 127, "3180143": 39, "3181542": 39, "319": [1, 50, 96, 126], "3190391": 39, "31914843": 39, "31926633646394e": 83, "31932186": 39, "31935642": [147, 152], "31965694": 39, "31it": 152, "32": [50, 52, 67, 69, 75, 76, 79, 82, 95, 96, 126, 151, 152, 153, 156], "320": [50, 76, 96, 126, 152], "3200": 126, "32061622": 39, "321": [50, 96, 126], "32107876": 39, "32126591": 39, "3217": 71, "322": [42, 126], "323": [1, 50, 96, 126], "32342084": 127, "32352735": 39, "323533a0": 1, "324": [9, 50, 96, 126], "32427424": 39, "32580419": 39, "326": [1, 50, 96], "326238": 133, "327": [50, 96], "3272": 133, "32745104": 127, "32755196": 39, "3278": 133, "327e": 127, "32847285": 127, "3285": 133, "32875387": 39, "329": [9, 82], "32933771": 39, "329492": 133, "32it": 152, "32m": 76, "33": [25, 38, 41, 67, 78, 82, 93, 95, 151, 152, 156, 161], "3306": 133, "331": 152, "3312": 133, "33145711": 39, "3315865": [147, 152], "331939": 133, "3323e": 71, "33333333": 153, "33424548": 39, "335": 9, "33513223": 39, "33587406": 39, "33722094": 39, "33776818e": 65, "3380": 71, "3380117": 39, "33844": 49, "33865576": 39, "3389": 1, "33it": 152, "34": [38, 151, 152], "340583": 133, "342": 152, "342680": 133, "342e": 123, "3436": 133, "3437": 133, "34429238": 127, "34539683": 39, "3456": 71, "3465969": 127, "347": 133, "34710546": 39, "348": 127, "3484e": 71, "349": [63, 133], "3490481": 133, "34927873": 39, "34950115": 127, "34it": 152, "35": [34, 38, 40, 82, 93, 95, 151, 152], "35010682": 39, "35016716": 39, "35054598": 39, "351": 152, "3511169": 39, "35145": 151, "35160924e": 78, "35249436": 39, "352e": 123, "353": 152, "35308331": 39, "35323281": 123, "35356722": 39, "35379069": 123, "35387043": 39, "353e": 123, "35421504": 127, "354e": 123, "355": 123, "35528451": 39, "35571726": 39, "356": 9, "356399": 133, "357508": 133, "35812806": 151, "35957131e": 151, "36": [41, 110, 136, 151, 152, 153, 156, 161], "36126959": 39, "361556": 133, "36180164": 39, "36184732": 39, "36255041": 39, "36300435": 39, "36347669": 5, "364": 152, "36476058": 127, "36633201": 39, "36723181": 39, "369": 63, "36919047": 39, "36928": 76, "36949272": 39, "37": [32, 38, 41, 66, 97, 100, 105, 112, 151, 152], "370": 30, "3705584": 39, "371": 152, "371431589126587": 151, "371431589126587tuning_step": 151, "37167029": 39, "371e": 123, "37231386": 151, "37245685": 39, "37256166": 39, "3733791492": 133, "374658": 39, "375694": 133, "376": 152, "37646927": 39, "376547": 133, "37756379": 39, "37975819": 39, "37999916": 39, "37it": 152, "38": [32, 38, 78, 82, 107, 113, 136, 151, 152], "38049834": 5, "38196315": 39, "382187": 133, "38263794": 39, "38271517": 39, "384": 82, "38422765": 39, "3845": 71, "384659": 127, "38496733": [147, 152], "38499134": 39, "38560229": 39, "38631426": 39, "38653915": 39, "387": [1, 152], "38755787": 39, "38759303": 39, "388": [9, 127], "38824359": 39, "3887794": 39, "389": 151, "38980737": 127, "38it": 152, "38m": 76, "39": [34, 63, 77, 83, 95, 133, 151, 152, 153], "39014596": 39, "39038637": 127, "391": 152, "39128": 151, "39206493": 65, "39233491": 39, "39286306": 5, "393": 41, "3930016": 39, "39310924": 39, "39334122": [147, 152], "39378773": 39, "394": 81, "39401868": 39, "39442803": 39, "3947": 71, "39470366": [147, 152], "395": 1, "39539703": 39, "39607937": 39, "397": 69, "39788042": 39, "39799638": [147, 152], "398": 1, "39859839": 39, "3988432": 39, "399": [127, 152], "39916273": 49, "39917309": 49, "39917581": 49, "39917625": 49, "39922144": 49, "39931716": 127, "39977467": 39, "399836": 133, "39984394": 39, "3998612": 39, "39it": 152, "3arrai": 151, "3d": [23, 37, 65, 76, 130], "3e": 66, "3f": [6, 9, 30, 33, 34, 38, 50, 69, 81, 82, 95, 96, 102, 123, 129, 133, 143, 147, 152, 161, 162], "3gb": 137, "3m": 46, "3rd": [15, 34, 37, 78, 86, 93, 102, 159], "3x": 23, "3x3": 136, "3x4": 136, "4": [0, 1, 2, 3, 4, 6, 8, 9, 12, 17, 19, 22, 23, 25, 30, 33, 34, 35, 37, 39, 42, 43, 46, 47, 49, 50, 53, 58, 59, 61, 63, 66, 69, 70, 73, 76, 78, 81, 82, 88, 90, 94, 95, 96, 118, 121, 123, 126, 127, 129, 133, 134, 135, 136, 137, 143, 144, 145, 147, 150, 151, 152, 153, 161, 162], "40": [5, 33, 38, 40, 77, 95, 123, 126, 151, 152, 153], "400": [30, 71, 78, 82, 123, 151], "4000": [123, 145, 162], "40000": [73, 129, 156], "40019547": 39, "40020999": [147, 152], "401": 33, "40120646": 49, "402": 1, "40262524": 151, "4027718": 127, "4028944": 127, "403": 127, "40340703": 127, "40349164": 39, "40391367": 39, "404": 30, "40433212": 39, "40615693": 39, "40665625": 39, "40753871": 39, "40754": 39, "4079e": 71, "4089": 1, "40890054": 39, "40925339": 39, "4096": [25, 30], "40977641": 127, "4097766": 151, "40_000": 151, "40it": 152, "41": [1, 38, 136, 151, 152], "410": 152, "41000": 126, "41005165": 39, "41026575": 39, "41157049": 130, "4133": 71, "41347606": 39, "415201": 133, "41536733": 127, "41677945": 126, "417": 30, "417302": 39, "41767401": 39, "417e": 123, "41m": 76, "42": [17, 34, 38, 40, 73, 82, 93, 95, 96, 123, 130, 133, 151, 152], "4202822": 39, "42084371": 39, "421": 152, "42142": 49, "4230685e": 76, "42349435": 39, "42361443": 39, "42589833": 151, "42592018": 39, "426": 30, "4262e": 71, "42844641": 151, "42887697": 39, "429": 152, "4292e": 71, "42952614": 39, "42e": 95, "42m": 76, "43": [31, 38, 49, 71, 78, 80, 83, 95, 151, 152], "43085135": 39, "43103028": 127, "43167399": 49, "43181": 130, "4321": 151, "433": 152, "43302619": [147, 152], "43426185": 39, "43499832": 39, "435163": 133, "4352351e": 69, "43549215": 39, "4359862": 39, "43621127": 39, "4367634": 39, "43769457": 39, "438136": 133, "43816635": 39, "4396473": 151, "43it": 152, "43rd": 133, "44": [34, 38, 63, 77, 123, 127, 151, 152], "44031858": 39, "44043213": 151, "441": 6, "441264": 133, "44136444": 39, "44250528": 39, "44287693": 39, "44305844": 39, "443217": 133, "4438": 151, "44450746": 151, "445": 152, "44509671": 39, "44513761": [147, 152], "4454902": 151, "446": 9, "446453": 133, "44703778": 127, "44730122": 39, "448": [38, 152], "44838065": 39, "4489894": 39, "44936865": 39, "45": [16, 78, 82, 83, 151, 152, 162], "450": 38, "45015551": 39, "45021774": 39, "45027229e": 127, "4504": 76, "45069099": [147, 152], "45112294": 39, "45128402": 39, "45142926": 39, "45161595": 39, "45194604": 39, "452553": 133, "4529": 71, "45306603": 151, "45391758": 39, "45422583": 39, "45454545": 127, "45459971": [147, 152], "45547004": 127, "45576187": 5, "4558919": 127, "455947": 133, "45652739": 39, "457": [1, 152], "45794708": 39, "458027": 133, "45810824": 39, "46": [1, 78, 151, 152, 162], "46012093": [147, 152], "46031844": 39, "46073481": 127, "46089238": 39, "4609029": [147, 152], "461": [9, 63], "4611641": 39, "46120675": 39, "462": 41, "46210794": 39, "46277698": 39, "46353432": 39, "463861": 133, "46461494": 151, "46476976": 50, "46664327": 39, "46697967": 39, "467": 152, "4674011": 49, "4675": 71, "46765106": [147, 152], "46776598": 39, "46860468": 151, "469": 152, "4696879e": 69, "469849": 133, "4698802": 39, "46it": 152, "46m": 76, "47": [151, 152], "47008945": 151, "47016034": 39, "47054044": 50, "47070392": [147, 152], "470714": 133, "47073986": 39, "470e": 123, "47182825": 39, "472": 1, "47239468": 127, "47277581": 151, "47302347": 127, "47385946": 151, "474": 40, "4741181": 127, "47431968": 39, "477": 127, "47758959": 151, "47761018": 39, "47764353": 39, "47985237": 39, "47it": 152, "47x": [49, 94], "48": [1, 34, 38, 77, 82, 83, 95, 151, 152], "480": 133, "48018748": 130, "481": [9, 152], "48185445": 39, "48290554": 39, "48365209": 39, "48369614": 39, "484": [81, 143], "4840": 126, "484537": [147, 152], "48550": 1, "486": [30, 152], "48673828e": 151, "48679509": 34, "488": 151, "48851815": 39, "4888": 71, "48946635": 5, "48954362": 39, "49": [1, 19, 38, 78, 95, 130, 151, 152, 161], "49042732": 39, "49056104": 39, "49102772": 39, "49152": 75, "49154287": 39, "49167851": [147, 152], "492": [41, 152], "49233656": 39, "493": 32, "49318338e": 127, "49355935": 39, "493754387128709": 78, "494": 32, "4940954": 133, "49434165": 39, "49515861": 39, "49521132": 39, "49553414": 39, "49588477": 39, "49602605": 39, "49681303": 65, "497": 130, "4972691": 39, "497630": 133, "49810818": 39, "4982711": [147, 152], "499": 151, "49it": 152, "4_000": 151, "4d": [75, 143], "4e": [71, 96], "4f": [71, 82, 96, 129], "4th": 15, "4x": 5, "4x6": 136, "5": [0, 1, 2, 3, 4, 6, 9, 11, 12, 13, 17, 19, 25, 29, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 51, 53, 67, 69, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 90, 92, 94, 95, 96, 99, 102, 120, 121, 123, 126, 127, 129, 133, 134, 135, 136, 137, 143, 145, 146, 147, 149, 150, 151, 152, 153, 159, 161, 162], "50": [17, 35, 38, 40, 41, 47, 50, 71, 73, 74, 76, 77, 79, 82, 83, 94, 95, 96, 106, 126, 129, 130, 132, 133, 136, 143, 144, 147, 151, 152, 153, 156], "500": [0, 7, 17, 33, 34, 37, 42, 71, 73, 77, 83, 93, 102, 123, 126, 132, 142, 143, 144, 145, 151], "5000": [0, 7, 9, 41, 71, 73, 96, 123, 144, 151, 161], "50000": [17, 147, 152], "500000": 126, "500px": [9, 132], "50142959": 39, "50172511": 39, "50178644": 39, "5018": 40, "50249434": 39, "50274088": 39, "503": [9, 130], "50315846": 127, "50318481": 39, "50346685e": 78, "50392793": 151, "504": 152, "50451298": 127, "505": 63, "5053819": 39, "50580623": 39, "50598029": 39, "506": [32, 50, 152], "50887486": 39, "50it": 152, "51": [19, 34, 41, 63, 151, 152, 162], "5103076": 39, "51066278": [147, 152], "510803461074829": 151, "510803461074829tuning_step": 151, "51093777": 39, "511": 50, "512": 42, "51238578": [73, 93], "51292982": 39, "5135": 76, "51350548": 39, "514219": 133, "51484355": 39, "51507361": 39, "5154138": 39, "51570956": 151, "516": 152, "5163e": 71, "51693696": 127, "51790686": [147, 152], "518": 50, "518895": 133, "51981682": 39, "52": [32, 41, 63, 95, 151, 152], "520319": 133, "52057634": 39, "52081508": 39, "5208429": 39, "52132764": 39, "52138593": 39, "52160464": 130, "52241915": 39, "52264716": 151, "522836": 133, "52287579": 39, "52343734": 39, "52385799": [147, 152], "52462712": 39, "52475049": 39, "525": 152, "5251309": 151, "527": 152, "52800342": 39, "52832571": 39, "52884307": 39, "52887975": 39, "52946532": 39, "52976291": 39, "52it": 152, "53": [38, 95, 151, 152], "53035547": 39, "53116379": 39, "531280": 133, "53132618": 39, "532": 63, "533": 1, "53384514": 39, "5343526": 127, "534362": 133, "53499597": 5, "53522913": 123, "53594643": 39, "536": 1, "53653633": 39, "538": [127, 152], "5385964": 39, "53920701": 39, "53it": 152, "54": [34, 38, 69, 82, 136, 151, 152, 162], "54005717": 39, "5400699": 39, "54026428": 127, "54028232": 39, "54077761": 127, "54092045": 151, "541605": 133, "54167554": 39, "54264529": 39, "54301214": 39, "54335911": 39, "54388244": 39, "544": 152, "544439": 133, "5447030e": 76, "545": 30, "5468e": 71, "54705484200538": 42, "54747503": 39, "54755159": 5, "5476": 76, "54812958": 39, "549": 152, "54it": 152, "55": [16, 34, 38, 82, 95, 151, 152], "550": 5, "5505375": 39, "55116388": 127, "55126197": 39, "55155435": 127, "55210482": 39, "55221938e": 151, "55267166": 127, "55287144": 39, "5533008": 39, "55466855": 151, "5548": 71, "554820483493709": 77, "555": 30, "55501599": 39, "55588619": 39, "55607351": 39, "556378888999681": 123, "55682807": 39, "55743945": 39, "55777072": 39, "558": 30, "55853654": 151, "55880554": 39, "559": 9, "55912398": 39, "5593865e": 69, "55it": 152, "56": [34, 38, 76, 151, 152], "560": 152, "56024485": 78, "560kb": 151, "56100234": 39, "5612e": 71, "56179973": 39, "56218": 49, "56249102": 39, "5627611": 39, "563167": 133, "56372833": 127, "564": 152, "56438286": 39, "56453928": 151, "56504332": 39, "56515267": [147, 152], "56516224": 39, "56536": 133, "56557871": 151, "56569145": 102, "56709265": 102, "56835227": 49, "56877654": 65, "56it": 152, "57": [32, 82, 96, 133, 151, 152], "570": 76, "5701": 1, "5707963": 49, "57085772": 39, "571": 152, "57180488": 39, "572069": 133, "57261246": 151, "57296273": 39, "57344458": 39, "57357138": 39, "57546791": 39, "57546953": 127, "57550721": 39, "57582227": 5, "5759": 151, "576": 76, "5765217": 39, "57709": 49, "57714304": 39, "57846442": 39, "57it": 152, "57x": [49, 94], "58": [16, 38, 41, 95, 127, 137, 151, 152], "580147499327772": 78, "58033011": 39, "58085122": 39, "5810621": 39, "58144397": [147, 152], "58281521": 39, "583": [123, 152], "583595": 133, "584": 152, "58464661": 39, "5849557": 151, "5851531": 39, "585662": 39, "58591043": 39, "586497": 39, "58662319": 39, "58697069": 39, "58836084": 39, "5892963": 5, "5894": 151, "5898": 76, "59": [34, 51, 63, 82, 96, 151, 152], "59003946": 39, "5911": 71, "5913": 71, "59197196": 151, "5924728": 39, "59274796": 39, "59275998": 39, "59357852": 39, "594": [81, 152], "59767085": 39, "598": 41, "59912181": 39, "59921324": 39, "59it": 152, "5a": 92, "5d": 92, "5r": 79, "5th": [15, 136], "5x5": 136, "6": [0, 3, 4, 5, 8, 13, 15, 19, 23, 25, 30, 33, 34, 37, 38, 39, 40, 41, 44, 47, 49, 50, 51, 53, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 82, 83, 88, 93, 94, 95, 96, 100, 102, 121, 123, 126, 127, 129, 133, 134, 136, 143, 144, 145, 148, 150, 151, 152, 154, 161, 162], "60": [16, 34, 38, 41, 76, 96, 121, 123, 151, 152], "600": 71, "6000": [53, 126], "60000": 69, "600px": 0, "60118718": 39, "602": [30, 67], "60231928": 39, "6024509": 39, "603": 152, "60324647": 39, "60337958": 39, "60350366": 39, "603636": 133, "60471697": 39, "60531032": 39, "606": 152, "60640394": 39, "6065484": 39, "60801169": 127, "60818376": 39, "60830612": 39, "60832959": 127, "6085147": 39, "60878366": 39, "6088": 1, "60885594e": 151, "609": 81, "61": [1, 38, 78, 95, 151, 152], "61223252": 39, "612939": 133, "613": 127, "61320418": [147, 152], "61336137": 39, "613579": 133, "61438456": 151, "6145": 76, "6147": 5, "61472628": 39, "61516775": 39, "61594565": 39, "6169496": 39, "617": 152, "6170278": 49, "61720311": 39, "61774201": 151, "61798553": 39, "61838026": 39, "61853913": 39, "618982": 133, "619": 1, "61e": 95, "61it": 152, "62": [34, 95, 151, 152], "62048248": 39, "62060066": [147, 152], "6209": 71, "62091229": 39, "6210827": 39, "621102": 133, "62133597": [147, 152], "6218035": 39, "622": 152, "6222546e": 76, "62246787": 49, "62270733": 130, "62284909": 39, "62289897": 49, "62290969": 49, "62290982": 49, "6229106": 49, "62291338": 49, "62336218": 39, "62434536": 39, "62471505": 39, "62519531": 39, "62556168": 39, "62688268": 39, "626e": 123, "62743708": 39, "62765075": 39, "62896866": 152, "629": 152, "62it": 152, "63": [4, 37, 38, 41, 46, 63, 151, 152], "63019567": 39, "63043757": 39, "6307441": 39, "63169151": 39, "63250358": 151, "633949": 133, "634137310269272": 83, "6350e": 71, "63546195": 39, "63658341": 39, "63738791": 39, "63750082": [147, 152], "63781955": [147, 152], "6385206": 130, "63it": 152, "64": [34, 41, 42, 76, 95, 96, 133, 137, 151, 152, 161], "640": 126, "6407759": 39, "64098587": 39, "641": 152, "6418": 76, "64189041": 127, "64435367": 39, "64659002": 39, "6471": 1, "64775015": 39, "648": 32, "64864364": 39, "64912811": [147, 152], "6497": 76, "64it": 152, "65": [1, 82, 95, 130, 136, 145, 151, 152, 161], "650": 76, "65032321": 39, "65065728": 39, "65101581": 39, "65130355": 39, "652": 152, "65223506": 39, "65458015": 39, "65498998": 39, "65501279": 39, "65600": 76, "65609929": 39, "65614632": 39, "656e": 123, "657041": 133, "65712464": 39, "65732421": 39, "65792424": 151, "6590498": 39, "65980218": 39, "66": [76, 78, 82, 95, 151, 152], "660": 152, "66023155": [147, 152], "66085975": [147, 152], "66102029": 39, "66168108": 39, "6619e": 71, "66236766": [147, 152], "663": 81, "66383179": 130, "664": 152, "66415954": 151, "66479728": 39, "666597": 133, "667239": 133, "66804833": 39, "66806749": 151, "668172": 133, "66871683": 39, "669": 1, "66it": 152, "67": [34, 38, 95, 151], "670067": 1, "67090927": 151, "67094845": 39, "671": 127, "67244070e": 65, "67261975": 39, "67262221": [147, 152], "672721": 133, "6735005": 39, "67393869": 39, "674": 81, "6743961": 39, "67457071": 39, "67471153": 39, "67486677": 49, "67545381": 39, "6755": 71, "67579578": 39, "676": 152, "67660201": 151, "6775828": 39, "67780757": 39, "6780": 76, "67802427": 151, "67887983": 123, "678e": 123, "67it": 152, "68": [9, 14, 15, 17, 19, 30, 34, 35, 37, 38, 40, 41, 44, 126, 127, 130, 147, 151, 152], "680": 152, "68006984": 39, "680144": 133, "6801984": 39, "682": 40, "68255141": 39, "683": 41, "6830988": 39, "68400133": 39, "68543614": 39, "68571612": 151, "6858752e": 76, "687": 152, "6870999932289124": 76, "6871": 76, "6875": 76, "68771659": 39, "68851": 49, "689": 151, "68901502": 39, "6891788": 151, "689345": 133, "68988323": 39, "68it": 152, "69": [34, 38, 82, 151, 152], "690617": 133, "69087868": 39, "692": 30, "6924546": 39, "69257435": 39, "6932e": 71, "69336623": 39, "69346593": 39, "69379599": 39, "69380911": 39, "69427308": 39, "69509206": 39, "696e": 123, "698": 152, "6980": 1, "69803203": 39, "6984613": 39, "699": [30, 152], "69902385": 39, "6993e": 71, "69942478": 5, "69it": 152, "6e": [50, 143], "6f": 78, "6omndqaaqbaj": 1, "7": [0, 1, 4, 5, 13, 17, 25, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 47, 49, 50, 51, 53, 69, 70, 71, 76, 77, 78, 81, 82, 83, 92, 94, 95, 96, 107, 113, 121, 123, 126, 127, 129, 130, 133, 134, 135, 136, 143, 144, 147, 150, 151, 152, 161], "70": [0, 4, 7, 34, 76, 95, 102, 127, 130, 151, 152], "700": 71, "70018815": 39, "70098212": 39, "70179412": 39, "70190716": 39, "70239643e": 78, "702428404296162": 83, "70263812": 39, "7029": 151, "703": 143, "70335885": 39, "704": 143, "7040": 76, "70459417": 39, "70474211": 39, "70548352": 39, "707": 51, "70816002": [147, 152], "7084054": 39, "709": 152, "709698": 133, "70it": 152, "70px": [9, 132], "71": [1, 16, 34, 38, 95, 96, 127, 136, 151, 152], "71042050e": 78, "71066184": 39, "71100266": 39, "71146298": 127, "71195902": [147, 152], "71269214": 39, "713": 134, "71304905": 39, "713163": 133, "71361508": 39, "714": 123, "7141": 71, "7147896": 39, "7151525e": 69, "71523518": 127, "71527897": [147, 152], "71563966": 151, "71713645": 39, "71826373": 39, "71829074": 39, "719": [147, 152], "72": [34, 38, 63, 82, 96, 151, 152, 156], "720": 152, "72090228": 39, "72171129": 39, "72176": 133, "722702": 39, "724": 75, "72415394": 39, "72476598e": 151, "7249": 71, "725474": 39, "72552256": 39, "72555052": 39, "72591685": 39, "7272": 71, "72744124": 39, "7278135": 39, "72875201": [147, 152], "7288": 133, "729": [127, 151], "72900394": 151, "72953922": 39, "73": [72, 76, 82, 145, 151, 152, 162], "73013751": 130, "731": 152, "731000": 133, "73140252": 39, "7316287": 39, "732": 95, "73211192": 39, "73268281": [147, 152], "7329e": 71, "73302323": 39, "733096": 133, "73334667": 151, "7334831242552866": 78, "73367312": 39, "73378149": 39, "735": 127, "73625": 49, "738": 152, "739": 127, "73953394": 39, "73it": 152, "74": [34, 151, 152, 156], "74055645": 39, "74101715": 39, "742": 152, "74204416": 39, "74335654": 39, "7434395": 151, "74481176": 39, "74481415": [147, 152], "74488454": 39, "74519611": 126, "74545455": 127, "74582013": 39, "74643509": 39, "747": 127, "74733116": 127, "74832579": 39, "749765": 133, "75": [16, 32, 35, 38, 41, 65, 80, 82, 130, 133, 151, 152], "750": 41, "75041164": 39, "750445": 133, "7504512": 130, "75062962": 39, "75133724": 39, "75136522": 39, "75188227": 151, "75273831e": 127, "753": 152, "75333243e": 151, "75539203": 39, "7562e": 71, "756352": 133, "757": 152, "75713609": 151, "75854047": 151, "75880566": 39, "75it": 152, "76": [38, 95, 151, 152, 156, 162], "760": 32, "76024923": 39, "76041518": 39, "76201118": 39, "76205806": 39, "76212473": 39, "76291349": 39, "76314662": 39, "76356305": 39, "764": 152, "7653351": 39, "76629285": 151, "76687926": 39, "7673e": 71, "76781774": [147, 152], "76795995": 39, "76864999": 151, "76916026": 39, "76994186": 39, "76e": 95, "76it": 152, "77": [83, 151, 152], "77042575": 39, "77123417": 39, "77124583": 39, "77154192e": 151, "77185931": 39, "77233431e": 151, "77288737": 39, "77323981": 39, "77368576": 39, "77496035": 151, "77576423": 39, "776": [6, 152], "776e": 127, "7772263": [147, 152], "77741921": 39, "77758597": 39, "77767186": 39, "777777": [69, 76], "777e": 123, "778": 151, "7781": 71, "77811": 133, "77817418": 39, "77896364": 127, "7789711": 39, "77it": 152, "78": [37, 41, 77, 95, 123, 151, 152, 162], "78002714": 39, "7802556": 39, "78046993": 39, "78126654": 39, "78186099": 151, "782": 133, "7837": 129, "784": 69, "78421011": [147, 152], "78477065": 39, "785061": 133, "78522692": 39, "78534616": 39, "78666187": 39, "78689273": 130, "78693299": 133, "787": [133, 152], "78730236": [147, 152], "78975468": 39, "7898": 5, "789e": 123, "78it": 152, "79": [145, 151, 152, 162], "79001759e": 151, "79024706": 39, "7903551e": 69, "7908587e": 69, "791": 81, "79110577": 39, "79203455": 127, "79215821": 39, "79280687": 39, "793167": 133, "79375551": 127, "79380228": 151, "79452824": 39, "7947": 129, "795": 152, "79502609": 39, "7957695978": 81, "79660555": 39, "798": 152, "7980638": 39, "799": 81, "79924193": 39, "8": [1, 2, 7, 15, 25, 30, 33, 34, 37, 38, 39, 40, 41, 42, 46, 47, 49, 50, 63, 65, 69, 70, 71, 73, 76, 77, 78, 79, 81, 82, 83, 93, 95, 96, 102, 107, 121, 123, 126, 127, 129, 133, 134, 135, 136, 137, 143, 144, 147, 150, 151, 152, 161], "80": [1, 40, 41, 42, 77, 95, 126, 151, 152, 162], "800": [41, 71, 123], "80043928": 39, "80073197": 39, "800b": 151, "80100182": 39, "80106255": 39, "80116214": 39, "80186103": 39, "80358898": 39, "80413849": 39, "80494266": 39, "805": 63, "80539342": 39, "80667836": 39, "80703718": 127, "8071": 133, "80745592": 39, "8079963": 39, "8080e": 71, "80816445": 39, "80884436": 39, "8094517": 39, "80977897": 39, "80it": 152, "80kb": 151, "80px": 9, "81": [1, 46, 151, 152, 161, 162], "810": [1, 152], "81020792": 127, "81053491": 39, "81095167": 39, "81163685": 78, "81252782": 39, "81304498": 39, "81342101": 39, "81343023": 39, "81434313": 39, "815": 152, "81582367": 39, "81604368": 39, "816454": 133, "8165998": 39, "816847": 133, "81693801": 39, "81757959": 39, "81768187": 39, "818": 40, "81889683": 39, "8190797": 39, "81it": 152, "82": [151, 152], "82033": 130, "82038771": 39, "821": 152, "8223678": 39, "82294167": 127, "82400562": 39, "82401733": 39, "82454103": 39, "82458463": 39, "82502982": 39, "82529684": 39, "82539979": [147, 152], "82581966": 39, "82699862": [147, 152], "827": 6, "82723844": 127, "8273e": 71, "82757179": 39, "82797464": 39, "82818662": 39, "82it": 152, "83": [82, 123, 151, 152, 162], "8300e": 71, "831": 152, "83180116": 39, "83189927": 127, "83351405": 39, "8337": 71, "83471763": 39, "835": 152, "83599203": 39, "83600472": 39, "83624672": 151, "83745497": 151, "8383258e": 69, "83863475": 39, "83880168": 39, "83898341": 39, "839818": 133, "8398299": 39, "8399": 76, "83e": 95, "83it": 152, "84": [1, 5, 17, 38, 41, 50, 78, 94, 96, 123, 130, 143, 147, 151, 152], "84086156": 39, "841": 152, "8415": 71, "84222474": [147, 152], "842436": 133, "84267539": 127, "843": 95, "84300633": 39, "84501737": 39, "84550881": 39, "84589891": 5, "84616065": 39, "84858": 1, "84887013e": 151, "849": 151, "84949567": 39, "84955076": 151, "84958685": 39, "849arrai": 151, "85": [9, 42, 73, 83, 93, 151, 152, 162], "85129577": 39, "85143789": 39, "8515102": 39, "85152915": 151, "852": 152, "85257974": [147, 152], "85270406": 39, "852e": 123, "85300949": 39, "85328122": 39, "85328219": 39, "85372673": 39, "853835": 133, "854": [41, 152], "8546e": 71, "85555595": 39, "85565861": 39, "85567185": 126, "85680425": 39, "8574818": 39, "85753327": 39, "858185": 133, "85987097": 39, "85it": 152, "86": [77, 95, 151, 152, 162], "86028827": 39, "86064819": 39, "86089124": 39, "8616231": 39, "861676": 133, "862": [127, 152], "86334532": 39, "86339779": [147, 152], "86355526": 39, "86402267": 39, "865": 152, "86520687": 39, "86540763": 39, "86620796": 39, "86647138": 39, "86828789": [147, 152], "86832437": 39, "86888616": 39, "86905703": 130, "8694594e": 76, "86it": 152, "87": [1, 51, 81, 83, 93, 151, 152, 162], "8709698": 39, "87123103": 151, "8726145e": 69, "87270": 49, "873": 152, "8743e": 71, "87583893": 39, "87616892": 39, "87710977": 39, "87784598": 39, "87798127": 39, "87809431": [147, 152], "878123": 133, "879246": 151, "87953543": 39, "87985002": 39, "87e": 95, "87it": 152, "88": [1, 38, 72, 95, 151, 152], "8805": 50, "8808846": 39, "88094581": 39, "88122883": 39, "88176277": 127, "8820": [50, 148], "88268965": 39, "88288931": 39, "88352998": 39, "88355585": 39, "884": [127, 152], "88401481": 39, "88490881": 39, "88512895": 39, "88514116": 39, "8858258": 39, "88583608": 39, "8865639": 39, "88772753": [147, 152], "88848273": 151, "88888889": 153, "88955297": 39, "8895a785550b": 135, "88e": 95, "88it": 152, "89": [82, 136, 151, 152, 162], "89000851": 39, "89160793": 39, "8922875": 39, "893": [50, 152], "89320601": 39, "89342693": 39, "89353988": 39, "89354624": 151, "89399564": 151, "894": 152, "89465529": 39, "895": 50, "896": 76, "89711278": 39, "89806796": 39, "89825413": 39, "89938082": 39, "89984477": 39, "89it": 152, "8x8": [78, 82], "9": [0, 7, 12, 15, 34, 37, 38, 39, 41, 42, 45, 46, 47, 49, 50, 53, 69, 71, 73, 76, 79, 80, 82, 83, 92, 93, 94, 102, 107, 118, 121, 123, 126, 127, 130, 133, 135, 136, 137, 147, 151, 152, 153, 161], "90": [1, 44, 77, 79, 127, 130, 151, 162], "900": 71, "90010873": 39, "90085595": 39, "90148689": 39, "90159072": 39, "902": 152, "90207746": 49, "90209405": 49, "90209893": 49, "90209978": 49, "90215938": 49, "902340": 1, "90284564": 39, "90399917": 39, "90448499": 49, "90465871": 39, "9050": 71, "90508815": 39, "90575218": 39, "90591928e": 127, "906": 152, "9063": 76, "9069": 71, "90712913": 151, "90756768": 39, "90907236": 127, "90909091": 127, "90966167": 39, "9099": 76, "90it": 152, "91": [1, 29, 127, 136, 151, 152, 162], "9104236": 39, "9116924877687354e": 78, "91197": 1, "912": 152, "9134397": 127, "91360943": 39, "9140e": 71, "9150833487510681": 69, "9154": 76, "91549197": 39, "91549927": 39, "91582": 133, "916": 152, "917": 127, "91745894": [147, 152], "91826915": [147, 152], "91858784": 151, "91887782": [147, 152], "918992": 133, "91928931": 39, "91979229": 39, "91it": 152, "92": [33, 38, 95, 151, 152, 162], "92001793": 39, "92019511": [147, 152], "92061512": 39, "92145007": 39, "9217895": 151, "92319798": 39, "92332064": 39, "923602": 133, "92381543": 39, "92442829": 39, "925": 1, "92550121": 39, "92583689": 151, "926": 152, "9268873": 39, "92703138": 39, "92703572": 39, "927732": 133, "92it": 152, "93": [151, 152, 162], "93037546": 39, "9306713": 39, "931": 133, "93110208": 39, "93122954": 39, "93125568": 39, "932": 152, "93212342": 39, "93258998": 39, "93272141": 39, "933": [127, 151], "93368994": 130, "93415215": [147, 152], "93514778": 39, "936": 151, "93645437": 151, "93674715": 151, "937": [127, 152], "937082": 133, "93752881": 39, "93808797": [147, 152], "93820324": 39, "939": 133, "93907827": 151, "93916874": 39, "93934751": 39, "93985929": 39, "93it": 152, "94": [1, 95, 151, 152, 162], "94056472": 130, "9406321": 39, "94317552": 39, "945": 5, "94623562": 39, "94634498": 127, "94645393": 39, "94651631": 39, "947": 81, "94750117": 39, "94844675": 151, "94881155": 39, "949": 152, "94940459": 123, "94980882": 39, "949e": 123, "94it": 152, "95": [7, 9, 17, 19, 29, 30, 35, 37, 40, 53, 77, 78, 80, 82, 83, 93, 96, 123, 126, 130, 132, 151, 152, 162], "95029742": 39, "95093225": 39, "95103519": 130, "95116949": [147, 152], "9518": 71, "952": [40, 152], "95413331": 39, "95446575": 39, "95449567": 39, "95486746": [147, 152], "95487808": 39, "955": 41, "95541062": 39, "955974163977225": 77, "9560789": 39, "9561217": 39, "9578333497047424": 69, "9586027": 39, "95it": 152, "96": [80, 82, 95, 123, 151, 152, 162], "960": 152, "9603313": 39, "96081768": 39, "96082174": 39, "96130449": 39, "96279877": 39, "962990": 133, "96318234": 39, "96371871": 39, "964": 151, "96400982": 39, "96448366": 151, "96463208": 39, "96550399": 127, "965548": 133, "96602": 5, "96622086": 39, "96653925": 39, "966899": 133, "9670395": 152, "96710175": 39, "96742435": 151, "96818283": 39, "9685333371162415": 69, "96908858": 39, "96it": 152, "97": [41, 42, 77, 78, 82, 83, 95, 147, 151, 152, 162], "97061": 133, "971": [41, 152], "97125676": 127, "9715e": 71, "972": 152, "97247061": 39, "9734333157539368": 69, "974": 32, "97409466": [147, 152], "97538304": 39, "97682437": 123, "9771833419799805": 69, "97779878": 39, "97794526": 123, "977e": 123, "978": 1, "9780470015629": 1, "9780470028735": 1, "9780521642989": 1, "9781009023405": 1, "9781108843607": 1, "97811406": 39, "9781420079425": 1, "9781491912133": 1, "9781491962299": 1, "9783319154305": 1, "978e": 123, "98": [16, 39, 53, 82, 93, 127, 151, 152, 162], "980": 69, "9800500273704529": 69, "98047744": 39, "98048015": 39, "98076837": 39, "98099948": 39, "9811": 5, "981321": 133, "9817500114440918": 69, "98181818": 127, "982": 152, "98218245": 39, "98228168": 39, "98254505": 39, "983310": 133, "9834499955177307": 69, "98365896": 127, "98401224": 39, "98495167": 39, "9850666522979736": 69, "98508459": [147, 152], "98519631": 39, "9857833385467529": 69, "986": 31, "98633519": 39, "98635218": 39, "98689281": 151, "9873354": 39, "9888561e": 76, "98907246": [147, 152], "98it": 152, "99": [16, 35, 37, 77, 78, 79, 83, 127, 130, 151, 152, 161, 162], "990": [63, 133, 162], "99052892e": 151, "990e": 123, "9915": 71, "99161615": [147, 152], "992": [34, 152], "99294077": 126, "993": 152, "9930": 82, "994": 34, "995": [95, 127], "99622225": 151, "99676119": 130, "997": [37, 40, 41, 162], "9972": 40, "99810852": 39, "998527": 78, "999": [25, 30, 107, 130], "9990": 151, "9991": 151, "9992": 151, "9993": 151, "9994": 151, "9995": 151, "9996": 151, "99962499": 39, "9997": 151, "9998": 151, "99983081": 39, "9999": 151, "9999052e": 69, "9999arrai": 151, "9999xarrai": 151, "99arrai": 151, "99it": 152, "9arrai": 151, "9e": 50, "A": [0, 1, 4, 8, 16, 18, 21, 22, 23, 24, 25, 26, 27, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 56, 61, 62, 63, 64, 65, 66, 67, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 86, 89, 93, 94, 95, 97, 99, 100, 102, 104, 105, 106, 110, 117, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 132, 134, 136, 145, 146, 147, 149, 150, 151, 152, 153, 154, 161, 162, 163], "AND": [25, 79], "AS": 76, "And": [19, 35, 37, 41, 44, 48, 59, 62, 64, 66, 69, 75, 77, 83, 86, 146, 147, 152, 153, 154, 161], "As": [4, 8, 10, 17, 23, 33, 34, 38, 41, 45, 47, 48, 51, 52, 53, 59, 63, 64, 65, 67, 68, 72, 73, 75, 76, 77, 78, 82, 83, 88, 92, 98, 102, 107, 110, 112, 126, 127, 130, 133, 134, 135, 142, 147, 151, 152, 153, 154, 156], "At": [0, 5, 8, 16, 25, 34, 37, 40, 46, 51, 53, 56, 66, 88, 94, 105, 107, 127, 143, 144, 148, 153], "BE": [34, 99, 133], "BY": [43, 56], "Be": [32, 67, 81, 90, 92, 106, 125, 133, 136, 137, 142, 156], "Being": 47, "But": [4, 7, 8, 13, 19, 21, 22, 23, 29, 31, 34, 38, 40, 41, 48, 51, 52, 58, 59, 60, 62, 63, 66, 73, 78, 82, 86, 95, 101, 115, 117, 121, 126, 136, 137, 143, 145, 146, 151, 153, 154, 159, 162], "By": [16, 25, 31, 33, 34, 38, 42, 48, 53, 64, 66, 71, 75, 77, 78, 82, 83, 102, 119, 123, 130, 134, 142, 145, 151, 156, 161, 162], "For": [0, 4, 7, 8, 9, 16, 17, 18, 19, 21, 25, 29, 30, 31, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 56, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 92, 93, 95, 96, 100, 103, 105, 110, 111, 117, 119, 125, 126, 127, 130, 131, 132, 133, 134, 136, 137, 139, 143, 144, 147, 149, 151, 152, 153, 156, 161], "If": [0, 4, 7, 9, 11, 13, 16, 17, 18, 19, 22, 23, 25, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 56, 62, 63, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 81, 83, 85, 86, 88, 90, 95, 96, 100, 117, 120, 123, 125, 127, 130, 131, 133, 134, 136, 137, 143, 146, 147, 148, 151, 152, 153, 154, 156, 159, 161], "In": [0, 2, 3, 4, 5, 7, 8, 9, 13, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 88, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 107, 110, 111, 112, 113, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 132, 133, 134, 135, 136, 137, 144, 145, 146, 147, 148, 152, 153, 154, 155, 156, 157, 158, 161, 162, 163], "Ising": [67, 117, 145, 162], "It": [0, 3, 4, 7, 8, 16, 19, 21, 22, 23, 25, 31, 34, 35, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 53, 56, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 77, 78, 79, 80, 83, 85, 88, 92, 93, 94, 95, 97, 100, 104, 105, 107, 110, 111, 113, 115, 117, 123, 127, 129, 130, 133, 134, 135, 136, 137, 142, 143, 144, 146, 147, 148, 150, 151, 152, 153, 154, 156, 159, 161], "Its": [46, 67, 78, 82, 85, 156], "No": [4, 16, 35, 44, 47, 48, 51, 59, 62, 65, 69, 70, 73, 79, 86, 93, 123, 126, 128, 151, 153, 154], "Not": [4, 35, 38, 39, 41, 42, 43, 44, 51, 64, 76, 126, 144, 147, 152, 159], "OF": 76, "OR": [25, 76, 79], "Of": [31, 34, 100], "On": [4, 21, 62, 63, 64, 66, 70, 73, 75, 123, 129, 134, 161], "One": [9, 11, 18, 19, 29, 33, 34, 38, 46, 47, 48, 52, 55, 59, 61, 62, 65, 66, 67, 69, 73, 88, 121, 133, 136, 137, 146, 148, 153, 154, 156, 161], "Or": [17, 25, 53, 58, 77, 83, 95, 130, 133, 146], "Such": [7, 34, 43, 46, 62, 64, 66, 111, 130, 153, 156], "TO": 133, "That": [15, 17, 22, 31, 33, 34, 38, 40, 41, 47, 48, 49, 53, 62, 66, 67, 68, 72, 73, 88, 95, 100, 115, 123, 130, 134, 143, 144, 145, 146, 147, 151, 152, 153, 156, 162], "The": [1, 3, 5, 8, 9, 10, 11, 12, 13, 15, 17, 18, 20, 22, 23, 24, 26, 29, 30, 31, 32, 33, 35, 37, 39, 42, 45, 47, 48, 50, 51, 52, 55, 56, 58, 59, 60, 61, 62, 64, 67, 68, 69, 70, 71, 73, 76, 79, 80, 81, 84, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 99, 102, 104, 105, 106, 107, 110, 111, 113, 115, 116, 117, 120, 122, 124, 125, 126, 127, 129, 132, 133, 135, 136, 137, 138, 139, 140, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 158, 159, 161, 162], "Their": [47, 67, 72], "Then": [3, 4, 7, 9, 19, 22, 23, 30, 34, 37, 41, 43, 44, 51, 52, 53, 65, 70, 71, 77, 79, 85, 86, 92, 125, 127, 130, 134, 135, 137, 142, 143, 144, 146, 147, 150, 152, 153, 154, 156, 158, 159, 163], "There": [4, 8, 9, 11, 16, 19, 25, 30, 32, 37, 38, 40, 43, 44, 45, 46, 47, 51, 56, 60, 63, 66, 67, 73, 75, 82, 86, 90, 95, 97, 104, 115, 129, 130, 132, 133, 134, 137, 143, 144, 146, 148, 151, 153, 154, 156, 163], "These": [4, 8, 22, 34, 37, 39, 43, 44, 45, 47, 48, 51, 52, 59, 61, 64, 65, 66, 67, 68, 69, 71, 72, 75, 82, 85, 88, 94, 95, 96, 101, 107, 110, 126, 127, 129, 130, 134, 147, 148, 151, 152, 154, 156, 161, 162], "To": [0, 8, 15, 16, 18, 25, 30, 34, 35, 38, 39, 43, 44, 46, 47, 48, 50, 51, 52, 53, 59, 61, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 81, 86, 94, 96, 101, 102, 106, 117, 130, 134, 137, 143, 144, 146, 147, 150, 152, 153, 154, 156], "Will": [17, 23, 34, 82, 102], "With": [4, 7, 9, 16, 29, 30, 34, 35, 40, 41, 44, 46, 47, 51, 53, 62, 65, 66, 67, 68, 69, 72, 76, 79, 86, 95, 97, 104, 133, 135, 147, 151, 152, 156, 161], "_": [4, 6, 7, 9, 10, 11, 12, 19, 23, 24, 30, 33, 34, 35, 39, 44, 45, 46, 48, 52, 53, 64, 65, 66, 67, 72, 73, 77, 78, 80, 81, 82, 83, 86, 92, 93, 95, 97, 100, 105, 106, 107, 113, 117, 123, 125, 127, 129, 130, 135, 137, 147, 150, 152, 153, 156, 161], "_0": [4, 39, 42, 53, 97, 147, 152, 153], "_1": [0, 7, 34, 48, 65, 67, 68], "_2": [34, 48, 66, 67, 100], "__": [73, 93], "_________________________________________________________________": [69, 76], "__enter__": 126, "__former_attrs__": [50, 96], "__future__": 76, "__getattr__": [50, 96], "__init__": [9, 50, 71, 96, 123, 126, 149, 150], "__version__": [38, 41, 50, 69, 96, 143, 151, 152], "_a": 53, "_adjust_frame_s": 126, "_alpha": 96, "_amp1": 50, "_amp2": 50, "_amplitud": 96, "_background": 96, "_base": 50, "_beta": [50, 96], "_check_optimize_result": 81, "_config": 0, "_d": [121, 123, 148], "_data": 9, "_execute_child": 126, "_fig": 126, "_g": [44, 121], "_generatorcontextmanag": 126, "_gpr": 81, "_h": [123, 126], "_i": [7, 34, 44, 46, 65, 66, 67, 97, 150, 153, 156], "_imag": 127, "_is_sav": 126, "_j": 46, "_k": [48, 66, 92], "_log": 126, "_m": [66, 67, 85], "_n": [85, 92, 107, 146], "_p": [24, 130], "_pformat_subprocess": 126, "_posit": 96, "_proc": 126, "_run": 126, "_sample_proba": [73, 93], "_setattr_cm": 126, "_sig": 50, "_sort": 41, "_supports_transpar": 126, "_t": 123, "_true": [39, 147, 152], "_v": 123, "_w": [88, 126, 132], "a0": [7, 96], "a0boogfu": 133, "a1": [17, 126, 130, 133], "a2": [17, 130, 133], "a3": 133, "a4": 133, "a_": [7, 35, 96, 125, 127], "a_0": [7, 34, 35, 49, 52, 90, 96, 99, 112], "a_1": [34, 49, 52, 82, 90, 96, 99, 112, 130], "a_1a": [34, 99, 133], "a_2": [34, 52, 82, 99, 130], "a_2a": [34, 99, 133], "a_3": [34, 99, 133], "a_4": [34, 99, 133], "a_arr": 7, "a_bar": 49, "a_grid": 37, "a_hat": 49, "a_i": [49, 53, 68, 82, 94, 130, 133], "a_j": [68, 82, 96, 130], "a_k": [49, 52, 68, 82], "a_margin": 37, "a_mat": 49, "a_max": 37, "a_n": [34, 112, 130, 156], "a_posterior": 7, "a_pt": 37, "a_tru": 37, "a_w": 132, "a_x": 53, "aa": 136, "ab": [1, 3, 6, 38, 40, 78, 82, 92, 123, 125, 136, 143, 144, 150, 153, 161], "abandon": 148, "abar": 49, "abar_": 49, "abbrevi": [119, 134], "abeca3": 1, "abil": [38, 46, 47, 64, 71, 73, 111, 134, 136, 153], "abl": [16, 25, 34, 38, 43, 44, 45, 47, 53, 56, 67, 71, 73, 78, 82, 88, 95, 131, 134, 142, 144, 161], "abnormal_termination_in_lnsrch": 81, "abolut": 38, "about": [0, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 22, 23, 25, 30, 31, 33, 34, 35, 37, 38, 40, 41, 42, 43, 46, 47, 48, 49, 50, 53, 58, 59, 62, 63, 64, 66, 67, 69, 72, 73, 76, 77, 78, 79, 81, 82, 83, 85, 86, 88, 90, 93, 94, 95, 96, 97, 101, 110, 117, 119, 120, 121, 130, 131, 132, 133, 134, 136, 137, 143, 144, 145, 151, 153, 154, 158, 159, 162], "abov": [0, 4, 5, 7, 9, 17, 19, 22, 23, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 44, 48, 49, 51, 53, 63, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 82, 83, 88, 92, 93, 101, 102, 107, 120, 121, 123, 127, 130, 133, 134, 136, 143, 144, 145, 146, 147, 151, 152, 153, 156, 161, 162, 163], "absenc": [8, 63, 117], "abserr": [149, 150], "absolut": [3, 4, 8, 16, 47, 65, 66, 67, 85, 110, 125, 133, 136, 153], "absolute_import": 76, "absorb": 25, "abspath": [130, 156, 161], "abstract": [8, 16, 53, 66, 73, 156, 161], "abstractmoviewrit": 126, "abund": 105, "abundantli": 38, "ac": [32, 77], "ac83dd": 1, "academ": [43, 56], "accelar": 123, "acceler": [62, 64, 121, 123], "accentu": 33, "accept": [6, 19, 29, 39, 44, 45, 46, 50, 51, 53, 61, 64, 71, 75, 123, 137, 144, 145, 146, 147, 148, 152, 153, 154, 156, 161, 162, 163], "acceptance_fract": [6, 50, 123, 143, 147, 152], "acceptance_r": 151, "access": [8, 16, 34, 43, 45, 48, 51, 53, 56, 64, 65, 71, 77, 83, 88, 100, 113, 130, 133, 134, 136, 137, 139, 153, 154], "accid": [35, 64], "accommod": [8, 88], "accompani": 64, "accomplish": [48, 50, 71, 136, 146, 154], "accor": 65, "accord": [7, 9, 16, 29, 33, 34, 41, 42, 43, 44, 46, 50, 53, 60, 67, 68, 71, 96, 117, 126, 130, 133, 144, 153, 156, 158], "accordingli": [23, 43], "account": [0, 4, 16, 23, 29, 34, 37, 38, 43, 48, 55, 59, 60, 61, 63, 72, 119, 123, 127, 133, 143, 145, 161, 162], "accumul": [7, 44, 67, 71, 107, 123, 159], "accur": [40, 45, 47, 48, 53, 63, 65, 66, 69, 80, 89, 117, 119, 122, 124, 126, 150], "accuraci": [38, 40, 41, 43, 47, 48, 49, 50, 51, 63, 65, 67, 70, 73, 76, 93, 125, 130, 143, 145, 150, 154, 162], "accus": 8, "aceept": 148, "acf": 144, "achiev": [8, 41, 44, 46, 47, 53, 64, 65, 66, 67, 76, 88, 111, 117, 121, 133, 143, 153, 156], "acknowledg": [48, 61, 63], "acor": [143, 144], "acquaint": [34, 101, 110], "acquir": [9, 10, 11, 27, 62, 67, 117], "acquisit": [58, 92], "across": [34, 40, 43, 46, 47, 48, 71, 75, 77, 83, 102, 119, 143, 148, 159], "act": [7, 8, 40, 41, 51, 53, 58, 62, 110, 117, 129, 134], "act_1": [73, 93], "act_2": [73, 93], "act_out": [73, 93], "action": [63, 64, 117, 128, 163], "activ": [8, 46, 47, 64, 65, 69, 70, 71, 72, 73, 74, 75, 76, 93, 117, 123, 129, 134, 137], "activaiton": 117, "activit": 67, "actual": [7, 8, 9, 13, 16, 19, 21, 22, 25, 30, 31, 34, 35, 38, 40, 41, 43, 46, 51, 53, 58, 63, 65, 66, 71, 72, 77, 83, 86, 88, 93, 95, 104, 111, 117, 119, 133, 142, 145, 153, 156, 159, 162], "ad": [19, 25, 37, 38, 40, 44, 50, 53, 56, 66, 69, 73, 74, 77, 79, 80, 83, 86, 92, 93, 94, 95, 96, 97, 107, 117, 121, 123, 127, 130, 134, 142, 143, 144, 147, 152, 156, 159, 161], "adadelta": [1, 107], "adagrad": [67, 71], "adam": [1, 56, 67, 69, 71, 76], "adapt": [1, 9, 34, 37, 38, 39, 40, 47, 50, 56, 61, 67, 71, 77, 78, 82, 83, 87, 90, 95, 116, 117, 121, 122, 127, 142, 143, 144, 145, 147, 148, 150, 151, 152, 154, 162], "adapt_diag": [151, 152], "adaptation_lag": [50, 96], "adaptation_tim": [50, 96], "add": [0, 9, 17, 19, 31, 33, 34, 40, 47, 52, 64, 66, 68, 70, 73, 74, 75, 79, 80, 82, 86, 90, 93, 94, 95, 115, 122, 123, 130, 133, 134, 135, 136, 137, 138, 142, 143, 144, 147, 148, 150, 152, 153, 159], "add_ax": 126, "add_subplot": [5, 9, 17, 37, 38, 40, 41, 42, 49, 65, 70, 95, 126, 127, 132, 134, 135, 145, 149, 150, 162], "addbackward0": 71, "addit": [0, 2, 7, 16, 24, 25, 27, 31, 34, 42, 44, 46, 48, 51, 52, 53, 58, 61, 62, 64, 66, 67, 68, 71, 72, 73, 75, 77, 78, 80, 82, 85, 88, 93, 107, 110, 121, 124, 134, 137, 151, 154, 156], "addition": 67, "address": [38, 53, 55, 56, 57, 63, 72, 90, 95, 110, 116, 122, 147, 148, 152, 153], "adequ": [7, 63], "adher": [43, 53, 63], "adjac": [51, 67], "adjust": [9, 17, 37, 38, 42, 44, 63, 67, 69, 71, 72, 73, 86, 88, 111, 117, 126, 130, 132, 142, 148, 149, 151, 154], "admin": 137, "admir": 133, "adopt": [34, 38, 51, 63, 75, 120], "ador": 63, "adress": 44, "advanc": [8, 9, 47, 50, 56, 63, 67, 71, 91, 95, 96, 131, 137, 153, 156, 160], "advantag": [16, 27, 28, 34, 38, 43, 47, 56, 71, 75, 107], "advertis": 86, "advi": [72, 93, 151], "advic": 159, "advoc": [40, 88, 95, 148], "af_fig": 7, "affect": [19, 25, 38, 40, 41, 43, 62, 63, 64, 71, 80, 100, 130, 149, 153], "affin": [1, 47, 123, 146, 147, 148, 152, 153], "afford": [44, 76], "after": [4, 7, 8, 9, 10, 11, 12, 16, 17, 21, 22, 23, 25, 30, 37, 38, 43, 44, 46, 47, 48, 52, 53, 59, 62, 64, 66, 67, 68, 69, 71, 77, 80, 81, 83, 85, 95, 123, 126, 133, 134, 136, 143, 144, 146, 148, 150, 151, 156, 159, 161], "afterward": 133, "ag": [63, 64], "again": [4, 7, 9, 22, 23, 30, 31, 33, 37, 44, 49, 53, 63, 65, 68, 77, 90, 95, 97, 112, 114, 115, 117, 125, 127, 130, 133, 134, 137, 144, 146, 147, 149, 151, 152, 153, 154, 156, 161], "against": [7, 8, 13, 14, 46, 51, 53, 63, 71, 127, 145, 161, 162], "agenc": 63, "agenda": 4, "agent": [8, 128], "aggress": 107, "agre": [13, 19, 53, 61, 76, 127, 147, 152], "agreement": [34, 39, 53, 102, 137, 147, 152], "ahead": [20, 23, 73, 93, 134], "ai": [1, 64, 89, 117], "aic": 51, "aid": [43, 46], "aim": [4, 34, 44, 46, 47, 56, 61, 62, 63, 64, 65, 66, 67, 77, 83, 100, 105, 123, 133, 161], "aip": 51, "air": [121, 123], "airplan": 76, "aka": [9, 30, 47, 85, 122], "akaiko": 51, "al": [0, 43, 44, 56, 66, 123, 126, 144], "alea": 72, "alexandr": 1, "alfio": 1, "algebra": [1, 7, 34, 50, 64, 67, 95, 99, 100, 112, 125, 134, 138], "algorithm": [1, 19, 38, 44, 47, 53, 56, 62, 65, 66, 70, 71, 72, 73, 89, 93, 97, 104, 105, 106, 111, 116, 117, 127, 130, 133, 136, 146, 151, 160], "alia": [50, 96], "alias": [50, 96], "align": [0, 4, 7, 13, 15, 19, 22, 24, 33, 34, 35, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 51, 66, 67, 72, 77, 79, 82, 83, 85, 86, 88, 95, 100, 107, 125, 126, 127, 130, 145, 146, 148, 149, 150, 151, 156, 158, 159, 162], "align_test": 0, "all": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 21, 22, 23, 25, 27, 30, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 77, 78, 79, 82, 83, 85, 86, 88, 89, 92, 94, 95, 96, 100, 102, 104, 105, 106, 107, 108, 117, 119, 120, 123, 124, 126, 127, 129, 130, 133, 134, 136, 137, 142, 143, 144, 145, 146, 147, 148, 151, 153, 156, 158, 159, 161, 162], "all_orbit": 149, "allow": [3, 4, 7, 8, 9, 11, 12, 16, 25, 30, 34, 38, 39, 43, 44, 46, 49, 53, 64, 65, 71, 73, 75, 80, 81, 82, 85, 89, 93, 95, 102, 104, 110, 111, 117, 123, 130, 133, 134, 136, 137, 144, 147, 151, 152, 153, 161], "allud": [0, 22], "almost": [7, 19, 63, 64, 65, 67, 73, 78, 82, 126, 148, 151, 153, 154, 161], "alo": 35, "alon": [4, 8, 51], "along": [43, 47, 62, 72, 75, 82, 90, 136, 148, 151, 156], "alongsid": [77, 83], "alp": 1, "alpha": [3, 6, 9, 13, 17, 19, 29, 30, 33, 34, 37, 39, 40, 41, 42, 47, 49, 50, 51, 65, 67, 70, 72, 73, 74, 77, 78, 80, 81, 82, 85, 88, 92, 93, 94, 95, 96, 102, 117, 123, 126, 127, 129, 130, 133, 143, 144, 150, 152, 153, 156, 158], "alpha_1": [9, 30], "alpha_1_w": 9, "alpha_2": 9, "alpha_2_w": 9, "alpha_3": 9, "alpha_3_w": 9, "alpha_bound": 81, "alpha_v": 123, "alphabet": 56, "alphavec": [23, 90], "alreadi": [7, 16, 17, 19, 31, 34, 37, 39, 49, 52, 56, 60, 63, 65, 73, 77, 83, 86, 110, 117, 127, 133, 134, 137, 144, 145, 147, 152, 154, 156, 160, 162], "also": [0, 3, 4, 5, 7, 8, 9, 16, 17, 19, 21, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 52, 53, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 78, 81, 82, 83, 85, 86, 88, 89, 92, 94, 95, 96, 97, 100, 101, 102, 104, 107, 110, 111, 113, 116, 117, 121, 124, 126, 127, 129, 130, 132, 133, 134, 135, 136, 137, 142, 143, 144, 147, 148, 151, 152, 153, 154, 156, 159, 161], "alter": [8, 9, 30], "altern": [3, 4, 6, 17, 34, 38, 39, 41, 44, 46, 47, 48, 53, 61, 64, 66, 88, 92, 94, 97, 115, 122, 126, 130, 138, 142, 152, 153, 156, 160], "although": [0, 7, 8, 11, 19, 22, 25, 33, 34, 43, 45, 47, 48, 53, 56, 60, 63, 82, 97, 98, 99, 104, 105, 112, 130, 133, 136, 153, 156, 159, 161], "altogeth": [44, 85], "alwai": [6, 7, 8, 16, 17, 19, 22, 23, 29, 34, 40, 43, 48, 49, 53, 58, 63, 64, 65, 66, 67, 72, 85, 92, 98, 101, 103, 112, 129, 130, 133, 134, 135, 144, 145, 146, 151, 153, 154, 156, 158, 159, 161, 162], "am": 1, "amat": 127, "amatt": 127, "amax": [42, 96], "amaz": [64, 73], "amazon": 56, "ambigu": 67, "ambit": [45, 67], "ambiti": [58, 62], "ame2003": 133, "ame2012": 133, "ame2016": 133, "amelior": 66, "american": [1, 61, 128], "amin": [42, 96], "among": [8, 29, 38, 40, 43, 47, 48, 55, 56, 66, 75, 88, 156], "amount": [8, 9, 25, 39, 40, 51, 53, 62, 63, 66, 73, 75, 90, 97, 111, 146, 147, 152, 156], "amplifi": 63, "amplitud": [7, 34, 50, 51, 53, 80, 82, 90, 96, 132], "an": [0, 1, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99, 100, 104, 105, 106, 107, 110, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 160, 162, 163], "anaconda": [50, 56, 71, 131, 134, 139, 140], "anaconda3": [50, 137], "anal": 1, "analog": [51, 66, 94, 125, 144, 154], "analogi": [0, 1, 8, 22, 33, 51, 61, 67, 72, 144], "analys": [25, 30, 34, 43, 46, 47, 122, 126], "analysi": [0, 1, 7, 8, 16, 19, 25, 27, 29, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 56, 61, 63, 64, 65, 66, 73, 86, 88, 93, 94, 95, 99, 102, 112, 116, 117, 121, 123, 124, 125, 127, 133, 134, 145, 147, 152, 153, 159, 162], "analyt": [7, 16, 30, 34, 35, 39, 40, 44, 47, 49, 53, 63, 65, 66, 67, 82, 88, 97, 99, 144, 147, 152, 156, 159], "analyz": [8, 16, 19, 25, 29, 34, 38, 49, 59, 63, 64, 75, 90, 94, 96, 98, 102, 117, 142], "anayt": 153, "ancestor": 110, "andrea": [1, 45, 56, 78, 82], "andrei": 25, "andrew": [0, 1, 56], "ang_mom": 150, "angl": [35, 40, 42, 142], "angular": 42, "angwin": 63, "anharmon": 47, "ani": [0, 4, 5, 7, 8, 9, 11, 16, 17, 19, 22, 25, 30, 31, 32, 33, 34, 38, 40, 41, 43, 44, 45, 48, 49, 50, 51, 52, 53, 56, 58, 59, 61, 63, 64, 65, 67, 71, 73, 76, 78, 80, 82, 85, 86, 88, 92, 95, 96, 101, 102, 117, 120, 123, 130, 134, 135, 136, 142, 143, 152, 153, 154, 156, 161, 163], "anim": [67, 126], "anindita": 1, "ankl": 76, "ann": 89, "ann_input": [73, 93], "ann_output": [73, 93], "anneal": 51, "annft": 117, "annot": [9, 17, 37, 42, 95, 126, 144], "anoth": [0, 4, 7, 9, 13, 16, 19, 23, 25, 33, 34, 37, 43, 44, 51, 53, 55, 63, 64, 65, 66, 67, 68, 75, 76, 79, 88, 90, 94, 95, 97, 110, 127, 130, 133, 134, 135, 136, 144, 145, 148, 150, 152, 154, 156, 159, 162], "ansatz": 133, "answer": [7, 8, 26, 27, 33, 39, 42, 52, 53, 59, 63, 64, 66, 77, 79, 83, 85, 92, 93, 94, 98, 103, 123, 127, 130, 134, 144, 147, 151, 152, 154, 161], "anteced": 47, "anti": [9, 11, 12, 53, 78, 130], "antialias": [37, 130], "anticip": 63, "anymor": 85, "anyon": [59, 135], "anyth": [11, 16, 21, 42, 61, 67, 130, 134, 142, 151, 153, 154], "anywai": 144, "anywher": [0, 17, 23, 32, 43, 52, 156], "ap": 127, "apach": 76, "apart": [44, 53, 73, 79, 86], "aperiod": [144, 153, 156], "api": [73, 76, 93], "apologi": 62, "app": [1, 86], "appar": [25, 146, 159], "apparatu": 23, "appeal": [46, 130], "appear": [4, 7, 8, 22, 32, 34, 38, 42, 43, 45, 47, 53, 56, 63, 64, 66, 67, 72, 77, 83, 85, 93, 115, 125, 133, 137, 149, 153, 154, 156, 158, 161], "append": [33, 35, 38, 50, 65, 70, 96, 123, 129, 132, 133, 135, 136, 137, 143, 144, 149, 153, 159, 161], "appendix": [23, 24, 27, 56, 92, 126, 131], "appl": 137, "appli": [0, 7, 8, 15, 17, 19, 20, 22, 25, 31, 32, 34, 39, 43, 44, 47, 48, 51, 52, 53, 58, 63, 65, 67, 68, 70, 71, 72, 73, 75, 88, 94, 104, 110, 117, 123, 129, 133, 136, 145, 148, 149, 153, 154, 156, 162], "applic": [1, 7, 8, 16, 18, 23, 24, 25, 37, 39, 41, 43, 44, 45, 46, 47, 48, 52, 56, 59, 62, 63, 64, 65, 66, 67, 71, 73, 76, 86, 88, 89, 104, 112, 121, 147, 152, 156, 161], "approach": [1, 4, 8, 9, 11, 16, 17, 18, 19, 21, 25, 28, 30, 33, 34, 35, 40, 43, 44, 45, 46, 47, 48, 51, 53, 55, 59, 60, 61, 64, 65, 66, 71, 72, 73, 74, 78, 79, 83, 88, 95, 97, 101, 102, 110, 111, 113, 117, 119, 120, 121, 125, 127, 128, 129, 130, 135, 148, 151, 153, 154], "appropri": [0, 4, 16, 17, 25, 34, 43, 48, 53, 63, 77, 83, 85, 120, 126, 127, 130, 134, 146, 154], "approx": [3, 4, 7, 12, 16, 19, 29, 31, 32, 38, 41, 45, 46, 52, 53, 67, 72, 73, 79, 93, 95, 110, 115, 125, 127, 146, 153, 154, 156, 159, 161], "approxim": [1, 4, 18, 19, 29, 34, 39, 41, 44, 45, 47, 51, 52, 53, 55, 66, 67, 71, 72, 73, 90, 93, 95, 96, 100, 110, 111, 115, 119, 122, 127, 130, 144, 146, 147, 148, 152, 153, 154, 158], "ar": [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 161, 162, 163], "aragorn": 133, "arang": [33, 37, 39, 42, 49, 50, 65, 70, 77, 78, 80, 82, 83, 95, 96, 130, 133, 134, 135, 136, 138, 143, 149, 150, 152], "arbitrari": [23, 43, 46, 47, 67, 80, 130, 153], "arbitrarili": [34, 82, 144], "archetyp": 67, "architectur": [69, 71, 73, 76, 117], "archiv": 8, "arcsin": 3, "area": [18, 19, 43, 48, 53, 56, 64, 72, 75, 104, 133, 148, 149, 163], "aren": 63, "arg": [0, 5, 6, 7, 34, 38, 40, 41, 70, 82, 92, 96, 100, 113, 123, 126, 130, 132, 143, 146, 147, 152], "argmax": [4, 9, 17, 30, 41, 42, 69, 76, 126], "argmin": [37, 66, 85, 104, 149, 150, 161], "argsort": [41, 96], "argu": [4, 7, 8, 19, 34, 43, 46, 58, 59, 60, 62, 63, 73, 117, 133, 143, 151], "argument": [0, 7, 13, 33, 34, 38, 43, 46, 50, 52, 67, 72, 76, 79, 92, 96, 102, 104, 117, 127, 133, 134, 136, 138, 144, 156, 159], "aris": [7, 34, 47, 48, 51, 53, 66, 77, 83, 124, 133, 161], "aristotelian": 62, "arithmet": [22, 136], "arlier": 135, "around": [7, 13, 19, 23, 25, 29, 34, 35, 41, 43, 44, 53, 71, 73, 76, 77, 83, 89, 105, 110, 126, 127, 130, 143, 144, 148, 151, 159, 163], "arr": 136, "arr1": 136, "arr1_2d": 136, "arr2": 136, "arr_from_list": 136, "arr_int": 136, "arr_to_list": 136, "arrai": [3, 5, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 44, 49, 50, 65, 67, 69, 70, 73, 76, 77, 78, 79, 82, 83, 93, 94, 95, 96, 103, 123, 126, 127, 130, 133, 138, 143, 144, 146, 147, 149, 150, 151, 152, 153, 156, 161, 162], "arrang": [75, 127], "array_equ": 136, "array_lik": 123, "array_split": 136, "arrest": 63, "arriv": [8, 66, 67, 100, 133, 134], "arrow": [17, 67, 117, 126, 134, 148, 154], "arrowprop": [17, 37, 126, 144], "arrowstyl": 144, "arsen": 22, "art": [44, 73], "articl": [27, 48, 66, 76, 89, 121, 123, 128, 136], "articul": [48, 53, 57, 61], "artifact": 7, "artifici": [34, 40, 45, 47, 63, 64, 70, 74, 88, 89, 101, 102, 104, 117], "artificialneuron": 67, "arviz": [73, 93, 151, 152], "arviz_vers": 151, "arxiv": [1, 40, 72, 86, 92, 94, 126, 163], "as_cmap": [73, 93], "as_grai": 127, "asarrai": [6, 77, 83, 92, 96], "ascend": [37, 136], "ascertain": [43, 53, 153], "asid": [20, 21, 25, 39, 43, 147, 151, 152], "ask": [7, 11, 16, 22, 31, 33, 41, 42, 43, 49, 51, 53, 59, 60, 68, 100, 134, 137, 145, 146, 162], "aspect": [25, 26, 37, 47, 49, 53, 55, 56, 58, 60, 63, 77, 78, 82, 83, 88, 89, 130, 163], "aspir": 43, "ass": 73, "assembl": [75, 92], "assembli": 133, "assert": [33, 37, 50, 70, 82, 96, 144, 147, 152, 161], "assess": [7, 34, 43, 48, 51, 63], "assign": [7, 8, 21, 22, 25, 30, 34, 38, 43, 44, 46, 53, 55, 58, 65, 72, 79, 85, 88, 101, 119, 120, 130, 136, 151, 154, 161], "assist": 134, "associ": [34, 39, 43, 45, 53, 67, 73, 77, 78, 83, 85, 97, 104, 110, 117, 133, 147, 150, 151, 152], "assum": [3, 4, 7, 8, 16, 19, 21, 22, 23, 25, 29, 31, 34, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 52, 53, 63, 65, 66, 67, 71, 72, 73, 78, 80, 82, 85, 86, 88, 90, 92, 95, 96, 99, 101, 102, 113, 115, 119, 120, 121, 123, 126, 130, 133, 136, 137, 142, 143, 144, 147, 151, 152, 153, 154, 156, 161], "assumpt": [7, 8, 12, 34, 41, 42, 43, 46, 53, 61, 62, 63, 65, 75, 78, 82, 95, 97, 100, 119, 133, 156], "asterisk": [0, 34, 134], "astro": 80, "astronom": [1, 7, 16, 41, 58, 110, 159], "astrophysicist": 159, "astropi": 142, "astyp": [73, 93, 136], "asymmet": 19, "asymmetr": [18, 19, 144, 154, 159], "asymmetri": [63, 133], "asymptot": [23, 66], "atari": 73, "atleast_1d": 123, "atol": [149, 150], "atom": [1, 62, 133, 144], "atomic_mass": 133, "attack": 47, "attain": [8, 48], "attempt": [9, 16, 35, 44, 48, 53, 66, 72], "attend": 63, "attent": [16, 22, 63], "attitud": [61, 63, 64], "attr": [50, 96, 156], "attract": 133, "attractor": 51, "attribut": [7, 43, 50, 53, 96, 130, 136, 151], "attributeerror": [50, 96], "au": 34, "audi": [1, 133], "augment": [44, 92], "aurelien": 66, "author": [46, 56, 73, 76, 77, 80, 81, 91, 117, 119], "authorize_download": 77, "authour": 64, "auto": [78, 82, 143, 151], "autocorrel": [43, 144, 146, 163], "autoencod": 73, "automag": 64, "automat": [1, 7, 38, 64, 71, 72, 73, 89, 97, 105, 133, 136, 158], "automobil": 76, "autonomi": 63, "autoscal": [9, 42, 129], "autoscale_on": [78, 82], "autotun": 146, "auxiliari": [156, 163], "avail": [4, 9, 17, 23, 25, 39, 40, 43, 44, 46, 48, 56, 64, 73, 77, 81, 82, 83, 85, 94, 104, 119, 121, 123, 130, 133, 134, 137, 138, 139, 144, 147, 150, 152, 153, 154], "availa": 123, "available_cor": 123, "avec": [49, 52], "avec_1": 52, "avec_2": 52, "avenu": 73, "averag": [4, 16, 18, 19, 21, 33, 35, 43, 44, 51, 52, 53, 59, 65, 66, 67, 71, 72, 75, 93, 96, 107, 110, 130, 133, 143, 144, 145, 146, 152, 153, 154, 159, 161, 162], "avg": 151, "avg_lnl": 96, "avoid": [16, 22, 31, 43, 44, 46, 50, 66, 67, 71, 72, 73, 86, 92, 96, 107, 133, 134, 137, 148], "awai": [7, 12, 34, 38, 39, 46, 53, 127, 134, 146, 147, 148, 152, 154, 159], "awar": [47, 61, 63, 81, 88, 106, 156], "award": 67, "awesom": 34, "awkward": 135, "ax": [0, 3, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 49, 50, 53, 65, 70, 73, 77, 78, 81, 82, 83, 88, 93, 95, 96, 102, 125, 126, 127, 129, 130, 132, 133, 134, 135, 136, 143, 144, 146, 147, 149, 152, 153, 156, 161, 162], "ax1": [17, 37, 39, 78, 82, 126, 127, 134, 144, 152], "ax2": [5, 17, 37, 39, 78, 82, 126, 127, 134, 144, 152], "ax2_1": 37, "ax2_2": 37, "ax2_3": 37, "ax2_4": 37, "ax3": [17, 37, 126, 127, 144], "ax3d": 130, "ax4": 37, "ax_1": [17, 42], "ax_2": [17, 42, 150], "ax_3": [17, 42], "ax_4a": 150, "ax_4b": 150, "ax_4c": 150, "ax_4d": 150, "ax_5a": 150, "ax_c": 149, "ax_pass": 135, "ax_plot": [145, 162], "ax_run": [156, 161], "ax_trac": [145, 162], "ax_tru": 37, "axes3d": [50, 65], "axhlin": [37, 126, 147, 150, 151, 152], "axi": [9, 17, 33, 35, 37, 38, 39, 40, 42, 50, 65, 66, 73, 77, 78, 81, 82, 88, 93, 94, 96, 123, 126, 127, 130, 134, 135, 136, 138, 142, 146, 149, 152, 156, 161], "axiom": [8, 16, 24], "axiomat": [25, 62], "axis_label": 149, "axs_vec": [25, 30], "axvlin": [9, 37, 42, 126, 127, 130, 144, 147, 152], "az": [151, 152], "azim": 65, "b": [0, 1, 4, 9, 13, 17, 21, 22, 23, 25, 31, 34, 35, 37, 38, 40, 41, 42, 44, 46, 47, 49, 62, 64, 65, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 82, 83, 90, 92, 93, 95, 96, 114, 115, 117, 123, 125, 126, 127, 130, 133, 134, 135, 143, 144, 146, 151, 154], "b1": [17, 126], "b2": 17, "b_": [35, 95], "b_0": 35, "b_1": [112, 130], "b_2": 130, "b_grid": 37, "b_i": [67, 130], "b_j": [67, 68, 130], "b_k": 127, "b_m": 67, "b_margin": [35, 37], "b_max": 37, "b_n": [34, 112, 130], "b_pt": 37, "b_std": 129, "b_true": 37, "b_true_fix": [35, 37], "b_true_index": 37, "b_x": 53, "b_y": 53, "ba": 1, "ba524": 1, "baath": 126, "bacciagaluppi": 128, "back": [1, 8, 9, 10, 11, 16, 17, 25, 30, 35, 40, 51, 53, 63, 65, 66, 67, 70, 71, 75, 78, 79, 82, 88, 93, 127, 134, 135, 143, 146, 151, 153, 154, 159], "backend": [73, 134], "background": [4, 8, 16, 24, 25, 38, 43, 53, 56, 62, 63, 90, 95, 96, 122, 154, 158, 160], "backpropag": 72, "backtick": 0, "backward": [15, 67, 68, 71, 72, 127, 146, 148], "bacteri": 161, "bacteria": 161, "bad": [19, 41, 66, 73, 76], "badli": [48, 151], "bag": 16, "baggin": 133, "bailei": 126, "baishan": 1, "balanc": [51, 53, 63, 66, 148, 153], "ball": [4, 16, 120, 147, 152], "balldrop": 121, "balzac": 45, "banana": [4, 153, 154], "band": [17, 47, 48, 79, 82, 86, 94, 156], "bandwidth_factor": 82, "bar": [4, 7, 16, 17, 22, 29, 31, 33, 37, 38, 40, 41, 44, 49, 52, 53, 65, 66, 69, 76, 77, 83, 107, 120, 123, 126, 127, 130, 133, 134, 143, 144, 146, 147, 151, 152], "bare": [35, 51, 63], "barnett": 85, "bartlett": 66, "base": [1, 4, 8, 9, 21, 22, 25, 31, 32, 33, 34, 37, 38, 39, 43, 45, 46, 47, 48, 50, 51, 53, 58, 62, 63, 64, 66, 67, 69, 71, 72, 77, 78, 82, 83, 88, 89, 92, 93, 95, 96, 100, 101, 107, 113, 117, 119, 123, 124, 130, 133, 134, 135, 137, 138, 140, 143, 144, 147, 148, 151, 152, 153, 154], "baselin": [33, 37, 150], "basi": [1, 4, 7, 22, 45, 47, 53, 62, 63, 65, 76, 79, 80, 85, 86, 88, 100, 101, 102, 110, 121, 122, 125, 127], "basic": [7, 8, 20, 22, 27, 35, 44, 47, 49, 50, 56, 62, 64, 66, 68, 69, 73, 79, 85, 87, 90, 91, 93, 105, 130, 133, 134, 138, 142, 146, 148, 149, 153, 156, 158, 159, 162, 163], "basic_model": [151, 158], "basic_model_alt": 151, "batch": [66, 67, 68, 76, 88, 97], "batch_siz": [69, 73, 106], "bay": [1, 7, 8, 9, 13, 15, 16, 19, 20, 24, 27, 30, 32, 34, 35, 37, 39, 41, 42, 43, 44, 49, 52, 53, 55, 56, 58, 59, 62, 85, 88, 95, 144, 147, 151, 152, 158], "bayes_text": 9, "bayesian": [1, 2, 11, 12, 13, 14, 18, 20, 21, 23, 24, 25, 28, 29, 35, 37, 40, 42, 44, 45, 46, 47, 49, 50, 52, 56, 57, 58, 60, 62, 64, 79, 85, 86, 88, 89, 90, 91, 94, 96, 97, 100, 101, 103, 110, 113, 116, 117, 119, 120, 121, 122, 123, 124, 126, 130, 142, 143, 144, 145, 151, 154, 161, 162, 163], "bayesian_7": 151, "bayesian_cr_slope_max": 41, "bayesian_cr_slope_min": 41, "bayesian_neural_network_advi": [73, 93], "bayesian_neural_networks_tif285": 93, "bayesian_research_cycl": 0, "bayesian_slope_maxprob": 41, "bayesian_slope_mean": 41, "bayesianastronomi": [37, 40], "bayesianoptim": 92, "bayesianworkflow": [0, 43], "baysian": 72, "bbox": [95, 126], "bbox_inch": [149, 150], "bbox_to_anchor": 81, "bckw15": [1, 72], "bda": [51, 146], "bda3": [0, 1, 34, 51, 53], "beach": [147, 152], "beam": 51, "bearer": 8, "beat": 73, "beaten": 62, "becaus": [5, 7, 13, 19, 23, 25, 31, 33, 34, 35, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 58, 62, 63, 66, 71, 72, 75, 76, 77, 78, 80, 82, 83, 95, 97, 125, 127, 135, 136, 143, 144, 146, 147, 148, 152, 154, 159], "bechmark": 73, "becom": [0, 4, 7, 17, 19, 25, 33, 34, 35, 39, 44, 45, 46, 48, 52, 53, 62, 64, 65, 66, 67, 72, 73, 77, 78, 82, 83, 85, 86, 89, 95, 97, 99, 100, 105, 107, 113, 120, 121, 122, 133, 134, 136, 147, 152, 153, 154, 156, 161], "been": [4, 7, 8, 19, 25, 27, 31, 43, 44, 46, 47, 48, 49, 53, 56, 59, 61, 63, 64, 66, 67, 72, 73, 80, 100, 107, 119, 123, 126, 137, 146, 151, 154, 158], "befor": [0, 7, 8, 9, 10, 16, 23, 24, 25, 31, 34, 39, 40, 42, 43, 44, 48, 52, 53, 59, 63, 65, 66, 67, 68, 69, 71, 75, 76, 77, 78, 80, 81, 82, 83, 88, 97, 105, 127, 130, 133, 136, 142, 143, 147, 148, 150, 152, 159], "beforehand": [53, 144, 153], "begin": [0, 3, 4, 7, 8, 9, 13, 15, 16, 19, 22, 24, 25, 34, 35, 37, 38, 39, 41, 44, 45, 46, 47, 48, 49, 51, 53, 63, 65, 66, 67, 68, 71, 72, 75, 77, 78, 79, 82, 83, 85, 86, 88, 95, 97, 99, 100, 102, 103, 104, 106, 107, 113, 120, 123, 125, 127, 130, 132, 133, 134, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 159, 161, 162], "beginn": 69, "behav": [7, 123, 154], "behavior": [11, 37, 44, 50, 53, 64, 71, 79, 90, 96, 121, 129, 133, 144], "behaviour": [53, 67, 68, 85], "behind": [16, 53, 63, 95, 133, 148], "being": [4, 7, 16, 19, 21, 22, 23, 25, 31, 32, 33, 34, 39, 40, 43, 44, 46, 47, 48, 53, 56, 58, 63, 64, 66, 67, 68, 71, 73, 77, 83, 85, 88, 89, 93, 117, 122, 126, 130, 137, 143, 144, 146, 147, 152, 154, 156, 158, 159], "belatedli": 23, "belief": [8, 10, 11, 15, 16, 17, 19, 22, 25, 34, 41, 43, 46, 61, 63, 130, 144], "believ": [10, 11, 25, 34, 42, 48, 57, 61, 63, 73, 110, 127], "bell": [126, 134], "belong": [62, 63, 65, 69, 72, 82, 86, 88, 125, 161], "below": [0, 4, 7, 17, 19, 21, 22, 33, 34, 38, 39, 43, 44, 46, 47, 50, 51, 53, 60, 63, 65, 66, 67, 69, 70, 72, 73, 76, 77, 78, 82, 83, 85, 92, 93, 95, 96, 100, 102, 120, 121, 126, 127, 130, 133, 134, 136, 142, 144, 145, 146, 150, 151, 153, 156, 159, 161, 162], "benchmark": 73, "benefici": 153, "benefit": [47, 56, 63, 66, 71], "benign": 66, "berg": 133, "bernardo": 1, "bernardo94": 48, "bernoulli": [8, 9, 73, 93], "besid": [16, 42, 86, 151], "best": [0, 4, 5, 7, 8, 9, 11, 17, 18, 19, 25, 29, 30, 34, 35, 38, 47, 50, 51, 53, 55, 59, 62, 65, 66, 67, 70, 71, 74, 79, 86, 88, 91, 92, 95, 97, 104, 106, 121, 123, 130, 134, 137, 142, 153, 154, 161, 162], "bet": [8, 25, 134], "beta": [9, 18, 19, 30, 34, 38, 41, 45, 47, 50, 51, 96, 123, 126, 127, 130, 133, 144, 156], "beta0": 34, "beta1": 34, "beta1_label": 17, "beta2_dist": 17, "beta2_label": 17, "beta_": 51, "beta_0": 34, "beta_1": [9, 30, 34, 158], "beta_1_w": 9, "beta_2": [9, 51, 158], "beta_2_w": 9, "beta_3": 9, "beta_3_w": 9, "beta_dist": 17, "beta_grid": 34, "beta_i": [34, 45, 47, 51, 158], "beta_n": 51, "beta_sampl": 17, "beta_v": 123, "betai": 34, "betas0": 96, "betavec": 47, "better": [0, 4, 5, 7, 8, 23, 25, 29, 31, 33, 34, 35, 39, 40, 42, 46, 47, 53, 63, 65, 66, 67, 69, 70, 71, 73, 75, 77, 79, 83, 85, 92, 93, 96, 97, 110, 117, 123, 125, 130, 133, 135, 147, 148, 150, 151, 152, 153, 154], "betti": [21, 62], "between": [0, 4, 7, 9, 11, 15, 16, 19, 21, 22, 23, 25, 26, 30, 34, 35, 37, 38, 40, 42, 43, 44, 46, 48, 51, 52, 53, 56, 59, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 76, 77, 78, 83, 85, 86, 88, 92, 93, 95, 96, 97, 104, 105, 110, 114, 116, 117, 119, 120, 123, 126, 130, 133, 134, 136, 138, 143, 146, 148, 151, 153], "beutler": 163, "bewar": 22, "beyond": [8, 19, 26, 47, 48, 53, 62, 78, 119, 145, 162], "bf": [49, 121, 123], "bf02551274": 1, "bfg": 92, "bgd": 106, "bgjm11": [1, 44], "bi": [34, 51, 82], "bia": [1, 19, 25, 34, 64, 65, 67, 68, 71, 72, 74, 77, 83, 88, 93, 95, 97, 99, 107, 117, 129], "bianca": 1, "bias": [9, 16, 23, 25, 30, 39, 59, 61, 64, 67, 68, 71, 72, 75, 93, 117, 119, 147, 152, 161], "bias_std": 129, "bib": 0, "bibtex": 0, "bic": 51, "bicyclist": 64, "bienaym\u00e9": 46, "big": [34, 60, 64, 100, 117, 154, 156], "bigg": [34, 45, 100], "bigger": [42, 56, 68], "biggest": 63, "biggl": [79, 86], "biggr": [79, 86], "bigl": [4, 19, 24, 29, 34, 35, 47, 51, 79, 86, 117, 148, 159], "bigr": [4, 19, 24, 29, 34, 35, 47, 51, 79, 86, 117, 148, 159], "bilbo": 133, "billiard": 38, "billion": 67, "bimod": [17, 67, 130], "bin": [4, 17, 19, 29, 33, 35, 37, 41, 42, 50, 82, 96, 126, 129, 130, 143, 144, 145, 146, 151, 156, 162], "bin_arrai": 33, "bin_bound": 42, "bin_edg": 126, "bin_num": [145, 162], "bin_width": [33, 42], "binari": [9, 30, 63, 64, 66, 69, 71, 72, 73, 74, 76, 93, 133], "binary_classification_data_fig": 65, "binarygibbsmetropoli": 151, "binarymetropoli": 151, "bind": 154, "binder": 137, "binomi": [13, 19, 25, 33], "biolog": [48, 67, 88, 110], "biologi": [1, 46], "bipoc": 63, "bird": 76, "birth": 133, "bit": [9, 11, 19, 38, 51, 137, 147, 152], "bitrat": 126, "bivari": [7, 44, 53, 72, 82, 86, 120, 153, 156, 161], "bivariate_fig": 130, "bla": 136, "black": [7, 17, 23, 34, 37, 38, 40, 42, 47, 60, 63, 65, 81, 88, 102, 117, 123, 126, 135, 145, 150, 162, 163], "blank": 32, "blei": [1, 72], "blind": [7, 130], "blindli": 151, "block": [7, 64, 66, 69, 85, 130, 133], "blockedstep": 151, "blog": [38, 72, 73, 93, 107, 126, 127, 134, 144, 148, 153, 154], "blond": 4, "bloodi": 62, "blow": 117, "blown": 91, "blr": [16, 28, 100, 103, 113], "blue": [5, 9, 17, 23, 30, 31, 32, 33, 34, 37, 38, 40, 42, 44, 47, 49, 65, 66, 69, 72, 75, 76, 79, 80, 88, 93, 95, 102, 121, 126, 127, 132, 134, 143, 144, 145, 147, 150, 152, 154, 162, 163], "blundel": 1, "bmatrix": [34, 88, 100], "bmax": 96, "bmc": 1, "bn": 95, "bnn": 89, "bnn_binary_classifier_mean": 72, "bnn_binary_classifier_stddev": 72, "bo": 153, "bob": 136, "bodi": [16, 45, 62, 64, 110, 114, 126], "boh": 121, "bohr": 25, "boil": 8, "bold": [34, 99, 110, 134], "boldfac": [93, 117, 127], "boldsymbol": [0, 7, 9, 30, 34, 44, 65, 66, 67, 68, 72, 74, 78, 82, 88, 96, 97, 100, 104, 105, 106, 120, 123, 127, 130, 133, 153, 156, 161], "boltzman": 51, "boltzmann": [4, 5, 44, 51, 67], "bon": 34, "bonu": [38, 90, 96], "book": [1, 9, 23, 39, 40, 42, 50, 58, 59, 62, 63, 72, 75, 81, 95, 96, 126, 131, 140, 152], "boolean": [25, 30, 123, 127, 136, 153], "boost": [67, 73], "boot": 76, "bootstrap": [15, 44, 73], "border": [42, 132, 134, 159], "bore": 51, "bori": [1, 56], "born": 23, "borrow": 133, "boson": [19, 130], "both": [4, 7, 11, 19, 22, 25, 31, 33, 34, 37, 38, 40, 43, 44, 47, 48, 50, 53, 56, 59, 63, 65, 66, 67, 71, 72, 74, 77, 80, 81, 85, 93, 97, 106, 107, 110, 113, 119, 120, 121, 125, 126, 130, 132, 133, 134, 136, 142, 143, 144, 145, 148, 150, 151, 159, 160, 161, 162], "bother": [8, 48], "bottleneck": 105, "bottom": [10, 11, 17, 33, 37, 53, 94, 126, 154, 159], "bought": 8, "bound": [19, 34, 38, 42, 46, 47, 53, 67, 82, 92, 100, 123, 144], "boundari": [34, 47, 70, 72, 73, 74, 144, 153, 159], "bovin": 62, "bower": 1, "bowl": 148, "box": [0, 4, 9, 16, 17, 19, 32, 43, 47, 50, 56, 60, 65, 108, 117, 132, 134, 137, 159, 163], "br": 9, "bra": 47, "bracket": [77, 83], "bragg": 7, "brain": [1, 62, 67, 88], "braket": 47, "branch": [8, 43], "brand": 73, "break": [0, 3, 22, 48, 71, 133, 134], "breakdown": 71, "bremen": [80, 81], "breviti": 130, "brewer": [0, 23], "bridg": 1, "brief": [48, 53, 122, 125, 134, 158], "briefli": [16, 23, 48, 64, 97, 133], "bring": [62, 63], "british": 63, "broad": [34, 39, 41, 47, 53, 64, 147, 152], "broaden": [59, 111], "broader": [104, 112], "broadli": [45, 48, 56, 61, 89, 125], "broken": 59, "brook": 1, "brown": [22, 32], "brownian": [77, 83, 161], "browser": 134, "bruno": 46, "brynjarsd\u00f3ttir": 119, "bs06": [1, 44], "bsd": [80, 81], "bubnov": 47, "bufsiz": 126, "bug": [62, 92, 133, 134], "build": [1, 4, 7, 23, 34, 42, 45, 47, 48, 61, 62, 63, 64, 65, 66, 70, 73, 74, 77, 83, 85, 89, 93, 95, 129, 134, 137, 148, 154], "build_model": 129, "built": [17, 19, 23, 33, 47, 48, 51, 66, 71, 130, 133, 134, 135, 153], "builtin": [50, 96], "bukov": 1, "bulk": 46, "bullet": [16, 123, 134], "buqey": [0, 1, 122, 127], "burden": 46, "burn": [6, 38, 50, 89, 96, 123, 145, 146, 147, 151, 152, 154, 159, 162], "burnin": [50, 152], "busi": 63, "bution": 43, "button": [5, 9, 132, 134, 137, 138], "button_styl": 9, "bv": 114, "bvec": 52, "bx": 127, "byte": [69, 133], "b\u00e5\u00e5th": 126, "c": [0, 1, 3, 11, 16, 21, 34, 35, 38, 44, 49, 50, 51, 53, 56, 64, 65, 66, 67, 68, 70, 71, 72, 73, 77, 78, 79, 82, 83, 86, 88, 92, 93, 97, 100, 104, 105, 106, 107, 113, 120, 123, 126, 127, 130, 131, 133, 134, 137, 142, 146, 150, 151, 156, 161], "c0": 123, "c2pread": 126, "c2pwrite": 126, "c41": 133, "c_": [66, 70, 82, 85, 100, 106], "c_0": 79, "c_1": 16, "c_2": 16, "c_i": 46, "c_k": 16, "c_n": [105, 106], "c_w": 72, "cal": [48, 68], "calcul": [0, 7, 9, 13, 16, 19, 22, 31, 33, 34, 37, 39, 42, 43, 44, 46, 47, 50, 52, 65, 67, 68, 71, 72, 86, 91, 95, 96, 101, 122, 123, 125, 126, 130, 132, 133, 134, 136, 143, 145, 146, 147, 148, 150, 151, 152, 154, 156, 158, 159, 162], "calculu": [0, 8, 16, 19, 58, 59, 154, 161], "calibr": [43, 44, 45, 47, 66, 77, 79, 86, 110, 119, 121, 122, 144, 151], "call": [0, 3, 7, 8, 9, 11, 12, 15, 16, 17, 18, 19, 23, 25, 29, 31, 34, 37, 38, 40, 44, 46, 47, 50, 52, 53, 55, 59, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 78, 79, 86, 88, 93, 94, 95, 96, 97, 100, 102, 104, 110, 125, 126, 127, 130, 132, 133, 134, 135, 136, 137, 143, 144, 145, 147, 148, 150, 151, 152, 153, 154, 156, 161, 162, 163], "callabl": [123, 144], "callback": [9, 126], "cambridg": [1, 56], "camco": 1, "camp": 53, "can": [0, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 97, 100, 101, 102, 104, 105, 106, 107, 110, 111, 112, 113, 115, 117, 119, 122, 123, 124, 125, 126, 127, 128, 130, 131, 133, 134, 135, 136, 137, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 161], "canada": 1, "cancel": [4, 44, 51, 52, 53, 66, 144], "candid": [4, 25, 55, 63, 104, 153, 154, 159], "cannot": [7, 19, 21, 25, 34, 43, 46, 47, 53, 63, 65, 73, 93, 100, 103, 130, 134], "canon": [44, 48, 148], "canva": 126, "cap": [22, 66, 130], "capabl": [17, 64, 104], "caprici": 22, "capsiz": 123, "caption": [0, 156], "captur": [43, 44, 46, 47, 63, 66, 67, 71, 119, 121, 143], "car": [16, 64, 73], "card": 32, "care": [5, 8, 16, 17, 23, 31, 32, 35, 37, 43, 47, 51, 58, 72, 73, 90, 127, 130, 133, 135, 136], "carefulli": [43, 46, 56], "carl": [1, 85], "carlin": 1, "carlo": [1, 7, 16, 43, 64, 72, 96, 123, 145, 147, 151, 152, 157, 159, 160, 161, 162, 163], "carlsson": 56, "carmak": 64, "carmen": [142, 148], "carri": [13, 34, 37, 43, 44, 49, 53, 59, 60, 61, 62, 66, 86, 88, 117, 121, 144, 145, 154, 162], "carrol": 58, "cartesian": 150, "cartoon": 51, "case": [0, 7, 8, 9, 10, 16, 18, 21, 22, 23, 25, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 43, 44, 47, 48, 49, 52, 53, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 79, 80, 86, 88, 92, 93, 95, 96, 97, 100, 101, 102, 103, 105, 110, 115, 117, 120, 123, 127, 130, 133, 134, 136, 137, 142, 144, 146, 147, 148, 151, 152, 153, 154, 156, 159, 163], "casino": 161, "cast": [47, 60, 67], "cat": [76, 117], "categor": [21, 43, 45, 64, 72, 110], "categori": [8, 47, 63, 64, 65, 67, 75, 88, 104, 124], "categoricalgibbsmetropoli": 151, "cauchi": [42, 126, 144], "cauchy_dist": 42, "cauchypropos": 151, "caus": [15, 31, 38, 48, 53, 62, 66, 71, 105, 106, 126, 151, 154], "causal": 62, "caution": [7, 41, 135], "caveat": 137, "cbar": [50, 73, 93, 123], "cbarbieri": 45, "cbo9780511790423": 1, "cbo9780511791277": 1, "cbook": 126, "cc": [34, 43, 67, 78, 103, 133, 156], "ccc": [67, 156], "cccc": 127, "cd": [137, 140], "cdf": 92, "cdot": [13, 16, 19, 23, 31, 32, 33, 34, 42, 44, 45, 47, 48, 49, 52, 65, 67, 71, 88, 94, 120, 123, 127, 136, 142, 143, 146, 156, 159], "ceil": 136, "celebr": 46, "cell": [7, 37, 42, 50, 65, 69, 70, 73, 93, 96, 126, 133, 135, 138, 142, 144, 151, 153], "cent": 8, "center": [8, 11, 19, 33, 34, 35, 37, 42, 50, 53, 72, 73, 74, 88, 125, 126, 127, 130, 143, 144, 150], "central": [24, 26, 42, 43, 64, 94, 120, 128, 129, 150, 154], "centrifug": 150, "centuri": [8, 53, 62, 110], "certain": [7, 11, 15, 34, 43, 45, 46, 48, 58, 63, 72, 73, 75, 88, 95, 104, 119, 133, 136, 144, 153, 156], "certainli": [44, 64, 67, 105, 134, 135, 147, 152, 161], "certainti": [8, 16, 43, 72], "cf": [19, 31, 32, 35, 51, 52, 73, 79, 85, 86, 93, 122, 148, 154, 159], "cft": 33, "cft_n": 33, "cft_n_pt": 33, "ch": [38, 39, 53, 152], "chain": [1, 6, 7, 16, 38, 41, 43, 51, 59, 67, 69, 71, 96, 123, 144, 145, 146, 147, 148, 151, 152, 159, 160, 161, 162, 163], "chain1": [50, 143], "chain1d": [143, 144], "chain2": [50, 143], "chain_data": 123, "chain_length": 151, "chainpandasindexpandasindex": 151, "challeng": [8, 16, 34, 44, 48, 51, 53, 73, 88, 92, 107, 110, 113, 119, 122, 154], "chalmer": [1, 56, 78], "champion": 73, "chanc": [16, 19, 25, 72, 144, 159], "chang": [3, 4, 9, 11, 13, 16, 17, 22, 24, 25, 30, 33, 34, 35, 37, 39, 40, 43, 45, 47, 49, 51, 53, 56, 58, 61, 64, 67, 68, 71, 73, 77, 79, 83, 86, 92, 93, 94, 95, 96, 122, 123, 126, 127, 131, 132, 133, 134, 135, 142, 143, 144, 146, 148, 149, 150, 151, 152, 153, 156, 158, 159], "channel": [65, 73, 75, 76, 88, 137], "chapman": [0, 1, 56], "chapter": [2, 7, 16, 20, 26, 27, 28, 30, 34, 35, 37, 43, 44, 46, 53, 55, 57, 61, 63, 64, 66, 72, 75, 86, 88, 89, 98, 99, 105, 110, 118, 119, 124, 153, 154, 156, 160], "charact": [9, 133], "character": [8, 16, 17, 19, 35, 43, 47, 66, 67, 79, 94, 106, 111, 122, 125, 126, 143, 147, 152, 154], "characteris": 63, "characterist": [63, 71, 86], "charg": [21, 133], "charl": 1, "chart": 95, "chase": 7, "chatterji": 66, "cheat": 136, "cheatsheet": 134, "chebyshev": 46, "check": [0, 3, 4, 13, 18, 20, 22, 34, 35, 37, 38, 42, 44, 49, 51, 59, 66, 69, 73, 77, 83, 85, 86, 92, 93, 94, 96, 123, 126, 127, 134, 136, 137, 143, 145, 146, 148, 151, 153, 156, 159, 162], "checkabl": 49, "checkbox": [5, 9, 132], "checklist": 28, "checklist_b": 0, "checkmark": 24, "checkpoint": 134, "chess": 79, "chi": [7, 18, 19, 26, 38, 45, 49, 51, 52, 95, 96, 97, 125, 127, 148, 153, 154], "chi2": 29, "chi_": 123, "chi_sqs_dof": 95, "chi_squar": 95, "chief": 59, "child": [45, 126], "child_exception_typ": 126, "children": [9, 63, 132], "chines": [1, 133], "ching": 1, "chiral": [1, 47, 126], "chisq_min": 49, "choic": [4, 8, 9, 15, 16, 17, 19, 23, 25, 30, 38, 39, 40, 41, 43, 44, 46, 53, 63, 64, 65, 66, 67, 71, 74, 77, 80, 83, 92, 94, 95, 100, 106, 107, 113, 117, 120, 130, 134, 138, 144, 147, 152, 153, 156, 159, 161, 163], "choleski": [78, 86], "choos": [5, 7, 13, 19, 35, 38, 40, 41, 42, 43, 44, 46, 47, 48, 53, 58, 62, 63, 66, 67, 69, 71, 72, 77, 83, 104, 105, 134, 143, 144, 145, 146, 153, 162], "chose": [47, 96, 156], "chosen": [0, 7, 25, 35, 46, 47, 50, 51, 53, 77, 83, 85, 105, 144, 145, 151, 153, 154, 162], "chri": [85, 128], "christian": [1, 38, 39, 44, 50, 56, 73, 77, 78, 93, 95, 143, 144, 147, 152], "christoph": [1, 128], "chromosom": 130, "ci": [9, 30, 123], "cifar": 76, "circ": [68, 78], "circl": [4, 34, 35, 38, 67, 72, 78, 153], "circular": 153, "circumst": [8, 19, 43, 63], "circumstanti": 62, "circumv": 53, "citat": [0, 63], "cite": [0, 43, 48, 72], "citizen": 64, "clabel": 130, "claim": [21, 42, 44, 51, 63, 64, 79, 86, 111, 115, 117, 127, 151, 154], "clang": [73, 93], "clariti": [78, 117], "class": [9, 28, 34, 46, 47, 53, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 81, 93, 96, 97, 105, 125, 130, 133, 137, 145, 150, 156, 159, 161, 162], "class_i": 65, "class_mean": 65, "class_mean_list": 65, "class_nam": 76, "class_weight": 70, "classic": [8, 25, 39, 42, 51, 133, 147, 148, 152, 153], "classif": [43, 47, 62, 66, 67, 69, 71, 72, 73, 75, 76, 91, 93], "classifi": [63, 64, 66, 67, 72, 74, 76], "classifier_elbo": [72, 73], "classmat": 34, "claus": [80, 81], "clean": [71, 126], "cleaner": 73, "cleans": 92, "cleanup": 126, "clear": [7, 10, 19, 23, 34, 38, 40, 44, 51, 53, 59, 61, 71, 72, 73, 78, 90, 95, 96, 97, 103, 130, 134, 156], "clearer": [31, 43], "clearli": [7, 12, 34, 38, 43, 61, 63, 66, 73, 75, 79, 101, 156, 159], "clever": [34, 156], "clf": [70, 126, 133], "click": [17, 56, 134, 137, 161], "clickabl": 56, "climat": 46, "climb": 144, "clint": 1, "clip": 38, "clockwis": 127, "clone": [137, 139, 140], "close": [0, 12, 16, 29, 31, 33, 34, 37, 38, 40, 43, 44, 49, 53, 56, 64, 67, 68, 72, 73, 77, 80, 83, 86, 89, 95, 96, 97, 104, 107, 119, 125, 127, 133, 143, 144, 151, 153, 154], "close_fd": 126, "closer": [17, 38, 86, 151], "closest": [7, 9, 30, 37, 53, 65, 127], "cloth": 76, "cloud": [0, 22, 56, 131, 137], "clt": [33, 129], "clt_pdf": 33, "cluster": [47, 62, 66, 148], "cluster_std": 74, "clutter": [19, 86], "cm": [34, 37, 49, 50, 65, 69, 70, 76, 126, 130], "cmap": [34, 37, 40, 50, 65, 69, 70, 73, 76, 93, 127, 130], "cnn": [67, 89], "cntl": 154, "co": [33, 34, 46, 51, 71, 77, 82, 83, 92, 112, 134, 149, 150], "code": [7, 13, 17, 30, 33, 34, 35, 38, 40, 42, 43, 47, 50, 51, 56, 64, 70, 73, 76, 77, 83, 87, 92, 93, 94, 95, 96, 102, 106, 123, 133, 138, 142, 144, 145, 146, 151, 153, 158, 161, 162], "codebas": 43, "codec": 126, "codeloc": [123, 156, 161], "coef": 133, "coef_": [70, 133], "coeffici": [4, 7, 24, 47, 49, 65, 66, 67, 73, 86, 88, 94, 123, 130, 133, 136], "coerc": 133, "coher": [8, 128], "coin": [8, 13, 16, 23, 110, 161], "coin_data": 9, "coin_ppd": 0, "coinflipping_fig_1": 25, "col": [25, 30, 133, 134, 135], "colab": 76, "collabor": [16, 56], "collaps": 52, "collat": 77, "colleagu": [56, 63], "collect": [8, 12, 16, 25, 34, 37, 39, 43, 44, 46, 47, 48, 62, 63, 64, 65, 66, 68, 69, 78, 79, 82, 85, 86, 100, 101, 102, 110, 117, 123, 124, 128, 130, 144, 147, 152, 153, 156, 161], "collid": 21, "collis": 161, "colon": [0, 134], "color": [3, 4, 5, 9, 17, 23, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 49, 63, 65, 66, 69, 71, 73, 75, 76, 77, 78, 80, 81, 82, 83, 88, 93, 95, 102, 120, 123, 126, 127, 130, 132, 134, 135, 143, 144, 145, 147, 149, 150, 152, 156, 161, 162], "color_channel": 76, "colorbar": [34, 50, 69, 73, 78, 82, 93, 152], "colour": 4, "columbia": 1, "column": [7, 31, 32, 34, 38, 45, 65, 95, 100, 102, 125, 128, 133, 134, 136, 143, 144, 146, 153, 156, 159], "com": [1, 73, 80, 81, 93, 127, 130, 135, 137, 140, 161], "combin": [0, 8, 16, 19, 31, 33, 34, 37, 39, 43, 44, 46, 47, 48, 50, 53, 55, 59, 62, 66, 67, 71, 73, 78, 79, 82, 85, 86, 88, 93, 106, 117, 120, 123, 125, 127, 142, 146, 147, 152, 153, 156, 158], "come": [0, 4, 8, 9, 10, 11, 16, 17, 19, 21, 29, 30, 34, 35, 38, 40, 43, 49, 51, 53, 62, 63, 66, 67, 72, 73, 79, 86, 92, 93, 101, 103, 126, 133, 137, 143, 144, 146, 147, 152, 154, 158, 159, 163], "comet": 110, "comfort": [19, 46], "comm": 1, "command": [0, 64, 69, 71, 77, 83, 94, 126, 133, 134, 135, 137, 142, 151], "comment": [17, 19, 35, 37, 40, 43, 49, 50, 51, 53, 65, 73, 96, 127, 134, 150, 154, 158], "commiss": 63, "commit": 63, "common": [0, 7, 11, 19, 26, 34, 38, 40, 41, 43, 44, 46, 47, 48, 53, 56, 58, 60, 62, 65, 66, 67, 68, 70, 73, 76, 78, 82, 85, 86, 88, 95, 97, 99, 105, 110, 113, 117, 126, 130, 132, 133, 135, 136, 148, 149, 150, 151, 153, 154, 161], "common_num": 135, "commonli": [4, 40, 66, 88, 107, 117, 151, 153], "commun": [19, 56, 61, 64, 67, 97, 156], "comp": 1, "compact": [23, 65, 67, 68, 123], "compani": 63, "compar": [1, 6, 7, 9, 11, 14, 17, 19, 29, 30, 34, 37, 38, 42, 43, 44, 47, 50, 51, 53, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 77, 78, 82, 83, 86, 92, 93, 94, 95, 120, 121, 125, 127, 129, 130, 133, 144, 150, 151, 156, 158, 159, 161, 163], "comparison": [16, 17, 33, 34, 38, 43, 47, 51, 52, 62, 73, 93, 95, 102, 107, 116, 119, 126, 144, 146, 150, 156], "compat": [43, 88, 92, 127, 146], "compel": 61, "compet": [7, 48, 53, 61, 62, 64], "competit": 47, "compil": [34, 64, 69, 73, 93, 133], "compl": 66, "complaint": 151, "complementari": 53, "complet": [0, 3, 7, 16, 22, 25, 28, 31, 32, 34, 37, 38, 43, 46, 48, 49, 51, 52, 65, 67, 71, 76, 82, 85, 86, 116, 123, 130, 133, 134, 151, 153, 156, 161], "completemodel": 48, "completenn": 67, "complex": [1, 7, 44, 46, 47, 48, 62, 64, 67, 70, 74, 95, 117, 119, 136, 151, 154], "complianc": 76, "complic": [16, 34, 38, 51, 53, 64, 67, 70, 95, 97, 99, 105, 106, 107, 112, 144, 147, 151, 152, 153, 154], "compon": [41, 47, 53, 64, 71, 85, 124, 125, 146, 149, 150, 154], "compos": [47, 67, 96, 156], "compoundstep": 151, "comprehens": [37, 43], "compress": [47, 125, 133, 134, 136], "compromis": [63, 71], "comput": [1, 5, 9, 11, 16, 19, 25, 30, 34, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 53, 56, 58, 59, 60, 62, 64, 65, 66, 67, 68, 70, 72, 73, 75, 76, 78, 79, 80, 82, 85, 86, 88, 89, 92, 95, 96, 97, 102, 104, 105, 107, 119, 122, 123, 124, 127, 130, 131, 133, 134, 136, 137, 140, 143, 144, 145, 146, 147, 151, 152, 153, 156, 159, 162], "computation": [7, 38, 44, 51, 71, 76, 79, 85, 105, 112, 122], "compute_sigma_level": 41, "compute_test_valu": [73, 93], "concat": 133, "concaten": [50, 96, 123, 134, 138, 162], "concentr": [9, 43, 72, 153], "concept": [1, 23, 24, 38, 43, 48, 61, 66, 73, 77, 83, 117], "conceptu": [19, 48, 66, 67], "concern": [7, 8, 34, 45, 46, 53, 64, 65, 73, 88, 104, 128, 130, 133, 156], "concic": 133, "concis": 66, "conclud": [19, 31, 34, 39, 40, 50, 51, 63, 66, 102, 127, 152], "conclus": [12, 17, 34, 35, 37, 40, 51, 58, 61, 62, 67, 95, 96, 110, 130, 150], "concret": [16, 24, 117, 143, 153, 154], "conda": [70, 71, 73, 93, 134, 142], "condemn": 46, "condens": 43, "condit": [4, 8, 16, 19, 20, 21, 22, 23, 24, 25, 29, 30, 31, 32, 34, 37, 43, 44, 47, 53, 58, 61, 76, 77, 83, 85, 86, 120, 123, 125, 127, 129, 148, 149, 150, 153], "condition": 16, "conduct": [8, 21, 43, 48], "conf": 51, "confid": [9, 11, 16, 17, 25, 26, 29, 30, 41, 43, 46, 53, 55, 76, 77, 80, 83, 88, 121, 147, 152], "config": [73, 93, 129, 137], "configur": [43, 51, 76, 129, 137, 156], "confin": 159, "confirm": [46, 63, 67], "confiur": 146, "conflict": [43, 134], "conform": 62, "confront": [25, 30, 46, 62, 64], "confus": [32, 41, 63, 65, 96], "conisd": 115, "conjectur": 61, "conjug": [9, 34, 40, 44, 52, 95, 126, 136], "conjugaci": 52, "conjunct": 47, "connect": [4, 8, 23, 26, 33, 44, 46, 48, 51, 60, 61, 63, 66, 67, 68, 69, 73, 75, 90, 96, 107, 117, 127, 135], "consecut": 136, "consensu": [43, 61], "consequ": [8, 20, 24, 33, 34, 45, 46, 47, 58, 61, 63, 65, 66, 67, 68, 129, 144, 146, 149, 153], "conserv": [7, 44, 79, 121, 148, 151], "consid": [3, 4, 5, 6, 7, 8, 9, 10, 16, 19, 22, 25, 26, 29, 33, 34, 37, 38, 39, 43, 44, 45, 46, 47, 48, 49, 52, 53, 57, 62, 63, 64, 65, 66, 67, 68, 72, 73, 74, 75, 77, 82, 85, 86, 88, 93, 96, 99, 100, 104, 105, 110, 111, 114, 115, 117, 123, 124, 125, 130, 144, 147, 148, 149, 150, 152, 154, 156, 158, 159, 160, 161], "consider": [10, 48, 51, 61, 62, 71, 100], "considerd": 123, "consist": [4, 8, 17, 22, 32, 34, 43, 47, 48, 49, 51, 53, 58, 59, 62, 65, 66, 67, 69, 71, 72, 74, 75, 79, 93, 121, 123, 126, 134, 136, 142, 145, 156, 162], "consolid": 129, "consruct": 73, "constant": [3, 4, 5, 7, 13, 25, 33, 34, 35, 37, 38, 40, 41, 42, 43, 45, 49, 51, 53, 67, 73, 78, 80, 85, 88, 90, 93, 94, 95, 96, 99, 102, 115, 120, 121, 122, 123, 130, 133, 134, 143, 144, 148, 153, 154, 159, 161], "constant_": 71, "constant_valu": 82, "constantkernel": [81, 82], "constantli": 154, "constitu": 133, "constitut": [12, 66, 72, 85], "constrain": [39, 40, 46, 47, 52, 53, 60, 66, 73, 75, 77, 83, 85, 111, 119, 121, 147, 152, 156], "constrain_posit": [77, 83], "constrained_layout": [123, 126], "constraint": [4, 8, 29, 38, 43, 46, 47, 66, 77, 83, 104, 126, 156, 161], "construct": [0, 7, 8, 18, 21, 22, 25, 38, 39, 43, 44, 45, 46, 47, 48, 49, 50, 53, 64, 65, 67, 70, 72, 73, 77, 82, 83, 85, 96, 110, 119, 129, 130, 134, 135, 146, 147, 149, 151, 152, 153, 156], "construct_nn": [73, 93], "constructor": 71, "consum": [60, 63], "contact": 133, "contain": [7, 8, 9, 15, 17, 19, 25, 30, 41, 44, 46, 48, 62, 67, 69, 72, 73, 75, 76, 88, 93, 111, 123, 127, 130, 133, 136, 142, 147, 151, 152, 153, 156], "contemp": 1, "contemporari": 148, "content": [9, 43, 56, 91, 119, 122, 125, 132, 133, 136, 137], "context": [2, 4, 7, 16, 22, 23, 29, 34, 43, 44, 47, 48, 50, 53, 57, 58, 59, 60, 61, 63, 65, 66, 71, 72, 77, 83, 85, 96, 104, 110, 111, 124, 125, 130, 146, 150, 151, 158], "contextlib": 126, "contextmanag": 126, "contigu": 136, "contin": 86, "conting": [4, 10, 21, 22, 23, 58, 124], "continu": [1, 9, 11, 16, 17, 20, 22, 23, 24, 25, 26, 44, 46, 47, 48, 49, 53, 63, 64, 65, 66, 67, 71, 72, 82, 86, 88, 97, 101, 105, 122, 151, 153, 154, 156, 159, 161], "continuo": 65, "continuosli": 64, "continuous_upd": [9, 132], "continuum": [4, 23, 30, 43], "contour": [35, 37, 40, 41, 44, 50, 53, 65, 70, 73, 78, 82, 93, 130, 151, 152], "contour_func": [50, 152], "contour_level": [37, 40, 41], "contourf": [34, 37, 40, 50, 65, 70, 73, 93], "contract": 127, "contradict": [22, 61], "contrari": [39, 59, 147, 152], "contrast": [8, 26, 29, 35, 49, 62, 67, 72, 121, 161], "contribut": [38, 51, 52, 53, 56, 61, 64, 85, 133, 153], "contributor": 64, "control": [1, 9, 11, 47, 64, 70, 71, 74, 76, 80, 94, 120, 133, 142], "controversi": [39, 147, 152], "conv": 75, "conv2d": [71, 76], "conv2d_1": 76, "conv2d_2": 76, "convei": 47, "conveni": [34, 35, 37, 38, 39, 40, 41, 47, 49, 67, 68, 73, 117, 132, 134, 143, 147, 152], "convent": [0, 34, 47, 53, 67, 101, 116, 127, 132, 134, 154], "convention": [23, 134], "converg": [5, 12, 25, 41, 43, 46, 49, 68, 71, 73, 81, 92, 93, 105, 106, 107, 151, 152, 153, 159, 160, 163], "convergencewarn": [50, 81], "convers": [19, 128, 130, 156], "convert": [19, 42, 48, 69, 133, 134, 136, 151], "convex": [88, 97, 104], "convexhul": 149, "convinc": [4, 16], "convolut": [7, 71, 73, 89], "cookbook": 86, "coolwarm": [65, 130], "coordin": [8, 40, 47, 53, 65, 96, 127, 143, 148, 150, 151], "copi": [9, 44, 76, 78, 93, 96, 133, 135, 142, 143, 144, 151, 154, 159], "copyright": 76, "core": [8, 123, 133, 151], "cornebis": 1, "corner": [7, 8, 17, 25, 35, 38, 41, 50, 51, 72, 74, 82, 94, 96, 123, 130, 137, 142, 143, 146, 147, 152, 156, 161], "cornerplot": [50, 152], "corollari": 15, "corrcoef": 136, "correct": [7, 12, 16, 22, 23, 43, 48, 51, 52, 53, 65, 66, 69, 76, 85, 86, 107, 115, 117, 133, 134, 142, 148, 153, 154, 159], "correctli": [16, 18, 34, 69, 101, 135, 136, 147, 150, 152, 159], "correl": [0, 4, 24, 43, 44, 46, 47, 50, 64, 67, 73, 78, 82, 85, 86, 93, 94, 110, 117, 120, 127, 136, 144, 153, 154, 159, 161, 163], "corrent": 105, "correspond": [4, 7, 24, 25, 34, 37, 38, 41, 43, 44, 46, 47, 48, 50, 53, 60, 61, 65, 66, 67, 68, 70, 72, 74, 75, 76, 77, 78, 81, 82, 83, 86, 88, 96, 97, 99, 100, 101, 102, 105, 106, 107, 112, 113, 115, 117, 120, 121, 127, 130, 133, 134, 136, 144, 146, 149, 153, 156, 161], "correspondingli": 67, "cortex": 67, "cosh": 71, "cosin": [33, 34, 134], "cosineft": 33, "cosineft2": 33, "cosmo": 51, "cosmolog": 51, "cosmologi": [1, 21, 40, 95], "cosmologist": 159, "cost": [34, 44, 45, 46, 51, 53, 63, 64, 66, 67, 69, 70, 72, 85, 97, 100, 104, 105, 106, 107, 113, 123, 154], "cost_funct": 106, "costli": [44, 73, 105], "couch": [58, 62], "could": [3, 5, 8, 9, 11, 19, 21, 22, 25, 34, 43, 44, 46, 47, 48, 51, 52, 53, 58, 61, 65, 66, 67, 70, 72, 73, 75, 77, 83, 88, 96, 97, 101, 104, 105, 110, 111, 115, 119, 124, 126, 130, 132, 133, 135, 144, 146, 151, 153, 154, 156, 158], "coulomb": [34, 99, 133], "count": [4, 8, 9, 17, 33, 35, 37, 39, 42, 60, 67, 117, 123, 126, 133, 143, 152], "countabl": [86, 104, 130, 156], "counter": [16, 39, 42, 63, 127, 147, 152], "counterexampl": 156, "counterpart": [31, 88], "coupl": [23, 26, 40, 47, 52, 53, 117, 122, 134], "courag": 61, "cours": [1, 4, 19, 25, 30, 31, 34, 38, 39, 40, 50, 56, 63, 72, 77, 79, 88, 91, 94, 95, 97, 100, 134, 138, 143, 144, 147, 152], "cov": [24, 34, 46, 50, 65, 78, 82, 95, 127, 130, 143, 146, 161], "cov_exp": 123, "cov_mat": 49, "cov_matrix": 123, "cov_new": 82, "cov_opt": 82, "cov_rbf": [78, 82], "cov_tot": 123, "covari": [4, 7, 24, 34, 41, 46, 47, 49, 53, 72, 79, 80, 86, 92, 95, 119, 120, 121, 123, 125, 146, 148, 153, 161], "covariancematrix": 82, "cover": [19, 44, 63, 72, 116, 121, 123, 134, 154], "coverag": [89, 153], "covparslr": 34, "covr": 34, "cow": 21, "cox": [1, 22, 31, 32], "cox61": [1, 22], "cprob": [16, 21, 22, 46, 130, 156], "cpu": [38, 41, 50, 73, 93, 123, 136, 143, 163], "cpu_affin": 123, "cpu_count": 123, "cr": [38, 41], "crank": 151, "crash": [64, 138], "crc": [0, 1, 56], "creat": [6, 7, 34, 35, 37, 38, 40, 41, 47, 64, 65, 66, 67, 71, 73, 74, 75, 77, 80, 81, 82, 83, 88, 92, 93, 94, 95, 102, 111, 123, 126, 127, 129, 130, 134, 140, 143, 144, 148, 149, 151, 153, 154, 156, 161], "create_multiple_process": [156, 161], "created_at": 151, "creation": [73, 135, 136], "creationflag": 126, "creativ": 56, "cred68": [9, 17, 30, 126], "cred95": [9, 17, 30, 126], "credibl": [9, 17, 18, 26, 30, 41, 43, 44, 62, 82, 86, 94, 126], "credible_range_dist": 82, "credibleregions_fig": 130, "credit": 143, "creep": 63, "cri": 62, "cricl": 70, "crime": 63, "crimin": 63, "crit": 19, "criterion": [53, 71, 148, 153, 154], "critic": [8, 38, 43, 53, 61, 63, 64, 66, 67, 71, 73, 117, 128, 130, 136, 148], "cross": [4, 47, 51, 64, 65, 67, 70, 72, 128], "crossval_err": 95, "croupier": 161, "crowd": 66, "crucial": [16, 22, 43, 48, 53, 63, 71], "crudest": 150, "cs231": 75, "cset": [50, 152], "csr": 136, "csr_matrix": 136, "cstride": [37, 65], "csv": 77, "cubehelix_palett": [73, 93], "cubehelix_r": 50, "cubic": 53, "cubism": 128, "cuda": 71, "cultur": [63, 161], "cumsum": [37, 40, 41, 127, 133, 136], "cumul": [44, 127, 136], "cup": [22, 130], "cup_": 130, "current": [9, 21, 25, 34, 44, 46, 49, 50, 51, 53, 67, 69, 71, 76, 77, 83, 95, 107, 134, 137, 143, 144, 148, 151, 153, 154, 156], "current_posit": [144, 159], "curs": 153, "cursor": 134, "curv": [17, 19, 38, 47, 71, 78, 82, 120, 126, 127, 129, 130, 144, 161], "curvatur": [34, 41], "cusp": 73, "custom": [73, 123, 153], "cut": [7, 17, 49, 52, 53, 95, 133, 135], "cutoff": [37, 38, 40, 41, 46], "cv": [64, 66, 70, 95], "cwd": 126, "cxxflag": [73, 93], "cyb89": [1, 67], "cybenko": 1, "cycl": [43, 67], "cycle_b": 0, "cycler": 49, "d": [0, 1, 3, 7, 8, 9, 10, 11, 15, 16, 17, 19, 23, 25, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 44, 48, 49, 51, 52, 53, 56, 66, 67, 71, 72, 77, 78, 79, 82, 83, 85, 86, 88, 92, 93, 95, 96, 100, 102, 114, 115, 117, 121, 123, 125, 126, 130, 133, 143, 144, 145, 146, 147, 148, 150, 152, 153, 154, 158, 162], "d0": [0, 7, 41], "d1": 37, "d1_": 49, "d1_c_5": 94, "d2": 37, "d_": [25, 30, 35, 72], "d_1": [15, 34], "d_2": [15, 34], "d_3": 15, "d_i": [38, 39, 51, 147, 152], "d_k": [4, 15, 35, 37, 96], "d_list": 33, "d_max": 37, "da": [7, 35, 52], "daan": 1, "dagger": [45, 48], "dai": [1, 16, 53, 156], "daili": 63, "damian": [78, 82], "damp": 149, "dan": [117, 147, 152], "danc": 143, "danger": [43, 45, 63], "daniel": [1, 5, 56, 133, 151, 159], "dare": 46, "dark": [17, 38, 56, 130], "darkgreen": [9, 23, 30], "darkgrid": [78, 92], "dash": [7, 9, 37, 38, 44, 94, 130, 147, 150, 152], "dat": [94, 133], "dat_id": 133, "data": [0, 1, 3, 4, 7, 8, 9, 10, 11, 12, 15, 17, 19, 20, 21, 23, 24, 25, 29, 30, 35, 39, 42, 43, 44, 46, 47, 48, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 66, 67, 68, 70, 71, 72, 78, 79, 80, 81, 82, 85, 86, 88, 89, 90, 91, 92, 94, 95, 97, 98, 100, 101, 102, 103, 105, 106, 109, 110, 111, 113, 115, 117, 118, 119, 121, 123, 125, 126, 129, 130, 131, 134, 138, 144, 145, 146, 147, 151, 153, 154, 158, 159, 162], "data1": 17, "data2": 17, "data_": [7, 34, 64, 66], "data_batch": 106, "data_fram": [34, 102], "data_generating_process": 66, "data_generating_process_measur": [34, 102], "data_generating_process_r": [34, 102], "data_i": [34, 66, 106], "data_id": 133, "data_in": 151, "data_inst": 106, "data_panda": 133, "data_path": 133, "dataarrai": 151, "databin": 37, "datacamp": 138, "datafil": 133, "datafram": [34, 102, 133, 143], "dataframegroupbi": 133, "datapoint": [34, 80, 88, 101, 102], "dataset": [37, 38, 39, 40, 52, 63, 66, 67, 69, 70, 71, 72, 73, 74, 77, 88, 93, 109, 117, 123, 142, 147, 151, 152], "dataset_mirror": 77, "datasetdimens": 151, "datat": 65, "date": [8, 45, 51, 63, 64, 126, 133, 137, 153, 154], "date_format": 126, "datetim": 126, "datum": [34, 38, 66, 72, 100], "daughter": 45, "dave": 121, "david": [1, 46, 56, 63, 72, 126, 128, 159], "db": 35, "dbeta": 96, "dc": 77, "ddot": [34, 52, 100, 150], "de": [1, 34, 43, 45, 46, 80, 81], "deactiv": 137, "deal": [7, 8, 17, 25, 34, 41, 48, 51, 52, 53, 55, 59, 62, 64, 65, 67, 75, 110, 112, 117, 125, 130, 133, 156], "dealt": 4, "dean": 1, "death": [147, 152], "debat": [147, 152], "debug": [71, 126, 138], "dec": 151, "decad": 64, "decai": [37, 47, 71, 72, 74, 88, 107, 133, 153, 156], "decemb": 1, "decid": [4, 15, 19, 23, 25, 34, 38, 48, 49, 64, 65, 71, 75, 92, 102, 132, 144, 146, 148, 153, 154, 159], "decim": [32, 123, 127, 133, 134, 154], "decis": [8, 16, 51, 61, 63, 70, 72, 73, 74, 88, 111, 153, 154, 156], "deck": 32, "declar": [9, 53, 62, 132, 134, 136], "decompos": [47, 48, 53, 127], "decomposit": [47, 67, 78, 86, 124, 127], "decreas": [25, 33, 46, 49, 52, 64, 66, 71, 95, 105, 106, 107, 121, 144, 151, 153, 154, 159], "decreasing_learning_r": 106, "decri": 153, "deduc": [16, 37, 62, 64], "deduct": 62, "deem": 46, "deep": [1, 68, 69, 71, 75, 93, 117, 161], "deeper": [43, 45, 62, 63, 64, 73, 76], "deeplearn": [73, 93], "deepli": 62, "deer": 76, "def": [0, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 40, 41, 42, 49, 50, 65, 69, 70, 71, 73, 76, 77, 78, 81, 82, 88, 92, 93, 95, 96, 102, 123, 126, 127, 129, 130, 132, 133, 134, 135, 138, 143, 144, 145, 147, 149, 150, 151, 152, 156, 161, 162], "defalt": 9, "default": [9, 23, 30, 33, 34, 49, 50, 66, 69, 77, 79, 82, 83, 92, 95, 96, 102, 107, 123, 126, 129, 133, 134, 136, 137, 138, 146, 149, 150, 151], "default_rng": [30, 34, 102, 130], "defect": [23, 53, 59], "defend": 63, "defer": 7, "defici": 41, "defin": [0, 6, 7, 8, 11, 13, 16, 17, 18, 19, 23, 34, 35, 37, 38, 40, 41, 43, 44, 46, 47, 49, 50, 51, 53, 56, 59, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 80, 81, 82, 83, 85, 86, 88, 89, 92, 93, 94, 95, 96, 100, 102, 107, 110, 113, 117, 120, 121, 125, 126, 130, 133, 134, 137, 138, 143, 144, 145, 147, 150, 151, 152, 156, 159, 161, 162], "definit": [0, 8, 9, 11, 16, 17, 19, 21, 23, 24, 25, 30, 40, 41, 42, 44, 46, 49, 61, 62, 65, 66, 70, 71, 77, 78, 82, 83, 85, 86, 88, 95, 96, 110, 120, 127, 134, 138, 144, 156, 159], "deform": 79, "deg": [21, 95], "degener": 50, "degeneraci": 47, "degre": [4, 8, 15, 17, 19, 22, 25, 29, 34, 38, 39, 43, 44, 46, 53, 55, 66, 86, 95, 96, 99, 100, 102, 117, 126, 127, 130, 147, 152], "degree_max": 95, "degreef": 130, "del": 126, "del_x": 37, "delet": [34, 95, 102, 134, 136], "deliber": 144, "delimit": [0, 134], "deliv": 97, "delta": [4, 15, 16, 17, 19, 23, 29, 34, 35, 37, 38, 40, 41, 45, 46, 49, 51, 52, 53, 68, 85, 88, 104, 118, 120, 123, 130, 133, 143, 146, 148, 150, 153, 156, 158, 161], "delta_": [29, 65, 66, 85, 125, 127], "delta_bin": 126, "delta_h": 133, "delta_i": 38, "delta_j": 68, "delta_k": 68, "delta_n": 133, "delta_t": [149, 150], "delta_x": 37, "deltah": [0, 7], "delv": 161, "demand": [56, 85, 112], "demetropoli": 151, "demetropolisz": 151, "demo": [7, 70, 86, 93, 148, 153, 154], "democraci": 63, "demograph": 63, "demonst": 127, "demonstr": [7, 11, 19, 26, 34, 39, 44, 47, 59, 62, 66, 71, 72, 86, 87, 89, 97, 102, 136, 147, 152, 153, 160], "den": 144, "denisti": 156, "denomin": [7, 10, 13, 16, 25, 34, 42, 46, 49, 52, 53, 107, 142, 143, 153], "denot": [4, 16, 19, 23, 25, 29, 34, 42, 44, 45, 46, 63, 66, 67, 68, 72, 78, 82, 85, 86, 88, 95, 96, 97, 99, 106, 110, 120, 123, 130, 143, 146, 151, 153, 154, 156], "dens": [34, 69, 86, 102], "dense_1": [69, 76], "denser": [34, 102], "densest": 82, "densiti": [8, 9, 11, 19, 20, 22, 25, 27, 29, 30, 33, 34, 35, 37, 42, 43, 44, 46, 48, 51, 53, 79, 82, 85, 123, 126, 129, 144, 148, 151, 153, 154, 156, 161], "depaoli": 1, "departur": 51, "depend": [4, 12, 13, 16, 18, 19, 25, 34, 35, 37, 38, 40, 43, 45, 46, 47, 48, 51, 52, 61, 63, 64, 65, 66, 67, 68, 71, 72, 76, 79, 85, 86, 88, 94, 96, 97, 99, 100, 104, 105, 106, 109, 110, 112, 117, 120, 129, 134, 135, 137, 140, 146, 147, 150, 151, 152, 153, 154, 156, 161], "depict": 156, "deploi": 63, "deploy": 63, "deprec": [37, 50, 70, 96, 133], "deprecationwarn": 37, "depth": [46, 53, 67, 71, 75, 117, 129, 134, 160], "deriv": [0, 7, 8, 16, 19, 25, 31, 33, 34, 37, 38, 39, 42, 43, 44, 45, 46, 47, 52, 53, 66, 71, 72, 88, 90, 96, 97, 100, 105, 107, 114, 117, 119, 123, 147, 148, 151, 152, 158], "derivati": 148, "desai": 51, "descend": [110, 127, 136], "descent": [65, 66, 67, 68, 70, 71, 73, 75, 88, 113, 116, 154], "describ": [4, 7, 16, 19, 34, 37, 38, 39, 41, 43, 44, 46, 47, 48, 49, 55, 56, 63, 64, 65, 66, 67, 71, 72, 73, 85, 88, 93, 95, 97, 100, 105, 107, 110, 111, 115, 116, 117, 118, 120, 130, 133, 137, 142, 143, 144, 147, 148, 150, 152, 153, 156, 160, 161], "descript": [9, 23, 34, 42, 43, 65, 99, 100, 110, 132, 134, 136, 151, 156], "deserv": [66, 97], "desiderata": 62, "design": [0, 8, 16, 23, 35, 37, 43, 44, 46, 47, 51, 53, 56, 60, 65, 67, 71, 72, 77, 83, 85, 88, 101, 102, 103, 122, 130, 133, 150, 153, 161], "desir": [7, 19, 25, 38, 41, 43, 47, 51, 53, 64, 66, 71, 86, 100, 117, 130, 143, 148, 156], "despin": [73, 93], "despis": 63, "despit": [7, 39, 43, 47, 63, 65, 66, 67, 110, 147, 152, 153], "desrib": 19, "destroi": [147, 152], "det": [49, 50, 52, 53, 78, 86, 95, 96, 123, 136, 156], "deta": 66, "detail": [9, 11, 16, 19, 20, 22, 23, 24, 27, 28, 34, 35, 38, 40, 43, 44, 45, 47, 50, 51, 52, 59, 60, 69, 72, 77, 86, 95, 96, 111, 116, 125, 126, 134, 137, 139, 142, 146, 147, 148, 152, 153, 158, 160], "detect": [7, 38, 42, 43, 62, 66, 67, 142], "detector": 51, "determin": [3, 4, 7, 9, 11, 19, 23, 34, 35, 37, 41, 49, 52, 53, 62, 63, 65, 66, 67, 68, 78, 82, 85, 86, 90, 96, 103, 110, 117, 121, 130, 133, 144, 147, 150, 152, 153, 154, 156, 161], "determinist": [48, 66, 72, 88, 110, 117, 123, 130, 145, 148, 161, 162], "determmin": 65, "detour": 44, "dev": [17, 81, 126], "devalu": 63, "devdoc": [50, 96], "develop": [8, 16, 33, 46, 47, 56, 61, 63, 64, 65, 67, 73, 121, 134], "devianc": 51, "deviat": [3, 4, 7, 12, 17, 19, 24, 29, 33, 34, 35, 37, 38, 39, 40, 41, 43, 46, 50, 53, 65, 71, 72, 73, 74, 78, 80, 81, 93, 94, 95, 120, 121, 123, 126, 129, 130, 133, 135, 143, 144, 145, 146, 147, 151, 152, 158, 159, 162], "devic": [25, 51, 73], "devinderjit": 7, "devis": [44, 67], "df": [7, 126, 130, 133], "df1": 133, "df_chain": 143, "dfm": 159, "dft": 79, "dgrid": [0, 7], "dh": [7, 121, 123], "dh_0": 41, "dhdt": 123, "dhs11": [1, 107], "di": [0, 7], "diag": [34, 47, 49, 50, 82, 123, 127], "diagnos": [43, 63], "diagnost": [43, 73, 93, 94, 141, 146, 152, 153, 159, 160], "diagon": [34, 41, 45, 47, 50, 53, 66, 72, 78, 82, 85, 86, 94, 107, 127, 130, 136, 146, 147, 148, 152, 156, 161], "dialect": 64, "dic": 51, "dice": [3, 72], "dick": [0, 5, 38, 50, 56, 77, 78, 132, 137, 143, 149, 151], "dick_in_tailcoat": 127, "dict": [9, 17, 37, 95, 126, 132, 144], "dict_kei": 69, "dictat": [8, 34, 37, 67, 78, 153], "dictionari": 133, "did": [7, 25, 34, 40, 50, 63, 73, 96, 130, 144, 145, 147, 150, 152, 162], "didn": [31, 49, 50, 126, 153, 154], "die": [4, 8, 23], "diederik": 1, "diff": [96, 126], "diffeq": 150, "differ": [3, 4, 6, 7, 8, 9, 11, 12, 15, 16, 17, 18, 19, 22, 23, 25, 26, 27, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 55, 56, 59, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 87, 88, 90, 92, 93, 94, 95, 97, 99, 100, 104, 105, 107, 111, 117, 123, 126, 129, 130, 133, 134, 135, 136, 137, 142, 143, 144, 145, 146, 147, 148, 151, 152, 153, 154, 156, 159, 161, 162], "different": [72, 73], "different_num": 135, "differenti": [1, 7, 35, 51, 64, 67, 71, 72, 73, 75, 78, 82, 85, 93, 97, 105, 130, 148, 149, 150, 158, 161, 163], "differentialmov": 50, "difficult": [25, 43, 44, 47, 52, 63, 67, 95, 97, 104, 105, 119, 146, 148, 154, 156, 159], "difficulti": [53, 105, 107], "diffus": [43, 148, 154], "digit": [63, 125, 133, 162], "dillon": 1, "dim": [41, 50, 67, 92, 96], "dimenion": 18, "dimens": [8, 23, 34, 44, 45, 47, 50, 60, 67, 75, 76, 77, 78, 79, 82, 83, 85, 86, 96, 97, 100, 105, 113, 123, 126, 127, 133, 136, 143, 144, 146, 147, 148, 151, 152, 153], "dimensin": 136, "dimension": [16, 17, 19, 23, 26, 33, 34, 40, 43, 44, 45, 46, 47, 49, 51, 53, 67, 69, 72, 73, 77, 80, 83, 85, 86, 92, 93, 113, 124, 125, 127, 129, 130, 133, 144, 146, 147, 148, 152, 153, 154, 156, 161, 163], "dimensionalisti": 51, "dimensionless": [23, 44, 113, 130], "diminish": 119, "dip": 43, "dir": 151, "dirac": [23, 123], "direc": 123, "direct": [4, 8, 13, 19, 34, 48, 53, 66, 67, 69, 88, 97, 105, 123, 127, 134, 144, 146, 147, 148, 150, 152, 153, 154, 159], "directli": [19, 23, 32, 33, 42, 44, 46, 47, 72, 73, 85, 93, 94, 121, 124, 127, 130, 161], "directori": [0, 123, 126, 130, 137, 140], "disabl": [9, 63, 126, 132], "disadvantag": [38, 63], "disappear": [53, 153, 156], "discard": [6, 44, 48, 50, 143, 147, 151, 152], "disciplin": [64, 67], "disclaim": 64, "discov": [16, 19, 128], "discoveri": [61, 62, 67], "discrep": [16, 29, 34, 48, 55, 59, 110, 111, 120, 121, 158], "discret": [4, 9, 11, 16, 17, 22, 23, 24, 25, 37, 44, 64, 65, 67, 72, 88, 110, 121, 123, 145, 146, 161, 162], "discrimin": [53, 63, 88], "discuss": [7, 16, 19, 21, 23, 25, 29, 33, 37, 39, 40, 41, 44, 46, 48, 56, 58, 59, 60, 63, 64, 66, 68, 72, 73, 88, 94, 95, 96, 98, 105, 110, 113, 114, 117, 120, 121, 127, 143, 151, 154, 156, 159], "diseas": [22, 31, 63, 88], "dishonest": 61, "disjoint": 130, "disk": [51, 134], "dismiss": 156, "disord": 88, "disp": 38, "dispers": 44, "displai": [3, 5, 7, 9, 48, 65, 66, 67, 69, 76, 78, 88, 126, 130, 133, 134, 144, 151, 152, 153, 156, 161], "display_nam": 0, "displaystyl": [34, 100, 159], "dispos": 146, "disproportion": 38, "disregard": 63, "disrupt": 64, "dist": [9, 17, 30, 42, 82, 126], "dist_hist_plot": 42, "dist_label": [17, 126], "dist_mod": [9, 17, 30, 126], "dist_plot": [17, 126], "dist_pt": 42, "dist_pts_alt": 42, "dist_stuff": [9, 17, 30, 126], "distanc": [34, 41, 47, 51, 65, 70, 78, 82, 114, 115, 123, 148, 161], "distant": 53, "distinct": [4, 7, 43, 46, 48, 58, 75, 89, 104, 121, 135], "distinguish": [22, 48, 51, 57, 58, 97, 153], "distract": 43, "distrbut": 161, "distri": 43, "distribut": [1, 5, 6, 7, 8, 9, 11, 13, 18, 19, 20, 23, 24, 25, 26, 27, 29, 30, 35, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 51, 53, 60, 63, 67, 72, 73, 74, 76, 77, 81, 83, 88, 89, 92, 93, 94, 95, 96, 102, 110, 117, 120, 121, 123, 124, 137, 142, 143, 144, 147, 148, 151, 152, 154, 158, 160, 161, 163], "distrubt": 156, "div": 0, "dive": [38, 133], "diverg": [19, 68], "diverging_palett": [73, 93], "divers": [23, 63], "divid": [4, 27, 29, 33, 38, 43, 53, 66, 67, 69, 76, 92, 93, 95, 104, 136, 143, 144, 146, 159], "divis": [66, 71, 76, 107, 136], "divorc": 23, "dj\u00e4rv": 56, "dk": [37, 96], "dk_pt": 37, "dkpr87": [1, 44], "dl": [19, 35], "dlnz": 96, "dmat": [34, 100, 101, 102, 103], "dmf": [1, 45], "dna": 88, "dnn": 67, "do": [0, 1, 3, 4, 5, 7, 8, 9, 11, 13, 15, 16, 17, 18, 23, 24, 25, 29, 30, 31, 32, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 59, 61, 62, 64, 65, 66, 67, 68, 71, 73, 74, 75, 76, 77, 79, 83, 85, 89, 90, 94, 96, 97, 100, 101, 102, 104, 117, 125, 129, 130, 132, 133, 134, 135, 136, 137, 142, 144, 147, 148, 150, 151, 152, 153, 154, 156, 162, 163], "dob": [9, 17, 19, 25, 30, 41], "dobrow": 161, "doc": [17, 73, 93, 130, 151], "docstr": [79, 134, 136, 151], "doctor": 63, "document": [9, 11, 13, 37, 39, 42, 43, 70, 71, 77, 83, 87, 94, 127, 134, 135, 136, 137, 145, 146, 147, 148, 151, 152, 158, 162, 163], "documentari": 62, "doe": [1, 5, 7, 8, 9, 12, 16, 18, 19, 22, 25, 29, 30, 31, 32, 34, 37, 38, 39, 40, 42, 44, 47, 48, 49, 50, 51, 53, 62, 63, 64, 65, 66, 67, 70, 71, 75, 77, 83, 85, 86, 90, 93, 94, 95, 96, 100, 107, 121, 124, 129, 130, 133, 134, 135, 136, 142, 143, 144, 146, 147, 148, 150, 151, 152, 154, 156, 159, 161], "doesn": [5, 13, 22, 29, 33, 38, 39, 51, 63, 68, 75, 147, 148, 149, 152, 154, 159], "dof": [95, 117], "dog": [76, 134], "doi": [1, 43], "dollar": 8, "domain": [0, 8, 17, 23, 43, 46, 47, 48, 53, 60, 64, 66, 82, 110, 119, 121, 123, 130, 146], "domin": [12, 19, 29, 48, 52, 53, 65, 73, 85, 110, 125], "don": [9, 11, 15, 17, 23, 25, 29, 30, 31, 33, 34, 35, 40, 42, 49, 58, 61, 63, 64, 65, 66, 72, 77, 78, 82, 83, 85, 94, 95, 96, 117, 133, 134, 145, 146, 151, 153, 154, 159, 162], "donald": [1, 153], "done": [0, 34, 35, 38, 41, 43, 48, 49, 50, 53, 58, 62, 66, 71, 72, 73, 97, 125, 126, 127, 135, 137, 143, 148, 154], "donut": [148, 153], "door": 16, "dordrecht": 1, "dot": [4, 34, 44, 48, 65, 66, 67, 68, 70, 73, 75, 78, 80, 82, 88, 93, 100, 102, 123, 127, 142, 143, 144, 149, 150], "dot_product_term": 123, "dotproduct": [81, 123], "doubl": [25, 43, 47, 63, 72, 125, 134, 135, 137, 161], "doubt": [19, 56], "dougla": 56, "down": [0, 7, 8, 17, 22, 52, 59, 67, 68, 71, 73, 78, 82, 93, 110, 117, 130, 134, 136, 156], "downhil": [97, 105], "download": [56, 70, 77, 133, 134, 137, 139, 140], "downsampl": 75, "downward": 123, "dozen": 127, "dp": [3, 19, 149], "dp_h": [11, 13, 25, 30], "dp_i": 148, "dp_phi": 149, "dphi": [149, 150], "dpi": [123, 126, 149, 150], "dq": 149, "dq_i": 148, "dr": [95, 123, 150], "draft": [1, 77, 83], "drag": [114, 115, 121, 123], "drastic": [117, 144], "draw": [16, 17, 18, 19, 23, 29, 32, 35, 38, 42, 44, 47, 51, 58, 66, 67, 72, 73, 74, 77, 79, 81, 83, 89, 96, 110, 120, 126, 130, 144, 146, 147, 151, 152, 153, 154, 156, 159], "draw_ev": 126, "drawback": [43, 66, 73, 95, 134], "drawn": [19, 29, 37, 41, 44, 71, 72, 81, 88, 95, 117, 123, 147, 148, 152, 159, 163], "drawpandasindexpandasindex": 151, "drawstyl": 37, "dream": 64, "dress": [65, 134, 138], "drink": 7, "drischler": 1, "drive": [50, 51, 58, 64, 96, 149, 156], "driven": [45, 47], "driver": 64, "drop": [16, 51, 73, 102, 120, 130, 133, 151, 159, 163], "drop_const": [34, 102], "dropbox": 50, "dropdown": [0, 5, 9, 132], "dropna": 133, "dropout": [67, 69], "drug": 63, "dry": [16, 64], "dsdt": 7, "dstack": [34, 65, 78, 82], "dt": [7, 13, 38, 121, 123, 148, 149, 150, 161], "dtp2023": 45, "dtype": [6, 33, 37, 50, 69, 71, 73, 76, 93, 95, 96, 129, 133, 136, 145, 151, 162], "du": [53, 150], "du_": 150, "du_1": 130, "du_cf": 150, "du_eff": 150, "du_i": 53, "du_n": 130, "dual": 70, "dualiti": 44, "duan": [1, 44], "dubourg": 80, "duchi": 1, "duchi11a": 1, "duco": 1, "due": [4, 7, 34, 38, 40, 46, 51, 53, 67, 71, 72, 73, 96, 97, 100, 104, 121, 123, 133, 143, 153, 156, 161], "dumb": 144, "dummi": [70, 135, 144], "dummy_out": [73, 93], "dumpti": 58, "dunson": 1, "duplic": 127, "durat": 115, "dure": [8, 44, 46, 67, 69, 71, 72, 73, 77, 83, 106, 114, 123, 136, 147, 152, 161], "durham": 56, "durrand": [77, 83], "dustin": [1, 73], "duvenaud": 86, "dvdt": 123, "dwell": 8, "dx": [3, 4, 7, 17, 19, 23, 24, 25, 35, 52, 82, 130, 146, 153], "dx1": 50, "dx2": 50, "dx_1": [19, 33, 130], "dx_2": [0, 17, 23, 33, 130], "dx_j": 19, "dx_k": 42, "dx_n": [19, 33], "dxdy": 7, "dxp": 50, "dy": [7, 35, 38, 40, 41, 67, 95, 130, 143, 146, 153, 161], "dy2": 40, "dy_data": 49, "dy_dt": [149, 150], "dy_pt": 49, "dynam": [44, 47, 67, 71, 73, 93, 123, 148, 161], "dz": [7, 130], "e": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 82, 83, 85, 86, 88, 90, 92, 93, 94, 95, 96, 97, 100, 101, 102, 105, 114, 117, 119, 120, 122, 123, 124, 125, 127, 130, 131, 133, 134, 136, 137, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 160, 162, 163], "e1": 127, "e2": 127, "e_": [34, 45, 66, 127, 133, 159], "e_1": 127, "e_2": 127, "e_i": [34, 38, 102], "e_tot_0": 150, "e_tot_0_eul": 150, "e_tot_0_lf": 150, "e_tot_pt": 150, "e_tot_pts_eul": 150, "e_tot_pts_lf": 150, "e_tot_rel_pt": 150, "e_tot_rel_pts_eul": 150, "e_tot_rel_pts_lf": 150, "e_w": [72, 88], "each": [4, 6, 7, 8, 9, 11, 15, 17, 24, 25, 29, 30, 31, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 56, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 76, 78, 79, 81, 82, 83, 86, 88, 90, 93, 96, 100, 106, 107, 110, 117, 120, 123, 125, 126, 127, 129, 130, 133, 134, 135, 136, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 154, 156, 159, 161, 162], "eapprox": 133, "earli": [8, 12, 46, 48, 73, 107, 121], "earlier": [34, 49, 53, 68, 71, 88, 121, 127, 137, 156], "earliest": 110, "earn": 153, "earth": 115, "easi": [0, 11, 13, 19, 21, 33, 42, 43, 44, 51, 66, 68, 73, 77, 83, 88, 130, 133, 134, 135, 143, 153, 156, 159], "easier": [6, 7, 40, 42, 51, 53, 64, 66, 67, 94, 119, 133, 151], "easiest": [46, 52], "easili": [0, 4, 34, 37, 43, 47, 53, 64, 68, 73, 77, 83, 88, 95, 101, 133, 134, 135, 136, 148, 153], "eat": [21, 62], "ebegin": 66, "ebind": 133, "ec": [47, 95, 126], "eccentr": [35, 53, 78, 150], "ecolor": 96, "econometr": 133, "economist": 62, "ed": 89, "edg": [47, 95, 104, 126, 159], "edgecolor": [37, 38, 65], "edit": [0, 1, 56, 86, 129, 134, 137], "edu": [0, 1, 51, 78, 80, 132, 137, 149, 151], "educ": [63, 64], "edward": [1, 64, 72, 73, 85], "eff": [44, 150], "effect": [1, 7, 16, 19, 25, 34, 38, 40, 43, 44, 46, 47, 48, 49, 50, 51, 53, 57, 62, 63, 66, 71, 72, 77, 80, 83, 94, 96, 114, 117, 123, 126, 127, 133, 146, 150, 151, 154, 163], "effectivepotenti": 5, "effici": [1, 33, 38, 44, 46, 47, 51, 67, 71, 73, 75, 93, 94, 106, 107, 127, 133, 136, 148, 151, 153, 154, 160, 163], "effort": [48, 56, 60, 63, 147, 152, 163], "eft": [45, 47, 52, 91], "ei": [32, 92], "eig": [77, 83, 127, 136], "eigen": 47, "eigen_galerkin": 47, "eigenenergi": 45, "eigensolut": 138, "eigenst": 45, "eigenvalu": [45, 47, 53, 77, 78, 79, 82, 83, 125, 127, 153, 156], "eigenvector": [1, 35, 47, 53, 122, 125, 127, 153, 156], "eigh": [127, 136], "eigval": [77, 78, 82, 83, 127], "eigvec": 127, "einstein": [8, 16, 127, 134], "einstein_equ": 0, "either": [0, 7, 8, 9, 11, 19, 38, 40, 43, 51, 53, 56, 63, 65, 66, 67, 72, 76, 86, 88, 130, 133, 134, 135, 137, 144, 161], "ek": 96, "ekstr\u00f6m": [1, 45, 56], "el": 133, "elabor": [11, 25, 27, 43], "elad": 1, "elast": 66, "elbo": [72, 73, 93], "eleanor": [1, 56], "elect": 25, "electr": [67, 133], "electromagnet": 90, "electron": [21, 130, 156], "elegantli": 7, "element": [1, 3, 9, 34, 37, 41, 43, 44, 45, 47, 53, 63, 64, 66, 67, 71, 72, 77, 78, 82, 83, 85, 88, 96, 100, 104, 107, 125, 127, 133, 134, 135, 138, 148, 150, 153, 156, 161], "elementwis": 75, "eleph": [104, 127], "elessar": 133, "elev": 65, "elevanth": [148, 154], "elif": [34, 78, 82, 96, 102, 123, 129, 134, 149], "elimin": [7, 12, 17, 63, 126, 127], "ell": [78, 79, 82, 86, 117, 120, 123], "ell_rbf": 78, "ellips": [37, 53, 78, 86, 146], "ellipsoid": 46, "ellipt": 35, "els": [3, 6, 8, 34, 37, 38, 40, 42, 48, 50, 69, 70, 76, 78, 82, 96, 102, 123, 126, 129, 142, 143, 144, 145, 147, 149, 152, 153, 154, 156, 159, 161, 162], "elsewher": [7, 34, 40, 42, 95, 130, 143, 158], "elu": [67, 70, 129], "em": [9, 45], "email": 137, "emce": [1, 6, 35, 38, 41, 50, 51, 90, 94, 142, 143, 146, 147, 148, 154, 159, 163], "emcee_lnprob": 41, "emcee_sampl": 123, "emcee_trac": 41, "emerg": [19, 51, 56], "emilia": 134, "emiss": 53, "emit": [42, 142], "emph": [48, 122], "emphas": [21, 31, 34, 47, 57, 65, 119, 130, 154], "emphasi": [31, 34, 133, 146], "empir": [4, 40, 43, 45, 53, 88, 89, 95, 110, 117, 129, 133, 144], "emploi": [7, 9, 16, 30, 34, 46, 51, 53, 62, 66, 67, 72, 96, 106, 107, 119, 144, 156], "employ": [63, 64], "employe": 64, "empti": [93, 96, 126, 129, 130, 134, 143, 144], "empty_lik": [73, 93], "emptyset": [66, 130], "emul": [1, 46, 62, 67, 124, 125], "en": [41, 104, 152, 163], "enabl": [8, 25, 34, 38, 43, 45, 47, 51, 53, 58, 62, 71, 79, 134, 146, 153, 154], "encapsul": 25, "enclos": 19, "encod": [19, 38, 39, 40, 49, 53, 58, 75, 78, 82, 121, 126, 147, 152, 158], "encompass": [8, 11, 46, 50, 51, 53], "encount": [8, 16, 25, 26, 38, 53, 57, 60, 64, 65, 66, 68, 88, 97, 104, 111, 134, 144, 153, 161], "encourag": [27, 43, 46, 59, 72, 133, 134, 137], "end": [0, 3, 4, 7, 8, 9, 12, 13, 15, 16, 19, 22, 23, 24, 25, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 53, 63, 64, 65, 66, 67, 68, 72, 75, 77, 78, 79, 82, 83, 85, 86, 88, 92, 95, 97, 99, 100, 103, 104, 106, 107, 113, 123, 125, 126, 127, 130, 132, 134, 136, 137, 146, 147, 148, 149, 150, 151, 152, 153, 156, 158, 159, 161], "end_tim": 123, "endeavor": 47, "endeavour": 110, "endow": 48, "endpoint": [9, 17, 130, 135, 148], "energi": [21, 44, 45, 47, 51, 72, 78, 79, 82, 91, 104, 130, 148, 151, 154, 156], "energy_0": 150, "enforc": [7, 33, 47, 67, 73], "engin": [1, 47, 63, 64, 67, 71], "english": [20, 53, 161], "enlighten": 4, "enorm": 45, "enough": [5, 9, 12, 19, 29, 30, 34, 37, 40, 43, 44, 45, 47, 53, 56, 63, 67, 77, 83, 86, 127, 131, 145, 146, 154, 156, 162], "ensambl": [72, 147, 152], "ensembl": [1, 50, 67, 72, 73, 96, 147, 152, 153], "ensemblesampl": [6, 38, 41, 50, 96, 123, 143, 146, 147, 152], "ensur": [4, 5, 43, 46, 47, 63, 71, 72, 77, 78, 82, 83, 123, 156, 158], "entail": [8, 34, 53, 102], "enter": [0, 25, 34, 43, 46, 64, 77, 83, 96, 99, 105, 112, 134, 140, 153, 154], "entir": [19, 34, 43, 48, 50, 51, 52, 63, 66, 75, 88, 132, 134], "entireti": 48, "entiti": 23, "entitl": [61, 64, 117], "entri": [0, 32, 38, 39, 42, 52, 63, 68, 72, 86, 126, 127, 133, 151, 152, 153, 154, 156], "entropi": [7, 8, 38, 40, 42, 43, 55, 62, 65, 67, 70, 72], "enumer": [0, 3, 6, 7, 33, 38, 41, 42, 46, 65, 77, 78, 81, 82, 83, 95, 96, 123, 130, 135], "env": [50, 70, 81, 96, 126, 152], "envelop": 79, "envi": 45, "environ": [35, 56, 69, 70, 93, 131, 134, 139, 142], "environment": 63, "environment_jb": [137, 140], "environment_window": 93, "envis": 44, "eotwash": 51, "epidemiologi": [46, 48], "epistemologi": [20, 21, 25], "eplac": 33, "epoch": [66, 67, 68, 69, 70, 71, 76, 88, 106], "epsilon": [3, 4, 34, 66, 72, 77, 79, 83, 100, 105, 123, 148, 150], "epsilon_i": [3, 34, 66, 95, 100, 120], "epsrel": 5, "eq": [0, 7, 16, 25, 34, 44, 45, 46, 47, 48, 53, 65, 66, 97, 100, 105, 107, 110, 120, 123, 130, 146, 149, 153, 156, 161], "eq_ppd": 0, "eqn": [48, 53], "equal": [3, 4, 8, 11, 19, 22, 23, 25, 31, 32, 33, 34, 35, 37, 38, 40, 44, 46, 50, 53, 63, 65, 66, 68, 71, 72, 77, 78, 82, 83, 100, 123, 125, 127, 130, 135, 136, 144, 145, 146, 150, 153, 156, 159, 162], "equat": [1, 3, 4, 7, 8, 16, 22, 23, 25, 39, 44, 45, 46, 47, 48, 49, 51, 53, 56, 64, 65, 66, 67, 72, 75, 79, 85, 88, 97, 99, 101, 104, 106, 107, 113, 114, 115, 120, 121, 123, 125, 130, 134, 142, 147, 148, 149, 152, 153, 156, 159, 161], "equilibr": [145, 154, 156, 159, 162], "equilibrium": [144, 153, 156, 161], "equip": 16, "equiv": [3, 4, 7, 13, 17, 19, 21, 24, 29, 34, 35, 39, 45, 46, 49, 51, 53, 65, 66, 68, 72, 79, 82, 85, 86, 88, 94, 95, 96, 100, 105, 106, 107, 125, 130, 143, 147, 149, 152, 153, 154, 156], "equival": [3, 4, 7, 19, 25, 34, 38, 39, 47, 48, 49, 53, 72, 78, 94, 96, 134, 146, 147, 152, 156], "ergod": 148, "eriador": 133, "ermal": 1, "ernest": 130, "err": 94, "err_filenam": 126, "err_msg": 126, "err_slop": 41, "err_slope_max": 41, "err_slope_min": 41, "err_theta_ml": 41, "err_v0": 41, "errno": 126, "errno_num": 126, "erron": [55, 63, 104], "error": [0, 1, 3, 4, 16, 17, 28, 29, 33, 38, 40, 43, 44, 46, 47, 48, 49, 50, 53, 55, 56, 59, 60, 64, 67, 68, 71, 72, 73, 77, 79, 85, 88, 93, 94, 95, 96, 97, 100, 101, 102, 110, 115, 120, 121, 123, 125, 126, 127, 133, 134, 135, 136, 146, 147, 151, 152, 153], "errorbar": [34, 38, 40, 41, 49, 80, 95, 96, 102, 123, 143], "errread": 126, "errstat": 92, "errwrit": 126, "esc": 134, "especi": [25, 67, 71, 73, 110], "ess": 44, "ess_bulk": [151, 152], "ess_tail": [151, 152], "essai": 117, "essenc": 71, "essenti": [1, 5, 8, 47, 48, 51, 57, 58, 61, 64, 67, 68, 121, 144, 148], "est": 34, "establish": [8, 47, 48, 62], "estim": [1, 5, 9, 11, 14, 17, 19, 20, 21, 22, 24, 25, 27, 30, 34, 35, 37, 38, 42, 43, 44, 46, 49, 51, 55, 59, 60, 64, 65, 66, 71, 72, 73, 79, 80, 88, 90, 91, 93, 95, 100, 102, 107, 110, 119, 121, 123, 124, 126, 127, 133, 142, 143, 145, 146, 151, 154, 156, 162], "et": [0, 43, 44, 56, 66, 123, 126, 144], "eta": [7, 49, 68, 70, 79, 88, 97, 105, 106, 107, 120, 123], "eta0": 70, "eta_n": [105, 107], "etc": [4, 7, 8, 9, 11, 17, 58, 60, 64, 67, 75, 77, 83, 88, 96, 110, 137, 156], "ethic": 1, "eti": 130, "euclidean": [34, 65, 78, 100, 104], "euclidean_dist": 65, "euler": [148, 150], "euro": 161, "european": 63, "evalu": [0, 1, 7, 13, 16, 25, 29, 34, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 51, 53, 63, 65, 66, 67, 71, 72, 73, 82, 85, 92, 93, 95, 100, 101, 102, 105, 106, 120, 123, 127, 133, 134, 135, 138, 143, 144, 145, 147, 150, 152, 153, 154, 156, 162], "evaluate_gradi": 106, "evd": 125, "even": [0, 5, 7, 8, 12, 16, 17, 21, 25, 34, 39, 43, 44, 45, 47, 48, 49, 53, 56, 58, 63, 64, 65, 66, 67, 72, 73, 75, 76, 78, 79, 82, 85, 86, 101, 103, 121, 133, 134, 142, 147, 148, 151, 152, 153, 156, 159], "evenli": [37, 40, 77, 83, 136], "event": [4, 8, 16, 17, 22, 23, 25, 37, 63, 156], "eventu": [12, 19, 25, 40, 49, 52, 56, 66, 67, 97, 107, 131, 134, 143, 144, 156, 159], "ever": [8, 16, 53, 62, 63], "everi": [6, 9, 11, 12, 19, 23, 25, 44, 49, 50, 51, 63, 67, 71, 75, 76, 78, 79, 82, 85, 96, 105, 106, 107, 123, 126, 152, 159], "everybodi": 53, "everydai": [53, 56], "everyon": 8, "everyth": [16, 23, 68, 73, 125, 134, 154], "everywher": [9, 48, 63, 67, 135], "evid": [3, 7, 8, 9, 10, 16, 23, 25, 29, 30, 34, 39, 50, 59, 62, 63, 90, 91, 96, 123], "evluat": 65, "evolut": [25, 72, 148, 153, 156], "evolv": [25, 30, 56, 64, 117, 149, 156, 161], "exac": 162, "exact": [37, 44, 45, 47, 48, 49, 51, 68, 72, 94, 106, 110, 133, 145, 148, 159, 162], "exact_data": 37, "exact_fev": 92, "exactli": [16, 29, 30, 34, 40, 48, 66, 68, 75, 102, 125], "examin": [38, 43, 44, 51, 69, 76, 121, 143, 151], "exampl": [0, 4, 6, 7, 8, 9, 11, 16, 17, 19, 20, 21, 22, 27, 30, 32, 37, 43, 44, 45, 46, 47, 48, 50, 52, 53, 55, 64, 66, 67, 68, 69, 72, 73, 74, 76, 79, 81, 83, 85, 87, 88, 93, 94, 95, 96, 97, 101, 102, 105, 107, 110, 112, 117, 119, 120, 121, 122, 125, 127, 129, 132, 133, 134, 135, 137, 144, 145, 148, 152, 153, 156, 158, 160, 162, 163], "example_revers": 156, "exce": [53, 67, 123, 161], "exceed": 123, "excel": [56, 64, 72, 144, 147, 148, 152, 153, 154, 163], "except": [31, 34, 37, 43, 65, 66, 71, 76, 96, 123, 126, 147, 152, 153, 159], "excercis": 151, "excerpt": 48, "excess": [97, 133], "exchang": [19, 51, 61], "excit": [11, 47, 64, 156], "exclud": [25, 46, 63, 66, 95, 133, 161], "exclus": [22, 23, 25, 31, 32, 48, 63, 66, 68, 76, 133], "execut": [71, 126, 135, 137], "exemplifi": [34, 130], "exercis": [9, 13, 20, 22, 30, 38, 49, 56, 69, 91, 92, 102, 131, 143], "exercisesp": 161, "exert": 38, "exhaust": [22, 23, 25, 31, 32, 46, 66, 130], "exhibit": 146, "exist": [4, 8, 19, 25, 34, 39, 48, 50, 60, 61, 62, 63, 64, 76, 92, 96, 100, 117, 130, 133, 134, 142, 147, 149, 152, 156], "exit": 134, "exp": [0, 4, 5, 7, 24, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 48, 49, 50, 53, 65, 67, 68, 70, 71, 72, 78, 82, 85, 88, 90, 92, 95, 96, 112, 120, 123, 129, 130, 134, 138, 143, 144, 145, 147, 152, 158, 161, 162], "expand": [8, 19, 22, 23, 31, 32, 34, 35, 38, 43, 47, 48, 53, 88, 89, 117, 163], "expans": [7, 16, 19, 34, 47, 53, 58, 67, 94, 117], "expect": [4, 7, 8, 9, 10, 12, 13, 19, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 65, 66, 68, 72, 73, 79, 86, 92, 93, 102, 110, 114, 126, 133, 136, 142, 143, 145, 146, 151, 152, 153, 154, 156, 158, 159, 161, 162], "expected_improv": 92, "expens": [31, 47, 79, 95, 122, 124], "experi": [4, 8, 9, 11, 16, 19, 21, 25, 30, 35, 37, 40, 42, 43, 51, 59, 60, 61, 62, 63, 64, 71, 80, 86, 89, 92, 96, 110, 114, 120, 121, 127, 128, 130, 133, 153], "experienc": 159, "experiment": [0, 7, 9, 17, 23, 25, 29, 30, 37, 39, 41, 47, 48, 51, 53, 58, 60, 62, 66, 96, 110, 119, 121, 122, 124, 130, 133, 147, 152], "expert": [0, 16, 43, 47, 62, 63, 67, 127], "expertis": 47, "explain": [7, 12, 19, 34, 43, 48, 59, 63, 65, 66, 71, 79, 90, 94, 96, 100, 126, 127, 133, 134, 142, 145, 153, 161, 162], "explan": [7, 19, 53, 62, 66, 107, 156, 158], "explanatori": 110, "explcitli": 85, "explic": 63, "explicit": [7, 9, 17, 34, 39, 43, 44, 47, 53, 59, 67, 75, 85, 117, 127, 134, 147, 152, 156], "explicitli": [4, 16, 22, 23, 25, 33, 42, 48, 53, 64, 71, 73, 80, 85, 86, 89, 123, 132, 133, 136, 161], "explod": [68, 71, 117], "exploit": [9, 11, 38, 44, 47, 67, 92], "explor": [9, 23, 26, 27, 30, 34, 37, 38, 41, 42, 44, 45, 47, 49, 51, 53, 59, 63, 65, 66, 73, 86, 91, 92, 94, 97, 102, 105, 110, 117, 119, 120, 123, 126, 135, 136, 146, 148, 153, 154, 156, 159, 161], "exploratori": [73, 93], "expon": [7, 34, 44, 52], "exponenti": [19, 34, 35, 44, 50, 67, 71, 77, 78, 82, 83, 85, 107, 115, 134, 138, 144, 153], "expos": [59, 66], "exposit": 43, "express": [4, 7, 9, 15, 16, 19, 22, 30, 31, 34, 38, 39, 40, 41, 44, 45, 46, 48, 49, 51, 53, 58, 59, 65, 66, 67, 68, 73, 75, 76, 77, 83, 85, 93, 96, 97, 99, 100, 101, 104, 114, 117, 120, 125, 127, 130, 133, 143, 144, 147, 152, 153, 156], "expsinesquar": 81, "expt": [29, 158], "extend": [4, 23, 27, 39, 47, 55, 56, 59, 62, 63, 65, 73, 78, 94, 134, 152, 161], "extens": [0, 20, 23, 43, 47, 63, 64, 67, 71, 85, 95, 107, 121, 127, 133, 134], "extent": [8, 17, 34, 37, 46, 64], "extern": [9, 132, 161], "extra": [35, 43, 52, 53, 67, 76, 86, 156, 163], "extra_anim": 126, "extra_arg": 126, "extra_group": 126, "extra_rbm_emul": 122, "extract": [7, 17, 23, 34, 38, 41, 44, 50, 69, 73, 74, 77, 82, 83, 88, 94, 95, 96, 102, 111, 119, 121, 123, 130, 137, 144, 147, 151, 152, 162], "extrapol": [45, 47, 48, 71, 79, 122, 133], "extrem": [8, 16, 19, 25, 38, 43, 48, 53, 63, 64, 66, 67, 73, 133, 134, 159], "extremum": [16, 34, 100], "ey": [22, 32, 38, 43, 49, 50, 64, 78, 82, 136, 143, 146], "e\u00f6t": 51, "f": [0, 1, 3, 4, 5, 6, 7, 9, 13, 16, 17, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 44, 49, 50, 64, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 80, 81, 82, 83, 86, 88, 92, 93, 95, 96, 102, 117, 121, 123, 126, 127, 129, 130, 132, 133, 134, 135, 136, 137, 143, 145, 146, 150, 151, 152, 153, 159, 161, 162, 163], "f11": 133, "f12": 133, "f13": 133, "f9": 133, "f_": [34, 47, 48, 67, 100], "f_0": [7, 34, 99, 100], "f_1": [48, 86], "f_2": [48, 67, 86], "f_arr": 7, "f_j": [34, 99, 100], "f_k": [48, 96], "f_likelihood": 7, "f_posterior": 7, "f_r": 135, "fab": [37, 149, 150], "face": [4, 16, 52, 153], "facecolor": [17, 37, 96, 126], "facet": 55, "facilit": [34, 43, 47, 73], "fact": [3, 4, 7, 15, 16, 23, 25, 34, 35, 38, 41, 44, 53, 62, 63, 64, 65, 66, 67, 72, 75, 82, 85, 99, 110, 111, 130, 133, 143, 153, 154, 156, 161], "factor": [5, 7, 10, 16, 19, 25, 33, 34, 35, 38, 42, 43, 44, 47, 48, 49, 50, 52, 53, 61, 63, 90, 95, 96, 100, 123, 127, 130, 142, 143, 144, 150, 151, 153, 154, 159], "factori": [4, 33, 37, 145, 162], "fail": [5, 7, 19, 22, 38, 42, 43, 44, 51, 53, 55, 59, 63, 81, 126, 133, 134, 137, 146], "failur": [29, 44, 48, 88], "fair": [3, 8, 9, 11, 13, 16, 19, 30, 43, 53], "fairli": [39, 62, 147, 152], "faith": 34, "fake": 148, "fall": [19, 34, 43, 46, 53, 63, 80, 102, 114, 115, 123], "fallaci": 31, "fallen": 114, "fals": [3, 7, 9, 21, 29, 31, 33, 34, 37, 38, 40, 41, 50, 63, 64, 65, 70, 73, 76, 78, 80, 82, 88, 92, 95, 102, 123, 126, 127, 130, 132, 133, 143, 144, 149, 153, 156, 161], "falsif": 61, "falsifi": [53, 62], "famili": [47, 56, 63, 66, 67, 86, 88, 112, 133, 156, 161], "familiar": [4, 7, 22, 23, 29, 31, 34, 37, 47, 53, 62, 65, 117, 133, 135, 145, 161, 162], "famou": [16, 46, 67, 68], "fan_out": 71, "fantast": 64, "far": [7, 8, 16, 25, 33, 34, 44, 47, 53, 63, 67, 71, 73, 76, 79, 80, 86, 126, 144, 146, 148, 153], "farther": 51, "fashion": 61, "fast": [17, 19, 46, 47, 68, 106, 124, 126, 130, 134, 135, 151, 159, 163], "faster": [45, 46, 47, 71, 73, 93, 135, 151], "fastest": 12, "fat": 153, "favor": [19, 38, 51, 52, 63, 65, 88, 97, 148, 153], "favour": [4, 37, 53], "fc": [75, 95], "feasibl": [104, 153, 154], "featur": [9, 11, 34, 37, 38, 39, 41, 46, 47, 53, 55, 60, 62, 63, 64, 65, 66, 67, 68, 71, 73, 78, 86, 93, 94, 97, 99, 100, 105, 117, 125, 127, 129, 130, 133, 136, 147, 148, 152, 158], "fed": 69, "federico": 1, "feed": [41, 68, 69, 70, 72, 76, 78, 117, 133], "feedforward": 67, "feel": [16, 25, 30, 37, 63, 144], "femal": 130, "feng": [7, 148, 153, 154], "feroz": 1, "few": [4, 7, 9, 11, 17, 23, 37, 38, 40, 42, 47, 53, 63, 64, 67, 69, 71, 75, 76, 80, 92, 126, 127, 130, 133, 148, 151, 153, 156, 161], "fewer": [29, 47, 53, 65, 66, 125, 133, 148], "ffmpeg": 126, "ffmpegwrit": 126, "ffnn": 67, "fhb09": [1, 153], "fhi": [1, 45], "fiber": 51, "fictiti": 148, "fiddl": 73, "fidel": [45, 46, 47, 122], "field": [1, 8, 16, 43, 47, 49, 62, 63, 64, 67, 73, 89, 91, 93, 94, 104, 117, 126, 154], "fieri": 53, "fifth": [53, 133, 143, 144], "fig": [0, 3, 4, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 50, 53, 65, 66, 67, 70, 72, 73, 75, 77, 78, 79, 81, 82, 83, 88, 93, 95, 96, 97, 102, 120, 121, 123, 126, 127, 129, 130, 132, 133, 134, 135, 144, 145, 147, 149, 152, 153, 156, 161, 162, 163], "fig1": [39, 152], "fig2": [37, 39, 152], "fig3": 33, "fig3d": 130, "fig_2": 150, "fig_4": 150, "fig_5": 150, "fig_af": 7, "fig_corn": [156, 161], "fig_cprob_revers": 156, "fig_cr": 130, "fig_id": 133, "fig_knn_classifi": 65, "fig_linear_classifi": 65, "fig_linear_classifier_plan": 65, "fig_pdfi": 130, "fig_point": 130, "fig_run": [156, 161], "fig_runs_revers": 156, "fig_slopesampl": 3, "fig_train_data": 65, "fig_tru": 37, "fig_x1x2": 130, "fig_x2givenx0": 156, "fig_xmgivenx0": 156, "figsiz": [5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 50, 65, 69, 70, 73, 76, 77, 78, 81, 82, 83, 88, 93, 95, 102, 123, 126, 127, 129, 130, 133, 134, 135, 143, 144, 145, 149, 150, 151, 152, 153, 161, 162], "figur": [5, 7, 9, 17, 25, 33, 35, 38, 39, 40, 41, 42, 49, 50, 51, 53, 65, 66, 68, 69, 70, 72, 76, 77, 78, 79, 80, 82, 83, 86, 88, 92, 93, 94, 95, 96, 120, 121, 123, 126, 127, 133, 135, 137, 138, 145, 148, 149, 150, 152, 156, 159, 162, 163], "figure1": 17, "figure2": 17, "figure_id": 133, "figure_titl": 42, "figurefil": 133, "file": [9, 43, 50, 70, 76, 93, 96, 123, 126, 132, 133, 134, 137, 139, 140], "filenam": [69, 126], "filenotfounderror": 126, "fill": [9, 30, 32, 34, 42, 46, 47, 52, 77, 79, 94, 96, 125, 126, 133, 142, 154], "fill_between": [9, 17, 41, 80, 81, 82, 94, 96, 126, 130], "filter": [75, 126, 127, 151], "filterwarn": [73, 93, 143], "final": [4, 6, 7, 23, 25, 31, 34, 38, 40, 41, 42, 43, 44, 46, 50, 53, 57, 62, 64, 65, 66, 67, 69, 71, 72, 74, 75, 76, 85, 92, 97, 100, 106, 115, 120, 125, 133, 143, 147, 152, 156, 158, 163], "financi": 64, "find": [0, 3, 4, 5, 7, 9, 16, 17, 19, 22, 23, 25, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 51, 52, 53, 56, 63, 64, 65, 66, 67, 68, 70, 71, 72, 77, 83, 85, 86, 88, 89, 92, 93, 94, 95, 96, 97, 99, 100, 101, 104, 105, 106, 110, 113, 117, 121, 123, 125, 126, 130, 131, 132, 133, 134, 135, 138, 142, 143, 144, 145, 147, 148, 149, 151, 152, 153, 154, 156, 158, 159, 161, 162], "find_contour_level": 37, "find_index": 37, "find_map": [151, 152], "findabl": 43, "fine": [47, 66, 71], "finer": [50, 51, 96], "finetti": 46, "finish": [40, 93, 137], "finit": [16, 19, 33, 34, 43, 44, 47, 66, 67, 78, 82, 85, 86, 91, 117, 125, 144, 156, 161], "firmli": 8, "first": [1, 3, 5, 7, 8, 9, 11, 15, 16, 17, 18, 19, 22, 23, 25, 26, 27, 31, 32, 34, 35, 38, 39, 42, 43, 44, 47, 48, 49, 50, 51, 53, 57, 59, 63, 64, 66, 67, 69, 71, 72, 73, 75, 76, 77, 78, 80, 82, 83, 85, 86, 88, 92, 93, 94, 95, 96, 107, 110, 115, 117, 121, 125, 126, 127, 130, 134, 135, 136, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 156, 158, 159, 160, 161, 162], "first_nam": 134, "fisher": [1, 95], "fission": 47, "fist": 156, "fit": [7, 17, 23, 29, 34, 35, 38, 43, 47, 49, 51, 52, 53, 63, 65, 66, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 92, 93, 94, 96, 97, 101, 102, 103, 104, 111, 119, 121, 124, 127, 138, 146, 153], "fit_degree_n": 95, "fit_intercept": [70, 133], "fit_transform": 123, "fiti": 133, "five": [25, 34, 37, 99, 104, 120, 130, 133], "fix": [3, 7, 9, 19, 22, 23, 34, 37, 43, 49, 50, 51, 53, 66, 71, 72, 75, 77, 82, 83, 85, 96, 105, 106, 117, 120, 121, 123, 128, 129, 130, 132, 133, 134, 143, 144, 145, 148, 150, 153, 154, 156, 158, 161, 162], "fk": 96, "flag": [37, 38], "flash": 35, "flat": [6, 8, 21, 25, 34, 35, 37, 38, 39, 40, 50, 52, 68, 86, 96, 123, 147, 152], "flatchain": [38, 41, 50, 143], "flatlnprob": 41, "flatten": [6, 33, 35, 41, 49, 50, 69, 75, 76, 77, 82, 83, 126, 136, 143, 146, 147, 151, 152], "flavor": 8, "flavour": 105, "flaw": 59, "flexibl": [37, 38, 47, 53, 66, 67, 71, 73, 85, 111, 133], "flexibli": 73, "flick": 148, "flip": [11, 13, 16, 25, 30, 148, 161], "flipper": 9, "float": [42, 50, 69, 70, 82, 96, 123, 129, 133, 134, 136, 149, 150], "float32": [69, 71, 73, 76, 129], "float64": [50, 96, 133, 151], "float640": 151, "float641": 151, "float6410": 151, "float649": 151, "float_widget": 132, "floatslid": [5, 9, 132, 134], "floatx": [73, 93], "floor": 136, "florian": 163, "flow": [44, 67, 117, 123, 153], "flowchart": 138, "fluctuat": [11, 23, 29, 35, 37, 40, 42, 90, 94, 96, 105, 106, 151, 154, 159], "fluid": 161, "flux": 53, "fly": [73, 93], "fm": 47, "fmhlg13": [1, 153], "fmin": 38, "fmt": [34, 38, 40, 41, 49, 95, 96, 102, 123, 143], "fn": [63, 64], "fnois": 92, "focu": [23, 43, 44, 64, 66, 72, 77, 83, 85, 104, 133, 142, 153, 156], "focus": [34, 43, 49, 62, 64, 73, 88, 89, 153], "fold": 95, "folder": 133, "follow": [4, 7, 8, 9, 11, 12, 16, 17, 19, 22, 25, 26, 34, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 53, 57, 61, 62, 64, 65, 66, 67, 69, 71, 72, 73, 75, 83, 85, 88, 92, 93, 94, 95, 96, 102, 103, 104, 105, 106, 110, 117, 119, 120, 123, 125, 126, 127, 130, 133, 134, 135, 136, 137, 138, 139, 142, 144, 145, 147, 148, 151, 152, 153, 154, 156, 159, 160, 161, 162], "font": [5, 9, 34, 37, 42, 110, 126, 127, 132, 133, 149, 150], "font_siz": [5, 9, 132, 149, 150], "font_size_w": 132, "fontsiz": [7, 17, 33, 38, 42, 50, 81, 96, 123, 130, 143, 147, 152], "food": 161, "fool": 31, "foolish": 66, "foral": [47, 65, 104, 156], "forc": [1, 51, 53, 59, 65, 114, 115, 121, 123, 126, 150, 154], "forcefulli": 148, "forecast": [16, 67], "forefront": 7, "foreman": [1, 147, 152, 159], "forest": [67, 73], "forestgreen": 120, "forev": 143, "forg": [73, 137], "forget": [21, 30, 65, 73, 93, 134], "forgotten": 133, "fork": 50, "form": [0, 4, 7, 8, 13, 19, 23, 25, 33, 37, 38, 40, 43, 47, 48, 49, 52, 53, 58, 63, 64, 65, 67, 68, 70, 71, 73, 75, 77, 78, 80, 82, 83, 86, 88, 91, 93, 95, 97, 100, 104, 106, 110, 117, 120, 125, 130, 134, 142, 144, 148, 150, 151, 153, 154, 156], "formal": [8, 25, 34, 47, 48, 53, 82, 100, 101, 110, 127, 156], "format": [0, 1, 25, 30, 38, 39, 40, 41, 42, 49, 50, 56, 69, 71, 73, 76, 92, 95, 96, 132, 133, 134, 135, 136, 143, 145, 147, 152], "format_nam": 0, "former": [8, 34, 43, 53, 66, 85, 100, 104, 110, 125], "formul": [0, 4, 5, 8, 9, 12, 25, 39, 43, 47, 59, 60, 65, 81, 90, 96, 113, 147, 152, 156, 161], "formula": [19, 37, 42, 47, 48, 49, 51, 53, 79, 85, 86, 90, 127, 133, 134, 144, 146], "forssen": [38, 39, 50, 77, 78, 95, 143, 144, 147, 152], "forss\u00e9n": [1, 44, 56, 73, 78, 93], "forth": [51, 67, 134], "fortran": [64, 133], "fortun": [43, 73, 137, 161], "forward": [8, 13, 41, 68, 70, 72, 75, 88, 97, 105, 114, 117, 148, 153], "fou": 51, "found": [4, 5, 8, 15, 17, 19, 21, 27, 29, 35, 38, 40, 44, 46, 47, 51, 53, 56, 63, 65, 67, 71, 72, 92, 104, 130, 136, 137, 144, 145, 150, 151, 153, 154, 159, 162, 163], "foundat": [25, 62], "four": [4, 37, 47, 50, 51, 63, 67, 68, 85, 86, 104, 120, 134, 156, 161], "fourier": [19, 34, 127], "fourth": [15, 68, 133], "fp": [63, 64, 126], "fphy": 1, "fr": [29, 33, 37, 130, 143, 156, 161], "frac": [3, 4, 7, 8, 9, 10, 13, 16, 19, 22, 23, 24, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 46, 48, 49, 51, 52, 53, 65, 66, 67, 68, 72, 78, 79, 82, 85, 86, 88, 94, 95, 96, 97, 100, 107, 113, 114, 120, 121, 123, 125, 126, 127, 130, 133, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 159, 161, 162], "frac12": [49, 78, 94, 149], "fraction": [4, 6, 9, 32, 42, 50, 53, 63, 65, 66, 69, 97, 105, 107, 110, 123, 127, 130, 143, 144, 147, 152, 153, 154], "fraction_100_after_10min": 161, "fraction_kept": 127, "fragoso2018": 48, "frame": [1, 48, 126, 133, 156], "frame_skip": 126, "frame_switch": 126, "frameon": 29, "framework": [8, 16, 25, 27, 28, 30, 43, 46, 48, 60, 61, 71, 73, 78, 85, 117, 119, 121, 123], "franci": [1, 110], "franciscan": 53, "frederi": 56, "free": [30, 38, 41, 49, 51, 67, 72, 95, 114, 115, 117, 123, 125, 163], "freedom": [19, 29, 39, 44, 53, 95, 117, 126, 130, 147, 152, 159], "freeli": [64, 73], "freq": 134, "frequenc": [4, 8, 32, 33, 34, 38, 90, 130, 132, 134, 149], "frequent": [4, 7, 23, 38, 39, 64, 88, 106, 147, 152, 153, 154], "frequentist": [9, 20, 21, 22, 23, 25, 26, 30, 32, 34, 35, 39, 41, 43, 51, 95, 101, 130], "fresh": 147, "frictionless": 148, "friedman": 1, "friedrich": 1, "friend": 134, "friendli": 27, "frivol": 21, "frobeniu": 127, "frodo": 133, "frog": 76, "from": [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 16, 17, 19, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 78, 80, 81, 82, 85, 88, 89, 90, 92, 93, 94, 95, 97, 99, 100, 101, 102, 104, 105, 110, 111, 114, 115, 117, 119, 120, 121, 122, 123, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 142, 143, 144, 145, 147, 148, 149, 150, 152, 156, 158, 161, 162, 163], "front": [1, 39, 44, 134, 135, 152], "fruition": 8, "frustra": 53, "fstring": [39, 134, 138, 152], "ft": 33, "ft_pt": 33, "ft_uniform": 33, "ft_uniform_pt": 33, "ft_valu": 33, "fuch": 128, "fuction": 129, "fulfil": [4, 43, 104, 130, 153, 156, 161], "full": [7, 17, 18, 19, 34, 38, 40, 43, 44, 46, 47, 49, 51, 53, 56, 61, 67, 72, 76, 78, 79, 80, 82, 91, 93, 95, 96, 100, 106, 125, 127, 130, 136, 137, 143, 146, 148, 149, 151, 154, 159, 163], "full_cov": [77, 83], "full_matric": 127, "full_nam": 134, "fulli": [10, 43, 46, 51, 66, 67, 69, 73, 75, 119, 156, 159, 161], "fun": [33, 73, 92, 123], "func": [95, 126], "funcanim": 126, "function": [1, 3, 4, 8, 9, 11, 15, 16, 19, 20, 24, 25, 26, 27, 30, 33, 35, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 64, 66, 67, 69, 72, 73, 74, 75, 79, 80, 86, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 104, 105, 106, 107, 110, 113, 115, 116, 117, 120, 121, 123, 126, 127, 129, 133, 135, 136, 138, 143, 144, 146, 147, 148, 150, 151, 152, 153, 156, 159, 161], "fundament": [8, 16, 25, 34, 39, 56, 60, 66, 101, 147, 152], "fundtion": 100, "fungibl": [9, 11], "furnstah": 50, "furnstahl": [0, 1, 5, 38, 50, 56, 77, 78, 132, 137, 143, 149, 151], "further": [4, 7, 20, 21, 23, 24, 34, 35, 46, 48, 52, 53, 72, 73, 75, 78, 82, 86, 134, 135, 146, 148, 151, 153, 154, 156], "furthermor": [7, 25, 34, 38, 39, 41, 44, 46, 47, 49, 60, 66, 67, 72, 75, 77, 82, 83, 85, 88, 130, 133, 147, 152, 153, 161], "futur": [16, 24, 25, 34, 43, 50, 63, 65, 66, 73, 96, 110, 133, 151, 156, 161], "futuredata": 16, "futurewarn": [50, 96, 133, 151], "fvec": 86, "fvec_1": [79, 86], "fvec_2": [79, 86], "fwhm": 144, "g": [0, 1, 3, 4, 7, 8, 16, 17, 18, 19, 21, 23, 25, 33, 34, 35, 38, 44, 45, 46, 47, 48, 49, 51, 52, 53, 56, 60, 61, 63, 65, 66, 67, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 86, 92, 93, 94, 95, 96, 105, 115, 117, 120, 121, 122, 123, 124, 125, 126, 127, 130, 131, 133, 134, 137, 142, 144, 146, 148, 149, 153, 154, 160, 161, 163], "g1": 38, "g2": 38, "g_": [49, 94], "g_1": 38, "g_2": 38, "g_fun": 49, "g_i": 38, "gabri": 51, "gain": [43, 47, 52, 53, 56, 64, 73, 127], "galact": 41, "galaxi": [1, 7, 41, 53, 56, 62], "galerkin": 47, "galerkin_ortho": 47, "galleri": [7, 64, 134, 153], "galton": 110, "gambl": 8, "gambler": 161, "game": [16, 47, 72, 73, 125, 161], "gamge": 133, "gamma": [13, 17, 38, 42, 44, 107, 126, 142], "gamma2_dist": 126, "gamma_1": 107, "gamma_2": 107, "gamma_a": 126, "gamma_dist": 126, "gamma_label": 126, "gamma_scal": 126, "gap": [66, 97], "garcia": 1, "gate": 67, "gather": [19, 53, 67, 86, 156, 161], "gaug": [67, 71], "gauss": 110, "gaussian": [0, 1, 3, 16, 18, 23, 24, 26, 29, 37, 38, 40, 41, 42, 44, 45, 47, 50, 51, 52, 60, 70, 71, 72, 73, 74, 79, 87, 89, 90, 92, 94, 95, 96, 117, 118, 119, 120, 121, 123, 124, 129, 142, 143, 146, 148, 153, 154, 158], "gaussian_model": 152, "gaussian_nois": [77, 78, 83], "gaussian_norm": 49, "gaussian_process": [80, 81, 82, 122, 123], "gaussianmov": [50, 143, 146], "gaussianprocessregressor": [80, 81, 82, 92], "gave": [9, 63], "gc": [0, 1, 34, 51, 53, 56], "gca": [50, 78, 82, 95, 96, 127, 149], "gcc": [73, 93], "gcf": [96, 126], "gd": 68, "ge": [7, 67, 72, 88], "gedankenmodel": 48, "gelfand": 1, "gelman": [0, 1, 51, 56, 61, 72, 86, 144, 146], "gelman2013bayesian": 0, "gelman_rubin_diagnostic_calc": 143, "gelmen": 151, "gen": 126, "gen_gaussian_sampl": 78, "gen_plot_gaussian_sampl": 78, "gene": [1, 130], "gener": [0, 3, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 22, 23, 26, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 56, 57, 59, 61, 62, 65, 66, 67, 68, 70, 71, 72, 74, 77, 78, 79, 82, 83, 85, 86, 89, 90, 92, 94, 95, 97, 100, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 115, 116, 117, 120, 121, 122, 124, 125, 126, 127, 133, 134, 137, 139, 143, 144, 145, 146, 147, 149, 150, 151, 154, 156, 158, 160, 161, 162], "generaliz": 89, "generallay": 67, "generate_binaryclass_data": 65, "generate_data": 9, "genesi": 56, "gentli": 144, "geoff": 107, "geoffrei": 1, "geometr": 8, "geometri": 16, "georg": [1, 16, 46, 61, 62, 63, 108], "geq": [4, 29, 35, 37, 38, 46, 82, 92, 104, 130, 145, 153, 154, 156, 159, 161, 162], "geron": 66, "geron17": [1, 66], "get": [0, 4, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 23, 25, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 42, 44, 46, 48, 49, 50, 51, 53, 65, 67, 68, 72, 73, 79, 86, 88, 90, 92, 93, 94, 95, 96, 101, 123, 125, 126, 127, 129, 130, 132, 136, 137, 138, 139, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 156, 159, 161, 162], "get_ax": 17, "get_batch": 106, "get_chain": [50, 123, 152], "get_cmap": 49, "get_fram": 9, "get_param": 82, "get_subplotspec": 3, "gev": 130, "gewek": 151, "gg": [4, 29, 37, 44, 48, 52, 53, 67], "gibb": 151, "gid": [70, 126], "gif": 126, "gif_filenam": 126, "gilk": 144, "git": [44, 64, 137, 140], "github": [40, 43, 56, 64, 70, 73, 76, 84, 93, 122, 130, 131, 136, 139, 148, 153, 154, 161], "githubusercont": 127, "gitlab": 64, "give": [0, 3, 4, 7, 9, 12, 13, 16, 17, 22, 23, 24, 25, 28, 30, 31, 32, 34, 35, 38, 40, 44, 45, 46, 48, 51, 53, 55, 63, 64, 65, 66, 67, 70, 71, 72, 73, 76, 77, 78, 79, 81, 82, 83, 85, 88, 94, 116, 124, 125, 127, 129, 130, 132, 133, 134, 136, 144, 146, 153, 155, 156, 159, 160, 161], "given": [0, 4, 5, 7, 8, 9, 10, 11, 16, 17, 18, 19, 21, 22, 23, 24, 25, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 62, 64, 65, 66, 67, 68, 70, 71, 72, 78, 79, 80, 82, 85, 86, 88, 90, 91, 93, 95, 100, 104, 105, 107, 110, 117, 120, 121, 122, 123, 126, 127, 129, 130, 133, 134, 136, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 159, 161, 162, 163], "glanc": 8, "glass": 58, "glean": 62, "glib": 137, "global": [1, 38, 50, 51, 53, 88, 97, 105, 126, 159, 163], "globalmov": 50, "glorot": 71, "gloss": [39, 147, 152], "glue": [3, 7, 65, 88, 130, 153, 156, 161], "gm": 115, "gmail": [80, 81], "go": [4, 9, 11, 13, 15, 16, 19, 22, 25, 29, 30, 33, 44, 52, 53, 56, 59, 63, 68, 73, 76, 86, 93, 97, 117, 127, 132, 133, 134, 136, 137, 140, 144, 145, 146, 147, 148, 152, 156, 159, 162], "goal": [7, 9, 17, 22, 30, 31, 32, 34, 35, 37, 42, 43, 44, 46, 48, 55, 58, 61, 64, 72, 79, 88, 89, 91, 97, 100, 104, 113, 117, 127, 147, 151, 152, 161], "goat": 16, "god": 19, "goe": [4, 7, 32, 52, 55, 66, 146, 156], "goggan": 51, "gold": [16, 77], "goldstein": [1, 46], "goldstein2009reifi": 48, "gone": 159, "good": [1, 2, 19, 22, 27, 29, 33, 34, 35, 39, 40, 42, 43, 44, 46, 47, 51, 53, 61, 63, 64, 66, 67, 68, 71, 73, 75, 77, 83, 85, 86, 92, 97, 100, 107, 121, 125, 126, 134, 136, 143, 144, 147, 148, 151, 152, 159], "goodman": [1, 153], "googl": [1, 17, 23, 42, 76, 79, 130, 132, 134, 138], "googlenet": 73, "gossett": [0, 23], "got": 29, "gothenburg": 16, "gotten": 19, "govern": [16, 63, 76, 121], "gp": [47, 77, 83, 87, 89, 92, 117, 119, 120, 121, 122, 123], "gp_kernel": 81, "gp_regress": [77, 78, 83], "gp_sklearn": 82, "gpkernel": 92, "gpplot": 82, "gpr": [81, 92], "gpr_model": 81, "gpr_sklearn": 82, "gpregress": [77, 78, 79, 83], "gpu": [73, 93], "gpy": [78, 79, 85, 86, 92], "gr92": [1, 44], "grab_fram": 126, "grad": 71, "grad_fn": 71, "grade": 8, "gradient": [34, 44, 65, 66, 67, 68, 70, 72, 73, 75, 88, 100, 113, 116, 117, 151, 154, 158, 163], "gradienttap": 76, "gradual": 47, "graduat": 56, "grai": [37, 38, 40, 96, 126, 127, 148], "grand": 32, "graph": [1, 9, 17, 35, 42, 64, 71, 73, 76, 77, 93, 104, 132, 135, 145, 154, 162], "graphic": [126, 137], "graphs_rjf": 126, "grass": [21, 62], "grate": 56, "gratefulli": 9, "gravit": [7, 51, 115, 121], "gravitation_orbit_1": 150, "graviti": [51, 121, 123], "grayscal": 75, "gre05": [1, 2, 27, 53, 56, 154, 162], "great": [7, 16, 47, 56, 73, 87, 137, 159], "greater": [19, 33, 37, 38, 44, 51, 53, 77, 83, 120, 121, 123, 143, 151], "greatest": [16, 93], "greatli": 65, "greedi": 47, "greek": 130, "green": [9, 33, 44, 69, 75, 96, 121, 126, 130, 134, 144, 148, 150, 154, 159, 163], "greenfield": 98, "gregori": [1, 2, 27, 37, 53, 56, 145, 162], "gregory_7_2": 53, "grei": [47, 65], "grid": [0, 7, 34, 37, 40, 41, 50, 51, 65, 70, 72, 73, 74, 76, 86, 93, 96, 102, 134, 156], "grid_2d": [73, 93], "griffith": 128, "grist": 58, "ground": [8, 47, 48, 121, 123, 133, 156], "groundwork": 34, "group": [4, 37, 64, 73, 77, 83, 85, 117, 126, 133, 136], "groupbi": 133, "grow": [29, 68, 86, 115, 117, 147, 152, 153, 154, 161], "growth_fig": 161, "growth_quest": 161, "gsl": 34, "gt": [115, 151, 154, 159], "guarante": [8, 16, 34, 47, 78, 82, 100, 144, 150, 156], "guess": [7, 17, 38, 82, 86, 92, 123, 147, 152, 156], "guesswork": 156, "gui": 126, "guid": [1, 11, 27, 41, 53, 62, 64, 69, 71, 81, 94, 117, 119, 131, 132, 137, 139], "guidanc": [50, 96, 126], "guidelin": [43, 94], "guido": 128, "guillaum": [80, 81], "guilti": 63, "guin": 23, "guiness": 0, "gull": [4, 42, 53], "gw07": [1, 46], "gw10": [1, 153], "h": [0, 1, 7, 8, 16, 24, 25, 31, 34, 44, 45, 46, 47, 53, 70, 85, 95, 115, 121, 123, 125, 130, 133, 144, 148, 149, 159, 161], "h0": [0, 7, 41, 123], "h2mc": 154, "h_": [7, 34, 41, 47, 53], "h_0": [7, 121, 123], "h_1": 25, "h_3": 16, "h_i": 25, "h_j": 16, "ha": [0, 4, 7, 8, 9, 10, 16, 17, 19, 22, 23, 25, 28, 29, 30, 31, 34, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 59, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 76, 77, 78, 79, 80, 82, 85, 86, 88, 89, 90, 92, 94, 95, 96, 97, 104, 105, 106, 107, 111, 114, 115, 117, 121, 123, 125, 127, 130, 131, 133, 134, 135, 136, 137, 144, 145, 146, 147, 148, 151, 152, 153, 154, 156, 160, 161, 162], "habit": 43, "hackernoon": 135, "had": [4, 13, 16, 17, 19, 25, 41, 53, 56, 72, 130, 133, 144, 146, 154, 159], "hadamard": [68, 136], "hagan": 119, "hair": 4, "hal21": [1, 117], "half": [8, 17, 35, 37, 38, 40, 41, 44, 53, 70, 143, 148, 156], "halfnorm": 151, "halfwai": [51, 150], "hall": [0, 1, 16, 56], "halt": 107, "halv": [46, 143], "halverson": 1, "hamilton": [44, 148, 149], "hamiltonian": [1, 45, 47, 122, 149, 153, 154, 157, 160], "hamiltonianmc": 151, "hamiltonianpendulum": 149, "hammer": 1, "hand": [0, 1, 4, 7, 9, 16, 21, 22, 25, 26, 34, 38, 53, 62, 64, 66, 67, 69, 72, 73, 75, 77, 83, 97, 127, 137, 149, 150, 153, 156, 161, 163], "handbook": [1, 44, 66], "handed": 4, "handl": [44, 67, 70, 71, 82, 95, 110, 113, 133], "handle_color": 9, "handsid": 68, "hang": 51, "hanin": 1, "hao": 1, "happen": [5, 7, 8, 11, 12, 29, 34, 35, 37, 40, 41, 49, 58, 66, 68, 76, 77, 86, 90, 96, 127, 130, 144, 146, 151], "happend": 34, "happi": 132, "hard": [1, 31, 44, 49, 65, 67, 73, 88, 117, 144, 151, 154], "harder": [34, 67, 151], "hardest": 72, "hardli": 67, "hardwar": [64, 137], "hare": 67, "harm": [63, 66], "harmon": 47, "harsher": 53, "hashtag": 134, "hast": [50, 51, 143, 146, 148, 151, 159, 160], "hasti": [1, 66], "hat": [29, 38, 43, 44, 49, 51, 52, 63, 85, 107, 121, 123, 143, 151], "have": [0, 3, 4, 5, 7, 8, 9, 10, 11, 13, 16, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 53, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 80, 82, 83, 85, 86, 87, 88, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 107, 111, 112, 113, 115, 117, 119, 120, 123, 124, 125, 126, 127, 129, 130, 131, 133, 134, 135, 136, 137, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 156, 158, 159, 160, 161, 162], "haven": 53, "hazan": 1, "hbox": [5, 9, 132], "hbox0": [9, 132], "hbox1a": [9, 132], "hbox1b": [9, 132], "hbox2": [9, 132], "hbox3": [9, 132], "hbox_1": 132, "hbox_2": 132, "hd": 7, "hdi_3": [151, 152], "hdi_97": [151, 152], "hdr": 130, "he": [1, 8, 16, 25, 37, 46, 47, 53, 61, 62, 71, 88, 117, 126], "head": [0, 8, 9, 11, 13, 16, 19, 23, 25, 30, 52, 133, 134, 161], "header": [133, 134], "headlin": 73, "heads_in_data_to_n": 9, "headstart": 127, "health": 73, "healthcar": 63, "hear": 64, "heart": [58, 119], "heavi": [12, 17, 18, 47, 64, 126], "heavili": [51, 64, 65, 106, 154], "heavisid": 44, "hei": 73, "height": [0, 9, 17, 35, 53, 75, 76, 110, 115, 121, 126, 132, 146, 163], "heisenberg": 16, "held": [22, 50, 148], "hello": [134, 135], "hello_funct": 134, "help": [9, 38, 42, 43, 44, 58, 63, 64, 66, 67, 69, 71, 73, 85, 93, 107, 111, 123, 132, 138, 139, 143], "help_bayes_w": 9, "help_max_height": [9, 132], "help_overview_w": [9, 132], "help_parameters_w": 132, "help_priors_w": 9, "help_setup_w": [9, 132], "help_tab": [9, 132], "help_times_w": 132, "help_toss_coin_w": 9, "helper": [34, 69, 70, 76, 102], "henc": [0, 22, 23, 34, 53, 66, 78, 82, 85, 91, 99, 133, 156], "henceforth": 156, "hendrik": [80, 81], "hennig": 61, "hensman": [77, 83], "her": [53, 63], "here": [0, 4, 5, 7, 9, 13, 16, 17, 19, 23, 24, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 83, 85, 86, 87, 88, 89, 92, 93, 95, 100, 102, 103, 112, 115, 116, 117, 120, 121, 122, 123, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 156, 158, 159, 160, 161, 162], "hereaft": 19, "hermitian": [47, 136], "heroic": 62, "hesian": 154, "hesit": 22, "hess_inv": 41, "hessian": [34, 35, 41, 53, 95], "heurist": [73, 159], "hexp_err": 123, "hexp_err_sc": 123, "hexp_mean": 123, "hexp_mean_sc": 123, "hexp_std": 123, "hg": [1, 44, 130], "hi": [0, 23, 25, 37, 53, 62, 104, 121, 151, 154], "hi95": [77, 83], "hick": 143, "hidden": [7, 43, 51, 63, 65, 67, 68, 70, 71, 73, 75, 93, 117, 129, 130], "hidden1": 71, "hidden2": 71, "hidden3": 71, "hide": 0, "hierarch": 73, "hierarchi": [40, 73], "higdon": [121, 123], "higdon2004combin": 48, "higg": [19, 130, 154], "high": [1, 5, 9, 21, 31, 34, 38, 43, 44, 45, 46, 47, 49, 51, 56, 63, 64, 66, 67, 72, 73, 75, 96, 97, 102, 106, 113, 122, 127, 133, 144, 146, 148, 149, 153], "higher": [9, 16, 19, 23, 34, 40, 47, 63, 64, 66, 73, 77, 80, 95, 123, 133, 144, 148, 149, 156], "highest": [19, 46, 50, 51, 73, 76, 79, 96, 125, 130, 151, 163], "highli": [27, 41, 44, 47, 52, 64, 66, 73, 78, 82, 86, 106, 133, 134, 152, 159], "highlight": [0, 33, 43, 55, 56, 63, 95, 125, 134], "hilbert": 47, "hill": 144, "him": [104, 117, 128], "himself": 53, "hinder": 105, "hint": [0, 7, 16, 31, 37, 39, 51, 77, 83, 88, 96, 142, 152, 156, 161], "hinton": [1, 107], "hist": [17, 29, 33, 39, 42, 50, 73, 82, 93, 126, 129, 130, 143, 144, 145, 151, 152, 162], "hist_kwarg": 123, "hist_norm": 126, "hist_pt": 126, "hist_pts_al": 126, "histogram": [17, 18, 19, 29, 33, 35, 39, 42, 43, 44, 50, 79, 82, 129, 130, 143, 144, 145, 146, 147, 151, 152, 153, 154, 156, 159, 161, 162], "histogram2d": 41, "histogram_ax": 33, "histor": [46, 48, 63, 88, 89, 104], "historam": 33, "historgram": 159, "histori": [1, 55, 67, 69, 76, 107, 110, 156, 161], "historian": [8, 62], "histplot": 144, "histtyp": [130, 144], "hit": [11, 17, 35, 130, 134], "hitchhik": 56, "hjorth": 56, "hmc": [44, 151, 154, 158, 159, 160], "hmodel_sc": 123, "hms21": [1, 117], "hmv": 148, "ho": 47, "hobson": 1, "hoc": 38, "hoffman": 1, "hogg": [1, 95, 159], "hold": [9, 11, 31, 34, 47, 48, 63, 66, 73, 75, 93, 123, 136, 148, 153, 156], "holdout": 66, "hole": [7, 51], "home": [0, 77], "homemad": 150, "homogen": [67, 136], "honest": [4, 61], "honesti": 61, "honor": 45, "hood": 71, "hope": [48, 58, 59, 61, 88], "hopefulli": [45, 69, 73, 127], "hopfield": 67, "hopkin": 1, "horizont": [17, 19, 50, 78, 82, 132, 136, 143], "horizontalalign": [7, 9, 42], "hors": [76, 88], "hospit": 63, "host": 16, "hour": 37, "hous": 16, "how": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 22, 23, 24, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 47, 49, 50, 51, 53, 56, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 77, 78, 79, 80, 82, 85, 88, 91, 92, 93, 95, 100, 102, 113, 114, 115, 117, 121, 123, 124, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 142, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 156, 161, 162, 163], "howard": 130, "howev": [4, 7, 8, 11, 16, 25, 34, 38, 39, 43, 44, 45, 46, 47, 48, 51, 53, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 77, 83, 85, 88, 92, 93, 97, 99, 100, 101, 104, 105, 106, 107, 110, 117, 119, 122, 130, 133, 134, 135, 136, 137, 144, 146, 147, 151, 152, 153, 156, 161], "hp_bound": 123, "hpd": [19, 151], "hspace": 133, "hsplit": 136, "htf09": [1, 66], "html": [0, 1, 9, 17, 41, 42, 50, 70, 73, 81, 93, 96, 122, 130, 132, 134, 151, 152, 163], "htmlmath": [5, 9, 132], "http": [0, 1, 17, 40, 41, 50, 51, 69, 73, 76, 77, 81, 93, 96, 104, 122, 127, 130, 135, 137, 140, 148, 151, 152, 154, 161, 163], "hu": 1, "huang": [1, 133], "hubbl": [7, 41], "huber_loss": 38, "huge": [4, 7, 60, 62, 73, 75], "hugh": 130, "human": [62, 63, 64, 67], "hump": 19, "humpti": 58, "hundr": [67, 127], "hungarian": 61, "hungri": 67, "hunt": 53, "hw": [78, 82], "hybrid": [1, 44, 47, 73], "hydrogen": [133, 144], "hyper": [48, 73, 151], "hyperbol": [67, 71], "hypercub": [47, 79, 153], "hyperlink": [0, 56], "hyperparamet": [9, 17, 43, 44, 47, 66, 67, 69, 71, 72, 75, 78, 80, 82, 83, 86, 88, 97, 106, 117, 119, 120, 121, 123, 158], "hyperparmet": 123, "hyperrectangl": 46, "hyperreduct": 47, "hypothes": [7, 25, 53, 63, 67, 111, 119], "hypothesi": [8, 11, 19, 25, 39, 52, 63, 147, 152], "hypothet": [19, 53], "i": [0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 15, 16, 18, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 158, 160, 161, 162, 163], "i1": 67, "i10": 161, "i3": 133, "i5": 133, "i6qkdaeacaaj": 1, "i_": [46, 86, 127, 156], "i_0": 156, "i_1": 156, "i_2": 156, "i_d": [0, 7, 86], "i_i": 46, "i_m": 46, "i_n": [153, 156], "i_num": 153, "i_rel_error": 153, "i_sort": 41, "i_unsort": 41, "ia": 7, "ian": [1, 56], "iax": 3, "ib": 96, "ichain": [50, 143], "iclass": 65, "iclass_mean": 65, "icol": [50, 143], "id": [1, 134], "idata": 65, "idea": [9, 19, 24, 30, 33, 38, 43, 44, 47, 51, 56, 63, 64, 66, 67, 73, 77, 79, 83, 85, 92, 94, 97, 117, 126, 127, 142, 144, 146, 148, 151, 159, 163], "ideal": [4, 34, 44, 62, 64, 96], "ideg": 95, "idenitfi": 156, "ident": [34, 47, 51, 53, 58, 62, 66, 72, 73, 96, 102, 121, 123, 133, 136, 148, 156], "identif": [46, 104, 130], "identifi": [4, 8, 19, 26, 34, 38, 41, 43, 44, 46, 48, 63, 64, 65, 67, 69, 86, 88, 94, 114, 125, 130, 134, 136, 146, 154, 156, 163], "idx": 81, "iexp": 153, "iexp_i_num": 153, "ignor": [3, 4, 7, 8, 9, 13, 17, 25, 29, 38, 41, 42, 44, 46, 48, 49, 53, 61, 73, 76, 93, 126, 130, 143, 144, 146, 153], "ii": [1, 34, 37, 38, 43, 52, 53, 59, 63, 82, 94, 95, 107, 121, 125, 127, 130, 133, 148, 156], "iia": 91, "iib": 91, "iib_how_many_lines_ptemce": 90, "iid": [53, 83, 96, 123, 143], "iii": [43, 53, 59, 94, 121, 156], "iiia": 91, "iiib": 91, "iint": 44, "ij": [29, 34, 47, 53, 67, 68, 82, 86, 95, 125, 127, 143, 156, 161], "ik": [65, 82, 125, 127], "il": 67, "ill": [125, 127], "illustr": [7, 31, 32, 41, 47, 48, 49, 51, 53, 66, 67, 77, 80, 82, 83, 87, 118, 120, 121, 130, 163], "ilogp": 38, "ils": 1, "im": [34, 65, 96], "imag": [63, 67, 69, 117, 125, 126, 134], "image_height": 76, "image_path": 133, "image_width": 76, "imagemagick": 126, "imagenet": 73, "imagin": [4, 16, 25, 31, 37, 40, 48, 65, 66, 73, 96, 126, 146, 153, 154, 159], "img": [69, 76, 127], "img2": 127, "img99": 127, "img995": 127, "img_orig": 127, "immedi": [4, 16, 19, 53, 58, 60], "imp": 92, "impact": [23, 43, 63, 64, 71, 90, 94], "imparti": 61, "imper": 43, "imperfect": [23, 48], "impi": 156, "implaus": [46, 72], "implement": [22, 27, 34, 35, 38, 42, 43, 44, 47, 48, 51, 58, 63, 70, 71, 72, 73, 74, 75, 77, 82, 83, 90, 92, 96, 106, 107, 133, 135, 136, 145, 146, 149, 150, 156, 159, 161, 162, 163], "impli": [3, 4, 7, 19, 22, 23, 29, 31, 32, 34, 38, 39, 40, 41, 44, 45, 47, 48, 49, 53, 62, 64, 65, 66, 67, 72, 75, 76, 78, 82, 85, 95, 97, 99, 100, 107, 112, 119, 127, 130, 134, 135, 143, 144, 147, 152, 156, 161], "implic": [10, 59], "implicit": [9, 23, 30, 34, 39, 49, 78, 82, 85, 147, 152], "implicitli": [19, 29, 40, 42, 143], "import": [0, 1, 3, 6, 7, 8, 9, 12, 17, 19, 24, 25, 28, 29, 30, 33, 34, 37, 39, 40, 41, 42, 43, 46, 47, 49, 53, 55, 56, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 78, 79, 80, 81, 82, 85, 88, 93, 97, 100, 102, 104, 105, 106, 119, 123, 125, 126, 129, 134, 135, 136, 138, 143, 145, 147, 149, 150, 152, 153, 154, 156, 159, 161, 162], "importantli": [25, 37, 43, 78, 82, 115], "impos": [46, 60, 66, 79, 161], "imposs": [7, 34, 47], "impract": 153, "impress": [147, 152], "imprint": [64, 156], "improv": [5, 7, 15, 16, 18, 43, 48, 50, 51, 53, 64, 66, 71, 73, 89, 92, 93, 96, 106, 107, 117, 135, 146, 148, 150, 151, 162], "imput": 62, "imread": 127, "imshow": [69, 76, 78, 82, 127], "in_featur": [71, 129], "inaccur": [63, 65, 121], "inaccuraci": 46, "inact": [46, 67], "inadequ": 154, "inadvert": 56, "inappropri": 126, "inch": 149, "includ": [0, 4, 7, 8, 12, 15, 16, 22, 24, 25, 26, 27, 28, 29, 33, 34, 35, 39, 41, 43, 46, 47, 48, 50, 51, 55, 56, 59, 64, 65, 66, 67, 70, 71, 72, 73, 74, 77, 82, 83, 85, 86, 88, 89, 92, 93, 96, 100, 102, 110, 115, 116, 117, 121, 122, 123, 125, 126, 130, 132, 133, 134, 137, 141, 144, 147, 151, 152, 153, 156, 161, 163], "include_group": 133, "inclus": [39, 43, 52, 63, 147, 152], "incom": 67, "incomplet": [8, 46, 53, 63, 153], "inconsist": 63, "incorpor": [0, 4, 7, 16, 25, 43, 61, 66, 67, 119, 120, 121, 150], "incorrect": [69, 76, 121, 123, 136], "increas": [16, 17, 23, 25, 33, 34, 41, 46, 47, 49, 50, 64, 65, 66, 67, 71, 72, 82, 95, 96, 97, 102, 107, 120, 123, 142, 143, 144, 146, 151, 153, 154, 159, 161], "increasingli": [25, 33, 40, 47, 48, 51, 53, 63, 78, 120, 121, 134, 146, 147, 152], "incredibli": 64, "increment": [9, 11, 71, 159], "inde": [8, 9, 16, 19, 22, 25, 30, 34, 53, 58, 60, 64, 100, 101, 133, 153, 156, 161], "indent": [134, 138], "independ": [3, 4, 7, 9, 12, 15, 16, 19, 20, 22, 23, 25, 29, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 63, 65, 66, 67, 72, 78, 80, 85, 86, 88, 95, 96, 99, 100, 102, 109, 110, 112, 113, 120, 121, 123, 127, 143, 148, 153, 154, 156, 161], "index": [5, 33, 34, 37, 44, 65, 76, 82, 85, 86, 88, 102, 117, 120, 125, 126, 130, 133, 135, 149, 150, 151, 152, 156, 161, 163], "index_col": 133, "index_cv": 95, "index_max": 126, "indiana": 56, "indic": [0, 4, 9, 17, 25, 29, 34, 38, 40, 41, 44, 46, 49, 51, 53, 63, 65, 69, 71, 72, 82, 104, 110, 125, 126, 127, 130, 133, 136, 137, 143, 146, 147, 148, 151, 152, 154, 156, 161], "indiffer": [7, 8, 43, 62], "indigen": 63, "indirect": 53, "indirectli": [43, 44], "individu": [22, 32, 33, 34, 38, 40, 41, 43, 44, 46, 48, 49, 63, 67, 73, 79, 81, 88, 95, 137, 143, 149, 161], "induc": [46, 51, 117], "induct": [1, 7, 42, 61, 113], "industri": 67, "ineffici": [44, 67, 106], "inequ": 46, "inevit": 130, "inexpens": [31, 47], "inf": [6, 33, 37, 38, 40, 42, 96, 123, 130, 143, 147, 152], "infeas": [43, 44, 47], "infer": [1, 8, 16, 18, 24, 25, 27, 28, 30, 34, 42, 47, 53, 55, 56, 57, 58, 59, 64, 65, 71, 89, 91, 95, 96, 102, 115, 119, 121, 124, 130, 143, 146, 151, 161, 163], "inference_librari": 151, "inference_library_vers": 151, "inferenti": [16, 48], "infil": 133, "infin": [7, 19, 38, 117, 126, 143], "infinit": [7, 38, 53, 64, 77, 82, 83, 85, 86, 110, 117, 153, 156], "infinitesim": [7, 25, 30, 53, 107], "influenc": [4, 16, 25, 38, 43, 46, 63, 66, 77, 83, 85, 121], "influenti": [43, 62], "info": [35, 73, 93, 123, 126, 133, 136, 139, 151], "inform": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 16, 18, 19, 22, 23, 24, 25, 29, 30, 31, 32, 34, 37, 38, 39, 40, 43, 44, 46, 47, 48, 49, 52, 53, 55, 56, 58, 59, 61, 62, 63, 65, 66, 67, 72, 73, 79, 85, 88, 94, 95, 101, 107, 111, 113, 117, 119, 121, 123, 127, 130, 132, 133, 135, 137, 143, 147, 151, 152, 154, 159], "informatik": [80, 81], "infrastructur": 63, "infti": [0, 4, 7, 15, 17, 19, 23, 24, 33, 34, 35, 37, 38, 41, 44, 48, 49, 53, 72, 102, 130, 143, 146, 153, 156, 161], "ingredi": [7, 20, 24, 27, 46, 47, 51, 59, 67, 142], "inher": [43, 44, 53, 66, 71, 72, 73, 119, 161], "inherit": [71, 100], "inhibit": 66, "init": [50, 71, 129, 159], "init_1": [73, 93], "init_2": [73, 93], "init_out": [73, 93], "init_weight": 71, "initi": [9, 11, 16, 23, 30, 37, 41, 42, 46, 47, 50, 51, 52, 53, 56, 66, 67, 73, 77, 79, 82, 83, 92, 93, 96, 97, 105, 107, 117, 121, 123, 127, 130, 135, 137, 143, 145, 146, 149, 150, 151, 152, 153, 154, 156, 158, 159, 161, 162, 163], "initial_text": [9, 132], "initial_text_w": [9, 132], "initialis": [50, 152], "initialize_model": 129, "initio": [1, 92], "initv": 151, "inlin": [5, 33, 37, 38, 39, 40, 41, 42, 49, 70, 73, 77, 78, 83, 92, 93, 95, 96, 127, 130, 133, 134, 143, 144, 145, 147, 149, 152, 162], "inner": [8, 68, 77, 83], "innov": 73, "innovi": 73, "input": [0, 5, 9, 34, 40, 43, 46, 48, 56, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 82, 85, 86, 88, 89, 92, 93, 96, 101, 104, 109, 110, 117, 119, 120, 121, 123, 131, 134, 136, 158, 159, 161], "input_dim": [77, 78, 83, 92], "input_shap": [69, 76], "input_v": 129, "inputs_i": [34, 64, 65, 66, 106], "inputs_j": 66, "inputt": [34, 99, 101, 102, 110, 112, 113, 114], "inputt_": 113, "inputt_1": [65, 67, 113], "inputt_2": [65, 67, 113], "inputt_i": 113, "inputt_p": 67, "inquiri": 119, "insensit": 65, "insert": [16, 22, 31, 32, 47, 68, 70, 77, 83, 92, 130, 134, 136, 156, 161], "insid": [71, 95, 133, 134, 135, 149, 153, 163], "insight": [7, 20, 24, 26, 34, 45, 46, 48, 53, 64, 71, 73, 77, 83, 100, 111, 119], "inspect": [8, 34, 38, 102], "inspir": [64, 66, 67, 72, 73, 136, 144], "instal": [70, 73, 134, 142], "instanc": [7, 16, 62, 63, 65, 67, 71, 85, 88, 106, 113, 130, 151, 156, 161], "instanti": [79, 123, 149, 151], "instead": [7, 8, 16, 19, 34, 38, 39, 43, 44, 46, 48, 49, 51, 52, 53, 58, 62, 65, 71, 72, 73, 74, 75, 77, 78, 79, 82, 83, 85, 97, 105, 106, 107, 130, 134, 135, 136, 137, 144, 146, 147, 151, 152, 156, 159, 161], "institut": [63, 64, 130], "instruct": [17, 25, 30, 43, 53, 64, 137, 142], "insuffici": 53, "insur": 56, "int": [4, 7, 9, 17, 19, 23, 25, 33, 34, 37, 41, 42, 44, 49, 51, 52, 53, 70, 72, 73, 81, 82, 85, 93, 95, 123, 126, 136, 143, 145, 149, 153, 154, 159, 162], "int64": 151, "int640": 151, "int8": [73, 93], "int_": [0, 3, 4, 7, 16, 19, 23, 24, 33, 38, 41, 48, 53, 130, 146, 153], "int_0": [4, 7, 11, 13, 25, 35, 38, 51, 130], "int_1": 130, "int_a": [17, 23, 130, 154], "int_v": 154, "integ": [9, 13, 33, 35, 37, 39, 44, 69, 104, 110, 123, 129, 134, 135, 143, 145, 154, 156, 162], "integr": [0, 4, 5, 7, 16, 17, 18, 19, 23, 24, 31, 32, 34, 35, 37, 38, 43, 44, 47, 50, 51, 52, 53, 60, 71, 72, 73, 93, 95, 123, 126, 130, 134, 147, 148, 149, 150, 152, 154, 159], "integrand": [24, 33, 34, 38, 49, 52, 130, 153, 154], "integrand_pt": 33, "integration_fig": 153, "intel": 137, "intellectu": 61, "intellig": [1, 63, 64, 89, 104], "intend": [51, 61, 71], "intens": [38, 56, 79, 90], "intent": 43, "interact": [0, 7, 16, 25, 27, 43, 45, 56, 67, 117, 132, 133, 134, 148, 153, 154, 159], "interactive_output": 9, "interc": [52, 79, 86, 125, 146, 148], "intercept": [3, 6, 23, 34, 35, 38, 40, 41, 53, 99, 100, 133, 143], "intercept_": 70, "intercept_limit": 40, "intercept_rang": 40, "intercept_sc": 70, "interchang": 156, "interdepend": 46, "interest": [4, 7, 8, 16, 17, 19, 23, 25, 31, 34, 40, 41, 43, 44, 45, 46, 47, 48, 53, 58, 60, 64, 66, 67, 68, 73, 77, 83, 88, 96, 105, 111, 116, 127, 130, 133, 135, 146, 148, 153, 161], "interestingli": 73, "interfac": [11, 134, 153], "interior": [104, 133], "interlaboratori": 126, "intermedi": [25, 79, 90, 144, 148], "intern": [0, 1, 67, 146], "internet": 153, "interoper": 43, "interplai": 67, "interplo": 45, "interpol": [37, 41, 45, 47, 48, 78, 79, 80, 86], "interpret": [4, 5, 7, 8, 11, 16, 19, 20, 21, 22, 23, 25, 26, 32, 34, 37, 39, 43, 46, 51, 53, 60, 61, 62, 68, 72, 77, 80, 83, 89, 94, 95, 117, 119, 124, 128, 130, 147, 152, 153, 156], "intersect": [21, 22, 163], "interv": [4, 7, 11, 15, 17, 25, 26, 35, 37, 41, 43, 51, 79, 80, 82, 86, 88, 92, 96, 126, 130, 147, 151, 152, 161, 163], "interview": [63, 128], "intial": [123, 156], "intimid": 133, "intp": [73, 93], "intract": [47, 72, 147, 152], "intric": 16, "intrins": [25, 60], "intro": 43, "introduc": [4, 7, 16, 18, 21, 22, 24, 25, 27, 34, 38, 40, 42, 43, 44, 45, 46, 48, 51, 53, 58, 59, 63, 64, 65, 66, 67, 71, 88, 95, 97, 100, 107, 113, 116, 118, 119, 120, 130, 134, 144, 146, 156, 163], "introduct": [1, 20, 27, 39, 47, 53, 55, 72, 89, 122, 125, 147, 152, 153, 154, 158, 160], "introductori": [87, 124, 133], "intrus": [45, 47], "intslid": [5, 9, 132], "intuit": [7, 8, 11, 16, 22, 31, 35, 38, 39, 42, 44, 51, 62, 66, 67, 72, 73, 93, 117, 127, 133, 134, 147, 152], "inv": [34, 49, 50, 65, 95, 102, 123, 136], "invalid": [134, 159], "invalu": 146, "invari": [1, 4, 8, 40, 41, 43, 44, 55, 85, 95, 117, 143, 146, 147, 148, 150, 152, 153, 156], "invcft": 33, "invent": [37, 94], "inventor": 107, "invers": [7, 8, 23, 33, 41, 49, 51, 53, 66, 85, 100, 101, 123, 125, 126, 127, 138, 153, 156], "invert": [34, 48, 65, 85, 88, 97, 100, 104, 125, 146, 148, 149], "invest": 66, "investig": [58, 61, 64, 77, 82, 83, 92, 142, 143, 158, 161], "invft": 33, "invft_uniform_pt": 33, "invgamma": 130, "invit": [21, 48], "invok": [0, 150, 151], "involv": [7, 22, 25, 34, 38, 39, 43, 46, 48, 53, 62, 63, 64, 66, 67, 71, 72, 73, 82, 88, 93, 104, 110, 111, 145, 147, 152, 153, 154, 161, 162], "io": [41, 73, 93, 122, 126, 127, 148, 151, 152, 154, 163], "ipad": 134, "ipr": 6, "ipsen": 1, "ipykernel_5397": 37, "ipykernel_5429": 38, "ipykernel_6386": 133, "ipykernel_6597": 151, "ipynb": [35, 38, 41, 51, 70, 90, 93, 94, 127, 134, 142, 143, 146, 148, 150, 154, 158, 159, 163], "ipython": [5, 9, 126, 133, 134], "ipywidget": [5, 9, 126, 134], "ironclad": 62, "irow": [50, 143], "irreduc": [66, 97, 144, 153, 156], "irregular": 43, "irrelev": [34, 37, 44], "irrespect": [25, 144], "irun": 161, "is_avail": 71, "is_first_col": 3, "isak": [1, 44, 56], "isbn": 1, "iscalar": [73, 93], "isinst": [33, 37, 71, 123, 129], "isn": [63, 73, 148], "isnet": 56, "iso": [53, 82], "isol": [56, 125, 127], "isotrop": 146, "issu": [38, 63, 71, 95, 97, 105, 113, 143, 151, 153, 156], "isupp": 151, "ital": [39, 42, 134], "item": [3, 71, 129, 136], "iter": [1, 15, 38, 43, 44, 50, 51, 66, 67, 70, 71, 72, 73, 79, 81, 92, 96, 97, 105, 106, 107, 133, 134, 138, 143, 144, 146, 148, 151, 152, 153, 156], "itila": 1, "its": [0, 4, 7, 8, 9, 11, 12, 17, 19, 22, 24, 25, 34, 37, 38, 40, 41, 43, 46, 47, 49, 52, 53, 60, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 75, 77, 78, 80, 82, 83, 85, 88, 96, 100, 104, 105, 107, 119, 121, 125, 127, 130, 132, 133, 134, 135, 136, 138, 143, 144, 147, 149, 151, 152, 153, 156, 161], "itself": [4, 7, 9, 19, 31, 33, 39, 40, 43, 44, 47, 50, 53, 58, 59, 63, 64, 67, 86, 96, 97, 117, 127, 132, 147, 150, 152], "iv": [60, 156], "ix": [41, 77, 83], "ix1": 65, "ix2": 65, "j": [1, 4, 5, 16, 19, 29, 34, 37, 44, 46, 48, 49, 56, 66, 67, 68, 78, 79, 82, 96, 99, 100, 107, 117, 125, 127, 130, 133, 143, 146, 149, 151, 153, 156, 161], "j_": [72, 107], "jacob": 8, "jacobian": [3, 7], "jaiswal": [121, 123], "jake": [66, 80], "jame": [1, 77, 83], "jan": [80, 81], "januari": 21, "javascript": [153, 154], "jax": 105, "jay03": [1, 56], "jay2020": 48, "jay88": [1, 62], "jayn": [1, 4, 40, 56], "jb": [0, 56, 131], "jb_test": 0, "jefferi": 53, "jeffrei": [3, 8, 38, 40, 51, 53], "jen": 1, "jensen": 56, "jeopard": 61, "jet": 37, "jforssen22": [1, 44, 46], "jhm": [80, 81], "ji": [67, 68, 125, 156], "jiang": [1, 44, 56], "jimmi": 1, "jitter": [78, 151, 152], "jk": [68, 125, 127], "jmlr": 1, "joanna": 63, "job": [63, 90, 151, 152], "john": [1, 8, 104, 163], "johnson": 4, "join": [133, 136], "joint": [4, 7, 17, 22, 31, 32, 34, 35, 41, 42, 44, 53, 78, 82, 85, 86, 120, 142, 146, 147, 148, 152, 153, 156, 161, 163], "jointli": [85, 148], "jonathan": 1, "jone": 1, "jordan": 56, "joukj": 1, "journal": [1, 15, 43, 63], "jpeg": 75, "jpg": 127, "jstor": 1, "judg": [29, 60, 66, 146], "judgement": [43, 46, 53], "judgment": [47, 110], "jul": 137, "juli": 123, "julia": 63, "julien": 1, "jump": [9, 11, 23, 35, 51, 126, 144, 154], "jump_w": 9, "june": [5, 38, 50, 77, 95, 143, 144], "junli": 1, "jupyt": [23, 26, 27, 70, 121, 123, 125, 129, 131, 132, 136], "jupytext": 0, "juri": 62, "just": [0, 6, 7, 9, 11, 13, 17, 19, 22, 23, 24, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 72, 73, 76, 77, 82, 83, 85, 86, 88, 90, 93, 95, 96, 97, 100, 102, 105, 111, 127, 130, 131, 132, 133, 134, 137, 144, 146, 147, 152, 153, 154, 156, 159, 163], "justic": 63, "justif": [15, 64], "justifi": [24, 42, 44, 119], "k": [1, 3, 4, 6, 9, 15, 16, 19, 29, 35, 37, 38, 40, 41, 42, 44, 48, 49, 51, 52, 53, 67, 68, 71, 72, 77, 79, 83, 85, 86, 88, 92, 94, 95, 96, 107, 117, 120, 123, 125, 127, 130, 133, 142, 145, 146, 148, 150, 153, 154, 156, 159, 161, 162], "k0": [145, 162], "k1": 82, "k1__constant_valu": 82, "k1__constant_value_bound": 82, "k2": 82, "k2__length_scal": 82, "k2__length_scale_bound": 82, "k99": 127, "k995": 127, "k_": [49, 78, 79, 86, 145, 162], "k_0": [67, 145, 162], "k_1": [67, 77, 83, 145, 162], "k_2": [52, 67, 77, 83, 145, 162], "k_3": [145, 162], "k_arrai": [145, 162], "k_b": [4, 51], "k_i": [67, 145, 162], "k_l": 67, "k_list": 65, "k_max": 49, "k_now": [145, 162], "k_order": 49, "k_rbf": [78, 82], "kaim": 71, "kaiming_normal_": 71, "kalman": 125, "kami\u0144ska": 63, "kangaroo": 4, "kappa": [79, 85, 86, 123, 125], "kappa_": 79, "karamani": 163, "karl": 62, "kaspar": 1, "kati": 136, "kavukcuoglu": 1, "kazantzidi": 51, "kb": [69, 137], "kb1": [77, 83], "kb2": [77, 83], "kbf": 86, "kde": [144, 152], "keegan": 1, "keep": [6, 15, 19, 22, 25, 33, 34, 37, 39, 40, 41, 43, 44, 45, 64, 69, 71, 73, 96, 102, 106, 107, 115, 125, 127, 134, 144, 145, 146, 147, 151, 152, 153, 159, 162], "kei": [9, 11, 21, 22, 23, 24, 34, 43, 44, 45, 48, 58, 62, 63, 65, 67, 69, 71, 77, 79, 82, 83, 85, 88, 117, 124, 125, 127, 134, 144, 146, 153, 154, 156, 159], "keith": 1, "kejzlar2019bayesian": 48, "kejzlar2020": 48, "kennedi": [1, 119], "kept": [9, 23, 30, 44, 56, 125, 127, 162], "kera": [64, 69, 70, 72, 76, 136], "kern": [77, 78, 79, 83, 92], "kern1": [77, 83], "kern2": [77, 83], "kernel": [47, 77, 79, 80, 83, 86, 87, 92, 117, 119, 120, 121, 123, 134, 144, 154], "kernel_": [80, 81, 82], "kernel_func": 123, "kernel_rbf": 82, "kernelspec": 0, "ket": 47, "kev": 133, "keyboard": 134, "keyword": [94, 134, 138, 150], "kg": [121, 123], "ki": [65, 125], "kick": 73, "kill": 33, "kilomet": 77, "kind": [8, 19, 34, 58, 64, 66, 67, 73, 76, 78, 82, 88, 97, 101, 110, 111, 152, 161], "kinet": [44, 45, 148, 151], "king": 1, "kingma": 1, "kingmaba14": [1, 107], "kj": [67, 68, 127], "kk": 125, "kl": 72, "km": [7, 41, 77], "kmax": 49, "knew": [39, 147, 152], "knn_classifi": 65, "know": [3, 4, 7, 8, 9, 11, 13, 16, 17, 18, 19, 21, 22, 23, 25, 30, 31, 34, 40, 41, 42, 47, 48, 56, 59, 63, 64, 65, 72, 73, 79, 81, 125, 131, 133, 134, 136, 145, 146, 153, 154, 156, 159, 162], "knowledg": [4, 7, 8, 9, 11, 13, 16, 21, 25, 27, 34, 37, 39, 40, 41, 43, 44, 46, 47, 53, 56, 58, 59, 60, 61, 64, 67, 73, 90, 111, 119, 120, 121, 124, 130, 147, 151, 152], "known": [4, 7, 8, 16, 17, 25, 29, 34, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 53, 60, 62, 63, 65, 66, 67, 68, 71, 72, 73, 75, 77, 78, 79, 80, 82, 83, 85, 88, 90, 95, 97, 99, 100, 104, 110, 111, 117, 127, 130, 142, 143, 144, 151, 153, 156, 161], "knuth": 153, "ko": 96, "kochurov": [73, 93], "koh": [48, 120, 121], "kohn": 47, "kolmogorov": [8, 25], "kondev": [1, 133], "korai": 1, "kp": [145, 162], "kr": 150, "kramer": 1, "krasser": 72, "krgb15": [1, 72], "krishak": 51, "kroneck": 7, "kucukelbir": [1, 72], "kullback": 4, "kutta": [148, 150], "kwarg": [34, 41, 50, 102, 126, 151, 152], "kwd": 126, "kx": [77, 83], "l": [1, 4, 7, 13, 19, 34, 35, 38, 39, 41, 44, 53, 67, 73, 82, 85, 86, 88, 92, 93, 117, 123, 130, 147, 148, 149, 150, 152, 161, 163], "l1": [67, 73], "l1_ratio": 70, "l2": [70, 73, 74], "l_": 67, "l_1": 88, "l_2": 88, "l_cumsum": 41, "l_h": 123, "l_i": 85, "l_j": [67, 68], "l_opt": 82, "l_pt": 42, "l_v": 123, "l_x": 53, "l_y": 53, "la": [34, 127], "la_i": 68, "la_k": 68, "lab": [41, 51, 64, 123], "label": [3, 5, 7, 9, 15, 17, 19, 29, 30, 33, 34, 35, 37, 38, 40, 41, 42, 43, 46, 47, 48, 49, 50, 53, 63, 64, 65, 67, 69, 70, 71, 72, 73, 75, 76, 77, 80, 81, 82, 88, 93, 95, 96, 97, 102, 107, 111, 117, 123, 126, 127, 129, 130, 132, 133, 134, 135, 143, 144, 147, 149, 150, 152, 153, 156, 161, 162], "labels": 33, "labels_corn": 96, "labor": 64, "laboratori": 16, "lack": [4, 8, 40, 66, 110, 117, 130], "ladder": [50, 51, 96], "lag": [44, 143, 144, 159], "lagrang": [4, 5], "lagrangian": [17, 149], "lai": [25, 34], "lam": 161, "lambda": [3, 5, 33, 35, 38, 53, 66, 70, 77, 123, 127, 133, 151, 156, 161], "lambda_": 53, "lambda_0": [4, 53, 156], "lambda_1": [4, 35], "lambda_2": 35, "lambda_i": 53, "lambda_mat": 49, "lambda_mat_inv": 49, "lambdas0": 5, "lambdas_min": 5, "land": 8, "landmark": 79, "landscap": 44, "lang": 1, "langermann": 92, "langevin": 154, "langl": [4, 19, 37, 42, 45, 51, 85, 146, 153, 159], "languag": [0, 34, 43, 58, 62, 63, 64, 65, 71, 76, 90, 96, 105, 134, 136, 152, 153], "lapack": 136, "laplac": [8, 34, 51, 62, 72, 95], "laplacepropos": 151, "laps": 56, "larg": [3, 4, 7, 17, 19, 25, 29, 33, 34, 37, 38, 40, 41, 44, 45, 46, 47, 48, 51, 53, 55, 58, 60, 62, 64, 67, 68, 71, 72, 73, 89, 97, 104, 105, 107, 110, 111, 113, 114, 124, 127, 129, 130, 144, 146, 149, 153, 154, 156, 161], "larger": [4, 23, 25, 29, 33, 35, 37, 38, 40, 41, 45, 46, 51, 53, 66, 75, 77, 78, 80, 82, 86, 121, 125, 126, 144, 154], "largest": [4, 41, 44, 63, 66, 69, 78, 82, 125, 127, 153, 163], "lasagn": 73, "laser": [51, 156], "last": [15, 16, 32, 34, 35, 37, 44, 48, 50, 51, 56, 64, 66, 68, 69, 70, 72, 73, 75, 76, 78, 92, 93, 95, 96, 100, 102, 123, 126, 127, 130, 133, 134, 137, 144, 149, 151, 154, 156, 158], "last_nam": 134, "lastli": 56, "later": [9, 10, 11, 19, 25, 33, 34, 35, 38, 40, 41, 46, 63, 64, 67, 73, 78, 82, 88, 93, 95, 97, 102, 113, 121, 133, 134, 135, 137, 142, 143, 144, 146, 154, 156, 159], "latest": [1, 41, 70, 71, 151, 152, 163], "latex": [0, 40, 41, 42, 49, 95, 126, 134, 135, 142], "latex_macro": 0, "latin": [47, 53, 72, 79], "latter": [24, 34, 42, 43, 48, 49, 51, 53, 62, 66, 85, 86, 107, 110, 120, 124, 125, 133, 144, 156], "lattic": [44, 67], "launch": 62, "laundri": 146, "law": [39, 51, 62, 63, 64, 76, 117, 130, 147, 152], "lawrenc": [77, 83], "lawyer": 62, "lay": 0, "layer": [67, 68, 69, 70, 71, 72, 73, 93, 117, 129], "layout": [5, 9, 136], "lbfg": [70, 81], "lbrace": 48, "lcb": 92, "ldot": [7, 15, 17, 18, 19, 23, 29, 33, 34, 35, 37, 39, 46, 47, 48, 51, 52, 53, 66, 67, 82, 86, 88, 90, 92, 96, 100, 112, 113, 125, 130, 138, 145, 146, 147, 148, 152, 153, 154, 156, 159, 161, 162], "le": [4, 7, 25, 34, 96], "lead": [7, 15, 22, 23, 25, 37, 38, 40, 43, 46, 47, 48, 49, 53, 55, 56, 57, 59, 62, 63, 64, 66, 67, 68, 71, 72, 73, 75, 88, 94, 105, 106, 117, 119, 121, 123, 125, 130, 133, 134, 136, 143, 146], "leaki": [67, 70, 129], "leaky_relu": 129, "leakyrelu": [71, 129], "leap": 34, "leapfrog": [44, 148, 150], "leapfrog_energy_test_1": 150, "leapfrog_orbit_1": 150, "learn": [1, 8, 17, 23, 25, 29, 34, 35, 39, 41, 47, 50, 56, 57, 58, 59, 61, 62, 69, 72, 75, 81, 85, 86, 95, 99, 104, 105, 106, 107, 110, 111, 117, 119, 121, 124, 127, 131, 133, 134, 136, 143, 144, 147, 152, 153], "learnabl": 75, "learner": 73, "learning_curv": 97, "learning_r": 106, "learningfromdata": [122, 127, 137], "least": [4, 7, 8, 9, 16, 19, 23, 30, 37, 39, 43, 44, 46, 59, 62, 65, 66, 69, 88, 94, 95, 102, 110, 123, 127, 130, 132, 147, 151, 152, 161], "leav": [23, 25, 38, 44, 51, 52, 66, 68, 75, 95, 147, 148, 151, 152], "lebesgu": 4, "lec": [45, 47, 52], "lectur": [1, 3, 33, 43, 45, 46, 53, 56, 63, 64, 66, 67, 68, 70, 72, 88, 92, 95, 97, 111, 127, 133, 134, 143, 159], "lecturenot": 127, "lee": [1, 73], "left": [0, 3, 4, 7, 9, 10, 13, 16, 17, 19, 22, 24, 25, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 56, 64, 65, 66, 67, 68, 72, 78, 81, 82, 85, 88, 92, 94, 95, 96, 97, 100, 103, 105, 106, 107, 114, 117, 120, 121, 125, 126, 127, 130, 143, 144, 145, 146, 147, 150, 151, 152, 153, 156, 159, 161, 162], "leftarrow": [68, 156], "leftmost": 125, "leftrightarrow": [7, 35, 104, 125, 156], "leg": 9, "legal": 8, "legend": [0, 5, 7, 9, 17, 29, 33, 34, 37, 38, 49, 70, 71, 73, 76, 77, 80, 81, 82, 83, 88, 93, 95, 102, 123, 126, 127, 129, 130, 133, 134, 135, 143, 144, 149, 150, 153, 161, 162], "legendr": [110, 149], "lemaitr": [80, 81], "lemaitre58": [80, 81], "len": [5, 25, 30, 34, 37, 38, 41, 42, 49, 50, 65, 70, 77, 78, 79, 82, 83, 95, 96, 102, 123, 127, 133, 136, 143, 144, 147, 150, 151, 152, 161], "lend": 43, "length": [1, 7, 8, 23, 34, 38, 42, 44, 47, 51, 65, 77, 78, 79, 82, 83, 85, 86, 88, 95, 96, 106, 120, 123, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 161], "length_scal": [80, 81, 82, 123], "length_scale_bound": [80, 81], "lengthscal": [77, 78, 79, 82, 83, 92], "lenp": 47, "leprechaun": 7, "leq": [7, 9, 11, 13, 17, 23, 29, 35, 38, 44, 46, 49, 51, 53, 65, 66, 82, 95, 96, 104, 121, 130, 145, 153, 154, 156, 159, 161, 162], "less": [4, 11, 21, 37, 38, 44, 52, 53, 58, 60, 62, 63, 66, 67, 80, 95, 100, 127, 130, 133, 136, 143, 144, 154, 159], "lesson": [12, 63], "lesssim": 45, "let": [4, 6, 7, 8, 9, 11, 15, 16, 19, 25, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 53, 59, 63, 64, 65, 66, 67, 68, 69, 71, 72, 76, 77, 78, 80, 82, 83, 85, 86, 88, 95, 96, 97, 101, 102, 107, 113, 120, 123, 127, 130, 133, 134, 135, 136, 143, 144, 146, 147, 148, 151, 152, 153, 154, 156, 159, 161], "lett": 1, "letter": [23, 88, 130], "level": [8, 9, 16, 19, 29, 35, 37, 40, 41, 43, 47, 53, 56, 59, 63, 65, 72, 73, 74, 80, 82, 130, 132, 136, 143, 146, 156], "level_1sigma": 41, "leverag": [48, 71, 119], "lewi": 58, "lfd": 122, "lfd_develop": 140, "lfd_for_physicist": 137, "li": [7, 8, 9, 25, 30, 46, 47, 53, 62, 63, 78, 82, 132, 136], "li6e_nnloopt_nmax10": [78, 82], "lib": [50, 81, 96, 126, 152], "libcxx": 137, "librari": [17, 26, 34, 56, 64, 72, 73, 76, 93, 105, 133, 134, 136, 137, 153], "licat": 43, "licens": [56, 76, 80, 81, 137, 153], "lie": [25, 51, 53, 66], "life": [37, 56, 64, 67, 98, 133], "light": [7, 17, 25, 30, 34, 47, 53, 56, 58, 73, 79, 93, 130], "lightest": 133, "lightgrai": 41, "lighthous": 154, "lighthouse_stat": 42, "like": [0, 4, 9, 11, 12, 16, 17, 18, 19, 21, 22, 23, 30, 31, 33, 34, 35, 37, 39, 41, 42, 43, 44, 47, 48, 50, 51, 52, 56, 58, 62, 63, 64, 65, 66, 67, 71, 73, 77, 78, 79, 82, 83, 86, 88, 92, 93, 105, 106, 107, 114, 117, 125, 127, 130, 131, 133, 134, 136, 137, 143, 144, 145, 146, 147, 148, 151, 152, 153, 156, 159, 162], "likelihoo": [50, 51], "likelihood": [4, 7, 8, 9, 10, 16, 23, 25, 29, 30, 37, 39, 40, 42, 44, 46, 47, 49, 51, 52, 53, 66, 72, 73, 74, 77, 80, 81, 83, 85, 93, 94, 96, 123, 127, 130, 142, 143, 144, 147, 151, 152, 154, 158], "likewis": 126, "lim_": [7, 44, 156], "limit": [1, 4, 7, 8, 9, 17, 23, 26, 30, 34, 37, 40, 42, 43, 51, 53, 58, 61, 65, 66, 76, 78, 82, 89, 94, 102, 110, 113, 119, 126, 129, 130, 132, 153, 154, 161], "limits_": 44, "lin": [78, 82], "linalg": [34, 49, 50, 65, 77, 78, 82, 83, 95, 102, 123, 127, 136], "lindholm": 1, "lindsei": 1, "lindsten": 1, "line": [0, 4, 7, 9, 10, 15, 19, 21, 23, 34, 35, 37, 38, 44, 50, 53, 64, 65, 66, 69, 70, 72, 73, 76, 77, 78, 79, 82, 83, 86, 88, 91, 93, 94, 102, 103, 117, 126, 130, 132, 133, 134, 137, 138, 142, 144, 145, 146, 147, 149, 150, 151, 152, 154, 158, 159, 162], "line1": 9, "line2": 9, "line3": 9, "linear": [1, 3, 7, 16, 27, 28, 38, 40, 41, 45, 47, 48, 50, 53, 55, 64, 66, 70, 71, 72, 73, 75, 77, 78, 82, 83, 86, 88, 95, 97, 103, 104, 105, 113, 116, 117, 123, 125, 126, 129, 133, 134, 138, 146, 158], "linear_model": [70, 74, 133], "linearli": [29, 34, 46, 53, 73, 85, 93, 96, 99, 112], "linearregress": 133, "liner": [65, 135], "lineshap": 53, "linestyl": [9, 34, 37, 40, 42, 49, 71, 77, 80, 81, 83, 102, 134, 144, 149, 150], "linewidth": [17, 37, 38, 40, 42, 49, 50, 130, 152], "link": [0, 1, 8, 17, 43, 44, 56, 67, 130, 131, 132, 134, 148], "linspac": [0, 5, 7, 9, 17, 25, 29, 30, 33, 34, 38, 40, 41, 42, 49, 71, 77, 78, 79, 80, 81, 82, 83, 88, 95, 96, 102, 123, 126, 129, 130, 132, 134, 135, 136, 144, 150, 153, 161], "linux": [93, 123, 134, 137], "liouvil": [44, 148], "liouville_test": 149, "liouville_theorem_visu": 148, "liquid": 133, "list": [1, 7, 9, 17, 25, 30, 37, 41, 42, 43, 44, 46, 56, 61, 62, 63, 65, 67, 75, 82, 93, 96, 120, 123, 126, 129, 130, 132, 133, 134, 137, 138, 140, 144, 146, 151, 153, 156, 158], "list_a": 135, "list_b": 135, "list_lik": 82, "liter": 38, "literatur": [10, 17, 23, 38, 43, 47, 48, 51, 56, 67, 68, 85, 88, 94, 122], "littl": [8, 40, 53, 68, 71, 72, 127, 143, 148], "liu": 1, "live": [40, 48, 63, 148, 153, 154], "liz": 136, "ll": [3, 6, 7, 9, 10, 11, 15, 17, 19, 21, 23, 25, 30, 31, 33, 34, 38, 39, 40, 41, 42, 45, 49, 52, 59, 65, 67, 71, 77, 78, 79, 82, 83, 85, 93, 94, 95, 119, 125, 126, 127, 130, 132, 134, 137, 143, 144, 145, 146, 147, 148, 152, 153, 154, 156, 159, 162], "ln": [4, 37, 44, 51, 67, 95, 96, 130], "lnlike": [50, 96], "lnpost": [38, 50, 143], "lnprob": [50, 96], "lnprobabl": [38, 41, 50, 143], "lnz": 96, "lnzl": 96, "lo95": [77, 83], "load": [69, 70, 77], "load_data": [69, 76], "load_model": 69, "loadtxt": [78, 82], "loc": [0, 7, 9, 17, 29, 33, 34, 38, 42, 50, 70, 76, 77, 80, 81, 82, 83, 88, 95, 96, 126, 130, 133, 150, 153, 161, 162], "local": [4, 17, 48, 51, 67, 73, 75, 88, 92, 97, 105, 117, 123, 130, 133, 137, 153], "locat": [6, 16, 34, 40, 42, 43, 53, 77, 82, 83, 92, 94, 95, 96, 130, 136, 137, 140, 146, 147, 152, 153], "log": [3, 5, 6, 17, 34, 35, 37, 38, 39, 40, 41, 42, 44, 49, 50, 51, 53, 66, 71, 72, 74, 77, 79, 81, 83, 88, 94, 95, 96, 123, 136, 143, 147, 148, 151, 152], "log10": 77, "log_evidence_estim": 96, "log_flat_prior": [6, 40], "log_jeffreys_prior": 6, "log_l_pt": 42, "log_likelihood": [37, 38, 40, 41, 42, 50, 77, 95, 96, 123, 142, 143, 147, 152], "log_likelihood_singl": 41, "log_likelihood_v": 123, "log_likelihood_valu": 123, "log_marginal_likelihood": 81, "log_p1": [40, 41], "log_p1_1": 41, "log_p2": 40, "log_posterior": [37, 38, 41, 50, 96, 123, 142, 143, 146, 147, 152], "log_posterior_cauchi": 38, "log_posterior_conserv": 38, "log_posterior_gaussian": 38, "log_prior": [6, 37, 38, 41, 42, 50, 96, 123, 142, 143, 147, 152], "log_prior_": 123, "log_prior_cbar": 123, "log_prior_l": 123, "log_prior_param": 123, "log_prior_phi": 123, "log_prior_pt": 42, "log_prior_r": 123, "log_prior_theta": 123, "log_prior_v": 123, "log_priors_mdgp": 123, "log_priors_model": 123, "log_priors_thetaphi": 123, "log_prob_cutoff": 41, "log_prob_max": 41, "log_symmetric_prior": [6, 40], "logaddexp": [38, 50], "logarithm": [3, 4, 19, 37, 38, 40, 41, 53, 71, 72, 88, 95, 96, 142], "logic": [1, 4, 8, 9, 11, 16, 20, 53, 56, 62, 64, 145, 162], "logical_and": [37, 130, 147, 152], "logist": [63, 65, 67, 68, 73, 89, 93], "logisticregressioncv": 70, "logisticregressioncvifit": 70, "logit": [65, 67, 88], "logl": [41, 50, 96, 123], "logl1": 38, "logl2": 38, "loglarg": [50, 96], "loglikelihood": 96, "loglkwarg": [50, 96], "loglog": [149, 153], "logp": [6, 38, 50, 96, 123, 151], "logparg": [50, 96], "logpkwarg": [50, 96], "logpr": 6, "logz": 123, "logz_err": 123, "long": [15, 16, 17, 21, 34, 37, 38, 43, 46, 47, 51, 52, 53, 56, 66, 67, 94, 130, 133, 136, 137, 144, 146, 152, 156], "longer": [8, 12, 47, 51, 66, 67, 88, 120, 143, 146, 151], "longleftarrow": [138, 148], "longrightarrow": [0, 3, 11, 12, 13, 15, 16, 17, 19, 24, 31, 32, 33, 34, 35, 37, 51, 52, 138, 146, 159], "loocv": 66, "look": [0, 2, 9, 11, 13, 16, 17, 18, 19, 20, 26, 27, 31, 33, 34, 35, 37, 38, 39, 42, 44, 49, 50, 51, 52, 53, 55, 58, 63, 67, 69, 76, 77, 78, 82, 83, 86, 90, 92, 96, 102, 106, 114, 125, 127, 130, 133, 134, 137, 141, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 156, 157, 159, 160, 162], "loop": [34, 68, 71, 106, 135, 145, 147, 152, 162], "loos": 67, "lorentzian": 53, "lose": [48, 53, 161], "loss": [8, 69, 71, 72, 75, 76, 82, 88, 93, 104, 116, 117, 127], "lost": [38, 125, 127], "lot": [7, 19, 22, 29, 33, 63, 73, 93, 135, 144, 154, 159], "love": 62, "low": [1, 11, 31, 34, 43, 44, 45, 46, 47, 50, 51, 63, 66, 72, 79, 91, 96, 102, 127, 136, 146, 149, 151, 153, 154], "lower": [19, 25, 34, 38, 42, 50, 51, 53, 63, 68, 71, 73, 76, 119, 121, 123, 129, 130, 135, 147, 151, 152, 156, 159], "lowest": [47, 94, 156], "lp": 123, "lr": 71, "lra": [0, 3, 4, 51, 52, 79, 86, 90, 125, 146, 148, 154, 159], "lstsq": 127, "lt": [78, 151, 159], "luck": 16, "lvert": [72, 104, 120], "lw": [9, 29, 34, 38, 42, 65, 88, 102, 127, 129, 130, 132, 133, 134, 144, 161], "lwahlstromlschon21": [1, 63], "m": [1, 4, 7, 16, 34, 35, 37, 38, 39, 40, 41, 44, 45, 46, 49, 50, 51, 52, 53, 66, 67, 70, 71, 72, 77, 78, 79, 82, 83, 85, 86, 90, 92, 95, 96, 99, 100, 101, 102, 104, 107, 114, 115, 118, 121, 123, 125, 127, 129, 130, 133, 134, 143, 147, 148, 149, 151, 152, 154, 156], "m_": [52, 68, 148], "m_0": 95, "m_1": [0, 7, 52, 79, 86, 95], "m_2": [7, 52, 79, 86], "m_h": 133, "m_i": [4, 7, 34, 46, 100, 148], "m_j": [4, 7], "m_k": [52, 65], "m_l": 68, "m_n": 133, "m_p": 133, "ma_theta0": 143, "ma_theta1": 143, "mac": [93, 134, 137], "mac03": [1, 56, 72], "mach": 1, "machin": [1, 34, 47, 50, 56, 57, 62, 66, 67, 71, 72, 85, 86, 87, 88, 93, 95, 99, 104, 107, 110, 111, 117, 124, 125, 127, 131, 133, 143, 144, 153, 158], "machineri": [41, 130], "mackai": [1, 56, 72], "mackei": [1, 147, 152, 159], "maco": [123, 137], "macosx": [73, 93], "macroscop": 4, "made": [7, 9, 11, 33, 34, 41, 43, 44, 51, 52, 53, 56, 61, 63, 64, 71, 72, 75, 80, 85, 88, 115, 116, 120, 127, 132, 133, 134, 135, 144, 153, 161], "mae": [65, 66, 67], "magazin": 128, "magic": [134, 135, 144], "magnifi": 125, "magnitu": 79, "magnitud": [7, 37, 46, 47, 49, 51, 53, 63, 71, 96, 97, 123, 127], "mahalanobi": 123, "mahlet": 1, "mai": [1, 7, 18, 19, 21, 22, 23, 34, 37, 43, 46, 47, 48, 49, 51, 53, 56, 58, 59, 61, 62, 63, 64, 66, 67, 68, 75, 76, 77, 83, 88, 94, 96, 104, 124, 126, 127, 131, 133, 134, 137, 145, 149, 154, 162], "main": [8, 43, 46, 47, 53, 72, 75, 79, 88, 90, 107, 127, 151, 153], "mainli": [43, 45, 63, 64, 73, 104, 110, 133, 144], "maintain": [35, 44, 48, 67, 71, 123, 136, 156], "maiti": 1, "major": [35, 38, 63, 65, 73, 104, 105, 133], "make": [0, 4, 6, 7, 8, 9, 11, 16, 17, 18, 19, 23, 24, 29, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 62, 63, 64, 65, 66, 67, 70, 72, 73, 74, 75, 77, 78, 79, 82, 83, 85, 88, 89, 92, 93, 94, 95, 96, 97, 99, 101, 102, 104, 106, 110, 111, 127, 129, 130, 133, 134, 135, 138, 142, 143, 144, 145, 147, 148, 151, 152, 153, 154, 158, 161, 162], "make_blob": 74, "make_circl": 93, "make_data": [40, 143], "make_dataset": 37, "make_fig": 37, "make_matric": 49, "make_moon": [70, 73, 93], "make_plot": 129, "makedir": 133, "mala": 154, "male": [63, 130], "manag": [9, 44, 48, 63, 75, 126, 137, 158], "mandat": 59, "mani": [4, 7, 8, 9, 11, 12, 17, 19, 21, 23, 25, 27, 29, 30, 32, 33, 34, 35, 39, 40, 43, 44, 45, 47, 48, 49, 51, 53, 56, 57, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 77, 78, 79, 82, 83, 88, 91, 93, 97, 102, 104, 105, 107, 111, 117, 119, 120, 121, 122, 126, 129, 130, 133, 134, 135, 136, 137, 144, 145, 146, 147, 148, 151, 152, 153, 154, 156, 159, 161, 162], "manifest": 63, "manifestli": 47, "manifesto": 48, "manifold": 45, "manipul": [8, 20, 25, 34, 79, 86], "mankind": 8, "manner": 75, "manual": [17, 23, 43, 64, 130, 134, 138, 146, 147, 152], "manufactur": 73, "manzoni": 1, "map": [7, 8, 34, 38, 46, 48, 64, 65, 67, 72, 88, 96, 101, 110, 123, 135, 146, 148, 151, 159], "map_estim": 152, "mapsto": [48, 106], "mar": [1, 78, 133, 149], "marathon": 77, "march": [53, 133], "margin": [0, 10, 15, 16, 17, 19, 20, 22, 31, 32, 35, 37, 38, 40, 43, 44, 49, 52, 53, 72, 77, 82, 83, 85, 94, 96, 123, 124, 126, 147, 148, 152, 153, 154, 156, 159, 161, 163], "margina": 37, "marin": 1, "marina": 1, "mark": [17, 65, 126, 127, 134, 145, 162], "markdown": [138, 142], "marker": [34, 38, 49, 72, 78, 80, 82, 102, 133, 144, 145, 151, 162], "markers": [49, 80, 123], "markov": [1, 7, 16, 38, 43, 51, 143, 144, 145, 146, 147, 148, 151, 152, 159, 160, 161, 162, 163], "markovprocessexampl": 156, "markovprocessexample_corner_fig": 156, "markovprocessexample_runs_fig": 156, "martin": 72, "masquerad": 7, "mass": [1, 7, 8, 19, 23, 33, 34, 37, 43, 44, 46, 48, 51, 72, 79, 82, 99, 104, 114, 115, 121, 123, 148, 149, 153, 154, 161], "mass16": 133, "mass16round": 133, "massag": 133, "masses2016": 133, "masseval2016": 133, "massiv": [44, 73], "master": [1, 16, 56], "match": [1, 38, 43, 55, 67, 77, 83, 121], "materi": [27, 66, 75, 124], "matern": [77, 79, 81, 83, 86], "matern32": [77, 83, 92], "matern52": [77, 79, 83], "math": [1, 5, 33, 37, 43, 73, 93, 132, 136, 145, 162], "mathbb": [0, 17, 24, 25, 34, 44, 66, 67, 72, 82, 85, 86, 88, 100, 104, 107, 113, 127, 130, 146, 148, 161], "mathbf": [23, 34, 65, 78, 82, 85, 92, 100, 121, 127, 150], "mathcal": [0, 3, 4, 7, 13, 16, 19, 24, 29, 34, 38, 39, 40, 41, 44, 46, 47, 49, 53, 67, 72, 77, 79, 82, 83, 85, 88, 92, 95, 100, 102, 104, 117, 120, 130, 143, 144, 147, 149, 152, 153, 154, 156, 158, 159, 161], "mathemat": [1, 8, 9, 11, 17, 19, 23, 25, 40, 56, 58, 61, 62, 64, 65, 73, 78, 82, 88, 93, 113, 116, 117, 130, 133, 144, 153], "mathematica": [1, 37, 134], "mathematician": [0, 43, 61, 62], "mathop": [34, 100, 113], "mathrm": [3, 4, 7, 9, 17, 25, 30, 33, 34, 37, 41, 44, 45, 46, 47, 48, 53, 64, 65, 66, 67, 72, 75, 78, 82, 85, 88, 95, 96, 100, 106, 113, 123, 127, 130, 133, 144, 156], "matlab": 134, "matmul": [34, 65, 71, 102, 153], "matplotlib": [0, 3, 5, 6, 7, 9, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 50, 65, 69, 70, 71, 73, 76, 77, 78, 80, 81, 82, 83, 88, 92, 93, 94, 95, 96, 102, 123, 126, 127, 129, 130, 132, 133, 135, 137, 138, 143, 144, 145, 147, 149, 150, 151, 152, 153, 156, 161, 162], "matric": [34, 45, 47, 49, 52, 67, 75, 77, 79, 82, 83, 85, 86, 88, 100, 125, 133, 153, 156], "matrix": [7, 35, 38, 41, 44, 45, 47, 49, 52, 53, 63, 65, 66, 68, 71, 72, 73, 75, 77, 78, 79, 80, 82, 83, 86, 88, 93, 95, 97, 101, 102, 103, 104, 106, 107, 117, 122, 123, 130, 133, 138, 146, 148, 153, 161], "matrix_larg": 136, "matrix_large_spars": 136, "matrix_rank": 136, "matshow": [77, 83], "matt": 56, "matter": [19, 35, 37, 44, 47, 53, 62, 154, 156], "matthew": 1, "matur": 47, "max": [4, 7, 9, 23, 29, 33, 35, 37, 40, 41, 42, 44, 49, 50, 53, 67, 69, 70, 75, 76, 78, 82, 92, 94, 95, 96, 126, 132, 133, 134, 136, 138, 145, 153, 161, 162], "max68": 130, "max90": 130, "max_": 46, "max_arg": 41, "max_height": [9, 132], "max_i_num": 153, "max_it": [50, 70], "max_lag": [143, 144], "max_lik": 123, "max_mode_theta": 41, "max_n": [33, 37], "max_n1": 37, "max_n2": 37, "max_norm_pt": 126, "max_of_mod": 41, "max_param": 123, "max_pooling2d": 76, "max_pooling2d_1": 76, "max_posterior": 42, "max_sigma_v": 126, "max_theta": [147, 152], "maxa": 7, "maxent": 5, "maxim": [8, 13, 35, 38, 39, 40, 41, 49, 51, 72, 73, 77, 83, 85, 88, 93, 95, 104, 147, 152], "maxima": [53, 133], "maximimum": 72, "maximum": [7, 8, 9, 13, 16, 17, 19, 25, 30, 33, 34, 35, 37, 38, 39, 40, 42, 43, 46, 47, 49, 51, 53, 55, 62, 72, 73, 75, 78, 79, 80, 90, 92, 96, 123, 126, 127, 129, 133, 142, 147, 151, 152], "maxlik": 35, "maxlike_result": [147, 152], "maxpooling2": 76, "maxpooling2d": 76, "may22": [1, 46], "mayb": [10, 31, 90, 130, 151, 154], "mb": [106, 137], "mb_k": 65, "mbgd": 106, "mbox": [9, 11, 13, 15, 17, 19, 30, 35, 37, 38, 42, 47, 78, 86, 125, 143, 145, 162], "mbpt": 47, "mbw": [1, 66, 117], "mc": [0, 134, 142, 146, 153], "mcculloch": 67, "mcelreath": [44, 148, 153, 154], "mchain": 143, "mcmc": [1, 6, 7, 38, 41, 42, 43, 45, 46, 50, 51, 72, 73, 93, 123, 141, 147, 148, 151, 152, 155, 160, 163], "mcmc_data0": 50, "mcmc_data_nt": 50, "mcmc_random_walk_and_sampl": 154, "mcmc_sampling_i": 159, "mcmc_sampling_ii": [148, 158], "mcmcsampl": [147, 152], "mcse_mean": [151, 152], "mcse_sd": [151, 152], "md": [0, 121, 123], "md2": 123, "md_kernel": 123, "mdc": 123, "mdf": [1, 45], "mdn": 73, "me": [21, 22, 78, 82, 129], "mead": 5, "mean": [0, 6, 7, 9, 11, 12, 13, 16, 17, 18, 19, 21, 23, 24, 25, 29, 30, 31, 34, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50, 51, 52, 53, 58, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 83, 86, 88, 93, 94, 95, 96, 97, 100, 101, 102, 110, 113, 117, 120, 121, 123, 125, 126, 127, 129, 133, 135, 136, 142, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 156, 158, 159, 161, 162, 163], "mean1000": 162, "mean100000": 162, "mean100000b": 162, "mean100000c": 162, "mean1000b": 162, "mean1000c": 162, "mean16000": 162, "mean16000b": 162, "mean16000c": 162, "mean4000": 162, "mean4000b": 162, "mean4000c": 162, "mean_": 123, "mean_68cr": 38, "mean_absolute_error": 133, "mean_dist": 42, "mean_k": 65, "mean_posterior": 42, "mean_predict": 80, "mean_squared_error": 133, "meaning": [43, 46, 69, 111, 119], "means_arrai": 33, "meant": 64, "meanwhil": 9, "measur": [4, 7, 8, 16, 23, 25, 34, 37, 38, 39, 40, 41, 43, 46, 49, 51, 53, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 79, 96, 97, 102, 110, 113, 119, 120, 121, 123, 124, 126, 133, 135, 143, 147, 152, 156, 161], "mechan": [4, 16, 22, 23, 34, 43, 47, 62, 64, 67, 71, 101, 124, 128, 137, 145, 156, 159, 162], "medal": 77, "media": 1, "median": [9, 17, 18, 25, 30, 43, 126], "medic": [20, 63, 130], "medicin": [48, 64, 67, 126], "mediev": 7, "mediocr": 48, "medium": 132, "meet": [56, 63, 136], "mehta": [1, 66], "mel": 47, "melendez": [1, 56, 78], "member": [22, 51, 63, 143], "memor": 117, "memori": [67, 71, 133, 136], "men": [77, 130], "meng": 1, "mention": [8, 39, 43, 48, 51, 66, 67, 73, 97, 147, 152], "menu": 137, "mere": [47, 119], "merg": 7, "merger": 56, "merit": [8, 53], "mermim": 128, "mermin": 128, "merriam": 110, "mesh": [5, 9, 30, 47, 130], "meshgrid": [37, 50, 70, 78, 82, 130], "messag": [78, 123, 134, 137], "messeng": 62, "met": 43, "meta": 19, "metadata": [43, 126], "meterologist": 156, "method": [1, 4, 5, 7, 8, 16, 17, 19, 25, 34, 38, 39, 43, 47, 48, 50, 51, 56, 58, 60, 61, 62, 63, 64, 65, 66, 67, 72, 73, 77, 83, 88, 89, 92, 93, 95, 97, 100, 105, 107, 110, 112, 113, 116, 117, 122, 123, 124, 125, 127, 130, 133, 134, 136, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 156, 160, 161, 162, 163], "methodologi": 46, "metr": 8, "metric": [46, 63, 65, 66, 69, 76, 97, 100, 110, 130, 133, 135], "metropoli": [44, 50, 51, 143, 146, 148, 151, 160], "metropolis_poisson_exampl": [154, 159], "metropolis_r": [145, 162], "metzen": [80, 81], "mev": [47, 78, 82, 133], "mew": [77, 83], "mg": [115, 121], "mgl": 149, "mgrid": [34, 65, 73, 93], "mh": [51, 146, 148, 151], "mi": [43, 46], "michael": [1, 46, 75], "michigan": 56, "micro": [4, 133], "micron": 51, "microst": 4, "mid": [9, 30, 31, 32, 33, 37, 38, 40, 41, 49, 62, 78, 95, 120, 143], "middl": [12, 56, 130], "might": [3, 4, 7, 8, 19, 21, 23, 25, 29, 31, 34, 38, 39, 40, 41, 43, 44, 45, 46, 48, 51, 52, 53, 56, 60, 62, 63, 64, 65, 66, 67, 71, 73, 81, 85, 92, 94, 95, 96, 100, 105, 110, 111, 125, 127, 130, 132, 134, 135, 136, 137, 143, 144, 147, 151, 152, 153, 154, 156, 161], "mild": 65, "mill": [58, 127], "millimet": 51, "million": [7, 63, 133], "mimic": [67, 88], "min": [4, 7, 9, 34, 41, 42, 44, 49, 51, 53, 70, 77, 78, 82, 95, 96, 100, 113, 132, 133, 134, 136, 138, 148, 153, 156, 161], "min68": 130, "min90": 130, "min_": 127, "min_height": [9, 132], "min_obj": 92, "min_param": 123, "min_theta": [147, 152], "min_val": 92, "min_x": 92, "mina": 163, "mind": [9, 25, 30, 40, 43, 44, 63, 64, 117, 147, 152], "mine": 1, "minfunc": [40, 41], "mini": [49, 66, 68, 97, 163], "minibatch": [73, 93], "minibatch_i": 73, "minibatch_x": 73, "miniconda": 137, "miniconda3": [50, 81, 96, 126, 152], "minim": [8, 11, 22, 29, 34, 38, 40, 41, 47, 49, 51, 62, 65, 66, 67, 68, 69, 71, 72, 91, 92, 97, 100, 101, 105, 116, 117, 123, 127, 154, 159], "minima": [73, 88, 97, 104, 105], "minimum": [4, 5, 7, 9, 34, 39, 42, 51, 65, 69, 78, 92, 97, 100, 104, 105, 106, 123, 129, 132, 147, 152, 154, 156], "minka": 95, "minor": [5, 35, 135], "minu": [19, 29, 40, 41, 44, 72, 148], "minut": [38, 53, 77, 79, 123, 144, 161], "mirror": [51, 156], "misclassif": [63, 66], "misclassifi": [65, 66], "misconcept": 56, "miser": 7, "misfit": 43, "misinterpret": 53, "mislead": [43, 48], "mismatch": [16, 34, 53, 118], "miss": [25, 43, 44, 46, 63, 110, 119, 153], "misspel": 134, "mistak": 7, "misus": 43, "mit": [1, 153], "mith": 136, "mitig": [45, 63], "mix": [44, 51, 54, 55, 66, 67, 143, 146, 151], "mixtur": [38, 50, 72], "mkdir": 133, "mkl": 34, "ml": [60, 63, 73, 77, 83, 88, 89, 97, 127], "mle": [38, 41, 51, 52, 72, 88, 125, 127], "mlmodel": [64, 65], "mloutput": [64, 65, 66], "mloutput_": 65, "mloutput_i": 65, "mltestoutput": [65, 66], "mm": 156, "mnemon": [0, 22], "mnist": 69, "mock": 121, "mod": [0, 136], "modal": [51, 163], "mode": [0, 9, 17, 18, 25, 29, 30, 34, 40, 41, 42, 46, 47, 50, 51, 53, 56, 67, 71, 96, 126, 134, 143, 153, 159], "model": [0, 1, 4, 8, 19, 20, 23, 24, 28, 35, 39, 44, 46, 47, 50, 51, 52, 55, 58, 59, 60, 61, 62, 63, 65, 70, 71, 79, 80, 81, 88, 90, 91, 92, 96, 97, 101, 102, 104, 105, 106, 109, 113, 117, 120, 122, 124, 125, 127, 129, 130, 133, 144, 145, 146, 147, 152, 153, 154, 156, 158, 162], "model_func": 96, "model_height": 123, "model_i": 96, "model_param_bound": 123, "model_select": [73, 74, 93, 133], "model_typ": [34, 92, 102], "modeldiscrep": 123, "modeloutput": [34, 98, 99], "modeloutput_i": 34, "moder": 48, "modern": [1, 7, 51, 64, 88, 136, 143], "modif": [43, 51, 53, 72, 95, 144], "modifi": [10, 25, 30, 34, 37, 38, 40, 41, 42, 50, 51, 56, 63, 66, 67, 68, 70, 71, 72, 77, 83, 93, 95, 96, 100, 107, 123, 131, 134, 135, 144, 151], "modul": [6, 8, 50, 69, 70, 71, 73, 81, 93, 96, 123, 129, 130, 134, 136, 137, 140, 147, 152, 156, 161], "modulenotfounderror": [69, 70, 73, 93, 134], "modulu": 7, "molecular": 44, "mom": [44, 104], "mom_": 44, "mom_i": 44, "moment": [67, 71, 107, 161], "momenta": 148, "momentum": [44, 67, 107, 148, 149], "monetari": 43, "monitor": [43, 44, 62, 66, 67, 69, 71, 97, 146, 159], "monk": 53, "monoton": [4, 67, 107, 159], "mont": [1, 7, 16, 43, 64, 72, 96, 123, 145, 147, 151, 152, 157, 159, 160, 161, 162, 163], "montepython": 44, "monthli": 1, "monti": 16, "moo": 62, "mor": 47, "moral": 159, "more": [0, 3, 4, 7, 8, 9, 11, 13, 15, 16, 17, 18, 19, 20, 23, 24, 28, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 79, 81, 82, 83, 85, 89, 91, 93, 94, 95, 96, 97, 99, 102, 103, 104, 106, 110, 112, 116, 117, 119, 121, 123, 127, 128, 130, 131, 133, 134, 135, 136, 137, 141, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 156, 158, 159, 160, 161], "more_replac": [73, 93], "moreov": [16, 43, 48, 63, 73, 75, 111, 119], "morn": 8, "morten": 56, "most": [4, 8, 11, 12, 16, 18, 19, 25, 33, 34, 37, 40, 41, 43, 44, 46, 48, 49, 50, 53, 56, 57, 58, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 76, 85, 86, 88, 93, 95, 96, 97, 105, 111, 113, 117, 125, 126, 127, 128, 130, 133, 134, 136, 143, 147, 148, 151, 152, 153, 161], "mostli": [34, 38, 68, 73, 99, 110, 156], "mot": 44, "motion": [16, 115, 121, 123, 148, 150, 161], "motiv": [7, 16, 19, 38, 44, 48, 60, 65, 73, 88, 117, 148, 153, 158], "mount": 51, "move": [4, 9, 15, 25, 42, 44, 48, 50, 67, 68, 71, 88, 105, 132, 134, 143, 144, 146, 151, 156, 163], "movement": 144, "moviewrit": 126, "mp4": 126, "mpc": [0, 7, 41], "mpl": [126, 133], "mpl_toolkit": [37, 50, 65], "mplot3d": [37, 50, 65], "mr": 53, "mr_k": 65, "mrg_randomstream": 73, "mse": [65, 66, 67, 71, 100], "mseloss": 71, "msg": 134, "mu": [4, 5, 7, 17, 19, 24, 33, 34, 35, 37, 39, 41, 44, 46, 52, 53, 72, 77, 78, 79, 82, 83, 85, 86, 92, 126, 127, 129, 130, 144, 145, 147, 150, 151, 152, 154, 158, 161, 162, 163], "mu0": 50, "mu1": [34, 50], "mu2": [17, 50, 126], "mu_": [53, 130, 158], "mu_0": [5, 39, 52, 53, 147, 152], "mu_est": [39, 147, 152], "mu_i": [4, 78, 82, 86, 161], "mu_interval__": 152, "mu_j": 4, "mu_k": 4, "mu_mean_prior": 151, "mu_new": 82, "mu_opt": 82, "mu_prior": 151, "mu_sampl": 92, "mu_sample_opt": 92, "mu_sd_prior": 151, "mu_tru": [35, 39, 147, 152], "mu_x": [78, 86], "mu_z": [67, 82], "much": [8, 12, 17, 25, 29, 31, 34, 35, 38, 43, 44, 45, 46, 47, 51, 52, 53, 56, 60, 62, 63, 64, 65, 66, 67, 68, 73, 93, 94, 95, 97, 102, 106, 112, 127, 130, 133, 134, 135, 142, 144, 147, 152, 153, 154, 161], "multi": [16, 26, 46, 50, 55, 59, 71, 73, 88, 91, 93, 95, 96, 136, 153, 161, 163], "multi_class": 70, "multiclass": [63, 88], "multidimension": [17, 34, 51, 67, 79, 95, 122, 133, 136, 148, 154], "multilay": [67, 71], "multimod": [18, 19, 51, 73, 96, 130, 148, 153, 154, 163], "multinest": [1, 51, 153], "multinomi": 88, "multipl": [1, 11, 16, 33, 34, 37, 39, 42, 43, 44, 46, 47, 51, 52, 55, 61, 64, 66, 67, 68, 71, 72, 79, 88, 95, 124, 125, 126, 127, 143, 146, 147, 151, 152, 153, 154, 161, 163], "multipli": [4, 5, 32, 33, 34, 38, 40, 41, 47, 49, 53, 67, 72, 77, 79, 83, 85, 127, 136, 138, 143, 146], "multiprocess": [123, 151, 152], "multivari": [4, 7, 43, 44, 49, 64, 79, 85, 151, 153, 154, 161], "multivariate_norm": [34, 65, 69, 77, 78, 82, 83, 92, 127, 130], "multivariatenormalpropos": 151, "multivers": 130, "mumv": 82, "mup": 50, "mus2": 5, "mus3": 5, "mus4": 5, "mus5": 5, "must": [4, 5, 7, 8, 16, 19, 25, 33, 34, 37, 38, 43, 44, 45, 48, 53, 58, 62, 63, 64, 65, 67, 78, 85, 92, 96, 104, 106, 121, 123, 127, 130, 135, 136, 147, 152, 153, 154, 156, 159, 161], "mutat": 88, "mutual": [22, 23, 31, 32, 66, 76], "muvec": [78, 86], "muz": 82, "mvec": 86, "mvec_1": [79, 86], "mvec_2": 86, "mvn": 82, "mx": [40, 41, 143], "my": [0, 9, 30, 73, 137, 144], "my_ax": [129, 134], "my_bin": 33, "my_fig": [129, 134], "my_funct": [132, 134, 138], "my_metropolis_model": 151, "my_model": 151, "my_mu": 129, "my_multinorm_rv": 130, "my_norm_rv": 130, "my_normal_rv": 130, "my_nuts_model": 151, "my_output": 129, "my_rv": 130, "my_sigma": 129, "my_student_t_rv": 130, "my_suptitl": 17, "my_titl": [77, 151], "mymodel": 71, "myst": 0, "myst_nb": [3, 7, 65, 88, 130, 153, 156, 161], "mysteri": 128, "m\u00e4rten": 1, "n": [1, 3, 4, 7, 8, 9, 11, 13, 15, 17, 19, 24, 25, 29, 30, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 51, 53, 63, 65, 66, 67, 68, 72, 73, 77, 78, 79, 81, 82, 83, 88, 92, 95, 96, 97, 99, 102, 105, 107, 112, 117, 120, 123, 125, 126, 127, 130, 133, 135, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 156, 158, 161, 162], "n_": [29, 42, 44, 45, 47, 51, 64, 66, 67, 71, 75, 78, 82, 106, 117, 159], "n_0": [35, 37, 67], "n_1": [79, 86], "n_2": [79, 86], "n_a": 8, "n_activ": 123, "n_active_mltpl": 123, "n_b": 47, "n_col": 82, "n_color": 126, "n_d": [34, 100, 102, 106, 113], "n_dim": [49, 123], "n_eff": 123, "n_effect": 123, "n_effective_mltpl": 123, "n_epoch": 106, "n_evid": 123, "n_featur": 74, "n_gamma": 126, "n_h": 47, "n_hidden": [73, 93], "n_i": [4, 135], "n_in": 71, "n_job": 70, "n_k": [35, 37, 65], "n_l": 67, "n_max": 42, "n_max_step": 123, "n_max_valu": 42, "n_mean": 33, "n_means_arrai": 33, "n_new": 82, "n_p": [34, 99, 100, 102, 107], "n_prior": 123, "n_pt": [33, 37, 143, 145, 162], "n_restart": 92, "n_restarts_optim": [80, 82], "n_row": 82, "n_sampl": [73, 74, 81, 129], "n_step": 123, "n_steps_mltpl": 123, "n_total": 123, "n_trials_max": 9, "n_trials_max_w": 9, "n_uncertainty_digit": 130, "n_val": 33, "n_w": 9, "nabla": [34, 79, 96, 97, 100, 105, 106], "nabla_": 34, "naimi": [1, 133], "naiv": [7, 43, 53, 88], "name": [0, 4, 7, 10, 17, 23, 25, 34, 39, 41, 42, 44, 49, 51, 53, 63, 64, 67, 68, 69, 70, 73, 75, 76, 77, 79, 83, 91, 93, 94, 95, 96, 102, 104, 123, 125, 127, 130, 133, 134, 136, 137, 138, 144, 146, 147, 151, 152, 154], "namespac": 134, "nan": [38, 136], "narrow": [7, 9, 11, 12, 15, 25, 29, 30, 38, 41, 53, 73, 93, 121, 153], "nasti": [9, 30], "nat": 1, "nation": 63, "nativ": 63, "natur": [1, 7, 8, 16, 25, 34, 37, 38, 42, 43, 44, 47, 49, 52, 53, 60, 62, 64, 67, 69, 71, 72, 73, 80, 86, 96, 110, 117, 120, 130, 136, 149], "navier": 67, "navig": [105, 107], "nb": 47, "nbin": 41, "nbsp": 70, "nburn": [6, 38, 96, 123, 147, 152], "nburnin": [50, 96], "nbviewer": 70, "nc": 56, "nchain": 143, "ncol": [3, 25, 30, 33, 39, 78, 82, 88, 93, 95, 130, 134, 144, 152, 153, 161], "ncore": 123, "ncorr": 6, "ncross": 95, "ncsm": [78, 82], "nd": [34, 102], "ndarrai": [42, 82, 123], "ndata": [34, 96, 102], "ndiffer": 151, "ndim": [6, 17, 38, 41, 50, 96, 123, 143, 146, 147, 152], "ndimens": 94, "ndoubl": [25, 30], "neal": [44, 148], "nearbi": [19, 44], "nearest": 136, "nearli": [34, 121, 127], "neat": 133, "necess": [8, 39, 147, 152, 154], "necessari": [4, 16, 42, 53, 69, 71, 93, 130, 133, 137, 142], "necessarili": [0, 8, 21, 23, 25, 34, 39, 43, 46, 64, 66, 100, 130, 137, 144, 147, 152], "necessit": [148, 154], "need": [6, 7, 17, 19, 22, 25, 31, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 56, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 79, 85, 86, 88, 90, 92, 93, 94, 95, 96, 97, 100, 104, 110, 115, 119, 122, 123, 126, 127, 130, 131, 132, 133, 134, 136, 137, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 156, 158, 159, 161, 162], "needless": 56, "neg": [4, 19, 21, 31, 33, 34, 37, 40, 41, 44, 50, 63, 64, 65, 71, 72, 77, 83, 88, 92, 96, 105, 133, 156, 159], "negat": 44, "neglect": [16, 19, 29, 45, 53, 114, 115, 121], "neglig": [34, 41, 51, 52, 85, 115], "negri": 1, "neighbor": [11, 19, 42], "neighborhood": [47, 65], "neighbourhood": 53, "neil": [77, 83], "neither": [58, 67, 71, 146], "neq": [0, 4, 7, 22, 31, 32, 34, 53, 66, 72, 125, 130, 156, 159, 161], "nest": [0, 51, 52, 53, 67, 153, 154], "net": [66, 67, 71, 73, 93, 129], "netherland": 1, "network": [1, 45, 47, 60, 88, 89, 91, 105, 106, 116, 117, 129, 136], "neumann": 104, "neural": [1, 45, 47, 60, 88, 89, 91, 105, 106, 116, 117, 136], "neural_network": [73, 93], "neural_network_minibatch": 73, "neuralnet": 70, "neuron": [1, 68, 69, 70, 71, 72, 73, 74, 88, 93, 117, 129], "neutral": 133, "neutron": [1, 34, 79, 99, 133, 154], "never": [16, 34, 53, 66, 68, 77, 83, 101, 134], "nevertheless": [16, 39, 100, 147, 152], "new": [0, 7, 9, 10, 11, 13, 15, 16, 25, 34, 37, 38, 40, 43, 44, 46, 48, 49, 50, 51, 53, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 70, 71, 72, 73, 76, 77, 79, 82, 86, 88, 89, 93, 95, 117, 126, 127, 131, 133, 134, 135, 136, 137, 142, 143, 144, 145, 148, 150, 151, 153, 154, 156, 162, 163], "new_arr": 136, "new_data": 73, "new_data_button_w": 9, "new_hobbit": 133, "newarr": 136, "newaxi": [78, 82], "newcommand": [0, 9, 30, 40, 41, 42, 44, 49, 78, 95, 104, 127, 151], "newer": 51, "newli": [44, 134], "newton": [51, 114, 115], "newtonian": [16, 51], "next": [8, 9, 11, 16, 25, 30, 31, 34, 37, 39, 40, 41, 43, 47, 48, 51, 63, 64, 69, 75, 80, 92, 100, 102, 107, 117, 126, 133, 134, 136, 137, 143, 144, 145, 147, 151, 152, 156, 159, 162], "next_button_w": 9, "nfev": 123, "nframe": 126, "nh": 85, "ni": 46, "nice": [38, 48, 69, 95, 121, 144, 147, 152], "nicer": [17, 33, 38, 39, 133, 144, 145, 147, 152], "nicola": [77, 83], "niel": 25, "nielsen": 75, "nifti": 7, "nine": [77, 83, 153], "nist": 63, "nit": 123, "niter": [50, 96], "nk_pt": 37, "nll": 123, "nlp": 123, "nm": [67, 79], "nm_n": 133, "nmap": 123, "nmax": [42, 78, 82], "nmaximum": 123, "nn": [65, 71, 85, 129], "nnloopt": [78, 82], "no_grad": [71, 129], "no_of_chain": [50, 143], "no_of_head": [25, 30], "no_of_sampl": 144, "no_of_tail": [25, 30], "nobel": 67, "node": [67, 68, 69, 73, 93], "nois": [3, 7, 19, 29, 38, 40, 41, 49, 63, 66, 70, 72, 73, 77, 78, 79, 82, 83, 85, 86, 90, 92, 94, 95, 96, 123, 127, 142, 143, 152, 158], "noise_std": 80, "noise_var": 79, "noisi": [65, 66, 71, 88, 90, 91, 92, 95, 96, 97, 123], "nomin": [4, 144], "non": [6, 11, 23, 24, 29, 31, 33, 34, 37, 38, 40, 43, 45, 46, 47, 48, 63, 65, 66, 67, 69, 70, 71, 72, 73, 75, 76, 82, 88, 89, 93, 96, 100, 101, 102, 113, 116, 117, 127, 130, 133, 136, 146, 156], "nonconvex": 104, "none": [4, 6, 17, 29, 33, 34, 37, 41, 42, 49, 50, 65, 69, 70, 76, 77, 78, 80, 82, 83, 92, 96, 102, 123, 126, 127, 129, 133, 143, 144, 147, 149, 152], "nonetheless": 63, "noninform": [39, 147, 152], "nonlinear": [34, 53, 67, 71, 102, 153], "nonlinearli": 47, "nonloc": 51, "nonneg": 66, "nonparametr": [78, 82, 86], "nonsens": [125, 130], "nonsequenti": 136, "nonstandard": 153, "nonstationari": 121, "nontreiv": 148, "nonumb": [48, 88], "nonzero": [19, 67, 136, 159], "nor": [8, 58, 64, 67, 71, 90], "norm": [5, 6, 9, 17, 25, 29, 30, 33, 34, 37, 39, 45, 49, 50, 65, 66, 73, 82, 92, 95, 100, 101, 126, 127, 130, 143, 144, 147, 151, 152], "norm1": 50, "norm1_dist": 17, "norm2": 50, "norm2_dist": [17, 126], "norm_dist": [17, 126], "norm_label": [17, 126], "norm_loc": 126, "norm_pt": 126, "norm_sampl": 17, "norm_scaled_v": 126, "norm_x_pt": 33, "norm_y_pt": 33, "normal": [0, 7, 10, 13, 15, 16, 18, 19, 23, 24, 26, 30, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 48, 49, 50, 51, 52, 66, 67, 69, 70, 72, 73, 76, 77, 79, 80, 83, 88, 92, 93, 95, 96, 97, 101, 102, 104, 110, 115, 123, 126, 127, 129, 130, 143, 144, 145, 147, 148, 151, 152, 153, 154, 156, 158, 159, 161, 162], "normal_": [71, 129], "normal_distribut": 34, "normaliz": 19, "normalize_i": 82, "normalized_posterior_funct": 144, "normalpropos": 151, "normp": 50, "northpoint": 63, "northwestern": 56, "notabl": 121, "notag": 47, "notat": [13, 16, 17, 20, 21, 23, 24, 31, 32, 34, 35, 37, 38, 42, 47, 48, 49, 65, 66, 68, 72, 89, 101, 102, 104, 107, 117, 123, 144, 145, 153, 156, 158, 162], "note": [1, 3, 4, 5, 7, 8, 9, 11, 13, 16, 17, 18, 19, 22, 23, 25, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 56, 63, 64, 65, 66, 67, 68, 72, 73, 75, 76, 77, 79, 80, 82, 83, 85, 86, 88, 90, 92, 93, 94, 95, 96, 97, 99, 100, 102, 105, 106, 110, 111, 112, 113, 123, 125, 126, 127, 130, 132, 133, 134, 135, 136, 137, 142, 143, 144, 145, 146, 147, 148, 151, 152, 153, 156, 158, 159, 161, 162], "notebook": [5, 9, 11, 14, 16, 17, 23, 26, 27, 31, 33, 34, 35, 37, 39, 41, 49, 50, 52, 55, 56, 70, 71, 72, 73, 76, 86, 89, 90, 92, 93, 94, 95, 96, 102, 121, 123, 124, 125, 129, 131, 132, 135, 136, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 154, 159, 162, 163], "noth": [3, 8, 19, 34, 35, 43, 47, 66, 67, 73, 93], "notic": [1, 4, 23, 39, 53, 68, 72, 78, 79, 82, 85, 88, 147, 152, 154, 159], "notin": [46, 130], "notion": [8, 9, 25, 30, 43], "notori": [44, 64, 135], "novel": 66, "novemb": [5, 77], "now": [0, 3, 4, 5, 7, 9, 15, 16, 17, 19, 21, 23, 25, 29, 30, 31, 33, 34, 35, 37, 38, 40, 41, 42, 46, 48, 49, 52, 53, 59, 63, 64, 65, 66, 67, 68, 73, 77, 78, 80, 82, 83, 85, 86, 88, 92, 93, 94, 96, 101, 102, 127, 129, 132, 133, 134, 135, 136, 137, 143, 144, 146, 147, 148, 149, 150, 151, 153, 154, 156], "nowadai": [8, 64, 153], "np": [0, 3, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 48, 49, 50, 65, 69, 70, 71, 73, 76, 77, 78, 79, 80, 81, 82, 83, 88, 92, 93, 94, 95, 96, 102, 106, 123, 126, 127, 129, 130, 132, 133, 134, 135, 136, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 156, 159, 161, 162], "np_random_numb": 130, "npl": 51, "nprop": [50, 96], "npropos": 144, "npy": [73, 93], "nrow": [3, 25, 30, 33, 39, 78, 81, 82, 88, 93, 95, 130, 134, 152, 153, 161], "nsampl": [17, 77, 79, 83, 94, 162], "nstep": [6, 38, 41, 50, 96, 123, 143, 147, 152], "nswap": [50, 96], "nswap_accept": [50, 96], "nt": 50, "ntemp": [50, 96], "ntemper": 50, "ntemps_hi": [50, 96], "ntemps_lo": [50, 96], "ntest": 69, "nthin": [50, 96], "nthread": [50, 96], "ntk": 117, "nu": [17, 29, 44, 81, 85, 126, 130], "nu1": 17, "nu2": 17, "nu3": 17, "nuclear": [1, 44, 46, 47, 48, 79, 91, 92, 126, 154], "nucleartal": [137, 140], "nuclei": [47, 79, 133], "nucleon": [1, 45, 126, 133], "nucleu": [47, 79, 133, 154], "nugget": [78, 79, 82, 86], "nuisanc": [17, 23, 25, 35, 96, 146, 159], "null": [11, 19, 53, 133], "num": [29, 41, 80, 81, 88, 132, 135, 153, 161], "num_bin": [17, 126, 151], "num_burn": 123, "num_coin_toss": 30, "num_col": [69, 76], "num_cor": 123, "num_data": 95, "num_data_per_class": 65, "num_draw": 33, "num_imag": [69, 76], "num_it": 143, "num_mean": 65, "num_model_param": 123, "num_param": 123, "num_plot": 95, "num_pt": [17, 42], "num_row": [33, 69, 76], "num_run": 161, "num_sampl": [17, 42, 78, 82, 149, 151, 153], "num_step": [123, 145, 162], "num_t": [132, 149], "num_t_pt": 150, "num_t_w": 132, "num_walker_per_dim": 123, "num_x_pt": 49, "number": [4, 6, 8, 9, 11, 16, 18, 19, 23, 25, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 83, 86, 88, 90, 91, 93, 94, 95, 96, 97, 99, 100, 102, 105, 106, 107, 110, 117, 123, 124, 125, 126, 127, 129, 132, 133, 134, 135, 136, 137, 142, 143, 144, 145, 147, 148, 151, 152, 153, 156, 159, 161, 162], "numer": [0, 7, 8, 16, 29, 34, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 65, 67, 72, 77, 79, 83, 85, 86, 90, 94, 95, 96, 101, 105, 106, 125, 127, 130, 133, 143, 144, 156], "numpeak": [90, 96], "numpi": [0, 3, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 50, 65, 69, 70, 71, 73, 76, 77, 78, 80, 81, 82, 83, 88, 92, 93, 95, 96, 102, 123, 126, 127, 129, 130, 132, 133, 137, 138, 143, 144, 145, 147, 149, 150, 151, 152, 153, 156, 161, 162], "numpt": 130, "numref": 0, "nut": [44, 73, 148, 151, 152, 154], "nwalker": [6, 38, 41, 50, 96, 123, 143, 146, 147, 152], "nwarmup": [38, 41, 50, 143], "nwe": 96, "nx": 49, "nx_iy_i": 127, "nz": 133, "o": [1, 3, 19, 34, 38, 40, 41, 49, 67, 69, 77, 78, 82, 95, 102, 117, 119, 123, 126, 130, 133, 143, 144, 145, 151, 156, 161, 162], "o1": 150, "ob": [7, 25, 30, 34, 151], "obei": [8, 13], "object": [6, 8, 9, 16, 17, 23, 30, 38, 43, 48, 50, 53, 71, 72, 73, 77, 78, 83, 92, 93, 96, 104, 105, 120, 126, 130, 132, 133, 134, 135, 136, 138, 149], "oblig": 53, "observ": [0, 1, 3, 4, 7, 9, 10, 11, 12, 16, 19, 23, 25, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 53, 58, 60, 61, 62, 63, 64, 65, 66, 67, 71, 73, 75, 77, 80, 81, 83, 85, 86, 92, 93, 96, 100, 105, 110, 111, 115, 117, 119, 120, 121, 124, 126, 127, 130, 142, 144, 145, 146, 147, 151, 152, 154, 156, 158, 161, 162], "observed_data": 151, "obtain": [4, 7, 8, 9, 14, 16, 23, 25, 30, 34, 35, 41, 43, 44, 45, 47, 48, 58, 59, 63, 65, 66, 67, 68, 71, 72, 76, 77, 82, 83, 86, 88, 92, 97, 100, 120, 121, 125, 130, 144, 145, 146, 150, 151, 153, 154, 161, 162, 163], "obviou": [16, 19, 34, 65, 156], "obvious": [4, 7, 8, 16, 25, 33, 34, 45, 66, 72, 73, 85, 88, 94], "occam": [51, 52, 53], "occasion": [56, 137, 156], "occupi": [4, 148], "occur": [8, 22, 25, 56, 63, 65, 88, 130, 133, 156], "occurr": 8, "ockham": [7, 53, 90], "oct": [78, 151], "octob": 1, "od": [148, 149, 150], "odd": [24, 25, 34, 53, 88, 133], "odds_ratio": 95, "odeint": 123, "odot": [45, 66, 72], "ofeffect": 91, "off": [7, 9, 17, 33, 35, 42, 48, 49, 51, 52, 53, 73, 92, 93, 127, 130, 133, 148, 151, 161], "offenc": 63, "offend": 63, "offer": [7, 41, 44, 46, 71, 113, 117, 134, 136, 151], "offici": 151, "offlin": [45, 47], "offset": [38, 41, 51, 53, 123, 133, 143], "often": [3, 4, 7, 13, 15, 16, 18, 19, 23, 29, 34, 38, 39, 40, 41, 43, 44, 45, 46, 47, 53, 55, 58, 60, 62, 63, 64, 65, 66, 67, 68, 71, 73, 85, 86, 88, 95, 97, 100, 102, 104, 105, 106, 110, 111, 119, 122, 124, 126, 130, 134, 135, 136, 143, 144, 146, 147, 152, 153, 154, 159, 161], "ohio": [21, 56], "oin": 9, "ok": [0, 22, 37, 42, 96, 127, 134, 151, 154, 159], "okai": 19, "ol": [34, 65, 66, 102, 159], "old": 153, "older": [38, 134], "oliv": 56, "ols_cov": [34, 65, 102], "ols_d": [34, 102], "ols_ep": [34, 102], "ols_s2": [34, 102], "ols_theta": [34, 65, 102], "ols_xtd": [34, 65, 102], "olymp": 77, "olympic_marathon_men": 77, "olympicmarathontim": 77, "omega": [16, 19, 33, 34, 132, 153], "omega_0": 149, "omega_i": 44, "omega_j": 44, "omega_pt": 33, "omega_w": 132, "omit": [16, 22, 24, 49, 53, 56, 73, 85, 117, 144], "on_click": 9, "onc": [4, 8, 9, 12, 15, 16, 22, 25, 30, 35, 37, 38, 40, 42, 43, 47, 48, 53, 59, 66, 67, 73, 85, 97, 134, 137, 153, 154, 161], "one": [0, 4, 5, 7, 8, 9, 11, 16, 17, 18, 19, 22, 23, 24, 25, 26, 29, 31, 32, 34, 35, 37, 38, 39, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 77, 78, 79, 80, 82, 83, 86, 88, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 104, 106, 107, 110, 111, 115, 117, 119, 120, 121, 125, 126, 127, 129, 130, 133, 134, 135, 136, 137, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 156, 158, 159, 161, 162, 163], "oned_arr": 136, "ones": [5, 19, 34, 37, 38, 43, 50, 53, 62, 65, 66, 67, 70, 73, 93, 95, 96, 102, 105, 117, 130, 133, 136, 153, 161], "ones_lik": [6, 38, 40, 96, 133, 136, 143], "onevariablenet": 71, "ongo": 8, "onli": [0, 4, 7, 8, 11, 15, 16, 17, 18, 19, 23, 24, 25, 29, 31, 34, 35, 37, 38, 40, 41, 43, 44, 47, 48, 49, 50, 51, 52, 53, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 72, 73, 75, 76, 79, 80, 81, 82, 85, 86, 88, 96, 97, 100, 102, 104, 105, 107, 115, 119, 121, 123, 127, 129, 130, 133, 135, 136, 143, 144, 146, 148, 151, 153, 156], "onlin": [1, 47, 64, 70, 71, 77, 83, 85, 134, 135, 151], "onto": [7, 45, 127, 153, 159], "onu": 53, "op": 126, "opac": 44, "open": [8, 16, 25, 43, 61, 64, 73, 122, 133, 134], "openli": 64, "oper": [7, 8, 25, 34, 44, 47, 62, 63, 64, 66, 67, 73, 75, 77, 79, 83, 99, 101, 133, 134, 138, 144], "operation": 66, "operatornam": [66, 85, 104], "opinion": [63, 159], "opportun": [44, 47, 53, 58, 64], "oppos": [19, 51, 116, 134], "opposit": [4, 8, 19, 37, 68, 97, 105], "opt_r": 81, "optic": 46, "optim": [1, 4, 5, 16, 34, 35, 38, 40, 41, 47, 51, 53, 65, 66, 67, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 82, 83, 85, 91, 93, 95, 99, 100, 106, 110, 116, 117, 119, 123, 127, 159, 163], "optima": 92, "optimis": [77, 83], "optimum": [7, 34, 41, 67, 77, 82, 92, 100, 109], "option": [9, 11, 25, 34, 38, 40, 47, 50, 52, 56, 67, 70, 71, 90, 94, 95, 96, 123, 131, 136, 137, 150, 151, 156, 158], "optpar": [44, 104, 109], "optpara": 44, "optpars_i": 44, "optparslr": 34, "opvi": 73, "oracl": 48, "orang": 80, "orbit": 110, "orbit_gam": 150, "order": [5, 7, 19, 34, 41, 43, 44, 46, 47, 49, 52, 53, 56, 58, 62, 66, 67, 68, 71, 72, 73, 79, 88, 94, 96, 97, 100, 101, 102, 115, 133, 134, 137, 148, 150, 156, 161], "ordinari": [47, 51, 53, 65, 66, 75, 88, 96, 148, 150], "ordinarili": 127, "org": [1, 17, 40, 50, 69, 70, 76, 81, 93, 96, 104, 130, 148, 154], "organ": [9, 63, 67, 132, 136, 161], "orient": [35, 50, 53, 63, 132, 143], "origin": [4, 16, 26, 33, 38, 42, 43, 44, 46, 47, 48, 50, 51, 53, 56, 63, 65, 66, 72, 73, 75, 77, 79, 88, 91, 93, 96, 127, 136, 143, 144, 151, 153, 163], "orthogon": [22, 45, 47, 53, 125, 127, 146], "orthonorm": [22, 31, 32, 47, 125], "oscil": [47, 51], "oslo": 56, "osu": [0, 78, 132, 137, 149, 151], "osx": 137, "other": [1, 4, 7, 8, 9, 10, 12, 13, 16, 17, 18, 19, 21, 23, 25, 27, 30, 31, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 56, 63, 64, 65, 66, 67, 68, 69, 71, 73, 75, 77, 78, 79, 82, 83, 86, 88, 92, 93, 94, 97, 100, 102, 105, 106, 110, 113, 117, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 143, 144, 145, 147, 148, 150, 151, 152, 153, 154, 156, 158, 160, 161, 162], "otherwis": [7, 8, 25, 30, 38, 41, 42, 44, 47, 53, 71, 81, 86, 88, 92, 95, 119, 130, 134, 145, 153, 156, 162], "ouput": 68, "our": [0, 4, 7, 8, 9, 10, 11, 13, 16, 17, 19, 21, 22, 23, 25, 27, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 71, 73, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 89, 93, 94, 95, 96, 97, 99, 100, 101, 102, 110, 113, 119, 121, 123, 127, 130, 136, 138, 143, 144, 145, 146, 147, 148, 150, 151, 152, 154, 156, 159, 161, 162], "ourselv": [46, 66, 67, 82, 104, 110, 130, 133, 153], "out": [1, 4, 5, 7, 9, 13, 16, 17, 19, 23, 29, 30, 31, 32, 33, 34, 37, 38, 39, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 59, 60, 61, 62, 63, 66, 68, 71, 72, 73, 76, 77, 83, 86, 88, 93, 94, 95, 100, 101, 115, 121, 123, 127, 132, 133, 134, 136, 137, 142, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 161, 162], "out_featur": 71, "outcom": [8, 9, 11, 22, 23, 25, 30, 31, 43, 46, 53, 63, 88, 89, 110, 123, 130, 136, 153, 156, 158, 161], "outer": [0, 68], "outfil": 126, "outlier": [41, 55, 154], "outlin": [38, 41, 48, 107, 144, 153], "outperform": 47, "output": [0, 5, 9, 34, 41, 43, 45, 46, 47, 48, 58, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 85, 88, 89, 93, 96, 99, 101, 102, 109, 110, 117, 120, 130, 133, 134, 135, 136, 161], "output_": [65, 113], "output_1": 113, "output_2": 113, "output_i": [65, 66, 113], "outputlayer1": 67, "outputs_i": [64, 106], "outsid": [3, 19, 46, 53, 82, 95, 135, 144, 163], "outward": 19, "over": [0, 4, 7, 16, 17, 18, 19, 22, 23, 31, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 55, 56, 63, 64, 65, 68, 71, 72, 73, 76, 77, 78, 82, 83, 85, 86, 88, 89, 93, 95, 96, 106, 117, 120, 124, 125, 126, 127, 130, 133, 135, 137, 142, 143, 144, 146, 147, 152, 153, 154, 161, 163], "overal": [9, 13, 31, 33, 37, 47, 48, 63, 73, 94, 96, 120, 132], "overall_titl": [37, 149, 150], "overarch": [64, 72], "overbrac": [9, 10, 23, 30], "overcom": 67, "overconfid": 121, "overestim": [66, 143], "overfit": [16, 29, 64, 65, 66, 67, 69, 71, 72, 73, 75, 94, 95, 97, 113], "overflow": 134, "overhead": 68, "overlai": 17, "overlaid": 129, "overlap": [7, 22, 44, 63, 66, 70, 76, 144, 159], "overli": [16, 38, 60], "overlin": [31, 42, 94, 143, 146, 154], "overlook": 63, "overrepres": 63, "overset": [13, 15, 19, 32, 86, 142], "overshoot": 106, "oversight": 63, "overview": [9, 16, 27, 28, 45, 56, 75, 89, 132, 137], "overview_text": [9, 132], "overweight": 63, "overwhelm": 53, "ow": 64, "own": [0, 4, 11, 22, 33, 37, 43, 56, 63, 64, 66, 69, 94, 127, 131, 133, 134, 139, 143, 161, 162], "oxford": [1, 56], "o\u02bchagan": 119, "p": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 13, 15, 16, 17, 23, 24, 25, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 63, 65, 66, 67, 70, 72, 73, 77, 78, 79, 82, 83, 85, 86, 88, 93, 95, 96, 99, 100, 102, 104, 113, 117, 125, 126, 127, 130, 132, 133, 142, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 156, 158, 161, 162, 163], "p0": [50, 96, 143, 146], "p1": [40, 41, 149], "p2": 40, "p2cread": 126, "p2cwrite": 126, "p_": [7, 15, 19, 48, 51, 72, 88, 130, 149, 156, 161], "p_0": 149, "p_1": [4, 15, 16], "p_2": [4, 15], "p_3": 4, "p_4": 4, "p_accept": 144, "p_current": 144, "p_h": [9, 11, 12, 13, 15, 19, 25, 30], "p_i": [3, 4, 16, 44, 148], "p_j": 4, "p_n": 15, "p_phi": 149, "p_phi_0": 149, "p_phi_now": 149, "p_phi_vs_time_label": 149, "p_propos": 144, "p_star": 95, "p_x": [25, 53, 130], "p_y": [53, 67], "p_z": [7, 67], "pa": 7, "pace": [77, 159], "pacif": 1, "pack": 133, "packag": [17, 23, 38, 41, 43, 50, 64, 73, 77, 81, 83, 93, 96, 123, 126, 130, 133, 134, 137, 146, 147, 152, 153], "pad": [70, 78, 95, 150], "page": [0, 1, 17, 23, 41, 56, 70, 77, 83, 84, 87, 94, 130, 133, 134, 137, 142, 146, 148, 153, 154], "pai": [22, 63, 67, 72], "painfulli": [105, 135], "painstak": 64, "pair": [34, 40, 43, 47, 48, 51, 78, 82, 95, 99, 127, 133, 135, 143, 146], "pairplot": 161, "palett": 134, "panda": [34, 102, 134, 143], "panel": [7, 25, 37, 41, 43, 56, 65, 72, 95, 97, 121, 130, 133, 144, 147, 152, 156, 161], "pankaj": 1, "papanicola": 5, "paper": [1, 34, 43, 44, 46, 49, 51, 61, 72, 86, 94, 95, 101, 126, 143], "par": [7, 16, 34, 35, 44, 45, 46, 47, 53, 64, 66, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 112, 113, 114, 117, 118, 120, 153], "para": [34, 43, 44, 130, 153], "para_": [66, 100, 107], "para_0": [99, 100, 101, 112, 114, 115], "para_1": [44, 47, 100, 101, 112, 114, 115, 153], "para_1f_1": [34, 100], "para_2": [44, 47, 100, 112, 114, 115, 153], "para_2f_2": 100, "para_3": 47, "para_i": [44, 45, 47, 107, 153], "para_j": [99, 100], "para_n": 47, "paradigm": [8, 16, 38, 43, 47, 64, 95, 119], "paradox": 128, "parallel": [21, 35, 50, 53, 56, 73, 90, 93, 117, 123, 148, 163], "paralr": 34, "paralr_": 34, "paralr_0": 34, "paralr_1": 34, "paralr_1f_1": 34, "paralr_2": 34, "paralr_2f_2": 34, "paralr_i": 34, "paralr_j": 34, "param": [34, 50, 69, 76, 82, 96, 102, 106, 123, 143], "param_bound": 123, "param_max": 123, "param_min": 123, "param_resc": 123, "paramet": [1, 3, 4, 6, 8, 9, 10, 11, 13, 17, 18, 19, 20, 23, 24, 25, 27, 29, 30, 34, 35, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 81, 82, 85, 86, 90, 91, 92, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 130, 131, 132, 133, 134, 136, 143, 144, 145, 146, 148, 149, 150, 151, 153, 154, 158, 159, 161, 162, 163], "parameter": [46, 72, 78, 82, 85, 117, 146], "parameter_estim": 163, "parameter_estimation_fitting_straight_line_i": [38, 41, 143], "parameter_estimation_fitting_straight_line_ii": 143, "parameter_estimation_gaussian_nois": 142, "parameter_estimation_gaussian_noise_compare_sampl": 163, "parameters_text": 132, "parametr": [8, 28, 44, 45, 47, 72, 73, 77, 78, 79, 82, 86, 116, 122, 133], "params_gradi": 106, "params_mod": 50, "params_rbf": 82, "paranmet": 106, "paraphras": 117, "parenthes": 125, "pars_": [45, 105, 107], "pars_0": 105, "pars_1": 47, "pars_2": 47, "pars_i": [7, 44, 45, 47, 153], "pars_j": [44, 47], "pars_n": [47, 105, 106, 107], "parsec": [7, 17], "parslr": 34, "parslr_1": 34, "parslr_2": 34, "part": [0, 16, 23, 27, 31, 32, 33, 34, 35, 41, 43, 45, 51, 56, 58, 59, 60, 62, 63, 64, 65, 71, 72, 73, 75, 77, 86, 90, 91, 94, 95, 100, 110, 111, 113, 124, 127, 133, 136, 142, 143, 148, 154, 156, 159], "parti": 21, "partial": [1, 3, 4, 7, 29, 34, 35, 39, 44, 53, 68, 88, 95, 97, 100, 105, 107, 125, 127, 147, 148, 149, 152], "particl": [0, 1, 17, 19, 21, 23, 117, 123, 126, 133, 148, 156, 161], "particulali": 56, "particular": [0, 3, 4, 7, 8, 9, 16, 22, 24, 25, 29, 30, 31, 34, 38, 39, 41, 42, 44, 46, 47, 48, 50, 51, 52, 53, 56, 59, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 77, 83, 85, 86, 88, 92, 94, 95, 97, 100, 104, 105, 110, 113, 116, 117, 120, 121, 122, 126, 130, 132, 133, 138, 145, 147, 152, 153, 154, 162], "particularli": [23, 24, 27, 38, 43, 51, 56, 62, 66, 71, 75, 119, 130, 134, 153, 154, 161], "partit": [5, 34, 85, 86, 130, 159], "partli": [43, 47, 53, 78, 82], "pass": [17, 23, 50, 67, 68, 71, 72, 75, 76, 78, 88, 96, 110, 117, 123, 126, 127, 129, 133, 134, 136, 146, 149, 151, 153, 156, 161], "pass_fd": 126, "passeng": 64, "past": [8, 9, 16, 17, 21, 24, 46, 53, 107, 135, 142, 156], "patent": 153, "path": [1, 48, 62, 70, 77, 83, 86, 123, 130, 133, 148, 156, 161], "patient": [56, 63, 88, 137], "pattern": [1, 16, 49, 51, 62, 64, 67, 71, 76, 89, 156], "pauciora": 53, "pauli": 133, "paus": 19, "pb": 1, "pc": 134, "pca": [79, 124], "pcg64": 130, "pcolor": 40, "pct": [37, 40, 41], "pd": [34, 102, 133, 143], "pd_d": [34, 102], "pd_design_matrix": [34, 102], "pd_m": [34, 102], "pd_m_ol": [34, 102], "pd_r": [34, 102], "pd_x": [34, 102], "pd_xmeasur": [34, 102], "pd_xrealiti": [34, 102], "pdf": [0, 1, 3, 9, 10, 11, 12, 13, 16, 19, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 42, 44, 46, 49, 53, 55, 72, 74, 78, 82, 85, 86, 92, 96, 123, 126, 147, 148, 151, 152, 154, 156, 158, 159, 160, 161], "pdf_1": [0, 7], "pdf_2": [0, 7], "pdf_2_grid": [0, 7], "pdf_3": [0, 7], "pdf_3_grid": [0, 7], "pdf_4": [0, 7], "pdfy": 130, "peacock": 163, "peak": [7, 9, 12, 19, 33, 34, 35, 37, 39, 41, 49, 50, 51, 52, 53, 67, 90, 91, 95, 96, 130, 146, 147, 148, 152], "pen": [0, 23, 34, 101], "penal": 53, "penalti": [51, 52, 53, 66, 70], "pendleton": 1, "pendulum": 51, "peopl": [0, 4, 19, 22, 31, 53, 56, 62, 63, 64, 77, 98, 143, 151, 153], "per": [29, 41, 47, 53, 58, 67, 71, 77, 80, 95, 123, 126, 129, 133, 142, 149, 161], "perceiv": [63, 64], "percent": [17, 25, 49, 130], "percentag": [18, 19, 76, 126, 127, 148, 151], "percentil": [38, 94, 96], "perceptron": [67, 71, 73, 93], "peregrin": 133, "perfect": [34, 40, 41, 44, 48, 59, 65, 79, 86, 133, 143], "perfectli": [39, 44, 143, 147, 151, 152], "perfom": [65, 67], "perform": [4, 7, 8, 16, 25, 30, 31, 34, 38, 41, 43, 44, 45, 46, 47, 48, 50, 51, 53, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 88, 92, 95, 97, 100, 102, 105, 106, 110, 111, 112, 119, 121, 125, 127, 130, 133, 134, 135, 136, 142, 143, 144, 146, 147, 152, 153, 156, 163], "perhap": [40, 62, 64], "perimet": 128, "period": [6, 34, 38, 44, 53, 77, 81, 83, 123, 145, 147, 152, 156, 162], "periodic_matern32": 77, "periodicexponenti": [77, 83], "periodicity_bound": 81, "perivolaropoulo": 51, "perm": [78, 82], "permeat": 72, "permiss": [44, 76, 121], "permit": [7, 43, 47, 53, 66], "permut": [78, 82, 88, 104], "persist": [43, 119], "person": [8, 9, 22, 30, 43, 63, 130], "perspect": [1, 8, 34, 47, 57, 59, 60, 61, 62, 77, 83, 86, 88, 89, 99, 110, 113], "persuad": 5, "pertain": [25, 30], "pertin": 68, "perturb": [58, 117], "pervers": 19, "pessimist": 38, "peter": 127, "petrov": 47, "petunin": 46, "pf": [7, 156], "ph": [25, 30], "phase": [43, 45, 47, 50, 51, 52, 67, 71, 96, 132, 148, 149], "phase_space_label": 149, "phd": 56, "phenomena": [7, 51, 122], "phenomenolog": [34, 48, 99], "phenomenon": [7, 40, 62, 110], "phi": [7, 51, 120, 123, 132, 149, 150, 153, 159], "phi_": [85, 150], "phi_0": [149, 150], "phi_and_p_high": 149, "phi_and_p_low": 149, "phi_i": 150, "phi_now": 149, "phi_pt": 150, "phi_pts_eul": 150, "phi_pts_lf": 150, "phi_vs_time_label": 149, "phi_w": 132, "phil": [1, 56], "phillip": [5, 56, 151], "philosoph": [7, 19, 20, 25, 39, 147, 152], "philosophi": [8, 39, 128, 147, 152], "phivec": [154, 159], "photon": 60, "phrase": 45, "phtrue": 30, "phy": [1, 5, 44, 49, 78, 82, 86], "physic": [0, 1, 4, 7, 16, 17, 19, 23, 34, 43, 46, 47, 48, 50, 51, 53, 56, 57, 59, 64, 65, 67, 72, 79, 88, 92, 94, 100, 102, 111, 117, 119, 121, 122, 126, 127, 128, 130, 133, 145, 153, 154, 159, 161, 162], "physicist": [1, 8, 17, 23, 27, 29, 53, 56, 57, 59, 60, 62, 67, 117, 126], "physrep": 1, "physrevc": 1, "physrevlett": 1, "pi": [4, 7, 19, 24, 33, 34, 37, 38, 39, 40, 41, 42, 44, 49, 50, 52, 53, 67, 70, 72, 77, 78, 83, 86, 92, 94, 95, 96, 102, 114, 123, 129, 130, 132, 134, 135, 143, 144, 146, 147, 150, 152, 156], "pi_": 156, "pi_1": 156, "pi_2": 156, "pi_3": 156, "pi_i": [153, 156], "pi_j": 156, "pi_jt_": 156, "pi_n": 156, "pick": [13, 16, 19, 29, 51, 53, 65, 93, 126, 134, 149], "pictur": [38, 40, 41, 73, 117, 127, 143], "piec": [9, 19, 29, 39, 47, 110, 147, 148, 152], "pierr": [8, 34], "pillar": 73, "pioneer": [0, 8, 23], "pipe": 126, "pipelin": 64, "pipenv": 137, "pipes": 126, "pippin": 133, "pitt": 67, "pivot": 8, "pixel": [69, 75, 76, 117], "place": [8, 16, 19, 22, 32, 39, 42, 43, 48, 51, 60, 62, 67, 71, 73, 75, 79, 96, 133, 134, 142, 143, 144, 147, 151, 152, 153, 161], "plai": [5, 9, 11, 17, 23, 27, 30, 34, 35, 52, 53, 64, 66, 67, 73, 86, 102, 127, 132], "plain": [68, 72], "plan": [19, 61, 96, 154], "plane": [19, 65, 74], "planetari": 16, "plate": 51, "plateau": [66, 97, 123], "platform": [44, 63], "plato": 156, "platon": 62, "plausibl": [1, 42, 61, 72, 123], "player": [16, 161], "pleas": [30, 49, 70, 95, 151], "plenti": [67, 146], "plethora": 67, "plot": [0, 3, 6, 7, 9, 11, 19, 25, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 43, 49, 50, 51, 53, 65, 66, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 81, 83, 86, 88, 92, 93, 94, 95, 96, 97, 102, 117, 127, 129, 130, 132, 133, 138, 142, 144, 145, 146, 147, 149, 152, 153, 156, 159, 161, 162, 163], "plot_autocorr": 151, "plot_conditional_distribut": 156, "plot_contour": 82, "plot_data": [34, 102], "plot_decision_boundari": 70, "plot_dens": 78, "plot_estim": 130, "plot_forest": 151, "plot_gaussian_contour": [78, 82], "plot_gpr_sampl": 81, "plot_hist": 17, "plot_imag": [69, 76], "plot_it": 134, "plot_limit": [77, 83], "plot_lin": 5, "plot_mcmc_model": 41, "plot_mcmc_trac": 41, "plot_num": 149, "plot_out": [9, 132], "plot_pair": 152, "plot_posterior": 151, "plot_process": [156, 161], "plot_propos": 144, "plot_result": 40, "plot_sample_dimens": [78, 82], "plot_sample_result": 33, "plot_sine_map": 135, "plot_start": [149, 150], "plot_stop": [149, 150], "plot_surfac": [37, 65, 130], "plot_titl": [40, 78, 143, 145, 162], "plot_trac": [151, 152], "plot_value_arrai": [69, 76], "plot_y_vs_x": 149, "plt": [0, 3, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 50, 65, 69, 70, 71, 73, 76, 77, 78, 80, 81, 82, 83, 88, 92, 93, 95, 96, 102, 123, 126, 127, 129, 130, 132, 133, 134, 135, 143, 144, 145, 147, 149, 150, 151, 152, 153, 156, 161, 162], "plu": [19, 26, 34, 37, 52, 56, 66, 67, 72, 90, 93, 94, 96, 127, 130, 137, 148, 156, 157, 160], "plug": [31, 40, 144], "plumle": 56, "plura": 53, "pm": [4, 7, 19, 29, 34, 35, 40, 41, 53, 73, 81, 93, 151, 152, 154, 156, 158], "pm1": [72, 74], "pm2": [72, 74], "pm3": 151, "pmatrix": [34, 35, 45, 52, 53, 67, 79, 85, 86, 153, 156], "pmc": 123, "pmf": [17, 23, 24, 33], "pmm": 122, "pn": 44, "png": [0, 3, 4, 6, 25, 53, 72, 73, 97, 133, 134, 149, 150], "po": [38, 44, 50, 104, 123, 143, 152], "pocomc_sampl": 123, "pod": [47, 125], "pofm": 48, "pofm1": 48, "point": [0, 4, 6, 7, 8, 9, 11, 16, 17, 19, 23, 25, 29, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 53, 61, 63, 65, 66, 69, 70, 71, 72, 73, 77, 78, 79, 80, 82, 83, 85, 86, 88, 90, 92, 94, 95, 96, 97, 101, 102, 103, 105, 107, 117, 119, 120, 121, 123, 125, 126, 127, 132, 133, 134, 136, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 156, 162, 163], "point_alpha": 126, "pointer": [20, 72, 73, 93, 122], "pointestimates_fig": 130, "pointwis": [80, 107], "poisson": [19, 35, 43, 160], "poisson_plot": [33, 37], "poisson_pt": [33, 37, 145, 162], "poissonpropos": 151, "pol54a": [1, 62], "pol54b": [1, 62], "polar": 150, "poldeg": [34, 102], "polic": 15, "polit": 48, "polya": [1, 61], "polyfit": 95, "polym": 67, "polyni": 95, "polynomi": [5, 66, 79, 86, 88, 97, 101, 102], "polyv": [34, 95, 102], "pool": [50, 73, 75, 96, 123], "poor": [17, 19, 29, 34, 47, 53, 63, 66, 96, 117], "poorli": [43, 48, 66], "popen": 126, "popper": 62, "popul": [31, 32, 39, 63, 65, 73, 89, 130, 147, 152, 161], "popular": [47, 63, 64, 67, 95, 97, 105, 121, 130, 133, 134], "pos1": 65, "pos2": 65, "pos_": 44, "pos_i": 44, "pose": 63, "posit": [4, 6, 7, 8, 19, 25, 31, 34, 37, 38, 39, 41, 42, 44, 50, 51, 53, 61, 62, 63, 64, 65, 66, 71, 72, 77, 78, 82, 83, 85, 86, 88, 90, 96, 97, 100, 105, 107, 123, 125, 127, 130, 138, 142, 143, 144, 146, 147, 148, 152, 153, 156, 159, 161], "possibl": [4, 7, 8, 9, 13, 19, 25, 31, 32, 34, 38, 40, 43, 44, 45, 46, 48, 49, 53, 56, 59, 61, 62, 64, 65, 66, 67, 68, 75, 77, 83, 88, 94, 95, 99, 103, 111, 114, 117, 120, 123, 125, 130, 136, 144, 147, 152, 153, 154, 156, 159, 161], "possibli": [34, 40, 41, 46, 48, 64, 65, 67, 71, 72, 88, 102, 104, 134, 144, 146, 161], "post": [38, 72, 73, 93, 107, 144, 152], "postdoc": 56, "postenti": 148, "posterior": [1, 7, 9, 10, 12, 15, 18, 19, 20, 23, 24, 25, 27, 29, 30, 37, 38, 39, 40, 41, 44, 46, 48, 49, 51, 52, 53, 59, 60, 72, 73, 74, 77, 79, 82, 83, 85, 86, 87, 90, 92, 93, 94, 95, 96, 120, 121, 142, 144, 145, 146, 147, 148, 151, 152, 153, 154, 158, 162], "posterior1": 34, "posterior_calc": 42, "posterior_func": 144, "posterior_funct": 144, "posterior_pt": 42, "posteriorbma": 48, "posteriori": [34, 72, 151], "postiv": 63, "postul": 16, "potenti": [43, 44, 45, 47, 48, 51, 61, 63, 64, 66, 67, 71, 82, 104, 119, 137, 143, 148, 151], "potest": 53, "pott": 67, "pound": 134, "pow": 71, "powel": 123, "power": [7, 25, 33, 34, 46, 55, 56, 60, 63, 65, 66, 67, 71, 73, 76, 111, 117, 121, 123, 125, 130, 134, 136], "pp": [130, 156, 161], "ppc": [73, 93], "ppd": [16, 34], "ppd_definition_b": 0, "ppf": 130, "pr": [17, 23, 30, 40, 41, 42, 44, 49, 95, 123, 151], "practic": [7, 9, 15, 20, 27, 37, 39, 40, 43, 44, 46, 48, 51, 53, 58, 59, 61, 62, 63, 66, 71, 85, 86, 88, 94, 100, 119, 125, 127, 145, 147, 148, 151, 152, 154, 156, 157, 159, 160, 161, 162], "practition": [59, 67, 88], "pradeep": 86, "pragmat": 113, "pratola": 56, "pre": [0, 43, 44, 45, 69, 73, 117], "preactiv": 117, "preced": [53, 67], "preceed": 134, "precent": 25, "precipic": 151, "precipit": 156, "precis": [5, 29, 34, 39, 40, 41, 43, 45, 46, 48, 51, 53, 63, 66, 67, 78, 79, 80, 82, 94, 96, 105, 111, 113, 125, 126, 127, 133, 147, 149, 150, 152, 153, 154, 158, 161], "preconceiv": [9, 30], "precondit": 123, "pred": [73, 93], "pred_func": 70, "predefin": [71, 134], "predetermin": [96, 153], "predic": 143, "predict": [1, 4, 7, 20, 24, 25, 29, 44, 45, 46, 48, 51, 53, 58, 60, 62, 63, 64, 65, 66, 67, 70, 71, 72, 74, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 92, 94, 102, 105, 110, 111, 119, 120, 121, 123, 127, 133, 145, 146, 153, 156, 158, 162], "predict_quantil": [77, 83], "predicted_label": [69, 76], "predicti": 44, "predictions_arrai": [69, 76], "predictor": [34, 64, 65, 85, 88, 101, 102, 109, 110, 133], "predispos": 63, "predominantli": 134, "preexec_fn": 126, "prefer": [3, 4, 34, 43, 53, 63, 65, 66, 71, 92, 135, 151], "preferenti": 53, "prejudic": 63, "preliminari": 31, "premis": [0, 7], "prepar": [25, 53, 69, 71, 126, 133, 137], "prepend": 88, "preprint": 94, "preprocess": [69, 73, 81, 93, 123], "prescrib": 33, "prescript": 150, "presenc": [8, 22, 38, 63], "present": [0, 8, 16, 22, 25, 34, 43, 48, 49, 53, 58, 62, 64, 65, 67, 73, 81, 92, 94, 101, 103, 107, 123, 126, 133, 134, 135, 156, 161], "preserv": [44, 51, 148], "presid": 25, "presidenti": 25, "press": [1, 9, 11, 56, 64, 134], "pressur": 4, "presum": [48, 71], "presumpt": 48, "pretti": [33, 62, 73, 133, 137, 161], "prettypleas": [130, 156, 161], "preval": 88, "prevent": [63, 64, 69, 71, 72, 77, 126, 153], "preview": 134, "previou": [9, 16, 23, 30, 34, 37, 38, 39, 40, 41, 43, 44, 56, 60, 67, 68, 71, 75, 77, 92, 95, 102, 106, 111, 117, 124, 127, 134, 143, 144, 145, 147, 151, 152, 154, 156, 160, 162], "previous": [7, 48, 49, 71, 72, 77, 83], "prf": 0, "price": 72, "primari": [88, 94], "primarili": [67, 73], "prime": [40, 77, 83], "primer": [1, 43], "primit": 25, "princeton": 1, "princip": [35, 47, 53, 89, 124], "principl": [1, 7, 8, 20, 28, 34, 38, 39, 40, 43, 44, 47, 48, 53, 57, 59, 61, 62, 67, 73, 80, 88, 97, 104, 117, 124, 125, 133, 147, 152], "print": [1, 5, 6, 9, 17, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 50, 65, 69, 70, 71, 73, 74, 76, 77, 78, 81, 82, 83, 93, 95, 96, 102, 123, 126, 127, 129, 130, 133, 134, 135, 136, 138, 143, 144, 145, 147, 149, 150, 151, 152, 153, 161, 162], "print_frequentist_estim": [9, 30], "print_funct": 76, "print_likely_fair_prior_measur": [9, 30], "print_likely_unfair_prior_measur": [9, 30], "print_uniform_prior_measur": [9, 30], "printopt": [40, 41, 78, 82, 96], "prior": [0, 2, 3, 7, 8, 9, 10, 11, 15, 16, 19, 23, 25, 29, 30, 35, 37, 38, 41, 42, 44, 46, 47, 48, 51, 52, 55, 58, 59, 60, 64, 72, 73, 74, 77, 78, 82, 83, 85, 86, 87, 93, 94, 95, 96, 117, 119, 120, 121, 126, 142, 143, 151, 158], "prior_func": 123, "prior_rang": 95, "priori": [47, 48, 53, 60, 86, 151], "priorit": [119, 121], "prioriti": [60, 64], "priors_text": 9, "priors_text_w": 9, "priorsamplesslop": 3, "privaci": 63, "privat": [63, 67, 128], "privileg": [22, 137], "prize": 67, "prng": 130, "pro": 63, "prob": [0, 8, 16, 17, 22, 23, 25, 31, 32, 38, 41, 46, 50, 65, 69, 88, 123, 130, 143, 144, 152, 156], "prob_": 156, "prob_head": 9, "prob_heads_w": 9, "probab": 34, "probabilist": [16, 22, 46, 55, 58, 59, 60, 62, 64, 80, 88, 89, 93, 152, 153], "probabilit": [130, 156], "probabilitii": 26, "probabilit\u00e9": 34, "probabl": [0, 1, 5, 7, 9, 10, 11, 12, 16, 18, 19, 20, 21, 24, 27, 30, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 48, 49, 50, 51, 53, 55, 56, 58, 59, 60, 62, 64, 65, 67, 69, 72, 74, 78, 79, 82, 85, 86, 89, 90, 95, 96, 97, 101, 105, 110, 117, 120, 123, 124, 126, 143, 145, 147, 148, 151, 152, 153, 154, 156, 158, 162, 163], "problem": [4, 7, 8, 9, 11, 15, 16, 25, 28, 31, 34, 35, 38, 39, 40, 44, 45, 47, 48, 49, 51, 53, 56, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 79, 85, 88, 90, 91, 92, 93, 94, 95, 97, 99, 100, 101, 104, 110, 113, 117, 122, 123, 126, 130, 134, 137, 142, 143, 146, 147, 148, 149, 154, 156, 159], "problemat": [39, 43, 48, 67, 117, 147, 152, 153, 154], "proc": 51, "proce": [19, 27, 34, 46, 53, 66, 102, 134], "procedur": [7, 8, 15, 38, 41, 44, 46, 47, 61, 63, 65, 66, 78, 82, 86, 97, 130, 134, 144, 153, 154], "proceed": 156, "process": [1, 8, 9, 16, 25, 30, 34, 43, 44, 45, 46, 47, 48, 59, 60, 62, 63, 64, 65, 66, 67, 69, 71, 73, 76, 79, 87, 89, 92, 93, 97, 100, 101, 102, 106, 110, 111, 117, 118, 119, 120, 123, 130, 136, 153, 160], "process_group": 126, "process_new_macros_for_config_fil": 0, "prod": [147, 152], "prod_": [4, 19, 34, 37, 38, 39, 40, 41, 48, 49, 88, 143, 147, 152], "prod_i": 72, "produc": [0, 5, 9, 11, 19, 25, 34, 38, 43, 44, 48, 51, 60, 63, 67, 88, 102, 113, 127, 130, 133, 134, 136, 144, 154, 156, 161], "product": [8, 13, 15, 16, 19, 20, 23, 31, 33, 34, 39, 41, 43, 44, 45, 47, 49, 52, 53, 65, 68, 75, 77, 83, 88, 100, 117, 123, 130, 137, 147, 152, 153, 154, 156], "production_step1": 73, "production_step2": 73, "prof": 95, "profici": 134, "program": [34, 62, 63, 64, 65, 67, 72, 89, 93, 105, 133, 134, 135, 136, 137, 152, 154], "programdata": 137, "programm": 64, "progress": [8, 50, 64, 68, 71, 123, 137, 152], "progress_callback": 126, "progressbar": 73, "prohibit": [122, 124], "project": [1, 37, 45, 47, 49, 63, 65, 127, 130, 134, 146, 153, 154, 163], "project_root_dir": 133, "promin": [67, 117, 128], "promis": [73, 97], "promot": [43, 134, 153], "prompt": [134, 137], "prone": [113, 135], "pronounc": [73, 93, 128], "proof": [3, 22, 31, 32, 33, 34, 62, 66, 67, 100, 144, 156], "propag": [0, 1, 3, 28, 43, 64, 70, 71, 75, 85, 88, 117, 149], "proper": [7, 43, 47, 64, 71, 105, 110, 125, 134], "properli": [4, 7, 43, 63, 71, 72, 88, 96, 130, 144, 147, 151, 152], "properti": [4, 7, 17, 25, 38, 44, 47, 48, 50, 53, 66, 67, 73, 75, 77, 78, 79, 80, 82, 83, 85, 97, 120, 127, 130, 144, 150, 153, 156, 161], "proport": [4, 7, 25, 29, 34, 39, 40, 66, 72, 93, 127, 133, 143, 146, 147, 148, 152, 154, 161], "proportion": [34, 43, 53, 63, 163], "propos": [8, 25, 38, 44, 51, 92, 96, 107, 117, 143, 144, 145, 146, 148, 153, 154, 156, 161, 162], "proposal_posit": 144, "proposal_width": [144, 159], "propose_loc": 92, "proposed_posit": 144, "proposit": [8, 25, 30, 62, 110], "propsal": [144, 153], "propto": [3, 4, 7, 13, 15, 25, 34, 35, 39, 40, 41, 44, 48, 51, 72, 85, 96, 146, 147, 148, 151, 152, 153, 156, 158, 159, 163], "protect": 137, "protocol": [47, 53, 61], "proton": [34, 79, 99, 133, 154], "prototyp": [16, 64, 77, 79, 91, 96, 158], "prove": [19, 33, 37, 53, 125, 127, 156], "proven": [12, 67, 111, 153], "provid": [3, 4, 7, 8, 9, 22, 24, 25, 28, 30, 34, 43, 44, 46, 47, 48, 51, 53, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 75, 77, 83, 86, 89, 91, 100, 110, 113, 119, 132, 133, 135, 136, 146, 147, 151, 152, 153, 156, 161], "provis": 61, "provoc": 16, "proxi": [9, 30, 72, 132], "psd": [77, 83], "pseudo": [92, 100, 106, 159], "pseudoconverg": 44, "psi": [0, 17, 23, 45, 47, 143], "psi_": [45, 143], "psi_1": 45, "psi_2": 45, "psi_chain": 143, "psi_i": [45, 47], "psi_j": [45, 47], "psi_mean": 143, "psi_mean_al": 143, "psi_n": 45, "psub": 34, "psutil": 123, "psychologi": 64, "pt": 126, "pt_sampler_t0": 96, "ptemce": [50, 51, 90], "ptemse": 50, "ptmcmc": [50, 96], "ptsampler": 96, "public": [1, 63, 64], "publica": 63, "publicli": [44, 56], "publish": [1, 15, 44, 53, 91, 110, 133], "puk94": [1, 46], "pukelheim": 46, "pukelsheim": 1, "pull": [48, 51], "pulldown": [9, 134], "punish": 64, "pure": [16, 44, 48, 53, 61, 62, 147, 152, 153], "purport": 48, "purpos": [7, 44, 48, 49, 50, 66, 67, 71, 95, 111, 146, 156], "push": 151, "put": [0, 8, 19, 20, 23, 24, 27, 31, 32, 34, 39, 40, 47, 52, 53, 56, 66, 72, 85, 133, 134, 135, 136, 143, 147, 152, 159], "px": 5, "py": [0, 37, 38, 50, 81, 96, 123, 126, 133, 151, 152], "pylab": 133, "pymc": [64, 73, 93, 143, 146, 148, 160, 163], "pymc3": [93, 151], "pymc_docs_getting_started_upd": 158, "pymc_nam": 152, "pymcinference_library_vers": 151, "pypi": 43, "pyplot": [0, 3, 5, 6, 7, 9, 17, 25, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 50, 65, 69, 70, 71, 73, 76, 77, 78, 80, 81, 82, 83, 88, 92, 93, 95, 96, 102, 123, 126, 127, 129, 130, 132, 133, 134, 135, 143, 144, 145, 147, 149, 150, 151, 152, 153, 156, 161, 162], "pytensor": 71, "python": [0, 1, 5, 11, 19, 23, 26, 34, 39, 40, 43, 52, 56, 66, 69, 72, 73, 78, 85, 93, 94, 96, 102, 105, 106, 125, 130, 131, 133, 136, 137, 139, 140, 147, 152, 153, 156, 158, 161, 163], "python3": [0, 50, 81, 96, 126, 137, 140, 152], "pytorch": [64, 129], "pytorch_thread": 123, "p\u00f3lya": 61, "q": [3, 4, 19, 35, 44, 46, 72, 78, 82, 85, 125, 144, 148, 149, 154, 156], "q_": 85, "q_0": 149, "q_i": [44, 148], "qbism": 124, "qcd": 44, "qfrsaikz4ric": 1, "qft": 117, "qmn15": [1, 45], "qoi": 48, "qquad": [4, 7, 35, 51, 52, 66, 78, 120, 121, 123, 130, 148, 150, 159], "quad": [0, 3, 4, 5, 7, 11, 13, 15, 17, 19, 23, 24, 33, 34, 35, 37, 42, 46, 47, 53, 66, 85, 86, 123, 125, 130, 143, 145, 148, 153, 156, 158, 162], "quadrat": [19, 34, 38, 53, 72, 77, 78, 81, 82, 83, 85, 100, 112, 115, 123], "quadratur": [51, 154], "qualifi": [63, 64], "qualit": [7, 62, 119, 130, 146], "qualiti": [34, 53, 60, 63, 72, 102], "quanta": 128, "quantif": [8, 45, 46, 47, 62, 85, 97, 122], "quantifi": [7, 8, 16, 22, 43, 46, 53, 60, 62, 65, 88, 95, 111, 113, 117, 119, 120, 130, 144], "quantil": [17, 38, 41, 43, 50, 77, 83, 94, 96, 123, 130, 143, 147, 152], "quantit": [7, 8, 16, 46, 58, 62, 71, 110, 119], "quantiti": [4, 7, 16, 17, 22, 23, 25, 31, 34, 41, 44, 45, 46, 47, 48, 51, 53, 64, 66, 67, 68, 72, 88, 94, 95, 101, 107, 109, 117, 119, 121, 124, 126, 130, 133, 143, 144, 153], "quantum": [1, 16, 22, 23, 45, 47, 64, 67, 104, 117, 124, 156, 161], "quarteroni": 1, "que": 34, "queri": 134, "question": [7, 8, 11, 17, 25, 26, 27, 33, 39, 42, 49, 50, 52, 53, 56, 60, 61, 66, 68, 71, 73, 92, 93, 127, 136, 142, 143, 147, 152, 156, 159, 161, 162], "questionnair": 63, "quick": [127, 134, 135, 146], "quickli": [40, 47, 66, 73, 75, 136], "quickstart": 69, "quiet": 67, "quirki": 38, "quit": [34, 38, 67, 68, 73, 93, 95, 135, 144], "quod": 53, "quot": [16, 19, 39, 51, 66, 95, 104, 134, 152], "r": [0, 1, 3, 5, 6, 7, 9, 11, 13, 15, 16, 17, 19, 29, 33, 34, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 65, 66, 67, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 93, 96, 100, 102, 104, 107, 113, 115, 120, 123, 126, 127, 129, 130, 132, 133, 134, 135, 136, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 159, 161, 162, 163], "r2": [38, 66, 78], "r2_score": 133, "r_": [85, 150], "r_0": 150, "r_dot": 150, "r_dot_0": 150, "r_dot_half": 150, "r_dot_pt": 150, "r_dot_pts_eul": 150, "r_dot_pts_lf": 150, "r_hat": [151, 152], "r_i": [38, 95, 150], "r_list": 135, "r_pt": 150, "r_pts_euler": 150, "r_pts_lf": 150, "r_sq": 38, "race": 63, "racial": 63, "radford": [44, 148], "radfriend": 154, "radial": [80, 85, 121], "radii": 47, "radio": 53, "radioact": [37, 154], "radioactive_lighthouse_exercis": 142, "radioactive_lighthouse_exercise_kei": 35, "radiu": [46, 47, 49, 115, 133, 150, 154], "rai": [42, 142], "rain": [0, 8, 16, 17, 22, 23, 130, 156], "raini": 16, "raio": 7, "rais": [33, 50, 96, 123, 126, 129, 136], "rajesh": 1, "ran_uniform_arrai": 33, "rand": [6, 17, 25, 40, 50, 71, 77, 78, 82, 83, 96, 123, 127, 136, 143, 144, 146, 147, 149, 152], "randint": [33, 136], "randn": [17, 40, 41, 73, 92, 93, 127, 133, 143, 151], "random": [3, 6, 9, 16, 17, 19, 23, 24, 25, 26, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 50, 51, 53, 60, 63, 65, 66, 67, 70, 71, 73, 74, 77, 78, 79, 80, 81, 82, 83, 86, 92, 93, 94, 95, 96, 97, 102, 105, 106, 110, 117, 120, 121, 123, 127, 129, 133, 136, 142, 143, 145, 146, 147, 148, 149, 151, 152, 153, 160, 162], "random_st": [29, 70, 73, 74, 81, 93, 130, 156, 161], "randomcovariancematrix": 82, "randomli": [16, 32, 35, 40, 42, 44, 47, 49, 50, 65, 69, 71, 142, 143, 144, 148, 154], "randomst": [40, 80, 81, 143], "randomwalk": 161, "rang": [3, 5, 6, 7, 17, 25, 29, 30, 33, 34, 35, 37, 38, 41, 42, 43, 46, 47, 49, 50, 51, 58, 64, 65, 66, 69, 71, 76, 77, 78, 79, 82, 83, 85, 86, 88, 91, 95, 96, 102, 106, 117, 120, 122, 123, 126, 129, 130, 132, 134, 143, 144, 145, 147, 152, 153, 154, 156, 161, 162], "ranganath": [1, 72], "ranganathan": 86, "rangl": [4, 19, 37, 42, 45, 85, 146, 153, 159], "rangle_": 51, "rank": [34, 55, 100, 125, 127], "rapidli": [33, 64, 79, 137, 154], "rare": [33, 34, 63, 102, 119, 151], "rasmu": 126, "rasmussen": [1, 85, 86], "rasumu": 126, "rate": [1, 31, 37, 44, 47, 63, 66, 67, 68, 69, 70, 71, 88, 97, 105, 106, 107, 129, 144, 146, 148, 159, 161, 163], "rather": [4, 8, 22, 23, 25, 34, 37, 38, 39, 41, 43, 44, 46, 47, 52, 53, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 88, 95, 106, 112, 119, 127, 133, 134, 135, 143, 147, 151, 152, 159], "ratio": [5, 7, 8, 44, 50, 51, 52, 53, 78, 82, 85, 86, 96, 115, 117, 125, 130, 145, 151, 153, 154, 156, 162], "ratio_max": [78, 82], "ratio_min": [78, 82], "ration": [7, 8, 62], "rational": 61, "rationalquadrat": 81, "ravel": [37, 40, 41, 70, 80, 123], "ravin": 105, "raw": [75, 127], "razor": 53, "rbf": [77, 79, 80, 81, 83, 85, 92, 121, 123], "rbf_kernel": 123, "rbf_lengthscal": 82, "rbf_term": 123, "rbf_varianc": 82, "rbfco": 77, "rbfkernel": 82, "rbm": [47, 122], "rbrace": 48, "rc_context": 126, "rcparam": [5, 9, 37, 126, 132, 133, 149, 150], "rct1": 133, "rct2": 133, "rdbu": 70, "rdbu_r": 65, "rdot": 150, "rdylbu_r": 65, "re": [1, 3, 5, 8, 13, 16, 19, 22, 38, 40, 41, 42, 51, 63, 69, 71, 72, 78, 92, 95, 96, 134, 142, 143, 144, 146, 151, 159], "reach": [8, 16, 43, 44, 62, 63, 66, 67, 68, 88, 97, 105, 143, 151, 153, 156], "react": [25, 133], "reaction": 47, "read": [0, 11, 23, 32, 35, 59, 64, 67, 68, 72, 75, 86, 94, 95, 127, 134, 135, 136, 137, 138, 158], "read_fwf": 133, "readabl": 152, "reader": [43, 46, 59, 61, 79], "readi": [42, 61, 68, 69, 133], "readili": 41, "readm": 43, "readout": 132, "readout_format": 132, "readthedoc": [41, 152, 163], "real": [0, 7, 8, 9, 16, 23, 40, 47, 63, 67, 72, 73, 77, 82, 83, 88, 98, 104, 110, 125, 136, 146, 161], "realis": 156, "realist": [16, 34, 100, 102, 153, 154, 156], "realiti": [8, 34, 48, 61, 62, 101, 102, 110, 123, 128, 130], "realiz": [4, 7, 8, 22, 34, 41, 53, 65, 66, 67, 86, 100, 159, 161], "realli": [7, 13, 17, 18, 23, 31, 38, 39, 40, 42, 44, 67, 73, 85, 93, 96, 115, 117, 144, 147, 152, 153, 159], "realm": 62, "rearrang": [23, 31, 32], "reason": [0, 1, 7, 8, 11, 16, 19, 22, 25, 34, 40, 43, 53, 58, 61, 63, 71, 77, 79, 86, 96, 100, 101, 106, 130, 136, 144, 146, 147, 152, 153, 154], "recal": [4, 9, 30, 31, 34, 38, 44, 48, 49, 52, 53, 63, 68, 82, 85, 88, 92, 125, 127, 143, 148], "recalcul": 142, "recalculate_data": 9, "recalculate_data_w": 9, "recapitul": 156, "recast": [51, 104], "receiv": [67, 82], "recent": [48, 49, 50, 63, 66, 69, 70, 71, 73, 93, 96, 104, 126], "recept": 67, "recess": 130, "recession": [7, 41], "recip": [16, 34, 69, 88, 95, 159], "recogn": [21, 39, 43, 46, 47, 53, 60, 62, 119, 127, 146, 147, 152], "recognis": [4, 88], "recognit": [53, 61, 63, 64, 67, 73, 75], "recommend": [38, 40, 41, 43, 56, 63, 64, 71, 75, 107, 130, 133, 134, 139, 142, 144, 151, 152], "reconstrain": [77, 83], "reconstuct": 5, "record": [4, 5, 8, 37, 42, 50, 53, 93, 96, 121, 123, 142, 145, 161, 162], "recov": [34, 121], "recreat": [44, 66, 127], "rectangl": 149, "rectifi": [67, 71, 75], "recurr": [68, 73, 136, 144, 153, 156], "recurs": 62, "red": [5, 9, 17, 23, 30, 33, 34, 37, 38, 39, 42, 49, 65, 69, 72, 75, 76, 77, 78, 81, 88, 93, 95, 102, 121, 123, 126, 127, 130, 134, 144, 145, 146, 147, 148, 150, 152, 154, 159, 161, 162, 163], "redefin": 92, "redirect": [73, 93], "redo": 41, "redrawn": 132, "redshift": 7, "reduc": [1, 22, 29, 34, 38, 39, 43, 44, 46, 47, 53, 60, 63, 66, 72, 75, 79, 88, 97, 102, 106, 107, 117, 119, 122, 125, 127, 143, 146, 150], "reduct": [1, 44, 46, 47, 66, 124, 125, 143, 151], "redund": 125, "ref": [0, 42, 44, 45, 46, 47, 48, 163], "refactor": 126, "refer": [1, 2, 7, 8, 16, 17, 27, 34, 41, 43, 45, 46, 48, 52, 53, 56, 63, 66, 67, 72, 75, 76, 78, 81, 86, 88, 100, 102, 110, 111, 117, 118, 120, 122, 125, 130, 134, 151, 153, 163], "refin": [5, 8, 46, 59, 67], "refit": 70, "reflect": [8, 25, 43, 46, 53, 63, 64, 121, 127, 133, 147, 152, 153, 156], "reformat": 69, "refresh": [56, 131], "regain": 34, "regard": [4, 8, 9, 25, 46, 51, 56, 58], "regardless": [8, 19, 77, 83, 153, 156], "regener": 9, "regenerate_data": 9, "regim": [48, 119], "region": [17, 19, 41, 44, 46, 48, 50, 51, 52, 53, 65, 66, 67, 72, 73, 75, 77, 78, 80, 82, 83, 93, 94, 95, 146, 148, 149, 153, 154, 159], "regist": [43, 137], "registri": 43, "regress": [1, 16, 27, 28, 38, 45, 47, 63, 67, 68, 71, 72, 73, 79, 86, 87, 89, 93, 95, 97, 99, 103, 104, 105, 112, 116, 133, 158], "regressor": [65, 82, 88], "regular": [60, 67, 70, 72, 73, 74, 77, 80, 83, 93, 151], "regularli": [71, 95], "reifi": 48, "reilli": 1, "reinforc": [32, 64], "reject": [4, 11, 19, 46, 53, 144, 145, 146, 148, 153, 154, 159, 162, 163], "rel": [8, 16, 31, 38, 43, 46, 47, 48, 49, 51, 53, 65, 88, 94, 96, 97, 115, 127, 134, 144, 153], "relat": [4, 7, 15, 17, 19, 23, 25, 34, 38, 40, 41, 42, 43, 46, 48, 53, 59, 61, 63, 64, 66, 67, 71, 77, 83, 89, 94, 96, 99, 110, 111, 114, 115, 127, 128, 153], "relationship": [7, 34, 46, 53, 59, 62, 64, 86, 110, 111, 117, 146], "relax": [47, 94], "releas": [43, 50, 56, 96], "relerr": [149, 150], "relev": [7, 9, 16, 25, 34, 38, 47, 53, 61, 63, 65, 66, 67, 72, 85, 88, 94, 95, 96, 100, 102, 110, 111, 130, 134, 137, 142, 146, 156, 161, 163], "reli": [22, 25, 46, 51, 53, 64, 71, 73, 93, 110, 136], "reliabl": [35, 38, 47, 51, 88, 96, 111, 119, 122, 135], "relu": [67, 69, 70, 71, 75, 76, 117, 129], "remain": [4, 16, 44, 47, 49, 53, 56, 66, 67, 121, 151, 153], "remaind": [25, 105], "remark": [20, 25, 43, 44, 47, 67, 121, 133, 146, 153, 161], "remedi": 8, "rememb": [4, 17, 22, 34, 46, 49, 65, 66, 74, 92, 125, 135, 136, 151, 154, 156, 161], "remind": 66, "remov": [37, 38, 46, 61, 63, 70, 78, 95, 125, 127, 144, 153], "ren": 1, "renaiss": 73, "renam": [134, 151], "render": [44, 45, 70, 134], "renewcommand": 0, "renorm": [12, 117], "reoffend": 63, "reorder": 88, "reorgan": 133, "rep": [1, 43], "reparameter": 151, "repeat": [29, 33, 34, 39, 41, 42, 43, 46, 50, 53, 66, 67, 77, 78, 80, 82, 90, 92, 94, 95, 96, 117, 122, 126, 127, 130, 135, 143, 145, 147, 151, 152, 153, 154, 159, 162], "repeatadli": 73, "repeatedli": [11, 15, 39, 44, 59, 147, 152], "repercuss": 63, "repetit": 130, "rephras": 7, "replac": [7, 16, 25, 44, 45, 46, 51, 52, 63, 68, 71, 72, 77, 80, 83, 85, 95, 122, 133, 142, 153], "repli": 128, "replic": 43, "replica": 51, "replot": 17, "report": [8, 43, 47, 53, 134, 147, 152], "repositori": [40, 43, 56, 64, 131, 137, 139, 140], "repres": [3, 4, 7, 8, 9, 16, 21, 22, 23, 25, 38, 39, 41, 44, 46, 48, 49, 51, 53, 59, 60, 63, 64, 65, 66, 67, 68, 71, 75, 76, 88, 94, 95, 96, 105, 117, 119, 120, 123, 127, 130, 135, 136, 143, 144, 146, 147, 152, 153, 154, 156], "represent": [1, 4, 7, 19, 35, 47, 48, 66, 69, 70, 73, 75, 85, 110, 125, 135, 146, 153], "reproduc": [4, 13, 25, 30, 34, 44, 49, 53, 61, 63, 64, 65, 66, 68, 72, 91, 94, 96, 102, 113, 123, 127, 130, 133, 144, 154, 156, 161], "reproduct": [33, 34, 61, 66, 161], "repuls": 133, "request": [64, 77, 123, 156], "requir": [7, 8, 19, 33, 34, 37, 38, 40, 43, 44, 45, 46, 47, 49, 51, 53, 59, 60, 62, 64, 67, 71, 73, 75, 76, 85, 90, 96, 97, 100, 105, 122, 123, 124, 130, 133, 136, 137, 140, 142, 148, 153, 156, 159, 161], "requires_grad": 71, "rerun": [37, 70], "resampl": [1, 46, 66, 123, 148], "rescal": [44, 70, 123], "research": [0, 1, 8, 19, 28, 34, 48, 57, 59, 60, 61, 64, 72, 73, 104, 117, 119], "resembl": [48, 144], "reserv": [34, 68], "reset": [6, 9, 38, 50, 71, 96, 123, 143, 147, 152], "reset_button_w": 9, "reset_n": 9, "reshap": [3, 6, 17, 25, 30, 34, 38, 41, 50, 70, 73, 76, 77, 80, 81, 82, 83, 92, 93, 96, 102, 123, 127, 133, 143, 146, 147, 152], "resid": [45, 46, 136], "residenti": 16, "residu": [5, 29, 34, 38, 47, 51, 95, 96, 100, 101, 105], "residual_": [34, 100], "residual_1": [34, 100], "residual_2": [34, 100], "residual_3": [34, 100], "residual_i": 34, "resist": 121, "resiz": [126, 136], "resolut": 149, "resolv": [46, 48], "reson": 47, "resort": 34, "resourc": [37, 43, 46, 134, 136], "respect": [4, 5, 7, 8, 16, 24, 25, 34, 38, 43, 44, 45, 46, 47, 48, 53, 63, 64, 65, 66, 67, 68, 71, 72, 75, 85, 88, 97, 100, 106, 107, 117, 130, 133, 136, 144, 156], "respond": [8, 67], "respons": [34, 56, 63, 64, 65, 67, 71, 77, 85, 88, 102, 109, 110, 113, 128, 130, 134], "rest": [8, 46, 66, 73, 78, 82, 94, 95, 111, 114, 154], "restart": [92, 134, 137], "restore_sign": 126, "restraint": 61, "restrict": [43, 46, 47, 52, 53, 58, 67, 82, 104, 105, 134, 146, 161], "restructur": 136, "result": [3, 4, 6, 7, 8, 9, 11, 13, 15, 16, 19, 23, 25, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 44, 47, 48, 50, 51, 52, 53, 55, 58, 59, 61, 62, 63, 64, 65, 66, 68, 71, 72, 75, 77, 78, 82, 83, 85, 88, 90, 91, 92, 93, 94, 95, 96, 100, 101, 102, 121, 123, 126, 127, 129, 130, 133, 134, 136, 142, 143, 145, 146, 147, 152, 156, 158, 159, 161, 162], "retain": [127, 135], "retriev": [69, 73], "return": [0, 4, 5, 6, 7, 8, 9, 17, 25, 29, 30, 33, 34, 35, 37, 38, 40, 41, 42, 46, 49, 50, 52, 65, 69, 70, 71, 72, 73, 74, 77, 78, 82, 85, 86, 88, 92, 93, 94, 95, 96, 97, 100, 102, 106, 123, 126, 127, 129, 130, 132, 133, 134, 135, 136, 138, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 156, 159, 161, 162], "return_cov": 82, "return_inferencedata": [151, 152], "return_std": [80, 81], "reusabl": 43, "rev": [1, 78, 82, 86], "reveal": [45, 53, 63, 117, 138, 156], "revers": [22, 23, 25, 44, 72, 137, 148, 150, 161], "reversibil": 44, "reversiblemarkovprocessexampl": 156, "reversiblemarkovprocessexample_cprob_fig": 156, "reversiblemarkovprocessexample_runs_fig": 156, "review": [34, 35, 41, 45, 49, 63], "revis": [5, 16, 38, 50, 56, 58, 61, 77, 78, 137, 143, 149, 151], "revisit": [25, 50, 59, 66], "revolut": 51, "revolv": 110, "reward": 64, "reweight": 154, "reword": 31, "rewrit": [25, 66, 67, 68, 72, 85, 88, 143], "rewritten": [66, 156], "rf": [17, 33, 37, 40, 42, 65, 78, 82, 126, 135, 143, 145, 149, 150, 161, 162], "rg": 117, "rhat": 143, "rho": [44, 72, 78, 79, 86, 130, 144, 159], "rho_": [24, 52, 82, 130], "rich": [47, 64], "richard": [1, 44, 148, 153, 154], "richardson": 1, "ridg": [1, 88], "riemann": 146, "right": [0, 3, 4, 7, 9, 13, 15, 16, 17, 19, 22, 23, 24, 25, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 44, 47, 48, 49, 51, 52, 53, 56, 63, 64, 65, 66, 67, 68, 69, 72, 73, 76, 78, 82, 85, 88, 92, 94, 95, 96, 97, 100, 103, 105, 106, 107, 114, 117, 120, 121, 125, 126, 127, 130, 134, 137, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 156, 159, 161, 162], "rightarrow": [0, 3, 4, 7, 13, 15, 19, 22, 23, 33, 34, 35, 37, 44, 48, 67, 72, 85, 86, 102, 146, 148, 154, 158], "rightli": [8, 53], "rightmost": 56, "rigidli": 56, "rigor": [43, 58, 59, 62, 64, 113, 126, 144], "rigour": 110, "ring": 51, "rise": [8, 34, 53, 127], "risk": [8, 43, 44, 46, 59, 63, 66], "ritz": 47, "rivalri": 45, "rjf": 122, "rk23": 150, "rlhick": 151, "rm": [9, 11, 16, 19, 29, 33, 37, 42, 44, 48, 49, 63, 66, 67, 71, 78, 79, 86, 94, 95, 120, 121, 130, 132, 150], "rmsprop": [67, 71], "rng": [30, 34, 80, 81, 102, 130], "rnn": 67, "roam": 159, "rob": 143, "rob21": [1, 117], "robert": [1, 117, 128, 144, 161], "roberto": 1, "robust": [1, 38, 43, 61, 63, 108, 121, 123, 151, 152, 163], "role": [43, 48, 53, 56, 64, 66, 67, 82, 86, 127, 130, 134], "roll": [4, 23, 65, 143], "rom": 47, "ron": 1, "ronald": 1, "rongzheng": 1, "rook": 79, "room": 134, "root": [24, 41, 56, 63, 64, 66, 71, 110, 130, 134, 136], "root_mean": 65, "rot": 133, "rotat": [46, 51, 127, 146], "rough": [18, 46], "roughli": [29, 33, 34, 39, 44, 51, 53, 63, 71, 125, 130, 144, 152], "round": [4, 123, 127, 133, 136], "routin": [50, 152], "row": [1, 25, 30, 32, 42, 67, 69, 78, 123, 127, 133, 134, 135, 144, 153, 156, 159], "roweth": 1, "royal": 1, "royalblu": 65, "rrapaj": 1, "rseed": [40, 143], "rsq": 38, "rst": [73, 93], "rstride": [37, 65], "rtol": [149, 150], "rub88": [1, 44], "rubin": [1, 146], "ruder": 107, "ruin": 8, "rule": [0, 1, 7, 13, 15, 16, 20, 23, 27, 29, 34, 37, 41, 51, 52, 53, 58, 61, 62, 63, 65, 71, 88, 107, 130, 146, 153, 156, 159, 161], "ruler": [7, 41], "rumelhart": 1, "rumelharthintonwilliams86": [1, 68], "run": [8, 9, 30, 34, 37, 38, 42, 43, 44, 46, 49, 50, 51, 56, 70, 71, 73, 76, 79, 83, 86, 93, 95, 96, 102, 106, 117, 123, 125, 126, 129, 130, 131, 133, 134, 135, 138, 143, 145, 150, 151, 152, 154, 156, 158, 159, 161, 162], "run_mcmc": [6, 38, 41, 50, 96, 123, 143, 147, 152], "run_model": 129, "rung": [148, 150], "runner": 77, "runtimeerror": 126, "runtimewarn": 38, "ruth": 1, "rutherford": 130, "rv": [9, 17, 29, 33, 37, 39, 42, 49, 65, 78, 82, 86, 126, 130, 144, 145, 147, 151, 152, 153, 162], "rvec": 51, "rvec_": 51, "rvec_i": 51, "rvert": [104, 120], "rw05": [1, 85], "rwidth": [145, 162], "ryh22": [1, 117], "r\u00e9duit": 34, "r\u00e9sum\u00e9": 63, "s1": 37, "s12918": 1, "s2": 37, "s41567": 1, "s43586": 1, "s_": 125, "s_eleph": 104, "s_i": 127, "s_j": [44, 127, 143, 151], "s_k": [125, 127], "s_n": 161, "s_shape": 127, "sa": 43, "saddl": [39, 53, 105, 147, 152], "safe": [50, 96], "safeti": [0, 63, 64], "sai": [0, 3, 4, 7, 8, 13, 16, 17, 19, 22, 23, 25, 30, 31, 32, 34, 37, 38, 39, 40, 42, 43, 44, 48, 49, 53, 56, 58, 62, 66, 68, 75, 86, 88, 95, 127, 134, 136, 137, 143, 144, 146, 147, 152, 156, 159], "said": [16, 58, 65, 156], "sake": [48, 88, 133], "salutari": 7, "sam": [133, 136], "same": [0, 4, 5, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 22, 23, 25, 30, 31, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 52, 53, 55, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 77, 79, 82, 83, 86, 92, 93, 94, 95, 96, 105, 107, 117, 121, 123, 125, 126, 127, 129, 130, 133, 134, 135, 136, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 156, 159, 161, 162, 163], "samp_label": 126, "sampl": [0, 1, 3, 6, 16, 19, 23, 29, 34, 37, 39, 40, 41, 42, 43, 45, 46, 47, 49, 51, 53, 59, 63, 66, 67, 69, 70, 72, 73, 79, 80, 81, 86, 88, 89, 92, 93, 94, 95, 96, 101, 102, 103, 117, 120, 121, 122, 124, 126, 127, 129, 130, 136, 142, 143, 147, 148, 158, 161, 163], "sample_i": 81, "sample_mean": 65, "sample_means_fixed_sample_s": 33, "sample_nod": [73, 93], "sample_posterior_predict": [73, 93], "sample_proba": [73, 93], "sample_s": 33, "sample_sort": 96, "sample_stat": 151, "sample_std": 65, "sampler": [1, 6, 7, 38, 41, 44, 51, 59, 73, 74, 93, 94, 143, 144, 146, 147, 148, 153, 154, 160], "sampler_object": 41, "samples_md": 123, "samples_md_poco": 123, "samples_save_dir": 123, "samples_spars": 6, "samples_unflatten": [50, 143], "samples_wmd": 123, "samples_wmd_poco": 123, "samplescor": [78, 82], "samplesuncor": [78, 82], "samplig": 154, "sampling_tim": 151, "samwis": 133, "sandbox": 86, "saniti": 136, "santayana": 46, "sarah": [1, 56], "satisfi": [3, 4, 7, 29, 31, 46, 51, 53, 95, 130, 148, 156, 159], "satur": [49, 52, 90, 96], "save": [6, 7, 19, 42, 44, 66, 69, 96, 123, 126, 133, 136, 138, 142, 147, 152], "save_fig": 133, "save_model": 69, "savefig": [6, 73, 126, 133, 134, 149, 150], "savefig_kwarg": 126, "saw": [49, 82], "sbn": 143, "scalabl": 73, "scalar": [44, 47, 50, 65, 71, 85, 86, 96, 125, 127, 129, 143, 146], "scale": [13, 17, 19, 33, 34, 37, 38, 40, 41, 42, 43, 44, 47, 50, 51, 65, 67, 69, 71, 72, 77, 78, 79, 80, 81, 82, 83, 86, 95, 96, 105, 113, 120, 123, 126, 127, 129, 130, 143, 145, 147, 151, 152, 153, 159, 162, 163], "scale_": 123, "scaled_sum": 29, "scaler": 123, "scan": 88, "scandinavian_entropi": 4, "scatter": [34, 38, 39, 41, 42, 45, 47, 65, 70, 71, 72, 73, 78, 80, 81, 82, 93, 102, 127, 133, 151, 152, 154], "scatter_joint_bnn_plot": 72, "scatterplot": 65, "scb": 130, "sccord": 130, "scenario": [4, 7, 43, 44, 48, 53, 64, 66, 67, 72, 121, 159, 161], "schack": 128, "sched_getaffin": 123, "schedul": [105, 107], "schemat": [47, 79, 117, 146, 159], "schematic_rbm": 47, "scheme": [46, 65, 116, 153], "school": [8, 22, 39, 53, 56, 63, 77, 83, 147, 152], "schoot": [1, 43], "schroding": [23, 47, 79], "schr\u00f6dinger": 45, "schwab": 1, "sch\u00f6n": 1, "sci": 1, "scienc": [0, 1, 8, 16, 43, 47, 48, 53, 56, 57, 58, 60, 61, 62, 63, 66, 67, 104, 117, 134, 145, 153, 162], "scientif": [7, 8, 15, 16, 25, 40, 43, 45, 46, 48, 53, 56, 58, 60, 61, 62, 64, 65, 67, 104, 110, 111, 119, 126, 128, 134, 137, 140, 161], "scientist": [1, 8, 53, 63, 64, 130], "scikit": [1, 64, 66, 81, 86, 93, 133, 136, 137], "scikitlearn": 133, "scipi": [0, 5, 6, 7, 9, 13, 19, 23, 29, 30, 33, 34, 37, 38, 39, 40, 41, 42, 49, 65, 69, 78, 82, 92, 95, 96, 123, 126, 127, 134, 136, 137, 143, 144, 145, 147, 149, 150, 151, 152, 153, 154, 162], "scope": [8, 111], "score": [67, 69, 70, 75, 133, 151], "scorn": 58, "scott": 136, "scratch": [44, 69], "screen": [31, 44, 56, 63, 149], "script": [0, 43, 129, 154, 156, 161], "scroll": [17, 130, 134], "sd": [145, 151, 152, 162], "se": [1, 16, 47, 58, 78, 82, 143, 146], "seaborn": [5, 9, 17, 33, 37, 38, 39, 40, 41, 42, 49, 50, 70, 73, 77, 78, 92, 93, 95, 96, 133, 135, 143, 144, 145, 147, 152], "seali": [0, 23], "search": [1, 46, 56, 67, 104, 105, 130, 134, 156, 161], "searchsort": [37, 40, 41], "sebastian": 107, "sec": [0, 41, 43, 123], "second": [7, 8, 16, 17, 19, 22, 23, 25, 31, 32, 34, 35, 38, 39, 41, 43, 44, 46, 48, 49, 52, 53, 64, 66, 67, 68, 69, 71, 72, 73, 85, 96, 102, 107, 110, 112, 125, 126, 130, 133, 134, 136, 144, 146, 147, 150, 151, 152, 156, 159], "secondari": 94, "secondli": 68, "section": [8, 9, 14, 23, 26, 30, 34, 35, 37, 42, 43, 48, 56, 58, 61, 65, 77, 81, 83, 86, 90, 91, 94, 96, 102, 112, 113, 118, 125, 132, 133, 137, 145, 155, 157, 162], "sector": [1, 64, 67], "sedol": 73, "see": [0, 3, 4, 5, 7, 9, 11, 13, 15, 16, 19, 23, 25, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 56, 59, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 92, 93, 94, 95, 96, 97, 100, 104, 105, 112, 113, 116, 118, 121, 127, 130, 131, 133, 134, 136, 137, 139, 140, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 156, 159, 162], "seed": [6, 9, 17, 25, 30, 38, 39, 40, 65, 66, 70, 78, 82, 92, 93, 95, 96, 123, 130, 133, 143, 144, 147, 152, 156, 159, 161], "seek": [9, 10, 16, 19, 23, 30, 34, 44, 45, 47, 49, 51, 55, 56, 62, 67, 85, 97, 100, 104, 107, 121, 147, 148, 152, 153], "seem": [0, 5, 19, 22, 25, 31, 38, 39, 44, 48, 49, 53, 62, 73, 75, 77, 83, 147, 151, 152, 154, 156, 160], "seen": [7, 8, 34, 53, 62, 63, 68, 72, 75, 78, 82, 86, 88, 102, 127, 134, 144, 146, 148, 153, 154, 156, 159], "sekstromforssen22": [1, 44], "selct": 130, "seldomli": 8, "select": [1, 9, 16, 43, 47, 52, 54, 55, 56, 59, 64, 65, 66, 72, 77, 78, 80, 82, 83, 86, 89, 90, 91, 92, 96, 103, 129, 133, 134, 137, 149, 157, 161], "selection_mini": 90, "self": [9, 50, 59, 64, 71, 79, 96, 123, 126, 149, 150, 156, 161], "semi": [34, 77, 83, 92, 127], "semicolon": 138, "semidefinit": [82, 86], "semilogi": [95, 127, 149, 150], "semilogx": 162, "sen": 34, "send": 67, "sens": [4, 7, 8, 16, 25, 34, 35, 38, 40, 41, 47, 52, 59, 62, 63, 66, 73, 93, 96, 100, 101, 130, 143, 144, 146, 151, 156], "sensibl": [4, 25, 75], "sensit": [0, 5, 8, 35, 38, 40, 43, 44, 46, 47, 49, 51, 66, 94, 95, 97, 122], "sentenc": [63, 67], "sentiment": 63, "sep": 133, "separ": [8, 34, 43, 44, 47, 50, 51, 53, 63, 64, 65, 73, 77, 83, 86, 93, 96, 99, 134, 135, 142, 143, 146], "septemb": 1, "sequenc": [1, 15, 30, 44, 67, 72, 75, 88, 92, 126, 130, 136, 138, 143, 156, 159, 161], "sequenti": [15, 25, 30, 67, 69, 70, 71, 76, 121, 129, 134, 136], "seri": [1, 8, 16, 33, 34, 37, 38, 39, 49, 55, 56, 64, 91, 94, 112, 133, 143, 147, 152, 154, 162], "serif": 133, "seriou": [8, 63, 64, 134], "serv": [44, 75, 86, 88, 120, 121, 123, 133, 158], "server": [56, 131], "servic": 64, "set": [0, 1, 3, 4, 5, 7, 8, 11, 15, 16, 17, 19, 21, 22, 23, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 76, 78, 79, 80, 82, 85, 86, 88, 91, 92, 93, 94, 95, 96, 97, 99, 100, 102, 104, 105, 106, 107, 110, 111, 115, 117, 120, 121, 126, 127, 129, 130, 131, 133, 134, 135, 137, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 156, 159, 160, 161, 162, 163], "set_alpha": 9, "set_aspect": [40, 50, 65, 78, 82, 127, 135, 149, 150], "set_axis_off": 127, "set_axisbelow": 40, "set_color": [69, 76], "set_context": [5, 9, 38, 39, 42, 70, 73, 77, 78, 92, 93, 143, 144, 147, 152], "set_data": 73, "set_limit": [78, 82], "set_printopt": 127, "set_size_inch": 17, "set_styl": [73, 78, 92, 143], "set_titl": [3, 6, 9, 17, 29, 33, 34, 37, 38, 40, 41, 42, 49, 50, 65, 77, 78, 81, 82, 83, 102, 126, 127, 129, 132, 134, 135, 143, 145, 149, 150, 161, 162], "set_tt_rng": [73, 93], "set_vis": 126, "set_xlabel": [0, 3, 5, 6, 7, 9, 17, 25, 30, 33, 34, 37, 39, 40, 41, 42, 49, 65, 70, 73, 78, 81, 82, 88, 93, 95, 96, 102, 126, 127, 129, 130, 132, 133, 134, 135, 143, 145, 149, 150, 152, 153, 161, 162], "set_xlim": [6, 29, 33, 37, 42, 49, 50, 70, 77, 78, 95, 96, 126, 129, 130, 145, 149, 150, 162], "set_xtick": [78, 82], "set_ylabel": [0, 3, 5, 6, 7, 17, 25, 30, 33, 34, 37, 39, 40, 41, 49, 50, 65, 70, 73, 78, 81, 82, 88, 93, 95, 96, 102, 126, 129, 130, 132, 133, 134, 135, 143, 145, 149, 150, 152, 153, 161, 162], "set_ylim": [3, 6, 37, 42, 49, 50, 70, 81, 95, 96, 126, 129, 130, 145, 149, 150, 161, 162], "set_ytick": [9, 42], "set_zlabel": [65, 130], "set_zlim": 65, "settl": [8, 156], "setup": [9, 25, 30, 34, 48, 50, 51, 71, 101, 102, 126, 132, 137, 143, 146, 147, 152], "setup_mod": 50, "setup_polynomial_design_matrix": [34, 102], "setup_rc_param": [123, 126], "setup_text": [9, 132], "seven": 63, "sever": [4, 7, 8, 9, 16, 17, 19, 29, 33, 38, 40, 42, 44, 46, 48, 53, 56, 63, 64, 65, 66, 67, 72, 73, 75, 76, 85, 88, 92, 95, 96, 97, 104, 105, 107, 117, 127, 128, 129, 130, 133, 134, 137, 140, 150, 153, 156, 163], "sexual": 63, "sg92": [1, 44], "sgd": [67, 106], "shade": [17, 37, 53, 126, 130], "shall": [46, 92, 123], "shallow": 19, "shannon": [4, 62], "shape": [6, 13, 25, 33, 34, 37, 41, 43, 50, 53, 65, 67, 69, 70, 73, 76, 77, 78, 80, 82, 83, 88, 92, 93, 94, 95, 96, 123, 126, 127, 130, 138, 143, 145, 146, 147, 148, 149, 151, 152, 153, 154, 156, 158, 159, 162], "share": [7, 43, 50, 56, 61, 72, 73, 81, 93, 96, 126, 133, 152, 156], "sharei": [3, 6, 25, 30, 40, 65, 78, 81, 82, 88, 130, 143, 161], "sharex": [3, 6, 25, 30, 40, 41, 81], "sharp": [19, 53, 65], "sharpli": [19, 34, 51, 67], "shave": 7, "she": [62, 88], "shed": 53, "sheet": [51, 136], "shef": 77, "sheffield": [77, 83, 85], "shell": [47, 126, 133, 154], "shift": [3, 5, 16, 39, 44, 72, 79, 123, 127, 134, 136, 138, 143, 144, 147, 152, 159], "shifti": 128, "shine": [40, 51], "ship": 76, "shire": 133, "sho": 1, "shop": 137, "shore": 4, "short": [7, 22, 23, 31, 32, 40, 44, 51, 56, 63, 67, 69, 72, 96, 126, 128, 136, 152, 156, 161], "shortcut": 136, "shorten": [0, 43], "shorter": [44, 144], "shorthand": [7, 25, 30, 66, 104, 107, 133], "shortli": 8, "shoud": 30, "should": [4, 7, 8, 9, 10, 15, 16, 18, 19, 21, 22, 23, 25, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 43, 44, 45, 46, 48, 51, 53, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 77, 78, 82, 83, 85, 86, 88, 93, 94, 95, 97, 102, 105, 106, 110, 111, 122, 123, 126, 127, 129, 130, 134, 136, 137, 143, 145, 147, 151, 152, 153, 154, 156, 159, 161, 162], "shouldn": [29, 137, 142], "show": [4, 7, 9, 11, 13, 16, 17, 24, 25, 30, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 49, 50, 51, 62, 65, 66, 67, 69, 70, 71, 72, 73, 76, 77, 79, 82, 83, 85, 86, 90, 93, 94, 96, 97, 99, 120, 121, 123, 124, 125, 127, 130, 132, 133, 134, 135, 137, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 159, 161], "show_titl": [17, 38, 41, 50, 82, 94, 96, 123, 143, 147, 152], "shown": [4, 7, 9, 17, 19, 25, 34, 37, 38, 44, 47, 51, 65, 66, 67, 72, 73, 77, 81, 83, 95, 107, 121, 127, 130, 133, 134, 135, 136, 144, 151, 156, 161, 163], "shrink": [17, 37, 46, 76, 126, 142], "shrinkag": 66, "shuch": 130, "shuffl": [65, 106], "side": [3, 7, 8, 10, 16, 19, 22, 23, 25, 31, 34, 39, 44, 47, 53, 65, 72, 125, 130, 142, 145, 147, 149, 150, 152, 153, 156, 159, 161], "sig": [41, 50], "sig0": [38, 95], "sig_vm": 41, "siga": 7, "sigd": [0, 7], "sigf": 7, "sigh": [0, 7], "sight": 53, "sigma": [1, 3, 4, 7, 9, 17, 19, 24, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 44, 50, 52, 53, 66, 70, 72, 73, 78, 79, 82, 85, 86, 92, 93, 94, 95, 96, 97, 117, 125, 126, 127, 129, 130, 143, 144, 146, 147, 148, 151, 152, 153, 154, 158, 159, 161, 162], "sigma0": [38, 95], "sigma1": [50, 130], "sigma11_sq": 34, "sigma1inv": 50, "sigma2": [17, 34, 50, 126, 130], "sigma2inv": 50, "sigma_": [7, 24, 29, 34, 45, 46, 52, 66, 82, 85, 86, 90, 96, 102, 123, 125, 130, 158, 161], "sigma_0": [34, 38, 39, 52, 81, 95, 147, 152], "sigma_0_bound": 81, "sigma_1": [34, 38, 48, 72, 86, 130], "sigma_2": [72, 86, 130], "sigma_a": 7, "sigma_b": 38, "sigma_contour": 41, "sigma_error": [34, 102], "sigma_est": [39, 147, 152], "sigma_exp": 96, "sigma_f": [7, 82, 85], "sigma_f_opt": 82, "sigma_fn": 70, "sigma_h": [7, 123], "sigma_i": [7, 29, 34, 35, 38, 48, 53, 65, 78, 82, 86, 96, 97, 113, 120, 146], "sigma_interval__": 152, "sigma_j": 82, "sigma_k": 4, "sigma_mat": 49, "sigma_mat_inv": 49, "sigma_max": 126, "sigma_mean_prior": 151, "sigma_n": [47, 86, 153], "sigma_now": 126, "sigma_nu": 82, "sigma_prior": 151, "sigma_sampl": 92, "sigma_sd_prior": 151, "sigma_t": [7, 50, 96], "sigma_tild": 33, "sigma_tru": [35, 39, 147, 152], "sigma_v": [7, 41, 123, 126], "sigma_w": 72, "sigma_x": [7, 35, 53, 78, 86], "sigma_z": [7, 67, 82], "sigmacor": [78, 82], "sigmai": 34, "sigmamat": 127, "sigmamv": 82, "sigmap": 50, "sigmapinv": 50, "sigmar": 34, "sigmauncor": [78, 82], "sigmavec": [52, 79, 86, 125, 154], "sigmoid": [1, 67, 68, 70, 71, 73, 88, 93, 129], "sigmoid_functions_fig": 88, "sign": [4, 43, 51, 53, 65, 66, 88, 119, 134, 137, 143, 148, 161], "signal": [1, 7, 25, 38, 44, 51, 53, 65, 70, 72, 73, 82, 85, 88, 90, 91, 96, 154], "signatur": [44, 51], "signific": [4, 50, 51, 53, 56, 105, 127, 136, 154], "significantli": [29, 45, 53, 66, 71, 97, 107, 121, 125, 136, 153, 154], "sigp": 50, "sigv": [0, 7], "silenc": [67, 133], "silicon": 137, "silver": 16, "sim": [3, 29, 34, 38, 40, 41, 44, 45, 49, 51, 72, 74, 77, 79, 82, 83, 85, 86, 95, 102, 120, 123, 126, 130, 143, 144, 145, 153, 154, 158, 159, 162], "similar": [39, 40, 43, 44, 46, 51, 53, 65, 67, 71, 73, 75, 80, 88, 96, 97, 107, 134, 142, 146, 148], "similarli": [15, 53, 72, 82, 133, 159], "simon": [8, 34], "simp": [37, 156], "simpl": [0, 1, 4, 5, 7, 20, 25, 32, 34, 38, 39, 40, 41, 44, 46, 47, 48, 49, 50, 53, 63, 64, 65, 66, 69, 71, 72, 73, 75, 76, 80, 88, 93, 95, 96, 98, 101, 102, 107, 117, 121, 130, 133, 134, 138, 143, 144, 147, 149, 150, 151, 153, 154, 163], "simpler": [7, 52, 53, 71, 121, 130, 132, 153], "simplest": [7, 15, 47, 53, 67, 69, 75, 85, 88, 130, 134, 161], "simpli": [7, 9, 13, 17, 24, 25, 34, 38, 39, 40, 41, 43, 48, 53, 56, 63, 64, 65, 67, 71, 95, 117, 119, 123, 127, 130, 133, 136, 142, 144, 146, 147, 149, 152, 153, 154, 161], "simplic": [7, 34, 38, 44, 48, 67, 71, 86, 88, 110, 121, 156], "simplif": [115, 127], "simplifi": [24, 34, 42, 44, 49, 52, 53, 65, 95, 107, 146, 153, 154], "simpson": [37, 51, 154], "simul": [1, 11, 25, 30, 43, 44, 45, 51, 58, 67, 122, 124, 143, 146, 148, 153, 154, 156, 161], "simultan": [25, 47, 62, 66, 119], "sin": [34, 71, 77, 80, 81, 83, 92, 95, 112, 114, 127, 132, 134, 135, 136, 138, 149, 150], "sinc": [4, 6, 7, 8, 13, 16, 19, 25, 33, 34, 35, 41, 44, 48, 53, 64, 66, 71, 72, 77, 78, 83, 85, 95, 96, 100, 104, 106, 111, 115, 121, 123, 125, 130, 133, 134, 142, 143, 144, 151, 153, 156, 161], "sine": [34, 132, 134, 135, 136], "sine_and_exp": 134, "sine_and_exp_transpar": 134, "sine_map": 135, "singer": 1, "singl": [4, 7, 30, 34, 37, 38, 39, 40, 43, 46, 47, 48, 49, 63, 65, 66, 67, 70, 71, 72, 73, 74, 75, 82, 85, 88, 95, 96, 99, 100, 106, 115, 130, 133, 134, 135, 136, 143, 144, 147, 152, 154, 161], "single_cauchy_likelihood": 38, "single_conservative_likelihood": 38, "single_gaussian_likelihood": 38, "single_neuron": 70, "single_neuron_binary_classifi": 70, "single_prior": 81, "singular": [5, 47, 66, 124, 127], "singularli": 125, "sinh": 71, "sir": 1, "sit": 34, "site": [50, 64, 81, 96, 126, 151, 152, 154], "situat": [4, 7, 8, 16, 33, 34, 38, 39, 40, 44, 46, 48, 51, 52, 53, 63, 66, 71, 77, 88, 90, 101, 102, 105, 130, 144, 147, 152, 153, 154, 159, 161], "sivia": [1, 2, 7, 9, 27, 37, 38, 39, 42, 53, 56, 90, 95, 96, 147, 152], "six": [3, 4, 47, 154], "sixth": 156, "size": [3, 4, 5, 7, 9, 17, 29, 34, 35, 37, 39, 40, 42, 43, 44, 46, 47, 49, 50, 66, 67, 69, 70, 73, 74, 75, 76, 77, 79, 80, 82, 83, 86, 92, 93, 95, 96, 97, 102, 106, 111, 117, 123, 126, 127, 130, 132, 133, 137, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 159, 161, 162, 163], "sk": 96, "skate": 151, "skater": 151, "skeleton": 134, "skew": [18, 35, 53, 63, 153], "ski": 156, "skill": [1, 4, 37, 56, 64], "skimag": 127, "skin": 1, "skip": [0, 35, 79, 127, 133, 142, 145, 159, 162], "skirt": [39, 147, 152], "skl": 133, "sklearn": [50, 70, 73, 74, 80, 81, 82, 93, 123, 127, 133], "sky": [0, 1, 22, 95, 156], "slab": 73, "slant": [53, 146], "slate": 71, "slice": [136, 149, 151, 152, 156], "slide": 75, "slider": [9, 11, 132, 134], "slider_bord": 132, "slight": [43, 71], "slightli": [5, 7, 34, 38, 40, 60, 66, 151, 161], "slope": [3, 6, 23, 34, 35, 37, 38, 40, 41, 53, 86, 105, 143], "slope_limit": 40, "slope_max": 41, "slope_prior": [3, 6], "slope_rang": [40, 41], "slope_sampl": 41, "slopesamples_fig": 3, "sloppi": [23, 127], "slow": [64, 73, 105, 126, 133, 135, 151], "slowli": [66, 68, 73, 79, 106, 154], "small": [0, 5, 7, 8, 9, 17, 19, 23, 29, 34, 38, 39, 44, 46, 47, 48, 51, 53, 63, 66, 67, 68, 71, 72, 73, 75, 77, 78, 80, 82, 83, 85, 86, 97, 101, 105, 107, 114, 115, 121, 127, 136, 137, 144, 146, 147, 151, 152, 153, 154], "small_list_a": 135, "smaller": [4, 7, 29, 31, 33, 37, 44, 45, 46, 47, 53, 63, 66, 68, 96, 97, 105, 149, 150, 153, 161], "smallest": [41, 125, 127, 130, 133], "smartphon": 134, "smhi": 16, "smith": 1, "sml": 1, "smlbook": 1, "smooth": [4, 5, 9, 30, 45, 47, 78, 79, 82, 85, 86], "smoother": [47, 151], "sn": [5, 9, 17, 33, 37, 38, 39, 42, 50, 70, 73, 77, 78, 92, 93, 95, 96, 133, 144, 147, 152], "snapshot": [45, 47, 126], "snippet": [92, 96, 146], "snow": 156, "so": [3, 4, 5, 7, 8, 9, 11, 13, 15, 16, 17, 18, 19, 22, 23, 25, 26, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 82, 83, 85, 86, 88, 89, 92, 93, 94, 95, 96, 97, 100, 102, 117, 119, 123, 125, 126, 127, 130, 132, 133, 134, 136, 137, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 159, 161, 162], "social": [8, 48, 63, 64], "societ": [63, 64], "societi": [1, 63], "soft": [43, 88], "softmax": [67, 69, 71, 75, 76], "softplu": [72, 117], "softwar": [43, 51, 63, 64, 73, 76, 77, 83, 89, 93, 105, 137, 143, 146], "sol": 123, "sold": 8, "sole": [8, 43, 49, 51, 56], "solid": [7, 37, 42, 44, 49, 64, 79, 86, 88, 132, 150], "solut": [4, 44, 45, 47, 48, 68, 79, 100, 104, 105, 117, 123, 127, 136, 137, 148, 149, 150, 154], "solv": [3, 7, 31, 34, 39, 44, 45, 46, 47, 61, 64, 65, 66, 67, 69, 79, 85, 96, 97, 100, 101, 104, 123, 125, 134, 147, 149, 152, 156, 161], "solvabl": 153, "solve_ivp": [149, 150], "solve_od": [149, 150], "solve_ode_eul": 150, "solve_ode_leapfrog": 150, "solver": [47, 70, 148], "some": [4, 5, 7, 8, 9, 10, 16, 18, 19, 21, 22, 23, 24, 25, 26, 28, 30, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 95, 96, 97, 101, 102, 104, 105, 107, 108, 110, 113, 116, 117, 122, 127, 128, 130, 133, 134, 135, 136, 137, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 156, 159, 161, 162], "someon": [8, 48, 56], "someth": [3, 8, 16, 19, 21, 39, 42, 62, 63, 66, 71, 73, 106, 134, 137, 147, 148, 152], "sometim": [7, 8, 16, 18, 23, 34, 39, 43, 47, 48, 53, 60, 64, 67, 72, 85, 98, 119, 122, 126, 130, 134, 144, 147, 152, 153, 156], "somewhat": [8, 16, 19, 23, 34, 51, 53, 99, 107], "somewher": [34, 144], "son": 1, "soon": 53, "sophist": [46, 48, 95, 133, 144, 153], "sort": [19, 37, 40, 41, 53, 65, 67, 73, 78, 82, 96, 127, 134], "sorted_": [37, 40], "sorted_lnprob": 41, "sound": [63, 64, 134], "sourc": [0, 17, 33, 42, 43, 51, 56, 64, 66, 76, 87, 122, 133, 134, 135, 137, 142, 161], "sp": [69, 78, 92, 127, 156, 161], "space": [8, 17, 19, 21, 23, 33, 37, 38, 40, 44, 45, 46, 47, 51, 52, 53, 59, 62, 64, 65, 67, 71, 72, 73, 77, 78, 79, 82, 83, 85, 86, 93, 95, 96, 104, 119, 120, 126, 130, 134, 143, 144, 146, 148, 149, 150, 151, 153, 154, 156, 159, 161], "spacetim": 16, "span": [34, 47, 48, 66, 102, 127, 133], "spars": 71, "sparse_categorical_crossentropi": [69, 76], "sparsiti": 73, "spatial": [51, 67, 75, 117, 123, 127, 149], "speak": [8, 56, 59, 79, 130], "speci": 62, "special": [8, 16, 17, 23, 34, 38, 39, 47, 48, 53, 63, 65, 68, 73, 86, 88, 96, 130, 133, 146, 147, 148, 151, 152, 153, 154], "specif": [4, 7, 23, 25, 34, 38, 41, 43, 45, 46, 48, 50, 53, 58, 59, 61, 62, 63, 64, 65, 66, 67, 71, 72, 74, 75, 76, 78, 82, 86, 88, 96, 111, 119, 120, 123, 129, 130, 133, 136, 144, 153, 156, 161], "specifi": [3, 4, 5, 7, 9, 10, 17, 22, 23, 25, 34, 37, 38, 39, 40, 41, 42, 43, 46, 48, 49, 50, 51, 53, 55, 58, 59, 67, 69, 73, 78, 79, 80, 82, 85, 86, 88, 91, 94, 95, 117, 119, 120, 121, 123, 129, 130, 132, 136, 137, 143, 147, 149, 150, 151, 152, 153, 154, 158, 161], "specifii": 79, "speckl": 156, "spectacular": 48, "spectroscopi": 96, "spectrum": [47, 90, 96, 125], "speech": [64, 67], "speed": [47, 68, 71, 73, 93, 134, 136], "spell": [61, 134], "spend": [43, 62, 154], "spent": [7, 60], "sphere": 123, "spheric": 148, "spike": 73, "spin": [67, 117, 130], "spirit": [40, 46, 53, 58], "spite": 64, "split": [6, 43, 50, 64, 66, 67, 85, 93, 128, 143, 146, 161], "spot": [53, 63], "spread": [4, 66, 79, 130, 142, 146, 159], "springer": 1, "sqrt": [0, 4, 7, 9, 19, 24, 29, 30, 33, 34, 37, 38, 39, 40, 41, 44, 46, 48, 49, 50, 52, 53, 66, 67, 71, 78, 79, 82, 86, 95, 96, 107, 123, 126, 129, 130, 134, 136, 138, 143, 144, 146, 147, 149, 151, 152, 153, 154, 159, 162], "squar": [4, 17, 19, 23, 24, 26, 38, 41, 44, 46, 51, 52, 65, 66, 67, 71, 72, 75, 77, 78, 83, 86, 88, 94, 95, 96, 97, 101, 102, 105, 107, 110, 125, 127, 130, 133, 134, 135, 136, 154], "square_cube_list": 135, "square_loss": 38, "squared_loss": 38, "squeez": [80, 81], "sr": [147, 152], "ss06": [1, 2, 27, 35, 53, 56], "st": 63, "stabil": [6, 16, 38, 61, 72, 73, 85, 93, 123, 146, 147, 152], "stabl": [1, 37, 44, 65, 81, 93, 106, 133, 143], "stack": [0, 69, 73, 75, 76, 93, 134], "stacklevel": [50, 96], "stackoverflow": [73, 93, 138], "stackrel": [19, 33, 37], "staffwww": 77, "stage": [9, 11, 23, 34, 40, 44, 47, 63, 64, 143], "stai": [144, 145, 146, 154, 156, 162], "stan": [1, 40, 44, 72, 73, 153], "stanc": 8, "stand": [9, 11, 21, 38, 40, 64, 66, 133, 143, 148, 151], "standalon": 152, "standard": [3, 4, 15, 16, 19, 20, 24, 25, 29, 32, 33, 34, 35, 37, 39, 40, 41, 43, 44, 46, 48, 50, 53, 62, 63, 64, 65, 66, 67, 71, 72, 73, 74, 77, 78, 80, 81, 83, 85, 93, 94, 95, 101, 105, 107, 120, 121, 123, 126, 127, 129, 130, 133, 135, 138, 144, 145, 146, 147, 151, 152, 153, 158, 159, 161, 162], "standardize_data": 65, "standardscal": 123, "stanford": 75, "stapl": 16, "star": [48, 147, 152, 163], "start": [5, 6, 7, 9, 15, 16, 19, 25, 26, 30, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 55, 65, 66, 67, 68, 71, 78, 79, 80, 81, 82, 86, 92, 93, 94, 95, 96, 97, 105, 110, 114, 117, 123, 125, 126, 129, 130, 133, 134, 135, 136, 137, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 156, 159, 161, 162], "start_index": [149, 150], "start_new_sess": 126, "start_po": 144, "start_posit": 144, "start_stop_indic": [149, 150], "start_tim": 123, "starter": [7, 137], "starting_guess": [6, 38, 41, 96, 123, 147, 152], "startupinfo": 126, "startval": 151, "stat": [1, 5, 6, 9, 13, 19, 23, 29, 30, 33, 34, 37, 39, 42, 43, 49, 65, 69, 78, 82, 92, 96, 123, 126, 143, 144, 145, 147, 151, 152, 153, 154, 162], "state": [0, 4, 6, 7, 8, 9, 11, 21, 22, 25, 31, 32, 38, 44, 45, 46, 47, 50, 53, 56, 61, 66, 67, 71, 73, 85, 88, 123, 124, 127, 130, 133, 143, 147, 148, 151, 152, 159, 161], "statement": [0, 8, 16, 17, 19, 20, 22, 31, 33, 34, 43, 46, 53, 56, 62, 64, 65, 101, 110, 111, 130, 134, 135, 140, 158, 159], "static": [133, 134, 159], "stationar": [43, 44, 47, 143, 146, 161], "stationari": [43, 44, 45, 47, 71, 77, 79, 82, 83, 143, 146, 151, 153, 161], "statisc": 120, "statist": [1, 3, 4, 7, 9, 17, 20, 23, 24, 25, 26, 27, 29, 30, 34, 35, 37, 39, 44, 45, 48, 51, 55, 56, 59, 60, 62, 64, 66, 67, 72, 73, 88, 89, 92, 94, 97, 102, 108, 113, 117, 118, 120, 124, 127, 133, 142, 145, 147, 152, 154, 156, 158, 159, 161, 162], "statistician": [0, 1, 43, 56, 121, 130, 159], "stats_random_numb": 130, "stats_titl": 42, "statu": [34, 81, 88, 123], "std": [7, 17, 33, 38, 41, 50, 65, 67, 71, 73, 78, 81, 82, 93, 126, 129, 130, 133, 136, 143, 145, 151, 161, 162], "std_predict": 80, "std_train_data": 65, "stddev": 129, "stderr": 126, "stdin": 126, "stdmv": 82, "stdout": 126, "stdperiod": [77, 83], "steadi": 159, "steadili": [66, 97], "stealthili": 63, "steep": 151, "steer": [64, 69], "stein": 154, "stem": [47, 53, 63, 64, 119], "step": [4, 6, 7, 9, 15, 16, 22, 24, 25, 30, 34, 35, 37, 38, 42, 44, 46, 49, 53, 60, 65, 67, 68, 69, 70, 72, 76, 79, 88, 90, 92, 96, 97, 105, 106, 107, 123, 125, 130, 132, 133, 134, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 159, 161, 162, 163], "step1": 151, "step2": 151, "step_fn": 70, "step_method": 151, "step_siz": 146, "stepfil": 144, "stepsiz": [50, 143, 146], "stereotyp": 63, "stern": 1, "stick": [8, 23, 44, 61, 134, 144, 154], "still": [3, 8, 31, 34, 41, 43, 45, 46, 47, 51, 64, 65, 66, 67, 73, 75, 85, 93, 110, 127, 132, 135, 142, 148, 150, 154], "stimuli": 67, "stirl": [4, 37], "stochast": [1, 34, 43, 48, 59, 67, 68, 71, 72, 73, 78, 82, 85, 86, 88, 97, 110, 116, 123, 130, 153, 160, 163], "stochasticprocess": [156, 161], "stochasticprocessexampl": 161, "stoke": 67, "stone": [8, 88], "stoner": 1, "stongli": [78, 82], "stop": [9, 19, 22, 80, 81, 134, 137, 148, 159], "stop_index": [149, 150], "stopiter": 126, "storag": 136, "store": [0, 34, 38, 45, 50, 69, 102, 107, 125, 133, 136, 137, 144], "stori": [95, 151], "storylin": 11, "str": [6, 69, 78, 82, 135], "straight": [23, 34, 35, 38, 53, 65, 70, 78, 94, 97, 102, 103, 105, 114, 146, 153, 154], "straightforward": [4, 7, 25, 33, 34, 38, 39, 43, 46, 47, 53, 67, 85, 112, 147, 152, 153], "straightforwardli": 38, "strainghtforward": 46, "strang": [25, 53], "strategi": [7, 31, 39, 43, 46, 47, 48, 51, 66, 71, 117, 146, 147, 148, 152], "street": 128, "strength": [7, 43, 46, 47, 51, 53, 62, 64, 80, 95, 96, 110, 117, 130, 133, 146, 154], "strerror": 126, "stress": [46, 66, 113, 117, 134, 156], "stretch": [127, 146], "strftime": 126, "strict": 19, "strictli": 67, "string": [21, 42, 77, 83, 123, 135, 138], "stringent": 153, "strive": 8, "stroke": 88, "strong": [7, 38, 43, 48, 51, 65, 67, 86, 121, 146], "strongli": [7, 43, 53, 63, 64, 65, 75, 78, 82, 133], "strprior": 6, "structur": [7, 11, 16, 34, 45, 46, 47, 51, 64, 65, 66, 67, 71, 75, 77, 79, 83, 117, 133, 136, 151, 153], "sts412": 1, "stuck": [31, 42, 51, 96, 127, 148, 153], "student": [0, 18, 19, 23, 32, 38, 41, 44, 56, 62, 121, 124, 130, 134], "student_t_animation_": 126, "student_t_animation_04sep2025": 126, "studi": [7, 16, 19, 40, 41, 43, 45, 46, 48, 53, 56, 62, 63, 64, 67, 89, 92, 97, 119, 144, 156, 161], "stumbl": 151, "sty": 0, "style": [0, 9, 42, 76, 96, 134, 149], "sub": [51, 62, 67, 73, 92, 136], "subclass": 76, "subdirectori": [0, 123, 137], "subfield": [64, 122], "subgradi": 1, "subject": [4, 8, 22, 38, 39, 43, 46, 61, 62, 72, 110, 130, 147, 152, 156, 161], "subplot": [0, 3, 6, 7, 17, 25, 29, 30, 33, 34, 38, 39, 40, 41, 44, 49, 50, 65, 69, 70, 73, 76, 77, 78, 81, 82, 83, 88, 93, 95, 102, 129, 130, 133, 134, 135, 138, 143, 144, 152, 153, 161, 162], "subplot2grid": 152, "subplot_kw": 130, "subplots_adjust": 33, "subprocess": 126, "subprocess_creation_flag": 126, "subroutin": 133, "subscript": [5, 24, 85, 150], "subsect": [20, 43, 48, 56, 134], "subsequ": [7, 25, 43, 45, 46, 56, 67, 71, 129, 156, 161], "subset": [44, 45, 46, 47, 48, 63, 66, 67, 74, 86, 89, 104, 130, 136, 144, 148, 154, 156, 161], "subshel": 133, "subspac": [1, 45, 47, 127], "substanti": [43, 63], "substitut": [4, 7, 13, 19, 47, 53, 71, 150], "subsum": 16, "subtask": 90, "subtl": [48, 63], "subtleti": [39, 147, 152], "subtract": [22, 42, 52, 66, 71, 97, 125, 136, 159], "succe": 16, "succeed": [72, 145, 162], "succes": 44, "success": [9, 11, 19, 30, 33, 37, 39, 65, 86, 88, 119, 123, 137, 145, 151, 154, 159, 162], "successfulli": [123, 142], "succinctli": [34, 100], "suffer": [47, 66, 68], "suffici": [5, 19, 38, 43, 47, 51, 70, 71, 73, 93, 151, 153, 158], "suggest": [42, 51, 56, 63, 66, 107, 127, 134, 137, 143, 144, 146, 153], "suit": [46, 67, 71, 123], "suitabl": [43, 45, 53, 71, 120], "sum": [5, 9, 13, 15, 19, 20, 23, 26, 30, 31, 34, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 53, 65, 66, 67, 68, 69, 71, 72, 77, 78, 79, 83, 90, 92, 95, 96, 99, 100, 105, 106, 107, 117, 120, 123, 125, 126, 127, 130, 134, 135, 136, 143, 146, 147, 151, 152, 153, 156, 159, 161], "sum21": [1, 63], "sum_": [4, 13, 16, 19, 24, 29, 33, 34, 35, 38, 39, 40, 41, 44, 45, 47, 48, 49, 51, 52, 53, 65, 66, 67, 68, 72, 78, 82, 85, 88, 94, 95, 96, 97, 99, 100, 106, 107, 112, 113, 125, 127, 130, 143, 144, 146, 147, 151, 152, 153, 154, 156, 159, 161], "sum_0": 37, "sum_h": 85, "sum_i": [3, 4, 22, 25, 31, 32, 66, 72, 82, 154, 156], "sum_j": [22, 31, 32, 88, 127, 156], "sum_k": [15, 68, 127], "sum_n": 72, "sum_norm_squar": 29, "sum_of_squar": 135, "sum_xsq_val": 29, "summar": [4, 7, 9, 23, 24, 25, 30, 34, 43, 44, 46, 60, 66, 120, 130, 142, 159], "summari": [3, 4, 9, 17, 18, 27, 30, 38, 43, 44, 47, 51, 52, 56, 66, 68, 69, 70, 75, 76, 77, 83, 92, 94, 95, 117, 130, 131, 151, 152], "summaris": 46, "summat": [38, 44, 127, 144], "summer": [56, 77, 83], "sumpter": [1, 63], "sun": [8, 110], "sunil": [121, 123], "super": [71, 134], "superconductor": 130, "superfici": 75, "superflu": 47, "superior": [47, 135], "supermodel": 48, "supernova": 40, "superpos": [17, 33], "superposit": 1, "superscript": [67, 85], "supervis": [64, 66, 69, 88, 111, 133], "supplement": [62, 63, 88, 94, 116], "supplementari": [27, 38], "suppli": 67, "support": [1, 35, 43, 47, 51, 56, 63, 66, 73, 93, 95], "suppos": [4, 7, 9, 13, 15, 16, 19, 29, 31, 33, 37, 41, 48, 50, 52, 65, 67, 86, 88, 130, 134, 135, 146, 154, 156, 159], "supposedli": [64, 96], "suppress": [13, 19, 40, 48, 73, 78, 82, 86, 88, 93, 127, 132], "suptitl": [17, 33, 37, 42, 81, 144, 149, 150], "sure": [16, 17, 18, 24, 25, 29, 34, 37, 39, 82, 85, 92, 101, 125, 127, 132, 146, 147, 151, 152], "surf": 130, "surfac": [34, 37, 65, 97, 99, 105, 107, 130, 133, 148], "surmis": 122, "surpris": [7, 17, 30, 35, 39, 41, 51], "surprisingli": [147, 152], "surrog": [92, 122], "surround": [0, 43], "survei": 48, "susan": 98, "suspect": 38, "suspici": [9, 30], "suspicion": [9, 30, 38], "svd": [47, 79, 124], "svd_shape": 127, "svensson": [1, 44, 56], "svg": 127, "svgd": 154, "svisak": [44, 130, 161], "swap": 51, "swedish": 130, "swift": 64, "switch": [16, 33, 56, 73, 86, 93, 96, 125, 126, 127, 134, 138], "sword": 47, "sy": [38, 41, 50, 93, 123, 130, 143, 156, 161], "syllog": 62, "symbol": [9, 11, 34, 53, 72, 73, 85, 93, 99], "symmet": 148, "symmetr": [17, 18, 19, 35, 38, 40, 41, 44, 52, 53, 71, 72, 78, 82, 85, 127, 136, 143, 144, 148, 153, 154, 156], "symmetri": [16, 18, 23, 25, 43, 55, 71, 125, 148], "sympi": 37, "symplect": [44, 148], "synonym": 58, "syntax": [73, 93, 125, 134, 136], "syntaxerror": 134, "synthet": [17, 63, 80], "system": [1, 4, 8, 16, 46, 47, 51, 64, 67, 68, 88, 110, 111, 117, 119, 120, 121, 123, 148, 156, 161], "systemat": [7, 48, 51, 60, 62, 63, 72, 97, 104, 117], "t": [1, 5, 7, 8, 9, 11, 13, 15, 16, 18, 19, 22, 23, 25, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 44, 45, 48, 49, 50, 51, 53, 56, 58, 61, 63, 64, 65, 66, 68, 70, 72, 73, 74, 77, 78, 81, 82, 83, 85, 86, 88, 93, 94, 95, 96, 97, 100, 101, 102, 103, 114, 115, 117, 121, 123, 124, 125, 127, 130, 132, 133, 134, 136, 137, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 159, 161, 162], "t0": 123, "t1_dist": 17, "t1_label": 17, "t2_dist": 17, "t2_label": 17, "t3_dist": 17, "t3_label": 17, "t_": [132, 156], "t_0": 123, "t_1": 161, "t_2": 161, "t_color": 126, "t_df": 126, "t_dist": 126, "t_dist_max": 126, "t_dist_pt": 126, "t_end": [149, 150], "t_eval": [149, 150], "t_i": [68, 161], "t_j": 68, "t_k": 161, "t_label": 126, "t_loc": 126, "t_max": 132, "t_max_w": 132, "t_min": 132, "t_min_w": 132, "t_n": 156, "t_nois": 123, "t_ob": 123, "t_old": 161, "t_pt": [132, 134, 149, 150], "t_scale": 126, "t_start": [149, 150], "t_test": 74, "t_train": 74, "t_x": 156, "t_y": 156, "tab": [5, 9, 11, 39, 56, 79, 80, 86, 127, 134, 136, 138, 147, 152, 159], "tab0": [9, 132], "tab1": [9, 132], "tab2": [9, 132], "tab3": [9, 132], "tab_height": [9, 132], "tabl": [1, 4, 20, 24, 32, 42, 49, 51, 53, 56, 63, 64, 79, 94, 95, 96, 133], "tablet": 134, "tabul": [133, 156], "tabular": 133, "tadess": 1, "tag": [0, 43, 73, 93, 123], "tail": [8, 9, 11, 12, 15, 16, 17, 18, 19, 25, 33, 38, 39, 42, 43, 44, 51, 52, 53, 126, 130, 152, 153, 161], "tak": 91, "take": [0, 4, 5, 6, 9, 11, 19, 22, 29, 31, 33, 34, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 51, 52, 53, 56, 58, 60, 62, 63, 66, 67, 71, 72, 74, 75, 76, 78, 79, 81, 82, 86, 88, 91, 96, 117, 123, 127, 128, 129, 130, 131, 133, 134, 136, 137, 144, 145, 146, 147, 148, 151, 152, 153, 154, 156, 159, 161, 162], "taken": [4, 25, 29, 34, 37, 42, 47, 49, 56, 59, 60, 72, 78, 79, 86, 117, 120, 123, 136, 151], "taku": 73, "talent": [38, 39, 50, 56, 77, 95, 143, 144, 147, 152], "talk": [5, 9, 31, 38, 39, 40, 41, 42, 49, 50, 60, 70, 73, 77, 78, 86, 92, 93, 95, 122, 133, 134, 143, 144, 147, 151, 152], "tall": [7, 22, 31, 32, 110], "tan": [3, 34, 42, 49, 94, 102, 134], "tangent": [67, 117], "tangl": 19, "tanh": [67, 70, 71, 73, 88, 93, 129], "target": [44, 45, 46, 51, 64, 65, 67, 68, 70, 71, 72, 88, 123, 133, 136, 143, 146, 148, 154], "task": [7, 16, 17, 34, 37, 38, 42, 47, 49, 53, 62, 64, 65, 66, 67, 71, 72, 92, 93, 94, 95, 96, 110, 113, 127, 130, 134, 135, 136, 142, 153, 158], "tau": [44, 51, 144, 159], "tau_": 44, "tau_1": 51, "tau_2": 51, "tau_3": 51, "taught": [56, 59, 75, 127], "taylor": [1, 19, 34, 35, 49, 53, 91, 94, 149], "td": 42, "teach": 62, "teacher": 67, "tear": 1, "tech": [1, 67], "technic": 63, "techniqu": [1, 34, 51, 55, 64, 65, 66, 73, 94, 130, 148, 158], "technologi": [56, 63, 64, 104, 153], "techtarget": 89, "tediou": 7, "telescop": 62, "tell": [7, 9, 10, 11, 16, 17, 19, 22, 23, 25, 30, 31, 37, 49, 53, 58, 62, 66, 73, 79, 86, 93, 144, 146, 149, 154], "temp": [50, 96, 126], "temper": [50, 53, 90, 148, 163], "temperatur": [4, 44, 50, 51, 96, 130, 148], "tempering_ptemce": 51, "tempering_ptemcee_vs_zeu": 163, "tempor": 8, "temporarili": 23, "temps_hi": [50, 96], "temps_lo": [50, 96], "tempt": [40, 41, 115], "ten": [66, 72, 74, 92, 150, 153, 161], "tend": [9, 11, 19, 33, 42, 53, 64, 66, 68, 76, 107, 110, 130], "tendenc": [43, 63, 133, 153], "tension": [63, 66], "tensor": [73, 75, 76, 93, 129], "tensorflow": [1, 64, 66, 70, 71, 72, 73], "tensorflow_vers": 76, "term": [4, 7, 9, 15, 16, 19, 21, 25, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 58, 62, 63, 64, 65, 66, 67, 71, 72, 73, 85, 88, 89, 91, 99, 100, 101, 102, 106, 110, 115, 117, 118, 121, 123, 125, 127, 130, 133, 134, 136, 143, 144, 147, 148, 152, 156, 163], "termin": [34, 114, 123, 134, 161], "terminologi": [53, 63], "terribl": 31, "territori": 53, "test": [0, 5, 19, 22, 31, 32, 33, 34, 38, 43, 47, 49, 50, 51, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 82, 86, 93, 95, 96, 119, 120, 121, 127, 130, 134, 143, 145, 153, 156, 160, 161, 162], "test_acc": [69, 76], "test_f": 134, "test_imag": 76, "test_label": 76, "test_loss": [69, 76], "test_poisson_pt": 33, "test_siz": [73, 74], "test_valu": [73, 93], "testimoni": 8, "testinput": [64, 65, 66], "testinputs_i": 65, "testoutput": [64, 65, 66], "testval": [73, 93], "tex": 139, "text": [0, 1, 4, 7, 9, 10, 11, 12, 13, 15, 16, 19, 21, 23, 24, 25, 30, 31, 34, 35, 37, 38, 41, 42, 43, 44, 46, 47, 48, 51, 52, 53, 56, 57, 58, 60, 63, 65, 66, 67, 82, 90, 92, 95, 99, 104, 117, 126, 127, 130, 132, 134, 143, 146, 148, 153, 154, 156, 158, 159, 163], "text_i": [17, 126], "text_mod": 126, "text_represent": 0, "text_x": [17, 126], "text_x_mid": [17, 126], "textbf": [17, 78, 151], "textbook": [25, 46, 56, 66], "textbox0": [9, 132], "textbox1": [9, 132], "textiowrapp": 126, "textit": [35, 51], "textrm": [9, 17, 23, 30, 40, 41, 42, 49, 71, 95, 143, 151], "texttt": 121, "textur": 48, "tf": [69, 70, 76], "tf_cpp_min_log_level": 69, "th": [0, 3, 9, 11, 29, 33, 34, 35, 40, 42, 48, 49, 50, 66, 67, 68, 88, 94, 96, 107, 120, 130, 143, 154, 156, 158], "th0": 38, "th0_mcmc": 38, "th0neg": 38, "th0po": 38, "th1": [6, 38], "th1_mcmc": 38, "th1neg": 38, "th1po": 38, "than": [4, 7, 8, 9, 12, 17, 18, 19, 22, 23, 25, 29, 30, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 60, 62, 63, 65, 66, 67, 71, 72, 73, 77, 78, 79, 82, 83, 88, 93, 95, 96, 97, 99, 102, 104, 105, 110, 117, 119, 120, 121, 123, 125, 127, 128, 130, 133, 134, 135, 136, 143, 144, 146, 147, 151, 152, 153, 154, 158, 159, 161], "thank": [56, 133, 137], "theano": [93, 158], "theanof": [73, 93], "theanorc": 73, "thei": [0, 7, 8, 9, 15, 16, 17, 18, 19, 21, 22, 23, 30, 31, 32, 34, 35, 43, 44, 45, 46, 47, 48, 51, 52, 59, 60, 61, 62, 63, 64, 66, 67, 68, 72, 73, 75, 76, 77, 78, 83, 86, 91, 98, 102, 104, 110, 114, 117, 119, 125, 126, 127, 129, 130, 133, 134, 136, 143, 144, 146, 148, 151, 153, 156, 159], "them": [4, 7, 16, 19, 22, 23, 25, 29, 31, 34, 37, 38, 39, 40, 43, 44, 45, 47, 48, 50, 52, 53, 58, 59, 63, 64, 66, 67, 68, 69, 70, 73, 75, 76, 77, 78, 82, 83, 92, 93, 95, 96, 119, 123, 127, 130, 133, 134, 136, 137, 138, 142, 144, 147, 148, 152, 156], "theme": [47, 72], "themselv": [25, 43, 47, 53, 62, 111, 133], "theorem": [7, 8, 9, 10, 13, 16, 20, 24, 26, 27, 30, 31, 32, 34, 35, 37, 39, 42, 43, 44, 49, 51, 52, 53, 58, 62, 67, 72, 85, 129, 142, 147, 148, 151, 152, 153, 154, 156, 158], "theoret": [0, 3, 7, 17, 23, 25, 29, 38, 39, 40, 41, 43, 49, 51, 55, 59, 62, 111, 117, 119, 120, 121, 123, 124, 143, 147, 152, 154], "theori": [1, 4, 7, 8, 16, 19, 21, 24, 29, 33, 34, 40, 41, 43, 44, 46, 49, 51, 53, 56, 58, 59, 60, 61, 62, 64, 65, 67, 72, 79, 88, 89, 91, 94, 115, 117, 119, 121, 124, 126, 128, 130, 143, 147, 152, 154, 157, 160, 161], "theorist": 53, "thereaft": 133, "therebi": [45, 46, 47, 64, 65, 82, 88, 119, 133], "therefor": [4, 7, 8, 21, 23, 25, 29, 31, 34, 39, 41, 43, 45, 46, 48, 52, 53, 58, 62, 64, 65, 66, 67, 72, 78, 85, 86, 88, 96, 100, 104, 107, 110, 111, 113, 115, 130, 133, 136, 153, 156], "thermodynam": [51, 53, 144, 148], "thesi": 1, "theta": [0, 3, 6, 7, 9, 19, 30, 34, 38, 40, 41, 42, 44, 48, 49, 53, 65, 66, 72, 77, 78, 81, 83, 85, 92, 95, 97, 102, 123, 127, 130, 143, 147, 151, 152, 154], "theta0": [38, 143], "theta1": [38, 143], "theta2": 38, "theta3": 38, "theta_": [7, 50, 85, 95, 127, 143, 153, 154], "theta_0": [3, 38, 40, 41, 50, 53, 101, 102, 143, 146, 153], "theta_1": [3, 38, 40, 41, 50, 101, 102, 143, 153, 154], "theta_2": 154, "theta_and_phi": 123, "theta_dist": 42, "theta_hat": 95, "theta_i": [53, 66, 95, 154, 159], "theta_j": [29, 53, 95, 127, 151], "theta_k": [42, 48, 127, 159], "theta_max": 95, "theta_min": 95, "theta_ml": [38, 41], "theta_n": 154, "theta_ol": [34, 65, 102], "theta_tru": [34, 40, 49, 102, 143], "thetavec": [9, 10, 23, 30, 51, 52, 79, 86, 125, 127, 146, 148, 154], "thetavec_": [51, 125, 127, 154, 159], "thetavec_0": 159, "thetavec_1": 154, "thetavec_2": 154, "thetavec_a": 154, "thetavec_b": 154, "thetavec_i": 154, "thetavec_j": 125, "thetavec_k": [125, 159], "thetavechat": 125, "thetavechat_": 125, "thetavechat_j": 125, "thi": [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 88, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 160, 161, 162, 163], "thick": 51, "thicker": 51, "thim": 56, "thin": [50, 51, 96, 152], "thing": [0, 5, 8, 9, 10, 11, 16, 17, 19, 22, 29, 30, 31, 33, 43, 51, 53, 58, 62, 71, 73, 86, 93, 134, 148], "think": [4, 8, 11, 15, 16, 25, 31, 33, 34, 40, 48, 53, 62, 63, 64, 66, 67, 69, 73, 77, 83, 86, 95, 101, 117, 130, 142, 144, 145, 154, 156, 161, 162], "third": [0, 1, 4, 7, 16, 17, 25, 32, 34, 46, 56, 64, 71, 73, 75, 78, 82, 93, 133, 144, 150, 156], "thirteenth": 53, "thisplot": [69, 76], "thoma": [8, 73, 93, 144], "thorough": [29, 46, 61], "those": [7, 8, 9, 17, 23, 25, 30, 34, 37, 43, 44, 46, 48, 51, 56, 59, 60, 62, 63, 66, 67, 71, 74, 78, 85, 94, 97, 105, 121, 127, 130, 147, 152], "though": [0, 5, 12, 22, 39, 62, 64, 72, 121, 147, 152, 159], "thought": [7, 8, 52, 53, 66, 85, 125], "thousand": [45, 64, 67, 72], "thread": [50, 96, 123], "three": [0, 1, 3, 6, 7, 8, 9, 11, 16, 17, 18, 23, 29, 32, 34, 35, 37, 41, 43, 44, 47, 48, 51, 53, 56, 61, 65, 66, 67, 68, 71, 72, 74, 75, 77, 83, 88, 93, 95, 96, 112, 115, 117, 121, 125, 126, 127, 130, 133, 134, 136, 144, 151, 156], "threlkeld": 1, "threshold": [43, 53, 67, 75, 88, 127, 161], "through": [0, 4, 7, 9, 14, 16, 17, 22, 23, 25, 27, 30, 33, 34, 35, 38, 41, 42, 43, 46, 47, 48, 49, 53, 56, 58, 67, 68, 69, 71, 75, 76, 77, 78, 79, 82, 83, 85, 86, 88, 89, 90, 95, 96, 103, 117, 120, 125, 134, 137, 143, 144, 145, 146, 148, 150, 154, 158, 162], "throughout": [16, 23, 44, 48, 56, 58, 62, 95, 133], "throw": [4, 41, 44, 127, 151], "thu": [7, 11, 23, 34, 38, 41, 44, 47, 48, 52, 53, 58, 63, 64, 66, 67, 68, 73, 105, 120, 127, 130, 146, 149], "thumb": 29, "thursdai": 8, "thusfar": 16, "th\u00e9ori": 34, "tibshirani": 1, "tick": [9, 42, 43], "tick_param": 33, "tight": [9, 73, 93, 126, 149, 150], "tight_layout": [5, 7, 17, 29, 33, 37, 39, 40, 41, 42, 49, 50, 65, 69, 73, 76, 77, 78, 81, 82, 83, 93, 95, 126, 127, 129, 135, 143, 144, 145, 149, 150, 152, 162], "tighter": [46, 121], "tikhonov": 80, "tild": [7, 34, 44, 45, 52, 65, 66, 79, 86, 88, 97], "tildecovparslr": 34, "tile": [82, 96], "time": [4, 7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 41, 42, 44, 45, 47, 49, 50, 51, 52, 53, 56, 63, 65, 66, 67, 69, 73, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 92, 93, 94, 96, 99, 100, 106, 107, 114, 115, 117, 120, 121, 122, 123, 125, 126, 127, 130, 132, 133, 135, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 154, 156, 161, 162, 163], "timeit": [73, 135], "times_overview_text": 132, "times_overview_text_w": 132, "times_text": 132, "timestep": [44, 136], "titl": [0, 19, 56, 71, 73, 76, 77, 80, 81, 83, 93, 134, 144, 147, 149, 151, 152], "title_fmt": 96, "title_kwarg": [17, 38, 50, 96, 123, 143, 147, 152], "title_loc": 130, "title_str": [17, 33, 42], "tmax": [50, 96], "tmp": [37, 38, 77, 82, 133, 151], "tmp2": [78, 82], "tn": [63, 64], "to_numer": 133, "to_numpi": [34, 102], "toal": 18, "toc": 56, "todai": [16, 49, 64, 126, 128, 130, 156], "togeth": [19, 25, 27, 31, 38, 39, 40, 41, 48, 49, 66, 69, 72, 73, 74, 77, 82, 83, 86, 95, 96, 133, 143, 147, 152, 159], "toggl": [56, 123], "toi": [39, 47, 73, 90, 91, 93, 147, 152], "token": 53, "tol": [5, 50, 70], "told": [4, 16, 22, 31, 148], "toler": 5, "tolist": 136, "tomorrow": [8, 16, 17, 23, 130, 156], "tone": 58, "tonight": 21, "too": [19, 29, 31, 43, 44, 53, 62, 63, 71, 79, 94, 105, 144, 146, 148, 154, 159], "took": [133, 151, 152], "tool": [1, 7, 22, 34, 40, 41, 48, 56, 58, 59, 63, 64, 73, 95, 102, 105, 117, 125, 133, 134, 143], "toolbar": 134, "tooltip": 9, "top": [0, 1, 4, 9, 19, 25, 33, 42, 44, 51, 53, 56, 73, 77, 83, 94, 95, 127, 132, 134, 144, 149, 156, 161], "topic": [8, 43, 55, 64, 88, 89, 94, 147, 152, 161], "topologi": [67, 154], "tor": 56, "torch": [71, 129], "torchvis": 71, "torqu": 51, "torsion": 51, "toss": [8, 12, 13, 15, 19, 23, 161], "toss_coin_text": 9, "tot_val": 29, "total": [6, 19, 25, 31, 32, 34, 37, 38, 41, 44, 46, 48, 50, 63, 67, 68, 69, 71, 75, 76, 88, 93, 106, 117, 123, 127, 130, 133, 134, 143, 147, 148, 151, 152], "total_count": 37, "total_draw": 33, "total_huber_loss": 38, "total_length": 151, "total_s": [73, 93], "total_sampl": 50, "totalenergi": 133, "touch": [16, 94], "tough": 154, "tour": 134, "toward": [16, 53, 58, 62, 68, 72, 78, 88, 110, 143, 151], "tower": [121, 123], "tp": [63, 64], "tr": 42, "trace": [38, 41, 43, 44, 47, 50, 71, 73, 96, 138, 143, 144, 145, 146, 151, 154, 159, 162], "trace1": 41, "trace2": 41, "trace_2_sampl": 151, "trace_arrai": 151, "trace_inferencedata": 151, "trace_mh": 151, "trace_nut": [151, 152], "trace_titl": [145, 162], "trace_two_param": 151, "trace_unord": 96, "traceabl": 60, "traceback": [50, 69, 70, 73, 93, 96, 126], "traceplot": 73, "track": [22, 45, 53], "tractabl": [7, 34], "traction": 64, "trade": [92, 148], "tradeoff": 97, "tradit": [8, 64, 73, 116], "tradition": [62, 119], "train": [47, 60, 62, 64, 67, 68, 70, 71, 73, 74, 75, 78, 79, 80, 81, 82, 86, 88, 89, 91, 93, 95, 97, 106, 111, 113, 117, 123, 129], "train_data": 65, "train_imag": 76, "train_label": 76, "train_test_split": [73, 74, 93, 133], "trainabl": [67, 69, 76], "training_err": 95, "training_indic": 80, "trainingdata": [64, 65, 66], "trainingdata_n": 66, "trajectori": [44, 45, 47, 50], "tran": [34, 72, 73], "tranform": 146, "transact": 137, "transax": [7, 25, 30, 95], "transfer": 73, "transform": [3, 4, 7, 25, 30, 48, 53, 65, 67, 69, 72, 88, 95, 127, 146, 149, 153], "transit": [37, 38, 47, 67, 95, 144, 153, 154, 156, 159, 161], "translat": [4, 17, 19, 20, 22, 37, 42, 43, 46, 53, 117, 119, 130, 146, 148], "translation": 85, "transmiss": [65, 88], "transmit": 67, "transpar": [8, 43, 61, 63, 66, 73, 92, 93, 94, 134], "transpos": [125, 127, 136, 138, 156], "trapezoid": [96, 146], "trapz": [25, 30, 33, 96], "travel": [115, 148, 161], "travers": [66, 67, 136], "treat": [16, 28, 38, 43, 47, 104, 117, 123, 148], "treatment": [28, 46, 53, 89, 96, 116, 117, 124], "tree": [67, 73], "tremend": [47, 56], "trend": [33, 43, 63, 72, 79, 121, 159], "trevor": 66, "tri": [16, 151], "trial": [9, 19, 21, 29, 45, 47, 64], "triangular": 33, "tribal": 73, "trick": [72, 73, 77, 83, 93, 144, 153], "tricki": 51, "trickier": 154, "trig": 134, "trigger": [67, 156], "trigonometr": [71, 112, 134], "trivia": [0, 23], "trivial": [8, 16, 33, 40, 65, 130, 154], "tro08": [1, 27, 51], "trotta": [1, 27, 51, 95], "troubl": [5, 63, 68, 148, 159], "troublesom": 53, "truck": [64, 76], "true": [3, 5, 6, 7, 9, 11, 12, 15, 16, 17, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 46, 48, 50, 53, 58, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 76, 77, 78, 80, 81, 82, 83, 85, 88, 90, 92, 93, 94, 95, 96, 102, 110, 111, 120, 121, 123, 126, 127, 129, 130, 132, 134, 135, 136, 142, 143, 144, 146, 147, 150, 151, 152, 153, 156, 158, 161], "true_func": 95, "true_height": 123, "true_label": [69, 76], "true_model": 48, "true_param": [34, 102], "truli": [34, 39, 43, 48, 56, 63, 147, 152], "truncat": [7, 16, 34, 53, 112, 125, 127], "trunk": 104, "trust": [9, 30, 43, 70], "trustworthi": 63, "truth": [8, 21, 25, 53, 64, 82, 96, 110, 121, 147, 152], "truths_corn": 96, "try": [4, 8, 9, 11, 13, 15, 16, 17, 19, 23, 30, 31, 33, 34, 35, 37, 39, 40, 41, 48, 51, 53, 65, 66, 70, 76, 77, 79, 83, 86, 88, 90, 92, 94, 95, 96, 102, 119, 123, 126, 127, 132, 134, 135, 136, 142, 143, 144, 146, 147, 149, 150, 151, 152, 153, 154, 158, 159, 162], "tumor": 88, "tune": [44, 47, 66, 67, 71, 97, 105, 107, 117, 143, 146, 148, 151, 152, 153, 154, 159, 163], "tungsten": 51, "tuning_step": 151, "tupl": [129, 135, 136], "turn": [1, 4, 7, 9, 17, 19, 34, 39, 42, 44, 52, 63, 64, 68, 73, 93, 95, 96, 100, 111, 115, 124, 127, 130, 133, 134, 144, 147, 148, 150, 151, 152, 153, 154, 159], "tutori": [1, 37, 39, 42, 56, 69, 71, 73, 76, 78, 82, 136, 147, 152], "tweak": [42, 71, 97, 126], "twentieth": 62, "twice": [31, 125, 143, 144], "twiecki": [73, 93], "twist": 51, "two": [0, 1, 3, 4, 8, 9, 11, 13, 15, 16, 17, 19, 22, 24, 25, 26, 29, 37, 38, 39, 40, 43, 44, 45, 47, 49, 51, 52, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 80, 82, 83, 85, 86, 92, 93, 94, 95, 96, 101, 102, 103, 104, 110, 117, 120, 121, 125, 130, 133, 134, 135, 136, 137, 140, 142, 143, 144, 145, 146, 147, 148, 151, 152, 153, 154, 158, 161, 162, 163], "two_param_model": 151, "tx": 127, "txt": [78, 82, 133], "ty": 127, "type": [0, 11, 16, 34, 43, 45, 47, 50, 51, 60, 69, 71, 73, 75, 76, 77, 83, 85, 89, 93, 94, 95, 96, 102, 110, 119, 123, 132, 133, 134, 135, 137, 148, 154, 161], "typeerror": 65, "typic": [4, 23, 34, 38, 43, 44, 47, 48, 49, 51, 60, 63, 67, 71, 75, 76, 82, 85, 88, 102, 105, 106, 110, 118, 119, 125, 126, 127, 145, 148, 151, 154, 159, 162], "u": [1, 4, 6, 7, 8, 9, 10, 16, 17, 19, 22, 23, 25, 30, 31, 34, 37, 38, 39, 41, 44, 45, 46, 48, 49, 50, 51, 53, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 77, 78, 79, 81, 82, 83, 85, 86, 88, 93, 95, 96, 97, 101, 102, 107, 113, 121, 125, 127, 130, 133, 134, 136, 137, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 159, 161, 162], "u_": [86, 125, 127], "u_0": 86, "u_1": [51, 86, 130], "u_deriv": 150, "u_i": [53, 153], "u_n": 130, "u_pt": 150, "u_shap": 127, "ua": 133, "ucf": 150, "ucf_deriv": 150, "ucf_pt": 150, "ud": 31, "udat": 73, "ueff": 150, "ueff_deriv": 150, "ueff_pt": 150, "ui": 138, "ui_box": [9, 132], "uid": 126, "uint8": [69, 76], "uk": [1, 50, 56, 77, 143, 144], "ul": [9, 132], "ultim": [23, 31, 48, 97, 106], "umask": 126, "un": 43, "unabl": 70, "unaccept": 44, "unaffect": 127, "unambigu": 61, "unawar": [16, 63], "unbalanc": 66, "unbias": [39, 143, 147, 152, 161], "unbow": 62, "unc": 133, "uncertain": [7, 8, 16, 34, 72, 73, 101, 126, 130, 161], "uncertainti": [0, 1, 4, 8, 16, 17, 23, 25, 34, 41, 43, 44, 45, 46, 47, 48, 49, 51, 53, 56, 79, 80, 85, 110, 111, 113, 119, 120, 122, 123, 126, 142, 143, 146, 154], "unchalleng": 79, "unchang": [68, 75, 148], "unchart": 53, "uncheck": 137, "uncolor": 154, "uncom": 123, "uncontrain": 52, "uncontrol": 63, "uncorrel": [35, 41, 50, 72, 78, 79, 82, 120, 123, 130, 146, 148, 159], "uncov": 43, "under": [3, 4, 7, 8, 9, 10, 16, 18, 19, 29, 44, 45, 48, 51, 53, 56, 64, 66, 71, 76, 86, 95, 96, 97, 121, 129, 132, 134, 137, 143, 156, 159, 163], "underappreci": 73, "underbrac": [4, 9, 10, 23, 30, 52], "underestim": [41, 111, 143], "underfit": [71, 95, 97], "undergird": 48, "undergo": 64, "underground": 62, "underli": [7, 29, 34, 43, 44, 45, 47, 48, 49, 60, 63, 65, 66, 67, 77, 79, 83, 90, 94, 102, 119, 143, 146], "underrepresent": 63, "underscor": 134, "underset": [52, 66, 85, 92, 104], "underst": 25, "understand": [8, 11, 17, 42, 43, 45, 47, 49, 53, 58, 60, 62, 64, 65, 66, 67, 71, 75, 104, 117, 119, 125, 127, 142, 145, 156, 161, 162], "understood": [23, 34, 43, 48, 58, 63, 64, 67, 73, 117, 123, 130, 153, 156], "undetect": 64, "undoubtedli": 62, "undul": 47, "unduli": 48, "unemploy": 25, "unequ": 135, "unessenti": 124, "unexpect": [40, 53, 146], "unexpected": 53, "unfair": [9, 15, 25, 30, 63], "unfairli": 46, "unfortun": [8, 44, 68, 72, 73, 110], "uni": [80, 81], "uni_dist": 33, "uni_dist_pt": 33, "uni_gauss_pt": 33, "uni_max": 33, "uni_min": 33, "unicode_liter": 76, "unif": 61, "uniform": [3, 4, 5, 6, 7, 9, 11, 12, 19, 25, 29, 30, 33, 35, 37, 38, 40, 41, 42, 43, 44, 49, 50, 51, 53, 71, 79, 81, 92, 95, 96, 102, 120, 123, 143, 144, 145, 149, 152, 154, 156, 159, 161, 162, 163], "uniform_1": [145, 162], "uniform_2": [145, 162], "uniformli": [6, 33, 35, 42, 47, 71, 77, 82, 83, 130, 142, 153, 154, 163], "uniformpropos": 151, "uniformsampl": 3, "unifrompdf": 130, "unimod": [18, 19, 46], "uninform": [11, 37, 49], "uninterest": 130, "union": [22, 48, 66, 130], "uniqu": [7, 18, 25, 44, 110, 113, 117, 130, 153, 156], "unit": [23, 34, 40, 42, 44, 60, 67, 68, 69, 71, 73, 93, 96, 130, 133, 153], "uniti": [16, 37, 53, 78, 95, 130], "unitless": [120, 121, 126], "univari": [43, 44, 82, 85, 110, 130, 151, 156, 161], "univers": [1, 7, 8, 47, 48, 56, 64, 67, 75, 79, 127, 130], "universal_newlin": 126, "unknown": [19, 22, 31, 34, 37, 43, 46, 53, 66, 85, 96, 101, 102, 120, 124, 129, 151, 158], "unknowwn": 68, "unlabel": 67, "unless": [4, 16, 46, 47, 52, 53, 71, 76, 104, 124, 133, 143, 144, 151, 153, 156, 159], "unlik": [23, 33, 37, 40, 53, 75, 134, 142, 153], "unlock": 73, "unlov": 45, "unnecessarili": [67, 147, 152], "unnorm": [13, 35, 42, 44, 53, 144, 159], "unobserv": 34, "unpack": [48, 78, 82], "unreason": [53, 117], "unrol": 76, "unround": 133, "unsatisfi": 62, "unscal": 95, "unseen": 88, "unshift": [143, 144], "unsort": 41, "unspecifi": 69, "unsqueez": 71, "unstabl": [65, 68, 79, 86], "unstack": 69, "unsupervis": [64, 67, 73], "unsur": 42, "until": [19, 63, 67, 68, 71, 88, 97, 105, 121, 144, 145, 151, 153, 154, 159, 162], "unverifi": 61, "unwant": 25, "up": [0, 4, 8, 11, 12, 16, 19, 23, 26, 33, 35, 38, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 56, 60, 62, 63, 64, 65, 69, 71, 72, 73, 82, 93, 101, 102, 107, 111, 117, 120, 125, 126, 127, 129, 130, 131, 133, 134, 136, 137, 138, 143, 144, 145, 146, 147, 151, 154, 158, 159, 160, 162], "updat": [1, 5, 11, 12, 13, 15, 23, 25, 27, 33, 34, 37, 43, 44, 48, 49, 56, 58, 59, 62, 66, 67, 68, 69, 70, 71, 72, 73, 77, 78, 83, 92, 93, 105, 106, 107, 120, 132, 134, 144, 146, 148, 149, 150, 153, 156, 161], "update_n": 9, "update_plot": [9, 132], "update_prob_head": 9, "update_t_max": 132, "uphil": [97, 151], "uphold": 61, "upon": [16, 19, 21, 38, 43, 47, 48, 58], "upper": [9, 17, 33, 42, 49, 51, 53, 56, 72, 81, 123, 126, 137, 150, 152], "uq": [47, 122], "url": 1, "us": [0, 1, 3, 5, 6, 8, 9, 10, 11, 13, 15, 16, 17, 18, 20, 23, 24, 25, 26, 29, 30, 32, 33, 34, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 76, 77, 78, 79, 80, 81, 82, 86, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 110, 112, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 161, 162, 163], "usag": [0, 71, 133], "usecol": 133, "usefulli": 48, "uselatex": 126, "user": [11, 38, 41, 44, 50, 63, 81, 86, 93, 107, 126, 129, 134, 137, 143, 151, 153, 161], "user_nam": 136, "userwarn": [50, 123, 152], "usetex": 123, "usr": [50, 81, 96, 126, 152], "usual": [0, 2, 4, 7, 19, 22, 24, 25, 29, 32, 34, 38, 43, 45, 46, 47, 48, 49, 52, 53, 60, 64, 65, 66, 67, 71, 72, 73, 82, 85, 88, 93, 97, 100, 106, 110, 111, 125, 127, 130, 133, 134, 144, 146, 148, 153], "util": [44, 64, 67, 77, 82, 104, 112, 119, 126, 130, 156, 161], "utmost": 64, "uvec": 86, "v": [7, 17, 33, 35, 38, 41, 47, 52, 78, 82, 96, 104, 114, 115, 121, 123, 125, 127, 134, 135, 138, 149, 151, 152, 154], "v0": [0, 7, 41, 123], "v1": [96, 127, 132], "v12": 1, "v2": [43, 127], "v3": 96, "v5": [151, 152], "v_": [7, 41, 47, 48, 125, 127], "v_0": [7, 45, 79, 121, 123], "v_1": 48, "v_1v_2": 48, "v_2": 48, "v_d": 153, "v_i": 45, "v_shape": 127, "v_t": [114, 115], "v_tran": 127, "va": [17, 33, 95, 149, 150], "vaiidat": 66, "vain": 53, "val": [64, 66], "val_accuraci": 76, "val_loss": 76, "vale": 4, "valid": [0, 29, 43, 44, 47, 51, 58, 59, 63, 64, 67, 77, 78, 82, 83, 85, 97, 104, 119, 121, 123, 153, 154], "validation_data": 76, "vallei": 105, "valu": [3, 4, 5, 7, 9, 10, 11, 13, 16, 17, 18, 22, 25, 27, 30, 33, 34, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 82, 83, 85, 86, 88, 89, 92, 94, 95, 101, 102, 103, 104, 107, 110, 111, 113, 117, 119, 120, 121, 123, 124, 126, 127, 129, 133, 134, 135, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 156, 159, 161, 162, 163], "valuabl": [125, 134, 136], "valueconstraintsprior": 78, "valueerror": [37, 123, 129, 147, 152], "van": [1, 43, 66], "van16": [1, 66], "vander": [34, 102], "vandermond": [34, 100, 102], "vanderpla": [1, 66, 80], "vandschootdk": [1, 43], "vanish": [68, 71, 117], "vannucci": 1, "var": [7, 17, 24, 44, 45, 46, 66, 77, 83, 96, 130, 136, 143, 151, 153], "var2": 17, "var_chain": 143, "var_lnl": 96, "var_nam": 152, "var_theta": 143, "varabl": 46, "varepsilon": [7, 40, 44, 48, 85, 96, 107], "varepsilon_": 48, "varepsilon_i": [40, 41, 49, 143], "vari": [19, 35, 37, 43, 45, 47, 51, 64, 65, 79, 95, 115, 120, 126, 129, 154], "variabl": [3, 4, 11, 16, 19, 22, 23, 24, 25, 26, 31, 32, 34, 37, 38, 39, 43, 44, 52, 53, 59, 61, 63, 64, 65, 66, 67, 72, 73, 78, 80, 82, 86, 88, 91, 93, 99, 100, 102, 104, 107, 109, 110, 112, 113, 114, 115, 119, 121, 126, 127, 133, 134, 135, 136, 143, 145, 147, 148, 151, 152, 153, 156, 158, 161, 162, 163], "varianc": [1, 7, 17, 19, 24, 29, 33, 34, 37, 38, 39, 41, 43, 46, 48, 50, 65, 67, 71, 72, 77, 78, 79, 80, 82, 83, 85, 86, 88, 92, 95, 96, 97, 100, 101, 102, 103, 106, 120, 123, 124, 126, 127, 129, 133, 143, 145, 146, 147, 148, 151, 152, 153, 154, 158, 162], "variance3": 78, "variant": [23, 67, 95, 150, 153], "variat": [1, 4, 34, 38, 44, 45, 46, 47, 51, 64, 65, 66, 79, 97, 105, 110, 119, 127, 133, 143, 146, 151, 153, 154], "varieti": [38, 55, 67, 136, 151], "variou": [0, 16, 18, 25, 31, 33, 46, 47, 56, 58, 64, 70, 71, 73, 74, 88, 94, 104, 110, 111, 131, 133, 160], "varphi": 7, "varz": 82, "vast": [45, 63], "vastli": 75, "vbox": [5, 9, 132], "vdot": [34, 52, 100, 127, 156, 161], "ve": [11, 17, 27, 29, 31, 38, 40, 52, 77, 78, 83, 127, 145, 146, 148, 151, 154, 162], "vec": [23, 85, 96], "vecor": 100, "vector": [5, 7, 9, 10, 23, 30, 34, 35, 38, 40, 41, 44, 45, 47, 49, 50, 52, 53, 65, 66, 68, 70, 72, 73, 75, 76, 77, 78, 82, 83, 85, 86, 88, 92, 93, 95, 96, 97, 100, 101, 105, 106, 107, 110, 117, 120, 123, 125, 127, 129, 130, 133, 135, 136, 138, 143, 146, 147, 148, 149, 150, 152, 153, 154, 156, 161], "vee": [73, 93], "veen": 1, "vega": 154, "vehicl": 64, "vehtari": [1, 51], "veloc": [7, 41, 114, 115, 121, 123], "venn": 8, "ventur": 64, "venv": 137, "verbos": [34, 65, 69, 70, 76, 102], "verdict": [8, 62], "veri": [4, 7, 8, 9, 16, 25, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 53, 56, 62, 64, 65, 66, 67, 71, 72, 73, 75, 76, 78, 79, 82, 85, 86, 94, 96, 97, 100, 101, 104, 105, 110, 111, 130, 133, 135, 143, 144, 147, 148, 151, 152, 153, 154, 156, 159, 161, 163], "verif": 43, "verifi": [3, 7, 13, 19, 34, 37, 39, 42, 43, 53, 63, 69, 127, 130, 136, 137, 142, 150, 152, 153, 156], "vernon": [1, 56], "versa": [130, 156], "version": [16, 19, 23, 24, 28, 35, 37, 38, 39, 40, 41, 43, 44, 45, 47, 49, 50, 51, 62, 64, 66, 67, 69, 70, 73, 76, 85, 88, 93, 107, 121, 123, 126, 127, 133, 134, 137, 139, 143, 144, 145, 146, 148, 151, 152, 153, 154, 162], "versu": [38, 52, 63, 78, 82], "vert": [30, 34, 45, 66, 88, 127, 130, 156, 159, 161], "vert_1": 66, "vert_2": 66, "vertic": [4, 9, 17, 37, 53, 94, 144], "verticalalign": [9, 42], "vgb10": [1, 46], "vgb14": [1, 46], "via": [4, 7, 27, 34, 41, 43, 44, 45, 46, 47, 48, 64, 66, 67, 68, 71, 72, 75, 88, 90, 91, 95, 102, 110, 123, 125, 130, 135, 137, 138, 142, 143, 151, 153, 154, 156], "viabl": 63, "vice": [130, 156], "vicin": 51, "video": [63, 67, 126], "vien": 56, "view": [9, 23, 25, 30, 38, 39, 40, 43, 53, 56, 61, 64, 66, 67, 72, 76, 128, 133, 136, 147, 152, 156], "view_init": 65, "viewpoint": [45, 116, 130], "vincent": 80, "violat": [8, 19], "virtu": [7, 57, 59], "virtual": [68, 137], "viru": 137, "visibl": 7, "vision": [64, 71], "visit": [144, 153], "visual": [7, 19, 26, 34, 37, 38, 39, 41, 43, 44, 47, 51, 53, 64, 65, 67, 70, 71, 73, 75, 77, 83, 86, 88, 102, 126, 127, 133, 143, 144, 146, 152, 156, 161], "vlg": [1, 46], "vline": [39, 41, 152], "vm": 41, "vmatrix": 3, "vmax": 65, "vmeasur": 41, "vmin": 65, "vocabulari": [17, 32, 40], "volum": [1, 4, 6, 34, 35, 41, 44, 46, 51, 62, 99, 113, 133, 147, 148, 149, 152, 153, 154], "volume_theta": [147, 152], "von": 104, "von_neumann": 104, "vote": 65, "vp": 78, "vp_mat": 49, "vp_mat_inv": 49, "vp_tran": 127, "vsigma": 41, "vstack": 17, "vt": 127, "vulner": 63, "vw15": [1, 66], "vysochanskii": 46, "w": [1, 4, 35, 37, 44, 67, 68, 70, 72, 74, 88, 95, 96, 117, 127, 133, 143, 151], "w_": [67, 68, 88], "w_0": [65, 67, 70, 72, 74, 88], "w_1": [65, 67, 70, 72, 74, 88], "w_1_2": [73, 93], "w_1x": 88, "w_2": [65, 67, 72, 74, 88], "w_2_out": [73, 93], "w_i": [72, 153], "w_in_1": [73, 93], "w_j": 88, "w_jx_j": 67, "w_p": [67, 88], "w_pad": 33, "w_std": 129, "wa": [0, 4, 7, 8, 15, 19, 21, 23, 25, 34, 39, 40, 44, 46, 47, 48, 49, 50, 51, 53, 56, 61, 62, 63, 66, 67, 71, 72, 73, 74, 77, 79, 81, 88, 93, 95, 96, 97, 107, 110, 114, 117, 119, 123, 129, 130, 133, 137, 143, 144, 145, 147, 150, 151, 152, 153, 154, 156, 161, 162], "wahlstr\u00f6m": 1, "wai": [0, 4, 5, 7, 8, 9, 12, 13, 16, 17, 18, 19, 22, 23, 25, 29, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 51, 53, 59, 62, 63, 64, 65, 67, 68, 69, 71, 73, 75, 78, 80, 82, 86, 88, 95, 97, 105, 106, 110, 117, 127, 130, 132, 133, 134, 142, 144, 145, 153, 154, 156, 161, 162], "waic": 51, "wak": [1, 133], "walk": [15, 35, 44, 50, 143, 148, 153, 160], "walker": [6, 35, 38, 41, 50, 51, 96, 123, 142, 143, 146, 147, 152, 159, 163], "wall": [38, 41, 50, 93, 143, 144], "wang": [1, 133], "want": [0, 7, 9, 11, 12, 13, 16, 18, 19, 22, 30, 31, 34, 35, 37, 39, 40, 41, 42, 43, 44, 48, 50, 51, 56, 58, 59, 63, 68, 69, 71, 72, 73, 77, 78, 79, 81, 82, 83, 86, 90, 92, 94, 96, 98, 104, 126, 131, 134, 135, 136, 137, 140, 142, 143, 144, 146, 147, 149, 151, 152, 154, 156, 159], "wantonli": 61, "ware": 43, "warm": [38, 41, 50, 101, 127, 143, 145, 146, 154, 159, 162], "warm_up_step": [145, 162], "warmup": [38, 41, 50, 103, 143], "warn": [7, 50, 53, 69, 73, 77, 83, 92, 93, 96, 123, 133, 143, 144], "warnup": 38, "warrant": 66, "warranti": 76, "wash": 51, "washington": [51, 80], "wasn": 151, "wasserman": 53, "wast": [48, 52, 66, 75, 154], "wave": [7, 17, 23, 45, 46, 47, 132, 134], "wavelength": 120, "we": [0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 77, 78, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 160, 161, 162], "weak": [7, 43, 46, 47, 52, 53, 78, 82, 107, 146], "weaker": 82, "weakli": [40, 43, 52, 78, 82, 117], "wear": [1, 153], "weather": [16, 67], "web": [17, 134], "webpag": 49, "websit": [63, 87], "webster": 110, "week": [56, 92], "weigh": [38, 53], "weight": [1, 19, 25, 33, 34, 38, 40, 44, 48, 53, 60, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 85, 93, 95, 117, 119, 123, 129, 143, 146, 151, 153, 154], "weight_0": [64, 65], "weight_1": 65, "weight_2": 65, "weight_std": 129, "weights_1_2": [73, 93], "weights_2_out": [73, 93], "weights_in_1": [73, 93], "weiguang": [1, 44, 56], "welcom": 8, "well": [0, 3, 7, 8, 12, 19, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 51, 53, 58, 59, 63, 64, 66, 67, 71, 72, 73, 77, 80, 83, 85, 88, 93, 95, 96, 97, 105, 113, 117, 123, 127, 133, 134, 137, 143, 144, 146, 147, 148, 151, 152, 153, 154, 158, 161], "went": 62, "were": [4, 7, 16, 18, 23, 25, 31, 32, 34, 38, 41, 43, 44, 47, 48, 50, 51, 53, 63, 71, 73, 75, 76, 88, 96, 129, 133, 142, 144, 152, 156], "wesolowski": [56, 126], "wessel": [1, 66], "what": [0, 4, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 42, 43, 47, 49, 50, 52, 53, 56, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 74, 75, 77, 78, 82, 83, 85, 86, 88, 90, 92, 94, 96, 114, 125, 126, 127, 130, 131, 132, 134, 135, 137, 142, 143, 144, 145, 148, 150, 151, 154, 156, 158, 161, 162, 163], "whatev": [21, 22, 37, 42, 64, 132], "when": [4, 7, 8, 15, 16, 17, 22, 23, 25, 27, 29, 30, 31, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 76, 77, 82, 83, 85, 86, 88, 92, 95, 96, 97, 100, 103, 106, 110, 111, 112, 113, 114, 117, 121, 122, 123, 124, 127, 130, 133, 134, 136, 143, 144, 145, 147, 148, 149, 151, 152, 153, 154, 156, 159, 161, 162, 163], "whenev": [63, 80, 123, 130], "where": [3, 4, 5, 7, 8, 9, 10, 13, 16, 17, 19, 23, 25, 29, 30, 32, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 79, 81, 82, 83, 85, 86, 88, 90, 92, 93, 94, 95, 96, 97, 100, 101, 102, 104, 105, 106, 107, 110, 112, 113, 114, 115, 117, 120, 121, 123, 125, 126, 127, 130, 133, 134, 135, 137, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 159, 161, 162, 163], "wherea": [8, 31, 34, 43, 53, 65, 66, 135, 136], "wherebi": 16, "wherein": [48, 62, 67], "whether": [16, 17, 22, 29, 32, 34, 37, 38, 40, 43, 49, 51, 53, 58, 63, 88, 94, 104, 130, 134, 144, 148, 153, 154, 159], "which": [0, 4, 5, 7, 8, 9, 12, 16, 17, 18, 19, 21, 22, 23, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 85, 86, 88, 89, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 103, 104, 105, 106, 107, 110, 111, 112, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 132, 133, 134, 135, 136, 137, 140, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 160, 161, 163], "while": [0, 4, 7, 19, 22, 23, 25, 32, 34, 38, 44, 46, 47, 48, 51, 53, 58, 63, 65, 66, 67, 68, 71, 73, 76, 78, 79, 81, 85, 86, 88, 89, 91, 105, 107, 110, 125, 130, 132, 134, 135, 136, 137, 144, 146, 147, 151, 152, 153, 154, 159, 161, 163], "whilst": [77, 83], "whistl": 134, "white": [63, 77, 82, 83, 85, 86, 117, 143], "who": [16, 43, 46, 48, 53, 56, 61, 62, 63, 64, 135], "whoever": 25, "whole": [70, 73, 75, 93, 135, 136], "whose": [17, 31, 34, 35, 53, 58, 65, 66, 85, 110, 126, 130, 154, 156], "why": [1, 5, 8, 9, 12, 15, 19, 23, 25, 26, 30, 31, 32, 34, 39, 40, 42, 44, 48, 65, 66, 70, 71, 73, 76, 77, 78, 79, 82, 88, 93, 95, 100, 101, 117, 126, 127, 133, 134, 136, 144, 147, 151, 152, 153, 156, 161], "wide": [34, 35, 43, 48, 51, 53, 64, 68, 71, 75, 85, 117, 122, 136, 154], "widehat": [44, 52, 154], "wider": [38, 73], "widespread": [148, 153, 154], "widetild": [34, 79, 86], "widget": [5, 11, 19, 30, 126, 138], "width": [9, 17, 25, 29, 33, 34, 37, 38, 42, 43, 50, 52, 53, 65, 67, 71, 75, 76, 82, 89, 90, 96, 126, 129, 132, 133, 142, 143, 144, 146, 153, 154, 159, 163], "wiecki": [73, 93, 144], "wieringen": [1, 66], "wierstra": 1, "wiggl": 104, "wigner": 117, "wiki": 104, "wikimedia": 43, "wikipedia": [19, 49, 52, 77, 89, 104, 121, 128], "wild": 49, "wildli": 37, "wilei": 1, "willemsen": 1, "william": [0, 1, 7, 23, 53, 85, 86], "willing": 8, "win": [16, 25, 77, 148], "window": [93, 123, 134, 137, 143], "wine": 7, "winner": 62, "wisdom": [48, 66], "wise": [61, 67, 71, 72, 73, 77, 78, 82, 83, 127, 136], "wish": [9, 30, 43, 44, 61, 77, 78, 82, 83, 88, 130, 133], "with_errorbar": [34, 102], "within": [3, 6, 7, 16, 19, 38, 39, 43, 44, 46, 47, 48, 51, 53, 58, 60, 62, 63, 64, 66, 71, 79, 88, 94, 95, 96, 100, 104, 117, 123, 130, 133, 137, 143, 144, 146, 147, 148, 151, 152, 153, 156, 161], "without": [1, 8, 34, 40, 44, 45, 46, 47, 49, 53, 56, 59, 61, 62, 64, 67, 69, 76, 79, 80, 82, 85, 86, 88, 89, 92, 93, 95, 96, 111, 115, 117, 119, 121, 127, 130, 134, 135, 143, 151, 156, 159, 163], "wm": 151, "wmap": 40, "wno": [73, 93], "women": [63, 130], "won": [38, 63, 73, 125, 132, 133, 144, 147, 148, 152], "wooff": [1, 46], "word": [21, 22, 31, 38, 40, 41, 42, 46, 49, 53, 58, 66, 75, 77, 78, 82, 83, 127, 130, 133, 135, 142, 143, 144, 156, 161], "work": [1, 3, 5, 7, 9, 12, 13, 14, 17, 19, 23, 27, 29, 32, 33, 34, 37, 38, 43, 44, 48, 49, 50, 51, 53, 56, 61, 63, 65, 67, 68, 71, 72, 73, 79, 80, 82, 86, 88, 90, 92, 93, 95, 96, 97, 101, 102, 117, 120, 121, 123, 127, 128, 130, 133, 134, 135, 136, 137, 142, 143, 144, 147, 148, 151, 152, 153, 154, 159], "worker": [63, 123], "workflow": [27, 28, 47, 57, 60, 134, 158], "workhors": 160, "world": [8, 16, 21, 40, 47, 63, 73, 77, 98, 134, 135], "worldwid": 133, "worri": [40, 43, 53], "wors": [65, 66, 75], "worsen": 63, "worst": 47, "worth": [23, 51, 61, 95, 97, 105], "worthwhil": 23, "would": [0, 3, 4, 7, 8, 15, 16, 17, 18, 19, 21, 23, 25, 29, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 51, 53, 56, 63, 65, 66, 67, 68, 70, 71, 72, 73, 75, 85, 88, 92, 93, 95, 99, 100, 106, 114, 115, 117, 125, 130, 133, 134, 144, 145, 147, 148, 151, 152, 153, 154, 156, 161, 162], "wreck": 63, "write": [9, 16, 19, 23, 24, 25, 30, 32, 34, 40, 41, 42, 47, 48, 49, 52, 56, 58, 64, 65, 66, 67, 68, 71, 73, 76, 77, 78, 82, 83, 85, 86, 93, 100, 102, 123, 125, 126, 127, 130, 133, 134, 144, 153], "writer": 126, "writervideo": 126, "written": [0, 3, 4, 5, 7, 22, 34, 44, 45, 48, 51, 53, 63, 64, 68, 73, 77, 78, 82, 83, 85, 86, 93, 99, 123, 133, 136, 150, 153, 156, 158], "wrong": [7, 12, 16, 19, 29, 34, 35, 44, 48, 59, 63, 67, 76, 97, 98, 100, 101, 108, 146, 159], "wrote": [22, 23, 59, 62, 159], "wrt": [33, 71], "wt": 47, "wvar": 33, "www": [1, 51, 69, 76, 137], "x": [0, 1, 3, 4, 5, 6, 9, 13, 17, 19, 22, 23, 24, 25, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 85, 86, 88, 92, 93, 94, 95, 96, 99, 100, 101, 102, 104, 117, 120, 121, 123, 125, 126, 127, 129, 130, 133, 134, 135, 136, 137, 138, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 156, 159, 161, 162, 163], "x0": [40, 41, 42, 92, 96, 153], "x0_max": [42, 70], "x0_min": [42, 70], "x0_pt": 42, "x0_true": [35, 42, 142], "x1": [23, 65, 70, 78, 92, 93, 96, 123, 130], "x1_max": 70, "x1_min": 70, "x1_orig": 65, "x1sq": 78, "x1x2": [65, 130], "x1x2_grid": 65, "x2": [23, 40, 65, 70, 78, 93, 123, 130], "x27": [70, 151], "x2_orig": 65, "x2givenx0_fig": 156, "x2sq": 78, "x_": [3, 4, 7, 34, 41, 42, 44, 65, 78, 82, 85, 94, 96, 100, 117, 144, 156, 159, 161], "x_0": [3, 4, 7, 17, 19, 23, 35, 37, 53, 65, 70, 88, 90, 96, 120, 142, 156, 161, 163], "x_1": [0, 7, 17, 19, 23, 33, 34, 39, 48, 52, 65, 67, 70, 72, 74, 78, 79, 82, 86, 88, 90, 96, 100, 101, 123, 127, 130, 147, 152, 156, 158, 161, 163], "x_2": [0, 7, 17, 19, 23, 33, 34, 52, 65, 67, 70, 72, 74, 78, 79, 82, 86, 88, 100, 101, 127, 130, 156, 158, 161], "x_3": [34, 67, 86, 161], "x_arang": 135, "x_arr": 41, "x_beta": 17, "x_co": 71, "x_col": 82, "x_cosh": 71, "x_cv": 95, "x_d": [33, 78], "x_data": 65, "x_data_pt": 49, "x_dist": [17, 42, 126], "x_exp": 71, "x_fit": 95, "x_gamma": 126, "x_i": [3, 4, 22, 24, 25, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 44, 48, 49, 53, 65, 67, 72, 82, 86, 95, 100, 120, 123, 127, 130, 143, 146, 147, 152, 153, 156, 161], "x_ip": 24, "x_j": [4, 7, 19, 48, 82, 88, 96, 120, 146, 156, 161], "x_k": [4, 35, 37, 39, 42, 82, 96, 142, 147, 152, 161], "x_l": 67, "x_label": 42, "x_list": 135, "x_log": 71, "x_m": [7, 39, 147, 152, 156], "x_max": [33, 37, 41, 42, 49, 95, 126, 143], "x_max_index": [9, 17, 30, 126], "x_mean": 41, "x_min": [33, 37, 41, 42, 95], "x_n": [19, 33, 48, 52, 67, 82, 123, 127, 130, 153, 156, 161], "x_new": 82, "x_norm": [17, 126], "x_norm_val": 29, "x_p": 88, "x_posterior": 41, "x_pt": [5, 33, 37, 40, 42, 49, 78, 134, 135], "x_pts_all": 49, "x_rang": 135, "x_row": 82, "x_row_til": 82, "x_sampl": 92, "x_sin": 71, "x_sinh": 71, "x_sort": 96, "x_sqrt": 71, "x_squar": 71, "x_t": [17, 44, 126, 144, 159, 161], "x_tensor": 129, "x_test": [69, 71, 73, 74, 93], "x_train": [65, 69, 71, 73, 74, 80, 81, 93, 95], "x_true": 81, "x_valu": 37, "x_with_fixedh": 41, "xarrai": [133, 151], "xavier": 71, "xaxi": 126, "xbar": [127, 159], "xbin": 41, "xdata": [34, 41, 65, 102], "xfit": [38, 41], "xi": [77, 83, 92, 147, 152], "xilin": 1, "xing": 1, "xk": 96, "xk_pt": 37, "xlabel": [7, 38, 69, 71, 73, 76, 77, 78, 80, 81, 82, 93, 95, 96, 123, 134, 144], "xlim": [73, 78, 82, 93, 129, 151], "xlinspac": 3, "xmax": [34, 41, 42, 96, 102], "xmeasur": [34, 102], "xmgivenx0_fig": 156, "xmin": [34, 41, 42, 96, 102], "xmode": 130, "xnew": [77, 83], "xp": [24, 77, 78, 82, 83], "xposterior": 41, "xposterior_fixedh": 41, "xposterior_pdfh": 41, "xrealiti": [34, 102], "xrightarrow": [44, 117], "xsq": 78, "xstar": 65, "xt": [78, 82], "xtick": [69, 76], "xtrue": 77, "xu": [1, 133], "xv": 50, "xvec": [23, 78, 79, 86, 146], "xvec_1": [79, 86], "xvec_2": [79, 86], "xx": [127, 130], "xx0": 70, "xx1": 70, "xx_j": 7, "xy": [7, 9, 17, 24, 35, 37, 42, 78, 126, 127, 130, 144], "xycoord": [9, 42], "xytext": [17, 126, 144], "y": [0, 3, 4, 5, 6, 9, 13, 17, 22, 23, 24, 25, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 48, 50, 52, 53, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 85, 88, 92, 93, 94, 95, 96, 97, 101, 102, 117, 120, 123, 125, 126, 127, 129, 130, 134, 135, 143, 145, 146, 149, 150, 152, 153, 156, 158, 161, 162, 163], "y0": [42, 161], "y0_true": [35, 42, 142], "y1": [82, 130], "y2": [40, 82, 130], "y_": [0, 3, 29, 34, 40, 82, 88, 100, 117, 125, 127, 143, 156, 158, 159], "y_0": [7, 35, 42, 53, 142, 156, 159, 161, 163], "y_1": [7, 9, 32, 34, 48, 52, 67, 79, 82, 88, 100, 101, 130, 156, 159], "y_2": [7, 9, 32, 34, 52, 67, 79, 82, 88, 100, 101, 130], "y_3": 9, "y_cv": 95, "y_d": 82, "y_data_pt": 49, "y_determinist": 161, "y_fit": 95, "y_i": [3, 7, 29, 34, 38, 40, 41, 48, 49, 51, 52, 65, 66, 67, 68, 82, 95, 97, 100, 125, 127, 143, 153, 161], "y_j": [7, 22, 31, 32, 66, 67, 82, 88, 146], "y_k": 82, "y_logit": 88, "y_m": [7, 38, 40, 41, 49, 95, 143], "y_max": [9, 161], "y_mean": [81, 161], "y_model": [40, 41, 49, 143], "y_n": [48, 52, 156], "y_ob": [151, 152], "y_obs_dim_0": 151, "y_obs_dim_0pandasindexpandasindex": 151, "y_perceptron": 88, "y_pt": [33, 37, 49, 134], "y_reconstruct": 5, "y_run": 161, "y_sampl": [81, 92], "y_sort": 65, "y_std": 81, "y_stochast": 161, "y_t": 159, "y_tanh": 88, "y_test": [69, 71, 73, 93], "y_train": [65, 69, 71, 73, 80, 81, 93, 95], "y_train_noisi": 80, "y_true": [5, 81], "y_vec": 49, "y_x": 82, "yaida": 1, "yau": 1, "yaxi": 126, "ybar": 127, "ybin": 41, "ydata": [34, 41, 102], "ye": [22, 34, 35, 64, 88, 156], "year": [25, 56, 62, 63, 77, 117], "yellow": 154, "yerr": [41, 96, 123], "yerror": [34, 102], "yet": [8, 16, 31, 34, 43, 49, 102, 121, 127, 156], "yexp": 0, "yfit": [38, 41], "yfunc": 77, "yhat_hard_grid": 65, "yhat_knn_grid": 65, "yhat_soft_grid": 65, "yhi95": [77, 83], "yhii": [77, 83], "yi": [78, 82, 130, 147, 152], "yield": [7, 22, 23, 25, 31, 32, 34, 38, 46, 47, 52, 53, 65, 66, 67, 86, 103, 117, 120, 126, 133], "ylabel": [7, 38, 71, 73, 76, 77, 78, 80, 81, 82, 83, 93, 95, 96, 123, 143, 144], "ylim": [69, 73, 76, 78, 81, 82, 93, 129, 143, 144, 151], "ylo95": [77, 83], "yloi": [77, 83], "ymean": [77, 83], "ymeani": [77, 83], "ymin": 96, "yml": [0, 70, 93, 137, 140], "ynew": [77, 83], "yoram": 1, "york": [50, 56, 143, 144], "yoshioka": 73, "you": [0, 3, 4, 5, 7, 8, 9, 11, 12, 15, 16, 17, 18, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 59, 62, 63, 64, 65, 66, 67, 69, 71, 73, 74, 76, 77, 79, 81, 83, 86, 88, 90, 92, 93, 94, 95, 96, 97, 100, 101, 102, 106, 117, 119, 125, 126, 127, 130, 131, 133, 134, 135, 136, 137, 139, 140, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 156, 161, 162], "young": [63, 64], "your": [0, 7, 8, 11, 12, 15, 16, 17, 19, 22, 31, 32, 34, 35, 37, 39, 40, 42, 49, 56, 62, 63, 64, 65, 66, 67, 69, 71, 73, 74, 76, 77, 85, 90, 93, 94, 95, 97, 126, 127, 130, 131, 134, 139, 140, 142, 143, 144, 145, 146, 147, 151, 152, 153, 158, 161, 162], "yourself": [7, 16, 18, 22, 30, 31, 37, 90, 96, 134], "yp": 78, "yt": [78, 82], "yth": 0, "ytick": [69, 76], "ytrue": 77, "yvar": [77, 83], "yvari": [77, 83], "yvec": [127, 146], "z": [5, 33, 34, 37, 44, 46, 50, 51, 64, 65, 67, 68, 70, 71, 72, 77, 78, 79, 82, 83, 85, 88, 92, 96, 99, 117, 121, 127, 130, 133, 148, 151, 159], "z_": [68, 88, 117], "z_0": 7, "z_1": [46, 88], "z_2": [46, 88], "z_grid": [37, 65], "z_i": [38, 46], "z_j": [46, 67, 88], "z_k": 68, "z_m": [46, 72], "z_n": 85, "z_p": [53, 95], "z_q": 53, "z_w": 72, "zdir": 65, "zdist": 82, "zeiler": 1, "zeiler12": [1, 107], "zenodo": 43, "zero": [3, 6, 7, 9, 19, 23, 24, 25, 29, 33, 34, 37, 38, 40, 42, 48, 49, 50, 53, 56, 65, 66, 67, 68, 71, 72, 75, 77, 78, 82, 83, 85, 86, 88, 95, 96, 97, 102, 107, 117, 120, 125, 126, 127, 129, 130, 131, 133, 134, 143, 144, 145, 146, 148, 150, 154, 156, 158, 159, 161, 162], "zero_grad": 71, "zeros_lik": [0, 7, 25, 30, 41, 65, 96, 130], "zeta": [47, 120], "zeta_i": 47, "zeus_multimod": 163, "zhang": 1, "zip": [33, 38, 65, 77, 83, 96, 123, 127, 130], "zm_h": 133, "zoom": 42, "zorder": [34, 81, 102], "zrang": 82, "\u00b2": 123, "\u00e9": 1, "\u03bc": [38, 129], "\u03c3": 129}, "titles": ["<span class=\"section-number\">32. </span>Guide to Jupyter Book markdown", "<span class=\"section-number\">31. </span>Bibliography", "<span class=\"section-number\">10. </span>Assigning probabilities", "<span class=\"section-number\">10.1. </span>Assigning probabilities (I): Indifferences and translation groups", "<span class=\"section-number\">10.2. </span>Assigning probabilities (II): The principle of maximum entropy", "<span class=\"section-number\">10.3. </span>\ud83d\udce5 Maximum Entropy for reconstructing a function from its moments", "\ud83d\udce5 Demonstration: Prior PDFs for straight lines", "<span class=\"section-number\">7.1. </span>Advantages of the Bayesian approach", "<span class=\"section-number\">4.8. </span>*Aside: Bayesian epistemology", "<span class=\"section-number\">6.7. </span>\ud83d\udce5 Demonstration: Coin tossing (with widget)", "<span class=\"section-number\">6. </span>Updating via Bayes\u2019 rule", "<span class=\"section-number\">6.1. </span>Coin tossing: Frequentists and Bayesaians", "<span class=\"section-number\">6.2. </span>When do priors matter? When don\u2019t they matter?", "<span class=\"section-number\">6.3. </span>Computing the posterior analytically", "<span class=\"section-number\">6.4. </span>Degree of belief/credibility intervals vs frequentist 1-sigma intervals", "<span class=\"section-number\">6.5. </span>Take-aways and follow-up questions from coin flipping:", "<span class=\"section-number\">4.9. </span>Data, models, and predictions", "<span class=\"section-number\">5.1. </span>\ud83d\udce5 Exploring PDFs", "Follow-up questions and answers to the <em>Exploring PDFs</em> section.", "<span class=\"section-number\">5.2. </span>Gaussians: A couple of frequentist connections", "<span class=\"section-number\">4. </span>Inference and PDFs", "<span class=\"section-number\">4.1. </span>Statements", "<span class=\"section-number\">4.2. </span>Manipulating probabilities: Bayesian rules of probability as principles of logic", "<span class=\"section-number\">4.3. </span>Probability density functions", "<span class=\"section-number\">4.4. </span>Looking ahead", "<span class=\"section-number\">4.7. </span>More on Bayes\u2019 theorem", "<span class=\"section-number\">5. </span>Bayesian posteriors", "<span class=\"section-number\">3. </span>Bayesian methods for scientific modeling", "<span class=\"section-number\">7. </span>Bayes in practice", "<span class=\"section-number\">5.4. </span>\ud83d\udce5 Demonstration: Sum of normal variables squared", "<span class=\"section-number\">6.6. </span>\ud83d\udce5 Demonstration:  Bayesian Coin Tossing", "<span class=\"section-number\">4.6. </span>Exercise: Standard medical example using Bayes", "<span class=\"section-number\">4.5. </span>Exercise: Checking the sum and product rules", "\ud83d\udce5 Visualization of the Central Limit Theorem", "<span class=\"section-number\">7.3. </span>Bayesian Linear Regression (BLR)", "<span class=\"section-number\">5.3. </span>Interpreting 2D posteriors", "<span class=\"section-number\">9. </span>More Bayesian parameter estimation", "<span class=\"section-number\">9.2. </span>\ud83d\udce5 Amplitude of a signal in the presence of background", "<span class=\"section-number\">9.5. </span>\ud83d\udce5 Dealing with outliers", "\ud83d\udce5 Parameter estimation example: Gaussian noise and averages I", "<span class=\"section-number\">9.3. </span>Parameter estimation example: fitting a straight line", "<span class=\"section-number\">9.4. </span>\ud83d\udce5 Parameter estimation example: fitting a straight line II", "<span class=\"section-number\">9.1. </span>\ud83d\udce5 Radioactive lighthouse problem", "<span class=\"section-number\">7.2. </span>Bayesian research workflow", "<span class=\"section-number\">17.1. </span>Advanced Markov chain Monte Carlo sampling", "<span class=\"section-number\">27.1. </span>Bayes goes fast: Emulators", "<span class=\"section-number\">11. </span>Bayes goes linear: History matching", "<span class=\"section-number\">27.2. </span>Emulators", "<span class=\"section-number\">12.2. </span>Model mixing", "Evidence calculation for EFT expansions", "Demo: Multimodal distributions with two samplers", "Computing the Bayesian evidence", "Evidence for an expansion", "<span class=\"section-number\">12.1. </span>Model Selection", "<span class=\"section-number\">12. </span>Multi-model inference with Bayes", "<span class=\"section-number\">8. </span>Overview of Part II: Advanced Bayesian methods", "About this Jupyter Book", "<span class=\"section-number\">2. </span>Introduction", "<span class=\"section-number\">2.1. </span>Physicist\u2019s perspective", "<span class=\"section-number\">2.2. </span>Bayesian workflow", "<span class=\"section-number\">2.3. </span>Machine learning", "<span class=\"section-number\">2.4. </span>Virtues", "<span class=\"section-number\">1. </span>Invitation to inductive inference", "<span class=\"section-number\">22.9. </span>Data bias and fairness in machine learning", "<span class=\"section-number\">22. </span>Machine learning: Overview and notation", "<span class=\"section-number\">21.5. </span>Machine Learning: First Examples", "<span class=\"section-number\">22.8. </span>Model validation", "<span class=\"section-number\">22.5. </span>Artifical neural networks", "<span class=\"section-number\">22.10. </span>*Neural networks: Backpropagation", "<span class=\"section-number\">22.6. </span>Demonstration: Neural network classifier", "<span class=\"section-number\">21.6. </span>Exercise: Logistic Regression and neural networks", "<span class=\"section-number\">22.7. </span>Feed-forward neural network for a function in PyTorch", "<span class=\"section-number\">24. </span>Bayesian neural networks", "<span class=\"section-number\">24.4. </span>Demonstration: Variational Inference and Bayesian Neural Networks", "<span class=\"section-number\">24.5. </span>Exercise: Bayesian neural networks", "<span class=\"section-number\">25. </span>*Convolutional Neural Networks", "<span class=\"section-number\">25.6. </span>Demonstration: Image recognition with Convolutional Neural Networks", "Exercise: Gaussian Process models with GPy", "Gaussian processes demonstration", "Lecture 20", "Gaussian Processes regression: basic introductory example", "Illustration of prior and posterior Gaussian process for different kernels", "Demonstration: Gaussian processes", "Exercise: Gaussian processes using <code class=\"docutils literal notranslate\"><span class=\"pre\">GPy</span></code>", "<span class=\"section-number\">20.6. </span>GPy demo notebooks", "<span class=\"section-number\">20.4. </span>Gaussian processes", "<span class=\"section-number\">20. </span>Overview of Gaussian process", "<span class=\"section-number\">20.5. </span>Scikit-learn demo notebooks", "<span class=\"section-number\">21. </span>Logistic Regression", "<span class=\"section-number\">19. </span>Machine Learning", "Overview of Mini-project IIb: How many lines?", "Overview of TALENT mini-projects", "Mini-project IIIa: Bayesian Optimization", "Mini-project IIIb: Bayesian Neural Networks", "Mini-project I: Parameter estimation for a toy model of an EFT", "Mini-project IIa: Model selection basics", "Mini-project IIb: How many lines are there?", "<span class=\"section-number\">34. </span>Gradient-descent optimization", "<span class=\"section-number\">37. </span>Linear models", "<span class=\"section-number\">37.1. </span>Definition of linear models", "<span class=\"section-number\">37.2. </span>Regression analysis with linear models", "<span class=\"section-number\">37.3. </span>Ordinary linear regression: warmup", "<span class=\"section-number\">37.4. </span>Ordinary linear regression in practice", "<span class=\"section-number\">37.5. </span>Solutions", "<span class=\"section-number\">38. </span>Mathematical optimization", "<span class=\"section-number\">38.1. </span>Gradient-descent optimization", "<span class=\"section-number\">38.2. </span>Batch, stochastic and mini-batch gradient descent", "<span class=\"section-number\">38.3. </span>Adaptive gradient descent algorithms", "<span class=\"section-number\">36. </span>Overview of modeling", "<span class=\"section-number\">36.1. </span>Notation", "<span class=\"section-number\">36.2. </span>Models in science", "<span class=\"section-number\">36.3. </span>Parametric versus non-parametric models", "<span class=\"section-number\">36.4. </span>Linear versus non-linear models", "<span class=\"section-number\">36.5. </span>Regression analysis: optimization versus inference", "<span class=\"section-number\">36.6. </span>Exercises", "<span class=\"section-number\">36.7. </span>Solutions", "<span class=\"section-number\">35. </span>Overview of scientific modeling material", "<span class=\"section-number\">23. </span>ANNs in the large-width limit", "<span class=\"section-number\">13. </span>Bayesian approach to model discrepancy", "<span class=\"section-number\">13.1. </span>KOH and BOH discrepancy models", "<span class=\"section-number\">13.2. </span>Framework", "<span class=\"section-number\">13.3. </span>The ball-drop model", "<span class=\"section-number\">27. </span>Emulators", "<span class=\"section-number\">13.4. </span>\ud83d\udce5 Model discrepancy example: The ball-drop experiment", "<span class=\"section-number\">26. </span>Overview of other topics", "<span class=\"section-number\">29. </span>PCA, SVD, and all that", "<span class=\"section-number\">28. </span>Student t distribution as a mixture of Gaussians", "<span class=\"section-number\">29.5. </span>\ud83d\udce5 Linear algebra games including SVD for PCA", "<span class=\"section-number\">30. </span>Quantum Bayesianism (QBism)", "<span class=\"section-number\">23.3. </span>\ud83d\udce5 Distributions of Randomly-Initialized ANNs", "<span class=\"section-number\">33. </span>Statistics concepts and notation", "<span class=\"section-number\">39. </span>Overview of getting started materials", "<span class=\"section-number\">41.7. </span>\ud83d\udce5 Making a simple widget-based UI", "<span class=\"section-number\">41.6. </span>\ud83d\udce5 Demonstration: Reading Data and fitting", "<span class=\"section-number\">40. </span>\ud83d\udce5 Exercise: Jupyter Notebooks and Python", "<span class=\"section-number\">41.4. </span>\ud83d\udce5 Exercise: Python lists and iterations", "<span class=\"section-number\">41.5. </span>\ud83d\udce5 Exercise: Linear algebra operations with NumPy", "<span class=\"section-number\">42.1. </span>Using Anaconda", "<span class=\"section-number\">41. </span>More on Python and using Jupyter notebooks", "<span class=\"section-number\">42. </span>Setting up to use this Jupyter book", "<span class=\"section-number\">42.2. </span>Using GitHub", "<span class=\"section-number\">17. </span>Advanced Markov Chain Monte Carlo", "<span class=\"section-number\">16.4. </span>Assignment: 2D radioactive lighthouse location using MCMC", "<span class=\"section-number\">17.2. </span>Overview: MCMC Diagnostics", "<span class=\"section-number\">15.11. </span>Exercise: Random walk", "<span class=\"section-number\">15.7. </span>Metropolis-Hasting MCMC sampling of a Poisson distribution", "<span class=\"section-number\">17.4. </span>Lecture 12", "<span class=\"section-number\">15.10. </span>Parameter estimation example: Gaussian noise and averages II", "<span class=\"section-number\">18.1. </span>Hamiltonian Monte Carlo (HMC) overview and visualization", "Liouville Theorem Visualization", "Solving orbital equations with different algorithms", "<span class=\"section-number\">18.3. </span>PyMC Introduction", "<span class=\"section-number\">18.4. </span>Comparing samplers for a simple problem", "<span class=\"section-number\">16.2. </span>Markov chain Monte Carlo sampling", "<span class=\"section-number\">16.3. </span>MCMC Intro from BUQEYE", "<span class=\"section-number\">16. </span>Overview of Markov Chain Monte Carlo", "<span class=\"section-number\">16.1. </span>Markov chains", "<span class=\"section-number\">18. </span>HMC and other samplers", "Overview of Intro to PyMC notebook", "<span class=\"section-number\">15.9. </span>Recaps", "<span class=\"section-number\">14. </span>Overview of Part III: Sampling", "<span class=\"section-number\">15. </span>Stochastic processes", "<span class=\"section-number\">15.8. </span>Demonstration: Metropolis-Hasting MCMC sampling of a Poisson distribution", "<span class=\"section-number\">18.2. </span>The Zeus Ensemble Slice Sampler"], "titleterms": {"": [7, 44, 46, 53, 58, 65, 93, 132, 136], "0": [86, 93], "05": 93, "06068": 159, "1": [0, 7, 14, 31, 32, 33, 34, 38, 41, 65, 66, 67, 74, 77, 79, 83, 85, 86, 92, 93, 103, 115, 129, 130, 132, 143, 144, 156, 161], "10": [33, 156], "100": 93, "1000": 93, "11": [143, 156], "12": [146, 154, 156], "13": 156, "14": 156, "15": [156, 161], "16": [153, 156], "17": 153, "1710": 159, "18": 153, "1d": [17, 136], "2": [5, 29, 31, 32, 34, 38, 41, 67, 74, 77, 83, 92, 93, 115, 129, 130, 132, 144, 154, 156, 161], "20": 79, "2025": 137, "21": 65, "22": [66, 67], "2d": [35, 136, 142], "3": [5, 7, 16, 31, 32, 38, 41, 67, 74, 77, 83, 92, 93, 103, 115, 130, 132, 144, 156, 161], "30000": 93, "32": 0, "33": 130, "36": 115, "37": 103, "3d": 75, "4": [5, 7, 16, 31, 32, 38, 41, 65, 67, 71, 77, 83, 92, 93, 115, 130, 132, 156], "5": [5, 7, 16, 31, 32, 65, 66, 77, 93, 130, 132, 144, 156], "50": 33, "6": [7, 16, 31, 66, 130, 132, 156], "60000": 93, "7": [7, 16, 31, 66, 132, 156], "8": [31, 66, 156], "9": [31, 66, 146, 156], "A": [7, 19, 38, 48, 53, 70, 74, 77, 83, 85, 88, 92, 96, 133, 156, 159], "But": [39, 147, 152], "For": 159, "In": [34, 151, 159], "No": [78, 82], "One": [8, 40, 53], "The": [0, 4, 7, 16, 19, 25, 34, 38, 40, 41, 43, 44, 46, 49, 53, 63, 65, 66, 72, 75, 77, 78, 82, 83, 85, 88, 95, 100, 121, 123, 130, 134, 143, 153, 156, 163], "To": [17, 19, 93, 133], "With": 123, "_": 85, "ab": 45, "about": [19, 39, 56, 60, 71, 138, 146, 147, 152], "abov": 159, "acceler": 71, "accept": [143, 151, 159], "accumul": 127, "accuraci": 69, "acknowledg": [56, 73], "activ": [67, 68, 88], "ad": [33, 136], "adagrad": 107, "adam": 107, "adapt": 107, "add": [76, 132], "addendum": 34, "addit": 94, "adjust": 53, "admonit": 0, "advanc": [44, 55, 134, 141], "advantag": 7, "advi": 73, "agre": 159, "ahead": 24, "ai": 63, "aka": [17, 78, 82], "al": [79, 86, 143], "aleator": 72, "algebra": [49, 52, 85, 127, 136], "algorithm": [46, 63, 64, 67, 68, 88, 92, 107, 143, 144, 148, 150, 153, 154, 159], "all": [19, 31, 32, 125, 132, 152], "amplitud": 37, "an": [23, 52, 56, 94, 159, 161], "anaconda": 137, "analogi": 159, "analys": 19, "analysi": [96, 100, 110, 113, 142], "analyt": 13, "analyz": [37, 151], "ani": [132, 159], "ann": [117, 129], "anoth": [5, 17], "answer": [0, 3, 11, 12, 15, 16, 18, 19, 22, 23, 24, 31, 32, 34, 35, 47, 95, 96, 100, 159], "appli": [23, 127, 142, 147, 152], "applic": [51, 79, 125], "approach": [7, 38, 39, 41, 85, 118, 143, 147, 152], "approxim": [7, 35], "ar": [35, 79, 96, 136, 159], "architectur": [67, 75], "argument": 4, "arrai": [134, 135, 136], "art": 153, "artif": 67, "artifici": 67, "arxiv": 159, "asid": [8, 86, 127, 134, 135], "ask": 71, "aspect": 64, "aspir": 61, "assess": [29, 143, 146], "assign": [2, 3, 4, 142], "assum": 159, "assumpt": 48, "atom": 159, "attribut": 63, "autocorrel": [44, 143, 151, 159], "autom": 63, "avail": 151, "averag": [39, 48, 136, 147], "awai": [15, 25], "axiom": 25, "b": [32, 53, 159], "back": [68, 69], "background": [34, 35, 37, 86, 152], "backprop": 72, "backpropag": [68, 71], "bad": 38, "balanc": [144, 156, 159], "ball": [121, 123], "base": [52, 76, 132, 136, 159], "basi": [34, 81, 99], "basic": [53, 71, 72, 80, 88, 95, 127, 151, 154], "batch": [73, 106], "bay": [10, 22, 23, 25, 28, 31, 45, 46, 51, 54, 72, 142], "bayesaian": 11, "bayesian": [0, 7, 8, 9, 16, 17, 19, 22, 26, 27, 30, 31, 32, 34, 36, 38, 39, 41, 43, 48, 51, 53, 55, 59, 61, 72, 73, 74, 92, 93, 95, 118, 128, 147, 152, 153], "bayesopt": 92, "bda3": 143, "befor": 96, "behavior": [33, 52], "belief": [9, 14, 30], "benchmark": 5, "beta": [13, 17], "between": [50, 159], "beyond": 61, "bia": [30, 63, 66], "bias": 63, "bibliographi": [0, 1], "binari": [65, 70, 88], "bind": [34, 99, 133], "bivari": [78, 92, 130], "blr": 34, "bma": 48, "bmm": 48, "boh": 119, "boldsymbol": [29, 85], "bonu": [94, 95], "book": [0, 56, 137, 138, 139], "bound": 72, "boundari": 65, "breakout": 41, "bridg": 73, "brief": [24, 43, 44, 56, 59, 75, 86, 133], "bring": 68, "build": [69, 75, 92], "buqey": 154, "c": [32, 85], "calcul": [35, 49, 51, 53], "call": 159, "callback": 132, "can": [19, 159], "cancel": 159, "carlo": [44, 141, 148, 153, 154, 155], "case": [4, 5, 13, 19, 41, 78, 161], "cauchi": 38, "cell": [0, 134], "central": [19, 33, 85, 130], "certain": 52, "chain": [44, 50, 68, 141, 143, 153, 154, 155, 156], "challeng": [68, 105, 153], "chang": [7, 52, 137], "characterist": [18, 22], "chart": 159, "chatgpt": [71, 129], "cheat": 138, "check": [7, 32, 43, 50, 52, 150, 154], "checklist": [0, 43], "checkpoint": [0, 3, 15, 16, 19, 22, 23, 24, 34, 47, 100], "chi": [29, 53], "choic": 93, "choos": 85, "cifar10": 76, "class": [0, 11, 17, 19, 35, 88, 123, 149, 151], "classif": [64, 65, 70, 74, 88], "classifi": [65, 69, 70, 73, 88, 93], "close": 48, "clt": 19, "cluster": 64, "cnn": [75, 76], "code": [0, 9, 65, 68, 69, 71, 129, 130, 134, 154], "coin": [9, 11, 15, 19, 25, 30], "collect": 159, "color": 0, "colorblind": 130, "combin": [77, 83], "command": 140, "comment": 94, "common": [4, 71, 152], "compa": 63, "compact": 88, "compar": [33, 35, 152], "comparison": [7, 29, 53, 135], "compil": 76, "complex": [66, 71, 73, 93], "compon": 127, "comprehens": 135, "compress": 127, "comput": [13, 51, 71, 77, 83], "concaten": 136, "concept": 130, "conda": 137, "condit": [130, 154, 156, 159, 161], "confid": [18, 19], "conjug": [13, 49], "connect": 19, "consequ": 19, "conserv": [38, 150], "continu": [4, 34, 45, 104, 130], "continuum": 25, "contrast": [19, 48], "control": 132, "converg": [44, 50, 143, 146], "convers": 136, "convert": 34, "convolut": [67, 75, 76], "cookbook": 81, "core": [78, 82], "correct": 38, "correl": [7, 35, 53, 79, 130, 146], "cost": [65, 68, 88], "could": 40, "coupl": 19, "cours": 127, "covari": [77, 78, 82, 83, 85, 127, 130], "cow": 62, "creat": [70, 76, 132, 135, 136, 137], "credibl": [14, 19, 130], "criteria": 51, "crocodil": 62, "cross": [66, 88, 95], "current": 73, "curv": [66, 97], "custom": 71, "d": [33, 159], "data": [16, 34, 37, 38, 40, 41, 49, 52, 63, 64, 65, 69, 73, 74, 76, 77, 83, 93, 96, 127, 133, 136, 137, 142, 143, 152], "dataset": [75, 76, 80, 81], "deal": 38, "debug": 134, "decis": 65, "decomposit": 125, "deep": [67, 73, 88], "default": 71, "defin": [5, 42, 123], "definit": [34, 68, 99, 130, 161], "degre": [9, 14, 30], "delta": [7, 154], "demo": [50, 84, 87], "demolit": 62, "demonstr": [6, 9, 29, 30, 69, 73, 76, 78, 82, 133, 162], "dens": 76, "densiti": [17, 23, 130, 159], "depend": [53, 78, 82, 114, 115], "derbi": 62, "deriv": [4, 68, 159], "descent": [97, 105, 106, 107], "design": [34, 100, 156], "detail": [71, 144, 154, 156, 159], "determin": [30, 43, 79, 88, 136], "develop": [69, 70], "deviat": 136, "diagnost": [44, 143, 151], "diagon": 125, "differ": [0, 5, 53, 81, 96, 150], "dimens": 154, "dimension": [64, 78, 82, 136], "dirac": 7, "discrep": [114, 115, 118, 119, 123], "discret": [3, 104, 130, 153, 156], "discuss": [8, 34, 38, 53, 130, 147, 152, 161], "displai": 132, "dissect": 127, "distanc": 7, "distribut": [4, 16, 17, 33, 34, 37, 43, 50, 71, 78, 82, 85, 86, 126, 129, 130, 145, 146, 153, 156, 159, 162], "diverg": 72, "do": [12, 19, 33, 40, 49, 69, 86, 92, 93, 95, 123, 127, 143, 145, 146, 159], "doe": [35, 52], "dof": 29, "don": [12, 75], "donut": 154, "dot": [81, 136], "download": 76, "dr": 53, "draw": [33, 86, 135], "drawn": 33, "drop": [34, 99, 121, 123], "duke": 127, "e": 159, "each": [19, 33, 53, 71, 132], "edwin": 62, "effect": 5, "eft": [49, 94], "eigendecomposit": 127, "eigenvalu": 136, "eigenvector": [45, 136], "elabor": 132, "eleg": 85, "element": 136, "elementwis": 136, "elicit": 43, "ellips": 35, "emce": [96, 123, 152, 153], "emul": [45, 47, 79, 122], "energi": [34, 52, 99, 133, 150], "ensembl": 163, "entropi": [4, 5, 88], "env": 137, "environ": 137, "epistem": 72, "epistemologi": 8, "equal": 13, "equat": [0, 34, 68, 100, 127, 150], "equilibrium": 159, "errat": 38, "error": [7, 34, 41, 63, 65, 66, 143], "estim": [0, 7, 16, 18, 36, 39, 40, 41, 53, 77, 83, 94, 96, 130, 147, 152, 153], "et": [79, 86, 143], "ethic": [63, 64], "evalu": [69, 76], "event": 130, "everi": 146, "everyth": 17, "evid": [49, 51, 52, 53, 72, 95], "evolut": 126, "exampl": [3, 23, 25, 31, 33, 34, 35, 38, 39, 40, 41, 51, 63, 65, 70, 71, 75, 77, 78, 80, 82, 92, 114, 115, 123, 130, 136, 147, 151, 154, 159, 161], "exchang": 159, "exercis": [0, 7, 11, 16, 19, 31, 32, 34, 40, 65, 66, 67, 70, 74, 77, 79, 83, 103, 114, 115, 125, 127, 130, 134, 135, 136, 144, 151, 153, 156, 161], "exp": 81, "expans": [49, 52], "expect": [24, 67, 130], "experi": [52, 123], "experiment": [43, 123], "explan": 71, "explicit": 132, "explor": [17, 18, 35, 69, 95, 96, 134], "exponenti": [4, 161], "express": [71, 88, 134, 142], "extend": 88, "extern": 0, "f": 154, "factor": 51, "failur": 5, "fair": [25, 63], "falsifi": 19, "fast": 45, "favorit": 96, "featur": [56, 88, 134], "feed": [67, 71, 129], "feedback": 67, "fft": 33, "fig": 143, "figur": [0, 37, 132, 134, 142, 146], "file": 0, "fill": 159, "final": 68, "find": [127, 136], "first": [13, 33, 65, 68, 132, 133, 152], "fit": [40, 41, 95, 133, 143], "fix": [33, 41], "flat": 13, "flip": [9, 15, 19, 156], "flop": 156, "fold": 66, "follow": [15, 18, 31, 37, 70, 77, 146], "foreman": 146, "form": [34, 127], "formal": 43, "formul": [38, 123], "forward": [67, 71, 129], "four": [43, 59], "fourier": 33, "fourth": 33, "framework": 120, "free": 80, "frequentist": [8, 11, 14, 19, 38, 53, 147, 152], "friend": 25, "from": [5, 15, 33, 71, 74, 77, 79, 83, 86, 96, 127, 136, 137, 140, 146, 151, 153, 154, 159], "frontmatt": 0, "full": [41, 75], "function": [5, 7, 13, 17, 23, 34, 40, 43, 63, 65, 68, 70, 71, 77, 78, 81, 82, 83, 85, 88, 99, 130, 132, 134, 149, 154], "further": 136, "g": 159, "galact": 7, "game": [86, 127], "gaussian": [4, 7, 17, 19, 33, 34, 35, 39, 49, 53, 77, 78, 80, 81, 82, 83, 85, 86, 126, 130, 147, 152, 161], "gelman": [44, 143, 151], "gener": [34, 64, 73, 80, 81, 93, 96, 123, 130, 132, 142, 152, 153], "get": [56, 77, 83, 131, 134, 154, 158], "github": [137, 140], "given": [77, 83], "global": 104, "goal": [94, 96, 142], "goe": [45, 46], "good": [38, 138], "gothenburg": 156, "gp": [78, 79, 82, 85, 86], "gpu": 71, "gpy": [77, 83, 84], "gpyopt": 92, "gradient": [71, 97, 105, 106, 107], "graphic": 134, "gregori": 154, "group": [3, 63], "growth": 161, "guid": [0, 56, 138], "guidelin": 63, "h_0": 41, "ha": [73, 93, 143], "hamiltonian": [44, 148], "handl": [41, 64], "happen": 159, "harmon": 19, "hast": [144, 145, 153, 154, 162], "have": 52, "hbar": [78, 82], "height": 123, "help": [7, 56, 134], "helper": [17, 81], "here": 96, "hick": 151, "hidden": 0, "higdon": 79, "high": [82, 154], "higher": [52, 159], "highli": 79, "hint": [19, 32, 34, 67], "histogram": 126, "histori": 46, "hmc": [148, 157], "hogg": 146, "how": [7, 40, 52, 71, 86, 90, 94, 96, 143, 159], "huber": 38, "hybrid": 7, "hydrogen": 159, "hyperparamet": 85, "hypothesi": 53, "i": [3, 7, 13, 17, 19, 25, 33, 39, 60, 79, 94, 156, 159], "icon": 56, "idea": 53, "ii": [4, 7, 13, 41, 55, 147], "iia": 95, "iib": [90, 96], "iii": [7, 160], "iiia": 92, "iiib": 93, "illustr": [44, 81], "imag": [75, 76, 127], "implement": [40, 66, 151, 153], "implicit": 63, "import": [5, 38, 44, 50, 73, 76, 77, 83, 92, 95, 96, 127, 130, 132, 133, 142, 144, 151], "improv": 40, "includ": [63, 127], "independ": [53, 114, 115, 130], "index": [127, 136], "indiffer": 3, "induct": 62, "infer": [0, 7, 20, 41, 43, 48, 54, 61, 62, 72, 73, 74, 85, 93, 110, 113, 153], "inferencedata": 151, "infinit": 78, "info": 86, "inform": [51, 71], "infti": 52, "ingredi": [25, 64], "initi": [71, 129], "initio": 45, "input": [77, 83, 129, 132], "insert": 0, "instal": [71, 137, 140], "integr": [33, 49, 96, 146, 153], "interactive_output": 132, "interfac": [9, 132], "interlud": 146, "interpret": 35, "interv": [9, 14, 18, 19, 30], "intial": 71, "intro": [154, 158], "introduct": [17, 57, 69, 86, 130, 151, 161], "introductori": 80, "intuit": [78, 146, 159], "invari": 3, "invers": [34, 136], "invit": 62, "ipython": 132, "ipywidget": 132, "ir": 44, "issu": 56, "iter": [46, 93, 135], "its": 5, "jayn": 62, "joint": [23, 130], "jupyt": [0, 6, 9, 56, 133, 134, 137, 138, 139, 140], "justifi": 19, "k": [65, 66, 78, 82], "kernel": [78, 81, 82, 85, 137], "knn": [65, 66], "know": [86, 138, 143], "known": 96, "koh": 119, "kraken": 132, "kullback": 72, "l": 68, "l1": 4, "label": 0, "langl": 154, "laplac": 53, "larg": [66, 117], "lasso": 66, "law": 153, "layer": [75, 76], "layout": 132, "learn": [60, 63, 64, 65, 66, 67, 68, 70, 71, 73, 74, 87, 88, 89, 93, 94, 96, 97, 137, 142], "learningfromdata": 140, "least": [34, 100], "lectur": [79, 146], "leibler": 72, "length": 136, "let": [73, 93], "lighthous": [35, 42, 142], "like": 5, "likelihood": [13, 34, 35, 38, 41, 43, 50, 88, 95], "limit": [19, 25, 33, 44, 52, 63, 67, 117, 156], "line": [3, 6, 40, 41, 90, 96, 135, 140, 143], "linear": [34, 46, 49, 52, 65, 67, 85, 98, 99, 100, 101, 102, 112, 114, 115, 127, 136], "liouvil": 149, "liquid": [34, 99], "list": [135, 136], "ll": 37, "local": 104, "locat": [3, 142], "log": [4, 19, 144], "logic": 22, "logist": [70, 74, 88], "look": [5, 24, 73, 93, 158], "lorentzian": 144, "loss": 38, "lower": 72, "m": 48, "machin": [60, 63, 64, 65, 73, 89], "mackei": 146, "macro": 0, "main": [9, 64], "major": 136, "make": [69, 71, 76, 86, 126, 132, 146, 149, 159], "mani": [38, 85, 90, 96], "manipul": [22, 127, 136], "margin": [7, 23, 25, 34, 41, 130, 146], "mark": 0, "markdown": [0, 134], "markov": [44, 141, 153, 154, 155, 156], "mass": [130, 133], "match": [46, 126], "materi": [56, 116, 131], "mathbf": [77, 83], "mathcal": [48, 86], "mathemat": [67, 71, 104, 134], "matplotlib": [17, 134], "matric": [127, 136], "matrix": [34, 67, 85, 100, 125, 127, 136, 156], "matter": 12, "mat\u00e9rn": 81, "maxent": 4, "maxim": 4, "maximum": [4, 5, 41, 88, 95, 136], "mc": 154, "mcmc": [44, 74, 96, 142, 143, 144, 145, 146, 153, 154, 159, 162], "mean": [4, 33, 35, 44, 82, 85, 130, 143], "measur": 130, "mechan": 19, "median": 130, "medic": [22, 31], "meet": 133, "melendez": 86, "memori": 156, "menu": [56, 134], "method": [27, 44, 45, 46, 53, 55, 71, 132, 153], "metropoli": [144, 145, 153, 154, 156, 159, 162], "mh": [50, 143, 154, 159], "mini": [73, 90, 91, 92, 93, 94, 95, 96, 106], "minim": [5, 88, 104, 132], "minimum": 136, "misclassif": 65, "mix": 48, "mixtur": 126, "mnist": 75, "mode": 130, "model": [3, 6, 7, 16, 27, 29, 34, 38, 40, 41, 43, 45, 48, 49, 53, 54, 64, 66, 67, 68, 69, 72, 73, 76, 77, 78, 82, 83, 85, 93, 94, 95, 98, 99, 100, 108, 110, 111, 112, 114, 115, 116, 118, 119, 121, 123, 143, 151, 161], "modul": [38, 77, 83, 92, 95, 133, 144], "moment": [5, 24, 130], "monkei": 4, "mont": [44, 141, 148, 153, 154, 155], "moor": 34, "moral": 61, "more": [25, 36, 52, 66, 88, 114, 115, 132, 138, 154], "move": 159, "movi": 126, "multi": [48, 54], "multilay": 68, "multimod": 50, "multipl": [48, 135, 136], "multivari": [34, 53, 78, 82, 86, 92, 130], "n": [5, 33, 52, 85, 86, 93, 136, 159], "n_a": 159, "n_b": 159, "n_sampl": 93, "naiv": 154, "name": 6, "ndarrai": 136, "nearest": 65, "need": [5, 37], "neighbor": 65, "net": 70, "network": [67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 93], "neural": [67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 93], "neuron": [67, 75], "new": 85, "newcommand": 29, "next": [46, 73], "nn": [66, 75], "nois": [35, 39, 80, 93, 147], "noisi": [67, 80], "non": [85, 111, 112, 114, 115], "norm": 4, "normal": [4, 17, 25, 29, 34, 53, 65, 71, 78, 82, 85, 86, 100], "notat": [64, 67, 85, 88, 109, 130, 161], "note": [0, 29, 49, 154], "notebook": [19, 79, 84, 87, 133, 134, 137, 138, 140, 151, 158], "now": [50, 71, 123, 152, 159], "nuclear": [34, 45, 99, 133], "nuisanc": [7, 38, 41], "number": [7, 130], "numer": [33, 136, 153], "numpi": [134, 135, 136], "object": [85, 151], "observ": [123, 132], "obtain": [85, 156], "occam": 7, "odd": 95, "omega": [78, 82], "one": [33, 71], "onli": [33, 132, 159], "onlin": [56, 138], "open": [48, 56], "oper": [71, 135, 136], "optic": 156, "optim": [88, 92, 97, 104, 105, 113], "option": [92, 132, 144], "orbit": 150, "order": [45, 95, 136], "ordinari": [34, 100, 101, 102], "organ": 133, "origin": [129, 152], "oscil": 19, "other": [124, 157, 159], "our": 133, "out": 159, "outlier": 38, "output": [68, 129, 132], "over": [66, 159], "overfit": 63, "overgener": 63, "overview": [55, 64, 86, 90, 91, 108, 116, 124, 131, 143, 148, 155, 158, 160], "own": [52, 70, 92], "p": [19, 159], "pair": 79, "panda": 133, "paper": 79, "par": 29, "parallel": [51, 96], "paramet": [0, 7, 16, 36, 38, 39, 40, 41, 53, 77, 83, 88, 93, 94, 96, 135, 147, 152], "parametr": [7, 85, 111], "part": [55, 83, 144, 160], "pass": 132, "pca": [125, 127], "pdf": [4, 6, 7, 17, 18, 20, 23, 37, 41, 130, 142, 144, 153], "pendulum": 149, "penros": 34, "penultim": 13, "perceptron": [65, 68, 88], "perform": 96, "permut": 3, "perspect": 58, "philosoph": 8, "physic": [60, 123, 148], "physicist": 58, "pi": 153, "pick": 150, "plausibl": 62, "plot": [5, 17, 42, 78, 82, 123, 126, 134, 135, 143, 150, 151], "plu": [92, 95], "pocomc": 123, "point": [18, 33, 130, 159], "poisson": [4, 33, 37, 145, 154, 159, 162], "polya": 62, "polynomi": [34, 95, 99, 100], "popul": 22, "possibl": [0, 11, 22, 51], "posterior": [13, 16, 17, 26, 34, 35, 42, 43, 50, 81, 123, 143, 159], "potenti": [5, 150], "power": 153, "practic": [22, 28, 34, 72, 102], "predict": [16, 34, 43, 52, 69, 73, 76, 85, 93], "preliminari": [125, 126, 127], "prelud": 34, "prepar": [37, 76], "presenc": 37, "princip": 127, "principl": [4, 22, 63], "prior": [6, 12, 13, 34, 39, 40, 43, 49, 50, 53, 79, 81, 123, 147, 152], "probabilist": [72, 73], "probabl": [2, 3, 4, 8, 17, 22, 23, 25, 31, 32, 73, 88, 93, 130, 144, 159, 161], "problem": [22, 42, 70, 74, 96, 152, 153], "proce": 94, "process": [77, 78, 80, 81, 82, 83, 85, 86, 156, 161], "product": [7, 22, 25, 32, 81, 136], "prof": 53, "program": 73, "project": [17, 90, 91, 92, 93, 94, 95, 96], "prompt": 129, "proof": [13, 19], "propag": [7, 41, 67, 68, 69], "properti": [34, 136, 159], "propos": 159, "prove": 34, "pseudo": [34, 130, 154], "pt": [50, 96], "ptemce": 96, "pukelsheim": 46, "pump": 156, "put": 96, "pymc": [151, 152, 158], "pymc3": [72, 73, 153], "pymultinest": 153, "pystan": 153, "python": [6, 9, 17, 38, 50, 64, 127, 134, 135, 138, 142], "pytorch": 71, "q": 159, "qbism": 128, "quadradt": 81, "quadrat": 35, "quadratur": 153, "qualiti": 61, "quantum": 128, "question": [0, 3, 4, 5, 12, 15, 16, 18, 19, 22, 23, 24, 31, 32, 34, 35, 41, 47, 70, 83, 85, 88, 95, 100, 144, 145, 154], "quick": [17, 130], "quot": 151, "r2": 65, "radial": 81, "radioact": [42, 142], "random": [7, 85, 130, 144, 154, 156, 159, 161], "randomli": 129, "rang": [53, 135], "rangl": 154, "rank": 136, "rate": [143, 151], "rather": 33, "ratio": [95, 159], "ration": 81, "razor": 7, "rbf": [78, 82], "read": 133, "real": 133, "reason": 62, "recal": [13, 154, 159], "recap": [49, 79, 159], "recognit": 76, "reconstruct": 5, "recurr": 67, "reduc": 45, "reduct": [45, 64, 75, 127], "refer": [0, 31, 32, 85, 128], "referenc": 0, "region": [71, 130, 144], "regress": [34, 64, 65, 66, 70, 74, 77, 78, 80, 82, 83, 85, 88, 100, 101, 102, 110, 113], "regular": [66, 75, 88], "relat": 159, "releas": 132, "remark": [0, 8, 66], "remind": 133, "remnant": 156, "remov": 136, "report": 63, "reproduc": 43, "request": 96, "requir": 63, "resampl": 44, "research": 43, "reshap": 136, "result": [5, 35, 43, 49, 151], "return": 79, "revers": 156, "review": [17, 44, 78], "revisit": [7, 143], "rewrit": 34, "rewritten": 88, "ridg": 66, "rightarrow": 52, "rmsprop": 107, "rob": 151, "root": 7, "routin": 136, "row": 136, "rubin": [44, 143, 151], "rule": [10, 19, 22, 25, 31, 32, 46, 67, 68, 142, 154], "run": [77, 137, 142, 146], "sampl": [7, 17, 18, 33, 35, 38, 44, 50, 74, 77, 78, 82, 83, 123, 144, 145, 146, 151, 152, 153, 154, 156, 159, 160, 162], "sampler": [50, 96, 123, 151, 152, 157, 163], "save": 134, "scalar": 136, "scale": [3, 73, 75, 93], "scandinavian": 4, "scienc": [7, 64, 110], "scientif": [27, 116], "scientist": 61, "scikit": [70, 74, 87], "scipi": [17, 130], "score": [65, 66], "second": [33, 132], "sect": 146, "section": [0, 18, 95, 154], "select": [34, 53, 63, 79, 95, 136], "sens": 86, "sensit": 34, "set": [6, 9, 48, 68, 74, 75, 77, 83, 123, 132, 139, 152], "setup": [123, 151], "shape": 136, "sheet": 138, "shell": [78, 82], "shortcut": 134, "should": [96, 138], "sigma": [14, 46], "sigmoid": 65, "signal": [35, 37, 67], "signific": 19, "simpl": [67, 70, 74, 132, 152, 156, 161], "sine": 81, "singl": [33, 41], "singular": 125, "sivia": 35, "size": [33, 136], "slant": 35, "slice": 163, "societi": 64, "soft": 65, "softmax": 88, "solut": [0, 7, 16, 34, 40, 65, 66, 67, 96, 103, 115, 130, 153, 156, 161], "solv": [127, 150], "some": [17, 126], "sort": 136, "sound": [0, 43], "space": 48, "spars": 136, "sparsiti": 117, "special": [19, 60, 136, 161], "specif": [73, 93], "specifi": 71, "spectral": 96, "speed": 135, "split": 136, "spot": 34, "squar": [7, 29, 34, 53, 81, 100], "standard": [7, 17, 22, 31, 38, 88, 136, 143], "start": [56, 77, 83, 131, 158], "stat": [17, 130], "state": [19, 153, 156], "statement": [21, 96, 127], "stationari": [85, 156, 159], "statist": [0, 19, 43, 46, 49, 53, 110, 123, 130, 136, 153], "step": [19, 41, 43, 59, 71, 73], "stochast": [106, 156, 161], "stori": 53, "straight": [3, 6, 40, 41, 143], "strategi": 96, "string": 134, "structur": 154, "student": [17, 126], "studi": 66, "style": 123, "sub": 70, "subtask": [94, 96], "suggest": [71, 94], "sum": [7, 22, 25, 29, 32, 33, 85], "summari": [7, 8, 24, 41, 85, 133, 159], "supervis": 67, "surfac": [73, 93], "svd": [125, 127], "switch": 71, "symmetr": [125, 159], "symmetri": 3, "system": 63, "systemat": [41, 75], "t": [12, 17, 75, 126], "tab": 132, "tabl": 35, "take": [7, 15, 25], "taken": 127, "tale": 48, "talent": 91, "target": [80, 85], "task": [70, 74, 77, 144], "tell": 71, "temper": [51, 96], "tensor": 71, "tensorflow": [69, 76], "term": [68, 159], "terminologi": 67, "test": [29, 44, 53, 92], "test_siz": 93, "text": 29, "than": 33, "theano": 73, "thei": 12, "them": 0, "theorem": [19, 22, 23, 25, 33, 149], "theori": [25, 45, 123], "thermodynam": [96, 159], "theta": 29, "thetavec": 159, "thetavec_i": 159, "thi": [25, 40, 52, 56, 71, 86, 92, 95, 138, 139, 143, 159], "thing": [40, 49, 95, 127, 129, 145], "think": [19, 159], "third": [33, 132], "those": 159, "three": [46, 64], "through": 135, "time": [146, 159], "tip": 0, "togeth": 68, "toi": [49, 94], "top": [35, 76], "topic": 124, "toss": [9, 11, 25, 30], "total": 159, "trace": 136, "tradeoff": 66, "train": [63, 65, 66, 69, 72, 76], "transform": [33, 34, 75], "translat": 3, "trend": 73, "trick": 85, "true": 49, "try": [5, 50, 129, 133], "two": [7, 33, 34, 35, 48, 50, 53, 88, 156], "type": [63, 64, 67, 130, 136], "ubiqu": 19, "ui": [9, 132], "uncertainti": [7, 72, 73, 93], "uncorrel": 4, "underfit": [63, 66], "uniform": [13, 34, 130, 153], "univari": [92, 143], "up": [6, 9, 15, 18, 31, 34, 37, 68, 70, 75, 77, 132, 139, 152], "updat": [9, 10, 30, 137], "uphil": 159, "url": 0, "us": [4, 7, 19, 22, 31, 41, 48, 49, 70, 71, 74, 75, 83, 85, 96, 127, 137, 138, 139, 140, 142, 144, 159], "user": [9, 132], "util": [71, 149], "v": [14, 136], "valid": [65, 66, 95], "valu": [19, 24, 73, 93, 96, 125, 130, 132, 136], "variabl": [7, 29, 33, 35, 71, 85, 130], "varianc": [4, 44, 66, 130, 136], "variat": [50, 72, 73, 74, 93], "vector": 67, "verbatim": 151, "verif": 71, "verifi": [18, 76, 159], "versu": [111, 112, 113, 135, 136], "via": 10, "view": [8, 34], "virtu": 61, "visual": [17, 23, 33, 148, 149, 153, 154], "volum": 75, "walk": [144, 154, 156, 159, 161], "wamb": 43, "want": 132, "warm": 34, "warmup": [34, 101], "warn": 0, "we": [5, 37, 52, 86, 143, 154, 159], "weather": 156, "websit": [71, 86], "weight": [67, 88], "well": [75, 79], "went": 159, "were": 159, "what": [5, 19, 35, 39, 46, 60, 73, 79, 93, 95, 136, 138, 146, 147, 152, 159], "when": [12, 19, 137], "why": [4, 67, 154, 159], "wide": 67, "widget": [9, 132, 134], "width": 117, "winter": 156, "without": 123, "workflow": [34, 43, 59], "would": 159, "x": [7, 77, 83], "x_0": 42, "x_a": 159, "x_b": 159, "y": 7, "yet": 5, "you": [19, 49, 56, 132, 138, 146, 159], "your": [52, 70, 92, 96, 137], "yourself": 133, "z": 7, "z_j": 68, "zero": 136, "zeu": [50, 152, 163]}})